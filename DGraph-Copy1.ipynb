{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e67f255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "from itertools import product\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as ss\n",
    "import scipy.sparse.linalg as sl\n",
    "import scipy.spatial\n",
    "from scipy.linalg import sqrtm\n",
    "from scipy.sparse import csr_matrix, csc_matrix, coo_matrix\n",
    "#from scipy.stats import ortho_group\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "import torch_scatter as ts\n",
    "from torch_sparse import SparseTensor\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import DGraphFin\n",
    "from torch_geometric.nn import GCNConv\n",
    "#from torch_geometric.transforms import LargestConnectedComponents\n",
    "from torch_geometric.typing import SparseTensor\n",
    "from torch_geometric.utils import (\n",
    "    to_undirected, \n",
    "    to_networkx, \n",
    "    from_networkx, \n",
    "    one_hot, \n",
    "    to_scipy_sparse_matrix\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    confusion_matrix, \n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    roc_auc_score, \n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "#from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import geotorch\n",
    "#import networkx as nx\n",
    "#import umap.umap_ as umap\n",
    "#import streamlit as st\n",
    "\n",
    "import autograd.numpy as anp\n",
    "#import pymanopt\n",
    "#import pymanopt.manifolds\n",
    "#import pymanopt.optimizers\n",
    "##from pymanopt.manifolds import (\n",
    "  #  Euclidean, \n",
    "   # Product, \n",
    "   # SpecialOrthogonalGroup,  \n",
    "   # Stiefel\n",
    "#)\n",
    "#from pymanopt.optimizers import SteepestDescent\n",
    "\n",
    "import local2global as l2g\n",
    "import local2global.example as ex\n",
    "import local2global_embedding\n",
    "from local2global import Patch\n",
    "from local2global_embedding.patches import create_patch_data\n",
    "from local2global_embedding.clustering import (\n",
    "    louvain_clustering, \n",
    "    metis_clustering, \n",
    "    fennel_clustering, \n",
    "    distributed_clustering\n",
    ")\n",
    "from local2global_embedding.network import TGraph, tgraph\n",
    "\n",
    "#import raphtory as rp\n",
    "#from raphtory import Graph as rgraph\n",
    "\n",
    "\n",
    "from utils.utils import prepare_folder\n",
    "from utils.evaluator import Evaluator\n",
    "from models import MLP, MLPLinear, GCN, SAGE, GAT, GATv2\n",
    "from logger import Logger\n",
    "\n",
    "# Jupyter Notebook Extensions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ad5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersections_nodes(patches):\n",
    "    double_intersections=dict()\n",
    "    for i in range(len(patches)):\n",
    "        for j in range(i+1, len(patches)):\n",
    "            double_intersections[(i,j)]=list(set(patches[i].nodes.tolist()).intersection(set(patches[j].nodes.tolist())))\n",
    "    return double_intersections\n",
    "\n",
    "\n",
    "\n",
    "def connected_components(data: tg.data.Data):\n",
    "    \"\"\"Find the (weakly)-connected components of graph data. Components are sorted by size, such that id=0 corresponds\n",
    "     to the largest connected component\"\"\"\n",
    "    edge_index = data.edge_index\n",
    "    is_undir = tg.utils.is_undirected(edge_index)\n",
    "    last_components = torch.full((data.num_nodes,), data.num_nodes, dtype=torch.long)\n",
    "    components = torch.arange(data.num_nodes, dtype=torch.long)\n",
    "    while not torch.equal(last_components, components):\n",
    "        last_components[:] = components\n",
    "        components = ts.scatter(last_components[edge_index[0]], edge_index[1], out=components, reduce='min')\n",
    "        if not is_undir:\n",
    "            components = ts.scatter(last_components[edge_index[1]], edge_index[0], out=components, reduce='min')\n",
    "    component_id, inverse, component_size = torch.unique(components, return_counts=True, return_inverse=True)\n",
    "    new_id = torch.argsort(component_size, descending=True)\n",
    "    return new_id[inverse]\n",
    "\n",
    "\n",
    "def largest_connected_component(data: tg.data.Data):\n",
    "    \"\"\"find largest connected component of data\"\"\"\n",
    "    components = connected_components(data)\n",
    "    nodes = torch.nonzero(components == 0).flatten()\n",
    "    return induced_subgraph(data, nodes)\n",
    "\n",
    "\n",
    "def induced_subgraph(data: tg.data.Data, nodes, extend_hops=0):\n",
    "    nodes = torch.as_tensor(nodes, dtype=torch.long)\n",
    "    if extend_hops > 0:\n",
    "        nodes, edge_index, node_map, edge_mask = tg.utils.k_hop_subgraph(nodes, num_hops=extend_hops,\n",
    "                                                                         edge_index=data.edge_index,\n",
    "                                                                         relabel_nodes=True)\n",
    "        edge_attr = data.edge_attr[edge_mask, :] if data.edge_attr is not None else None\n",
    "    else:\n",
    "        edge_index, edge_attr = tg.utils.subgraph(nodes, data.edge_index, data.edge_attr, relabel_nodes=True)\n",
    "\n",
    "    subgraph = tg.data.Data(edge_index=edge_index, edge_attr=edge_attr)\n",
    "    for key, value in data.__dict__.items():\n",
    "        if not key.startswith('edge'):\n",
    "            if hasattr(value, 'shape') and value.shape[0] == data.num_nodes:\n",
    "                setattr(subgraph, key, value[nodes])\n",
    "            else:\n",
    "                setattr(subgraph, key, value)\n",
    "    subgraph.nodes = nodes\n",
    "    subgraph.num_nodes = len(nodes)\n",
    "    return subgraph\n",
    "\n",
    "\n",
    "def conductance(graph: TGraph, source, target=None):\n",
    "    if target is None:\n",
    "        target_mask = torch.ones(graph.num_nodes, dtype=torch.bool, device=graph.device)\n",
    "        target_mask[source] = False\n",
    "    else:\n",
    "        target_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n",
    "        target_mask[target] = True\n",
    "    out = torch.cat([graph.adj(node) for node in source])\n",
    "    cond = torch.sum(target_mask[out]).float()\n",
    "    s_deg = graph.degree[source].sum()\n",
    "    t_deg = graph.num_edges-s_deg if target is None else graph.degree[target].sum()\n",
    "    cond /= torch.minimum(s_deg, t_deg)\n",
    "    return cond\n",
    "\n",
    "\n",
    "def speye(n, dtype=torch.float):\n",
    "    \"\"\"identity matrix of dimension n as sparse_coo_tensor.\"\"\"\n",
    "    return torch.sparse_coo_tensor(torch.tile(torch.arange(n, dtype=torch.long), (2, 1)),\n",
    "                                   torch.ones(n, dtype=dtype),\n",
    "                                   (n, n))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_patches(data, model, loss_fun, num_epochs=100, verbose=True, lr=0.01, logger=lambda loss: None):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    # schedule = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "    for e in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fun(model, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        logger(float(loss))\n",
    "        if verbose:\n",
    "            print(f'epoch {e}: loss={loss.item()}')\n",
    "        # schedule.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def GAE_patch_embeddings(patch_data, dim=2, hidden_dim=32, num_epochs=100, device='cpu', decoder=None, lr=0.01):\n",
    "    patch_list = []\n",
    "    models = []\n",
    "    for patch in patch_data:\n",
    "        if patch.x is None:\n",
    "            patch.x = speye(patch.num_nodes)\n",
    "        print(f\"training patch with {patch.edge_index.shape[1]} edges\")\n",
    "        model = tg.nn.GAE(encoder=GAEconv(dim, patch.x.shape[1], hidden_dim=hidden_dim), decoder=decoder).to(device)\n",
    "        patch.to(device)\n",
    "\n",
    "        def loss_fun(model, data):\n",
    "            return model.recon_loss(model.encode(data), data.edge_index)\n",
    "        model.train()\n",
    "        model = train_patches(patch, model, loss_fun, num_epochs=num_epochs, lr=lr)\n",
    "        model.eval()\n",
    "        coordinates = model.encode(patch).to('cpu').data.numpy()\n",
    "        patch.to('cpu')\n",
    "        models.append(model)\n",
    "        patch_list.append(l2g.Patch(patch.nodes.numpy(), coordinates))\n",
    "    return patch_list, models\n",
    "\n",
    "\n",
    "def intersections_nodes(patches):\n",
    "    intersections = dict()\n",
    "    for i in range(len(patches)):\n",
    "        for j in range(i+1, len(patches)):\n",
    "           intersections[(i,j)]=list(set(patches[i].nodes.tolist()).intersection(set(patches[j].nodes.tolist())))\n",
    "    return intersections\n",
    "\n",
    "def preprocess_graphs(list_of_patches, nodes_dict):\n",
    "    emb_list = []\n",
    "    for i in range(len(list_of_patches)-1):\n",
    "        emb_list.append([torch.tensor(list_of_patches[i].get_coordinates(list(nodes_dict[i,i+1]))),\n",
    "                         torch.tensor(list_of_patches[i+1].get_coordinates(list(nodes_dict[i,i+1])))])\n",
    "    emb_list = list(itertools.chain.from_iterable(emb_list))\n",
    "    return emb_list    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#TO ADD HYPERPARAMETERS TUNING ( LEARNING RATE & NUM_EPOCHS) WITH GRID SEARCH\n",
    "def prepare_test(test_data, min_overlap=100, target_overlap=200):\n",
    "\n",
    "    TG=TGraph(edge_index=test_data.edge_index, edge_attr=test_data.edge_attr,  num_nodes=test_data.num_nodes, ensure_sorted=True, undir=False)\n",
    "    pt, pgraph= create_patch_data(TG, partition_tensor= louvain_clustering(TG),\n",
    "                                           min_overlap=min_overlap, target_overlap=target_overlap, verbose=True)\n",
    "    patch_data = [induced_subgraph(test_data, p) for p in pt]\n",
    "    \n",
    "    neg_edges = tg.utils.negative_sampling(test_data.edge_index, num_nodes=test_data.num_nodes)\n",
    "    return patch_data, neg_edges\n",
    "\n",
    "\n",
    "def test_new_emb(test_data, dimensions, patches, neg_edges, device='cpu'):\n",
    "    \n",
    "    \n",
    "    nodes = intersections_nodes(patches)\n",
    "    n_patches=len(patches)\n",
    "    \n",
    "    AUC=[]\n",
    "    AP=[]\n",
    "    Loss=[]\n",
    "    PATCHES=[]\n",
    "    new_emb=[]\n",
    "    for dim in tqdm(dimensions):\n",
    "        patches_emb, _ =VGAE_patch_embeddings(patches, dim=dim, num_epochs=50, device=device)\n",
    "        PATCHES.append(patches_emb)\n",
    "        emb_patches = preprocess_graphs(patches_emb, nodes)\n",
    "        print('New Alignment')\n",
    "        res, loss_hist= train_model(emb_patches, dim, n_patches ,device=device, num_epochs=50, learning_rate=0.5, verbose=False)\n",
    "        print('Get new embedding & Statistics')\n",
    "        emb=get_embedding(patches_emb, res)\n",
    "        new_emb.append(emb)\n",
    "        full_model_ip = tg.nn.VGAE(encoder=VGAEconv(dim, test_data.num_node_features))\n",
    "        auc, ap = full_model_ip.test(torch.tensor(emb), test_data.edge_index, neg_edges)\n",
    "        AUC.append(auc)\n",
    "        AP.append(ap)\n",
    "        Loss.append(loss_hist)\n",
    "\n",
    "    test_results={'AUC': AUC, 'AP': AP, 'Losses_hist': Loss}\n",
    "    \n",
    "\n",
    "    return test_results, PATCHES, new_emb, neg_edges\n",
    "\n",
    "\n",
    "def test_old_emb(list_patches_emb, test_data, neg_edges, dimensions):\n",
    "\n",
    "    \n",
    "    OLD_AUC=[]\n",
    "    OLD_AP=[]\n",
    "    old_emb=[]\n",
    "    for i in tqdm(range(len(list_patches_emb))):\n",
    "        prob=l2g.AlignmentProblem(list_patches_emb[i])\n",
    "        e=prob.get_aligned_embedding()\n",
    "        old_emb.append(e)\n",
    "        full_model_ip = tg.nn.VGAE(encoder=VGAEconv(dimensions[i], test_data.num_node_features))\n",
    "        auc, ap= full_model_ip.test(torch.tensor(e), test_data.edge_index, neg_edges)\n",
    "        OLD_AUC.append(auc)\n",
    "        OLD_AP.append(ap)\n",
    "    test_results={'AUC': OLD_AUC, 'AP': OLD_AP}\n",
    "\n",
    "    return test_results, old_emb\n",
    "\n",
    "def test_new_vs_old(test_data, dimensions, patches, neg_edges, device='cpu'):\n",
    "    print('Testing new algorithm')\n",
    "    test_results_new, list_patch_emb, new_emb, neg_edges= test_new_emb(test_data, dimensions, patches, neg_edges, device=device)\n",
    "    print('Testing old algorithm')\n",
    "    test_results_old, old_emb=test_old_emb(list_patch_emb, test_data, neg_edges, dimensions)\n",
    "    \n",
    "    \n",
    "    print('Computing the error')\n",
    "    ERR=[]\n",
    "    for i in range(len(dimensions)):\n",
    "        _, _, error = procrustes(new_emb[i], old_emb[i])\n",
    "        ERR.append(error)\n",
    "\n",
    "    \n",
    "\n",
    "    return test_results_new, test_results_old, ERR, new_emb, old_emb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_patch_embeddings(patch_data,model, dim, device):\n",
    "    patch_list = []\n",
    "   \n",
    "    for i, patch in enumerate(patch_data):\n",
    "        print(i)\n",
    "\n",
    "        patch.to(device)\n",
    "        coordinates = model(patch.x, patch.edge_index).to('cpu').data.numpy()\n",
    "        patch.to('cpu')\n",
    "       \n",
    "        patch_list.append(l2g.Patch(patch.nodes.numpy(), coordinates))\n",
    "    return patch_list\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====== Graph Autoencoder (GAE) Model ======\n",
    "\n",
    "class GAEconv(torch.nn.Module):\n",
    "    def __init__(self, dim, num_node_features, hidden_dim=32, cached=True, bias=True, add_self_loops=True, normalize=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = tg.nn.GCNConv(num_node_features, hidden_dim, cached=cached, bias=bias, add_self_loops=add_self_loops, normalize=normalize)\n",
    "        self.conv2 = tg.nn.GCNConv(hidden_dim, dim, cached=cached, bias=bias, add_self_loops=add_self_loops, normalize=normalize)\n",
    "\n",
    "    def forward(self, data):\n",
    "        edge_index = data.edge_index\n",
    "        x = F.log_softmax(self.conv1(data.x, edge_index))\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "def GAE_patch_embeddings_no_train(patch_data, dim=2, hidden_dim=32, device='cpu', decoder=None):\n",
    "    patch_list = []\n",
    "    models = []\n",
    "    for patch in patch_data:\n",
    "        if patch.x is None:\n",
    "            patch.x = torch.eye(patch.num_nodes)\n",
    "        model = tg.nn.GAE(encoder=GAEconv(dim, patch.x.shape[1], hidden_dim=hidden_dim), decoder=decoder).to(device)\n",
    "        model.eval()\n",
    "        patch.to(device)\n",
    "        coordinates = model.encode(patch).to('cpu').data.numpy()\n",
    "        patch.to('cpu')\n",
    "        models.append(model)\n",
    "        patch_list.append(l2g.Patch(patch.nodes.numpy(), coordinates))\n",
    "    return patch_list, models\n",
    "\n",
    "# ====== Alignment Model ======\n",
    "\n",
    "class Alignment_Model(nn.Module):\n",
    "    def __init__(self, dim, n_patches, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.transformation = nn.ParameterList([nn.Linear(dim, dim).to(device) for _ in range(n_patches)])\n",
    "        [geotorch.orthogonal(self.transformation[i], 'weight') for i in range(n_patches)]\n",
    "        \n",
    "    \n",
    "    def forward(self, patch_emb):\n",
    "        m = len(patch_emb)\n",
    "        transformations = [self.transformation[0]] + [item for i in range(1, len(self.transformation)-1) for item in (self.transformation[i], self.transformation[i])] + [self.transformation[-1]]\n",
    "        transformed_emb = [transformations[i](patch_emb[i]) for i in range(m)]\n",
    "        return transformed_emb\n",
    "\n",
    "def alignment_loss_function(transformed_emb):\n",
    "    m = len(transformed_emb)\n",
    "    diff = [transformed_emb[i] - transformed_emb[i+1] for i in range(0, m-1, 2)]\n",
    "    loss = sum([torch.norm(d) ** 2 for d in diff])\n",
    "    return loss\n",
    "\n",
    "def alignment_train_model(patch_emb, dim, n_patches, device='cpu', num_epochs=10, learning_rate=0.05):\n",
    "    patch_emb = [p.to(device) for p in patch_emb]\n",
    "    model = Alignment_Model(dim, n_patches, device).to(device)\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_hist = []\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        transformed_patch_emb = model(patch_emb)\n",
    "        loss = alignment_loss_function(transformed_patch_emb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_hist.append(loss.item())\n",
    "    \n",
    "    return model, loss_hist\n",
    "\n",
    "def alignment_eval_model(patch_emb, dim, n_patches, device):\n",
    "    patch_emb = [p.to(device) for p in patch_emb]\n",
    "    model = Alignment_Model(dim, n_patches, device).to(device)\n",
    "    model.eval()  # Keep evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # Prevents gradients from being computed\n",
    "        transformed_patch_emb = model(patch_emb)\n",
    "        loss = alignment_loss_function(transformed_patch_emb)\n",
    "\n",
    "    return model, loss.item()  # No training, so return final loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_embedding(patches, result):\n",
    "    n = len(patches)\n",
    "    rot = [result.transformation[i].weight.to('cpu').detach().numpy() for i in range(n)]\n",
    "    shift = [result.transformation[i].bias.to('cpu').detach().numpy() for i in range(n)]\n",
    "    emb_problem = l2g.AlignmentProblem(patches)\n",
    "    embedding = np.empty((emb_problem.n_nodes, emb_problem.dim))\n",
    "    \n",
    "    for node, patch_list in enumerate(emb_problem.patch_index):\n",
    "        embedding[node] = np.mean([emb_problem.patches[p].get_coordinate(node) @ rot[i] + shift[i] for i, p in enumerate(patch_list)], axis=0)\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "def get_aligned_emb_from_patches(patches, nodes, dim, train, eval_):\n",
    "    emb_patches = preprocess_graphs(patches, nodes)\n",
    "    n_patches = len(patches)\n",
    "    if train:\n",
    "        res, _ = alignment_train_model(emb_patches, dim, n_patches, device=device, num_epochs=50, learning_rate=0.05)\n",
    "        emb = torch.tensor(get_embedding(patches, res))\n",
    "    if eval_:\n",
    "        res, _ = alignment_eval_model(emb_patches, dim, n_patches, device=device)#, num_epochs=10, learning_rate=0.05)\n",
    "        emb = torch.tensor(get_embedding(patches, res))\n",
    "    return emb\n",
    "\n",
    "# ====== Training, Validation, and Testing Functions ======\n",
    "\n",
    "def train_tot_model(patches, data, nodes, model, reducer, dim, device, optimizer, epochs=50):\n",
    "    model.train()\n",
    "    reducer.train()\n",
    "    loss_hist = []\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute patch embeddings\n",
    "        patch_embeddings, _ = GAE_patch_embeddings_no_train(patches, dim=dim, hidden_dim=32, \n",
    "                                                            device=device, decoder=None)\n",
    "        \n",
    "        # Get full graph embedding\n",
    "        full_graph_embedding = get_aligned_emb_from_patches(patch_embeddings, nodes, dim,\n",
    "                                                            train=True, eval_=False).to(device).float()\n",
    "\n",
    "        # Reduce embedding dimension\n",
    "        reduced_embedding = reducer(full_graph_embedding, data.edge_index.to(device))\n",
    "\n",
    "        # Compute loss using node labels\n",
    "        loss = F.nll_loss(reduced_embedding[data.train_mask], data.y[data.train_mask].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_hist.append(loss.item())\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "    \n",
    "    return loss_hist\n",
    "\n",
    "def validate_tot_model(patches, data, nodes, model, reducer, dim, device):\n",
    "    model.eval()\n",
    "    reducer.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        patch_embeddings, _ = GAE_patch_embeddings_no_train(patches, dim=dim, hidden_dim=32, \n",
    "                                                            device=device, decoder=None)\n",
    "        full_graph_embedding = get_aligned_emb_from_patches(patch_embeddings, nodes, dim,\n",
    "                                                           train=False,\n",
    "                                                           eval_=True).to(device).float()\n",
    "        reduced_embedding = reducer(full_graph_embedding, data.edge_index.to(device))\n",
    "        \n",
    "        loss = F.nll_loss(reduced_embedding[data.val_mask], data.y[data.val_mask].to(device))\n",
    "        val_mask = data.val_mask.to(device)\n",
    "        y_val = data.y.to(device)\n",
    "        accuracy = (reduced_embedding[val_mask].argmax(dim=1) ==y_val[val_mask]).float().mean().item()\n",
    "    \n",
    "    return loss.item(), accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_model(patches, data, nodes, model, reducer, dim, device):\n",
    "    model.eval()\n",
    "    reducer.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        patch_embeddings, _ = GAE_patch_embeddings_no_train(patches, dim=dim, hidden_dim=32, device=device, decoder=None)\n",
    "        full_graph_embedding = get_aligned_emb_from_patches(patch_embeddings, nodes, dim,\n",
    "                                                           train=False,\n",
    "                                                           eval_=True).to(device).float()\n",
    "        reduced_embedding = reducer(full_graph_embedding, data.edge_index.to(device))\n",
    "        \n",
    "        loss = F.nll_loss(reduced_embedding[data.test_mask], data.y[data.test_mask].to(device))\n",
    "        test_mask = data.test_mask.to(device)\n",
    "        y_val = data.y.to(device)\n",
    "        accuracy = (reduced_embedding[test_mask].argmax(dim=1) == y_val[test_mask]).float().mean().item()\n",
    "    \n",
    "    return loss.item(), accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_tot_model(patches, data, nodes, model, reducer, dim, device):\n",
    "    model.eval()\n",
    "    reducer.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get embeddings\n",
    "        patch_embeddings, _ = GAE_patch_embeddings_no_train(patches, dim=dim, hidden_dim=32, device=device, decoder=None)\n",
    "        full_graph_embedding = get_aligned_emb_from_patches(patch_embeddings, nodes, dim, train=False, eval_=True).to(device).float()\n",
    "        reduced_embedding = reducer(full_graph_embedding, data.edge_index.to(device))\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.nll_loss(reduced_embedding[data.test_mask], data.y[data.test_mask].to(device))\n",
    "        test_mask = data.test_mask #.to(device)\n",
    "        y_val = data.y.to(device)\n",
    "        # Get predictions\n",
    "        #test_mask = data.test_mask.to(device)\n",
    "        y_true = data.y[test_mask].cpu().numpy()\n",
    "        y_pred = reduced_embedding[test_mask].argmax(dim=1).cpu().numpy()\n",
    "        \n",
    "        # Compute metrics\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "        auc = roc_auc_score(y_true, y_pred) if len(set(y_true)) == 2 else \"N/A\"  # Only for binary classification\n",
    "        \n",
    "        print(f\"Test Loss: {loss.item()}\")\n",
    "        print(f\"Test Accuracy: {acc}\")\n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F1-score: {f1}\")\n",
    "        print(f\"ROC-AUC: {auc}\")\n",
    "\n",
    "    return loss.item(), acc, precision, recall, f1, auc\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d86e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79940ccbb4f4eb999c416acbdb16b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3700550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, not converged: 3700550\n",
      "number of patches: 10\n",
      "average patch degree: 3.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f7ab5f570e4404b40301e90ed7b8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "enlarging patch overlaps:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = DGraphFin(root='./dataset')\n",
    "data = dataset[0]\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device='cpu'\n",
    "\n",
    "nodes=torch.concat((data.edge_index[0,:],data.edge_index[1,:])).unique()\n",
    "\n",
    "data.nodes=nodes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TG=TGraph(edge_index=data.edge_index,  num_nodes=data.num_nodes, x=data.x, ensure_sorted=True, undir=False)\n",
    "partition_tensor=fennel_clustering(TG,400  )\n",
    "pt, pgraph= create_patch_data(TG, partition_tensor= partition_tensor,\n",
    "                                           min_overlap=200000, target_overlap=500000, verbose=True)\n",
    "\n",
    "patch_data = [induced_subgraph(data, p) for p in pt]\n",
    "#neg_edges = tg.utils.negative_sampling(data.edge_index, num_nodes=data.num_nodes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for p in patch_data:\n",
    "    p.y=data.y[p.nodes]\n",
    "    p.x=data.x[p.nodes]\n",
    "    #p.nodes=torch.concat((p.edge_index[0,:], p.edge_index[1,:])).unique().sort()[0]\n",
    "    labels=p.y\n",
    "    p.num_nodes=p.nodes.size()[0]\n",
    "    \n",
    "    p.train_mask=data.train_mask[p.nodes]\n",
    "    p.valid_mask=data.val_mask[p.nodes]\n",
    "    p.test_mask=data.test_mask[p.nodes]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data.adj_t = SparseTensor(row=data.edge_index[0], col=data.edge_index[1], sparse_sizes=(data.num_nodes, data.num_nodes))\n",
    "data.adj_t = data.adj_t.to_symmetric()  # Make it symmetric efficiently\n",
    "\n",
    "\n",
    "\n",
    "for p in patch_data:\n",
    "    p.adj_t = SparseTensor(row=p.edge_index[0], col=p.edge_index[1], sparse_sizes=(p.num_nodes, p.num_nodes))\n",
    "    p.adj_t = p.adj_t.to_symmetric()  # Make it symmetric efficiently\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a57fc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789591728dfd4409a5f008940c715231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_272950/1677825295.py:346: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.log_softmax(self.conv1(data.x, edge_index))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9653268cf6d8486aaf1f779e884a2cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.9248353242874146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b524837800074fe9be1167bcb1b45dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9f3ecc182649e4b1684502ac4e52e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0696cd0e61947c2ac2b768a8890a0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d907c6c3d146cf92660ee7c7d8d135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af343f5f69842b4ad61ecddcd06d85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013d1d590085436d8ff95cdc9753ad82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede8e0f6cb4d4acd9f1f484242f53288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c908279889481cbcf1d1143f3b2890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614354192c114305a0977bdacc9dea0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b6179864c84166884765e2642259ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.11027222871780396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e47c0d499d4c2182196b6e28489487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf3f9bb6345485bb9480c1cbf268deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83614b35b6b943bcb229eb39d59e39a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c08209be494666bb23da9a41677c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f71b90430dd44e483007cb39577e498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db31ae35cfb54ba3bfd9d9179836b66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000da0474f274955a3d155a5e937557a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9198360482f44c5acf7ac580ef60f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f41653d5fab434bac74836817413cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64a83e9252d4304b5f72928611ade5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.1307126134634018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66faf666a76e463ba043959b239b6165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b6ca051b6749ecad18942f587fa902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f6686b75e64abab350a699b62e9392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea21fd7755434317b8bf6e7e1a43ded6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e95734a99f4189a2d189cd62b83b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5fd0c9a4ff4d0f8fca5cb68679ecce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c08dfbad6d4e0c80f6dba928f68cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca38952c18ce4e74a3070dd114fe8a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6922cbd304244e5fb904a24fd80b2ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e6bbd053e94f4c9de511f81b847605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 0.12313489615917206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee278b43a704440980394825693c57e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5372ca569cb4437fa89cedf2e6115b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b071cb13b1af472ababe134e642b3042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1bdc4b0bfa42c7b4859c4a37fa1e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc52a212ee6349f6b53f35b8661ced9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a140cb13be84c579939b1888a38a3bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e02168e96544afb5427bcb32236542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7470f0adb61544e4af617d3e895ac8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8b8a117ea14b06b285b6b7b787fb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e71bbc96964ce29b1b0211d93ce7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 0.10678329318761826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7ef85bd49c4b888530bff34b917aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f0951ae9b24d279d29b6fde860f0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bb23e513dd4281be1e1447f3580b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb6c1c3494441b7979b27a03c8ca853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33df8cf788684d97931baba9f2fbd839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b710955b46f048b5bbd85cf786732a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc3dfdfdf2943abadc3e6e528ad73ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8cc9e4816d498f99e89e53315ff35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b91d3e348048a3a2d7fbb3526fcc62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ed7e0f992f4d37b3b407f29d2a8fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.09226977825164795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1178b7b543ef41618c1519014d1a272d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9c61dc652b47deb205012933433211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6e8ee3f8a74a4eadf683d6c71d3e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5408c2d416134cdeafed1a057ec5c111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e73c6a94124edcabb2cf55fd668a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16ff209094c467691d053c72a6324de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8b50b339844781abb8c5b194159108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ee179fca0b441fadf1f68f7e71b4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5bf2e372dd4df08370f27947d6fe58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.08831328898668289, Accuracy: 0.9873491525650024\n",
      "Test Loss: 0.10296610742807388\n",
      "Test Accuracy: 0.9873476936466492\n",
      "Precision: 0.9748554681493575, Recall: 0.9873476936466492, F1-score: 0.9810618154698068\n",
      "ROC-AUC: 0.5\n",
      "Test Loss: 0.10296610742807388, Accuracy: 0.9873476936466492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maths/marmlv/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs=60\n",
    "\n",
    "\n",
    "patches=patch_data\n",
    "dim=128\n",
    "\n",
    "nodes=intersections_nodes(patches)\n",
    "\n",
    "device = torch.device( \"cuda\")\n",
    "\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "gcn_model = GCN(in_channels=17, out_channels=dim, hidden_channels=dim, num_layers=2, dropout=0.0).to(device)\n",
    "dim_reducer = GCN(in_channels=dim, out_channels=2, hidden_channels=dim, num_layers=2, dropout=0.0).to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(list(gcn_model.parameters()) + list(dim_reducer.parameters()), lr=0.01)\n",
    "\n",
    "# Train\n",
    "loss_history = train_tot_model(patches, data, nodes, gcn_model, dim_reducer, dim=dim, \n",
    "                               device=device, optimizer=optimizer, epochs=num_epochs)\n",
    "\n",
    "# Validate\n",
    "val_loss, val_acc = validate_tot_model(patches, data, nodes, gcn_model, dim_reducer, dim=dim, device=device)\n",
    "print(f\"Validation Loss: {val_loss}, Accuracy: {val_acc}\")\n",
    "\n",
    "# Test\n",
    "test_loss, test_acc, precision, recall, f1, auc = test_tot_model(patches, data, nodes, \n",
    "                                                                 gcn_model, dim_reducer, dim=dim, device=device)\n",
    "print(f\"Test Loss: {test_loss}, Accuracy: {test_acc}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d55806f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.08831328898668289, Validation Accuracy: 0.9873491525650024\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d97170e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.10296610742807388, Test Accuracy: 0.9873476936466492, Precision: 0.9748554681493575, Recall: 0.9873476936466492, f1_score: 0.9810618154698068, AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_acc}, Precision: {precision}, Recall: {recall}, f1_score: {f1}, AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "236c21d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f85a118ebf0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fbb0bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08732563257217407"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e9ee0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
