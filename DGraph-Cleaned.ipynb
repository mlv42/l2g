{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b67977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from dask import delayed\n",
    "from runpy import run_path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import umap.umap_ as umap\n",
    "import streamlit as st\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import local2global as l2g # ADDED\n",
    "\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.transforms import LargestConnectedComponents\n",
    "from torch_geometric.utils import to_networkx, from_networkx, one_hot\n",
    "#from torch_geometric.nn import Node2Vec, GCNConv, VGAE\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import local2global as l2g\n",
    "import local2global.example as ex\n",
    "from scipy.stats import ortho_group \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import local2global as l2g\n",
    "import local2global.example as ex\n",
    "import local2global_embedding\n",
    "from scipy.stats import ortho_group \n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.sparse import csr_matrix, csc_matrix, coo_matrix\n",
    "import random\n",
    "#import manopt_optimization as moptim\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric as tg\n",
    "from local2global_embedding.network import tgraph\n",
    "from local2global_embedding.patches import create_patch_data\n",
    "from local2global_embedding.clustering import louvain_clustering, metis_clustering\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import local2global as l2g\n",
    "import local2global.example as ex\n",
    "import local2global_embedding\n",
    "\n",
    "\n",
    "import torch_geometric as tg\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "import torch_scatter as ts\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from scipy.linalg import sqrtm\n",
    "from scipy.sparse import diags\n",
    "\n",
    "\n",
    "import scipy.sparse as ss\n",
    "import scipy.sparse.linalg as sl\n",
    "\n",
    "from local2global import Patch\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "\n",
    "import autograd.numpy as anp\n",
    "import pymanopt\n",
    "import pymanopt.manifolds\n",
    "import pymanopt.optimizers\n",
    "import random\n",
    "import local2global as l2g\n",
    "import local2global.example as ex\n",
    "import numpy as np\n",
    "from pymanopt.manifolds import Stiefel, Euclidean,SpecialOrthogonalGroup,  Product\n",
    "from pymanopt.optimizers import SteepestDescent\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from itertools import chain\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.max_open_warning'] = 0\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import embedding as emb\n",
    "import torch_geometric as tg\n",
    "import local2global as l2g\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "#ADDED\n",
    "#import patches as pt\n",
    "#import network as ntw \n",
    "import autograd.numpy as anp\n",
    "import pymanopt\n",
    "import pymanopt.manifolds\n",
    "import pymanopt.optimizers\n",
    "import random\n",
    "import local2global as l2g\n",
    "import local2global.example as ex\n",
    "import numpy as np\n",
    "\n",
    "def double_intersections_nodes(patches):\n",
    "    double_intersections=dict()\n",
    "    for i in range(len(patches)):\n",
    "        for j in range(i+1, len(patches)):\n",
    "            double_intersections[(i,j)]=list(set(patches[i].nodes.tolist()).intersection(set(patches[j].nodes.tolist())))\n",
    "    return double_intersections\n",
    "    \n",
    "import itertools\n",
    "\n",
    "\n",
    "#import patches as pt\n",
    "#import network as ntw \n",
    "import numpy as np\n",
    "import geotorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import local2global as l2g\n",
    "\n",
    "\n",
    "import local2global.example as ex\n",
    "import local2global_embedding\n",
    "from scipy.stats import ortho_group \n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.sparse import csr_matrix, csc_matrix, coo_matrix\n",
    "import random\n",
    "#import manopt_optimization as moptim\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric as tg\n",
    "from local2global_embedding.network import tgraph\n",
    "from local2global_embedding.patches import create_patch_data\n",
    "from local2global_embedding.clustering import louvain_clustering\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.sparse as ss\n",
    "import scipy.sparse.linalg as sl\n",
    "\n",
    "import raphtory as rp\n",
    "from raphtory import Graph as rgraph\n",
    "\n",
    "\n",
    "from local2global_embedding.patches import create_patch_data\n",
    "from local2global_embedding.clustering import louvain_clustering, fennel_clustering, distributed_clustering\n",
    "import local2global as l2g\n",
    "\n",
    "import local2global_embedding\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "\n",
    "#from Local2Global_embedding.local2global_embedding import  clustering\n",
    "import community\n",
    "#from Local2Global_embedding.local2global_embedding.network import graph\n",
    "from local2global_embedding.network import TGraph\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "\n",
    "from local2global import Patch\n",
    "#import Local2Global_embedding.local2global_embedding.embedding.svd as svd\n",
    "#import Local2Global_embedding.local2global_embedding.embedding.gae as gae\n",
    "#import Local2Global_embedding.local2global_embedding.patches as patches\n",
    "\n",
    "\n",
    "import torch_geometric as tg\n",
    "import torch_scatter as ts\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#import optuna\n",
    "#from optuna.trial import TrialState\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from google.colab import drive, files\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.transforms import LargestConnectedComponents\n",
    "\n",
    "def connected_components(data: tg.data.Data):\n",
    "    \"\"\"Find the (weakly)-connected components of graph data. Components are sorted by size, such that id=0 corresponds\n",
    "     to the largest connected component\"\"\"\n",
    "    edge_index = data.edge_index\n",
    "    is_undir = tg.utils.is_undirected(edge_index)\n",
    "    last_components = torch.full((data.num_nodes,), data.num_nodes, dtype=torch.long)\n",
    "    components = torch.arange(data.num_nodes, dtype=torch.long)\n",
    "    while not torch.equal(last_components, components):\n",
    "        last_components[:] = components\n",
    "        if not is_undir:\n",
    "    component_id, inverse, component_size = torch.unique(components, return_counts=True, return_inverse=True)\n",
    "    new_id = torch.argsort(component_size, descending=True)\n",
    "    return new_id[inverse]\n",
    "\n",
    "\n",
    "def largest_connected_component(data: tg.data.Data):\n",
    "    \"\"\"find largest connected component of data\"\"\"\n",
    "    nodes = torch.nonzero(components == 0).flatten()\n",
    "    return induced_subgraph(data, nodes)\n",
    "\n",
    "\n",
    "def induced_subgraph(data: tg.data.Data, nodes, extend_hops=0):\n",
    "    if extend_hops > 0:\n",
    "        nodes, edge_index, node_map, edge_mask = tg.utils.k_hop_subgraph(nodes, num_hops=extend_hops,\n",
    "                                                                         relabel_nodes=True)\n",
    "        edge_attr = data.edge_attr[edge_mask, :] if data.edge_attr is not None else None\n",
    "    else:\n",
    "        edge_index, edge_attr = tg.utils.subgraph(nodes, data.edge_index, data.edge_attr, relabel_nodes=True)\n",
    "\n",
    "    subgraph = tg.data.Data(edge_index=edge_index, edge_attr=edge_attr)\n",
    "    for key, value in data.__dict__.items():\n",
    "        if not key.startswith('edge'):\n",
    "            if hasattr(value, 'shape') and value.shape[0] == data.num_nodes:\n",
    "                setattr(subgraph, key, value[nodes])\n",
    "            else:\n",
    "                setattr(subgraph, key, value)\n",
    "    subgraph.nodes = nodes\n",
    "    subgraph.num_nodes = len(nodes)\n",
    "    return subgraph\n",
    "\n",
    "\n",
    "def conductance(graph: TGraph, source, target=None):\n",
    "    if target is None:\n",
    "        target_mask = torch.ones(graph.num_nodes, dtype=torch.bool, device=graph.device)\n",
    "        target_mask[source] = False\n",
    "    else:\n",
    "        target_mask[target] = True\n",
    "    out = torch.cat([graph.adj(node) for node in source])\n",
    "    cond = torch.sum(target_mask[out]).float()\n",
    "    s_deg = graph.degree[source].sum()\n",
    "    t_deg = graph.num_edges-s_deg if target is None else graph.degree[target].sum()\n",
    "    cond /= torch.minimum(s_deg, t_deg)\n",
    "    return cond\n",
    "\n",
    "\n",
    "def speye(n, dtype=torch.float):\n",
    "    \"\"\"identity matrix of dimension n as sparse_coo_tensor.\"\"\"\n",
    "    return torch.sparse_coo_tensor(torch.tile(torch.arange(n, dtype=torch.long), (2, 1)),\n",
    "                                   torch.ones(n, dtype=dtype),\n",
    "                                   (n, n))\n",
    "\n",
    "\n",
    "class DistanceDecoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistanceDecoder, self).__init__()\n",
    "        self.dist = torch.nn.PairwiseDistance()\n",
    "\n",
    "    def forward(self, z, edge_index, sigmoid=True):\n",
    "        value = -self.dist(z[edge_index[0]], z[edge_index[1]])\n",
    "        return torch.sigmoid(value) if sigmoid else value\n",
    "\n",
    "    def forward_all(self, z, sigmoid=True):\n",
    "        adj = torch.cdist(z, z)\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\n",
    "\n",
    "\n",
    "class GAEconv(torch.nn.Module):\n",
    "        super().__init__()\n",
    "        self.conv1 = tg.nn.GCNConv(num_node_features, hidden_dim, cached=cached, bias=bias, add_self_loops=add_self_loops,\n",
    "                                   normalize=normalize)\n",
    "        self.conv2 = tg.nn.GCNConv(hidden_dim, dim, cached=cached, bias=bias, add_self_loops=add_self_loops,\n",
    "\n",
    "        x = F.relu(self.conv1(data.x, edge_index))\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "\n",
    "class VGAEconv(torch.nn.Module):\n",
    "        super().__init__()\n",
    "        self.mean_conv2 = tg.nn.GCNConv(hidden_dim, dim, cached=cached, bias=bias, add_self_loops=add_self_loops,\n",
    "        self.var_conv2 = tg.nn.GCNConv(hidden_dim, dim, cached=cached, bias=bias, add_self_loops=add_self_loops,\n",
    "\n",
    "\n",
    "\n",
    "        mu = self.mean_conv2(x, edge_index)\n",
    "        sigma = self.var_conv2(x, edge_index)\n",
    "        return mu, sigma\n",
    "\n",
    "\n",
    "def VGAE_loss(model, data):\n",
    "    return model.recon_loss(model.encode(data), data.edge_index) + model.kl_loss() / data.num_nodes\n",
    "\n",
    "\n",
    "def VGAE_model(dim, hidden_dim, num_features, dist=False):\n",
    "    if dist:\n",
    "        return tg.nn.VGAE(encoder=VGAEconv(dim, num_node_features=num_features, hidden_dim=hidden_dim),\n",
    "                          decoder=DistanceDecoder())\n",
    "    else:\n",
    "\n",
    "\n",
    "def lr_grid_search(data, model, loss_fun, validation_loss_fun, lr_grid=(0.1, 0.01, 0.005, 0.001),\n",
    "                   num_epochs=10, runs=1, verbose=True):\n",
    "    val_loss = torch.zeros((len(lr_grid), runs))\n",
    "    val_start = torch.zeros((len(lr_grid), runs))\n",
    "    for i, lr in enumerate(lr_grid):\n",
    "        for r in range(runs):\n",
    "            model.reset_parameters()\n",
    "            val_start[i, r] = validation_loss_fun(model, data)\n",
    "            model = train(data, model, loss_fun, num_epochs=num_epochs, lr=lr, verbose=verbose)\n",
    "            val_loss[i, r] = validation_loss_fun(model, data)\n",
    "    model.reset_parameters()\n",
    "    return lr_grid[torch.argmax(torch.mean(val_loss, 1))], val_loss, val_start\n",
    "\n",
    "\n",
    "def train(data, model, loss_fun, num_epochs=100, verbose=True, lr=0.01, logger=lambda loss: None):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    # schedule = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "    for e in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fun(model, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        logger(float(loss))\n",
    "        if verbose:\n",
    "            print(f'epoch {e}: loss={loss.item()}')\n",
    "        # schedule.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "def VGAE_patch_embeddings(patch_data, dim=2, hidden_dim=32, num_epochs=100, decoder=None, device='cpu', lr=0.01):\n",
    "    patch_list = []\n",
    "    models = []\n",
    "    for patch in patch_data:\n",
    "        #for i in range(len(patch)):#added this for loop and replace the commented part with this\n",
    "            #if patch[i].x is None:\n",
    "                #patch[i].x=speye(patch[i].num_nodes)\n",
    "        \n",
    "        \n",
    "        if patch.x is None:\n",
    "            patch.x = speye(patch.num_nodes)\n",
    "        print(f\"training patch with {patch.edge_index.shape[1]} edges\")   #added [i] to every patch\n",
    "        patch.to(device)\n",
    "\n",
    "        def loss_fun(model, data):\n",
    "            return model.recon_loss(model.encode(data), data.edge_index) + model.kl_loss() / data.num_nodes\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            coordinates = model.encode(patch).to('cpu').numpy()\n",
    "            models.append(model)\n",
    "            patch_list.append(l2g.Patch(patch.nodes.to('cpu').numpy(), coordinates))\n",
    "    return patch_list, models\n",
    "\n",
    "\n",
    "def GAE_patch_embeddings(patch_data, dim=2, hidden_dim=32, num_epochs=100, device='cpu', decoder=None, lr=0.01):\n",
    "    for patch in patch_data:\n",
    "        if patch.x is None:\n",
    "        print(f\"training patch with {patch.edge_index.shape[1]} edges\")\n",
    "        patch.to(device)\n",
    "\n",
    "            return model.recon_loss(model.encode(data), data.edge_index)\n",
    "        model.train()\n",
    "        model.eval()\n",
    "        patch.to('cpu')\n",
    "        models.append(model)\n",
    "        patch_list.append(l2g.Patch(patch.nodes.numpy(), coordinates))\n",
    "    return patch_list, models\n",
    "\n",
    "    for i in range(len(patches)-1):\n",
    "        double_intersections[(i,i+1)]=list(set(patches[i].nodes.tolist()).intersection(set(patches[i+1].nodes.tolist())))\n",
    "    return double_intersections\n",
    "\n",
    "def preprocess_graphs(list_of_patches, nodes_dict):\n",
    "    emb_list = []\n",
    "    for i in range(len(list_of_patches)-1):\n",
    "        emb_list.append([torch.tensor(list_of_patches[i].get_coordinates(list(nodes_dict[i,i+1]))),\n",
    "                         torch.tensor(list_of_patches[i+1].get_coordinates(list(nodes_dict[i,i+1])))])\n",
    "    return emb_list    \n",
    "\n",
    "def get_embedding(patches, result):\n",
    "    n=len(patches)\n",
    "    rot=[result.transformation[i].weight.to('cpu').detach().numpy() for i in range(n)]\n",
    "    shift=[result.transformation[i].bias.to('cpu').detach().numpy() for i in range(n)]\n",
    "\n",
    "    emb_problem = l2g.AlignmentProblem(patches)\n",
    "    embedding = np.empty((emb_problem.n_nodes, emb_problem.dim))\n",
    "    for node, patch_list in enumerate(emb_problem.patch_index):\n",
    "        embedding[node] = np.mean([emb_problem.patches[p].get_coordinate(node)@rot[i] + shift[i] for i, p in enumerate(patch_list)], axis=0)\n",
    "\n",
    "    #prob=l2g.AlignmentProblem(patches)\n",
    "    #old_embedding=prob.get_aligned_embedding()\n",
    "    #embedding=embedding[nodes]\n",
    "    #old_embedding=old_embedding[nodes]\n",
    "    #error= l2g.utils.procrustes_error(embedding,old_embedding)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import geotorch\n",
    "\n",
    "\n",
    "    \n",
    "class Model(nn.Module):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.transformation = nn.ParameterList([nn.Linear(dim, dim).to(device) for _ in range(n_patches)])\n",
    "        [geotorch.orthogonal(self.transformation[i], 'weight') for i in range(n_patches)]\n",
    "    \n",
    "        m = len(patch_emb)\n",
    "        transformations = [self.transformation[0]] + [item for i in range(1, len(self.transformation)-1) for item in (self.transformation[i], self.transformation[i])] + [self.transformation[-1]]\n",
    "        transformed_emb = [transformations[i](patch_emb[i]) for i in range(m)]\n",
    "        return transformed_emb\n",
    "\n",
    "def loss_function(transformed_emb):\n",
    "    diff = [transformed_emb[i] - transformed_emb[i+1] for i in range(0, m-1, 2)]\n",
    "    return loss\n",
    "\n",
    "def train_model(patch_emb, dim, n_patches, num_epochs=100, learning_rate=0.05):\n",
    "    #device = get_device()\n",
    "    patch_emb = [p.to(device) for p in patch_emb]\n",
    "    \n",
    "    loss_hist = []\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        transformed_patch_emb = model(patch_emb)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        loss_hist.append(loss.item())\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "    \n",
    "    return model, loss_hist\n",
    "\n",
    "\n",
    "     to the largest connected component\"\"\"\n",
    "    while not torch.equal(last_components, components):\n",
    "        if not is_undir:\n",
    "    return new_id[inverse]\n",
    "\n",
    "\n",
    "    \"\"\"find largest connected component of data\"\"\"\n",
    "    return induced_subgraph(data, nodes)\n",
    "\n",
    "\n",
    "    if extend_hops > 0:\n",
    "    else:\n",
    "\n",
    "    for key, value in data.__dict__.items():\n",
    "        if not key.startswith('edge'):\n",
    "                setattr(subgraph, key, value[nodes])\n",
    "            else:\n",
    "                setattr(subgraph, key, value)\n",
    "    return subgraph\n",
    "\n",
    "\n",
    "    if target is None:\n",
    "    else:\n",
    "    return cond\n",
    "\n",
    "\n",
    "    \"\"\"identity matrix of dimension n as sparse_coo_tensor.\"\"\"\n",
    "                                   (n, n))\n",
    "\n",
    "\n",
    "        super(DistanceDecoder, self).__init__()\n",
    "\n",
    "        return torch.sigmoid(value) if sigmoid else value\n",
    "\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_patches(data, model, loss_fun, num_epochs=100, verbose=True, lr=0.01, logger=lambda loss: None):\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    # schedule = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "    for e in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        logger(float(loss))\n",
    "        if verbose:\n",
    "        # schedule.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for patch in patch_data:\n",
    "        if patch.x is None:\n",
    "        print(f\"training patch with {patch.edge_index.shape[1]} edges\")\n",
    "        patch.to(device)\n",
    "\n",
    "            return model.recon_loss(model.encode(data), data.edge_index)\n",
    "        model.train()\n",
    "        model.eval()\n",
    "        patch.to('cpu')\n",
    "        models.append(model)\n",
    "        patch_list.append(l2g.Patch(patch.nodes.numpy(), coordinates))\n",
    "    return patch_list, models\n",
    "\n",
    "\n",
    "def intersections_nodes(patches):\n",
    "    intersections = dict()\n",
    "    for i in range(len(patches)):\n",
    "        for j in range(i+1, len(patches)):\n",
    "           intersections[(i,j)]=list(set(patches[i].nodes.tolist()).intersection(set(patches[j].nodes.tolist())))\n",
    "    return intersections\n",
    "\n",
    "    for i in range(len(list_of_patches)-1):\n",
    "        emb_list.append([torch.tensor(list_of_patches[i].get_coordinates(list(nodes_dict[i,i+1]))),\n",
    "                         torch.tensor(list_of_patches[i+1].get_coordinates(list(nodes_dict[i,i+1])))])\n",
    "    return emb_list    \n",
    "\n",
    "\n",
    "    for node, patch_list in enumerate(emb_problem.patch_index):\n",
    "\n",
    "    #prob=l2g.AlignmentProblem(patches)\n",
    "    #old_embedding=prob.get_aligned_embedding()\n",
    "    #embedding=embedding[nodes]\n",
    "    #old_embedding=old_embedding[nodes]\n",
    "    #error= l2g.utils.procrustes_error(embedding,old_embedding)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        super().__init__()\n",
    "        [geotorch.orthogonal(self.transformation[i], 'weight') for i in range(n_patches)]\n",
    "    \n",
    "        return transformed_emb\n",
    "\n",
    "    return loss\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        loss_hist.append(loss.item())\n",
    "        if verbose:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "    \n",
    "    return model, loss_hist\n",
    "\n",
    "\n",
    "from local2global_embedding.patches import create_patch_data\n",
    "from local2global_embedding.clustering import louvain_clustering\n",
    "from scipy.spatial import procrustes\n",
    "\n",
    "\n",
    "#TO ADD HYPERPARAMETERS TUNING ( LEARNING RATE & NUM_EPOCHS) WITH GRID SEARCH\n",
    "def prepare_test(test_data, min_overlap=100, target_overlap=200):\n",
    "\n",
    "    TG=TGraph(edge_index=test_data.edge_index, edge_attr=test_data.edge_attr,  num_nodes=test_data.num_nodes, ensure_sorted=True, undir=False)\n",
    "    pt, pgraph= create_patch_data(TG, partition_tensor= louvain_clustering(TG),\n",
    "                                           min_overlap=min_overlap, target_overlap=target_overlap, verbose=True)\n",
    "    patch_data = [induced_subgraph(test_data, p) for p in pt]\n",
    "    \n",
    "    neg_edges = tg.utils.negative_sampling(test_data.edge_index, num_nodes=test_data.num_nodes)\n",
    "    return patch_data, neg_edges\n",
    "\n",
    "\n",
    "def test_new_emb(test_data, dimensions, patches, neg_edges, device='cpu'):\n",
    "    \n",
    "    \n",
    "    n_patches=len(patches)\n",
    "    \n",
    "    AUC=[]\n",
    "    AP=[]\n",
    "    Loss=[]\n",
    "    PATCHES=[]\n",
    "    new_emb=[]\n",
    "    for dim in tqdm(dimensions):\n",
    "        patches_emb, _ =VGAE_patch_embeddings(patches, dim=dim, num_epochs=50, device=device)\n",
    "        PATCHES.append(patches_emb)\n",
    "        emb_patches = preprocess_graphs(patches_emb, nodes)\n",
    "        print('New Alignment')\n",
    "        res, loss_hist= train_model(emb_patches, dim, n_patches ,device=device, num_epochs=50, learning_rate=0.5, verbose=False)\n",
    "        print('Get new embedding & Statistics')\n",
    "        emb=get_embedding(patches_emb, res)\n",
    "        new_emb.append(emb)\n",
    "        full_model_ip = tg.nn.VGAE(encoder=VGAEconv(dim, test_data.num_node_features))\n",
    "        auc, ap = full_model_ip.test(torch.tensor(emb), test_data.edge_index, neg_edges)\n",
    "        AUC.append(auc)\n",
    "        AP.append(ap)\n",
    "        Loss.append(loss_hist)\n",
    "\n",
    "    test_results={'AUC': AUC, 'AP': AP, 'Losses_hist': Loss}\n",
    "    \n",
    "\n",
    "    return test_results, PATCHES, new_emb, neg_edges\n",
    "\n",
    "\n",
    "def test_old_emb(list_patches_emb, test_data, neg_edges, dimensions):\n",
    "\n",
    "    \n",
    "    OLD_AUC=[]\n",
    "    OLD_AP=[]\n",
    "    old_emb=[]\n",
    "    for i in tqdm(range(len(list_patches_emb))):\n",
    "        prob=l2g.AlignmentProblem(list_patches_emb[i])\n",
    "        e=prob.get_aligned_embedding()\n",
    "        old_emb.append(e)\n",
    "        OLD_AUC.append(auc)\n",
    "        OLD_AP.append(ap)\n",
    "\n",
    "    return test_results, old_emb\n",
    "\n",
    "def test_new_vs_old(test_data, dimensions, patches, neg_edges, device='cpu'):\n",
    "    print('Testing new algorithm')\n",
    "    test_results_new, list_patch_emb, new_emb, neg_edges= test_new_emb(test_data, dimensions, patches, neg_edges, device=device)\n",
    "    print('Testing old algorithm')\n",
    "    test_results_old, old_emb=test_old_emb(list_patch_emb, test_data, neg_edges, dimensions)\n",
    "    \n",
    "    \n",
    "    print('Computing the error')\n",
    "    ERR=[]\n",
    "    for i in range(len(dimensions)):\n",
    "        _, _, error = procrustes(new_emb[i], old_emb[i])\n",
    "        ERR.append(error)\n",
    "\n",
    "    \n",
    "\n",
    "    return test_results_new, test_results_old, ERR, new_emb, old_emb\n",
    "\n",
    "\n",
    "\n",
    "#last_day=data.edge_time.max()\n",
    "#last_day\n",
    "#days=[]\n",
    "#for i in tqdm(range(1, last_day)):\n",
    "   # day_mask=data.edge_time==i\n",
    "    #edge_index=data.edge_index[:, day_mask]\n",
    "   # day_nodes=torch.concat((edge_index[0,:], edge_index[1,:])).unique()\n",
    "    ##x=data.x[day_nodes]\n",
    "    #day=Data(edge_index=data.edge_index[:, day_mask], nodes=day_nodes, x=x)\n",
    "    #days.append(day)\n",
    "   \n",
    " #nodes_dict=[]\n",
    "#new_patches=[]\n",
    "#for p in tqdm(patches):\n",
    "    #old_new_nodes={x.item():i for i, x in enumerate(p.nodes)}\n",
    "    #nodes_dict.append(old_new_nodes)\n",
    "    #new_nodes=torch.tensor(list(old_new_nodes.values()))\n",
    "    #new_edge_index = torch.tensor([[old_new_nodes[val.item()] for val in row] for row in p.edge_index])\n",
    "    #new_patches.append(Data(edge_index=new_edge_index, nodes=p.nodes, x=p.x))\n",
    "\n",
    "from torch_geometric.datasets import DGraphFin\n",
    "\n",
    "dataset = DGraphFin(root='./dataset')\n",
    "data = dataset[0]\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device='cpu'\n",
    "\n",
    "\n",
    "data.nodes=nodes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "partition_tensor=fennel_clustering(TG,400  )\n",
    "\n",
    "#neg_edges = tg.utils.negative_sampling(data.edge_index, num_nodes=data.num_nodes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "for p in patch_data:\n",
    "    p.y=data.y[p.nodes]\n",
    "    p.x=data.x[p.nodes]\n",
    "    #p.nodes=torch.concat((p.edge_index[0,:], p.edge_index[1,:])).unique().sort()[0]\n",
    "    labels=p.y\n",
    "    p.num_nodes=p.nodes.size()[0]\n",
    "    \n",
    "    p.train_mask=data.train_mask[p.nodes]\n",
    "    p.valid_mask=data.val_mask[p.nodes]\n",
    "    p.test_mask=data.test_mask[p.nodes]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "! python gnn.py --model gcn --dataset DGraphFin --epochs 20 --runs 1 --device 0\n",
    "\n",
    "import gnn\n",
    "from models import gcn\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "\n",
    "data.adj_t = SparseTensor(row=data.edge_index[0], col=data.edge_index[1], sparse_sizes=(data.num_nodes, data.num_nodes))\n",
    "\n",
    "\n",
    "\n",
    "for p in patch_data:\n",
    "    p.adj_t = SparseTensor(row=p.edge_index[0], col=p.edge_index[1], sparse_sizes=(p.num_nodes, p.num_nodes))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from utils import DGraphFin\n",
    "from utils.utils import prepare_folder\n",
    "from utils.evaluator import Evaluator\n",
    "from models import MLP, MLPLinear, GCN, SAGE, GAT, GATv2\n",
    "from logger import Logger\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.utils import to_undirected\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from typing import Union\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.typing import SparseTensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def GAE_patch_embeddings_no_train(patch_data, dim=2, hidden_dim=32, num_epochs=100, device='cpu', decoder=None, lr=0.01):\n",
    "    for patch in patch_data:\n",
    "        if patch.x is None:\n",
    "        #print(f\"training patch with {patch.edge_index.shape[1]} edges\")\n",
    "        patch.to(device)\n",
    "        model.eval()\n",
    "        patch.to('cpu')\n",
    "        models.append(model)\n",
    "        patch_list.append(l2g.Patch(patch.nodes.numpy(), coordinates))\n",
    "    return patch_list, models\n",
    "\n",
    "\n",
    "class Alignment_Model(nn.Module):\n",
    "        super().__init__()\n",
    "        [geotorch.orthogonal(self.transformation[i], 'weight') for i in range(n_patches)]\n",
    "    \n",
    "        return transformed_emb\n",
    "\n",
    "def alignment_loss_function(transformed_emb):\n",
    "    return loss\n",
    "\n",
    "def alignment_train_model(patch_emb, dim, n_patches,device='cpu',  num_epochs=10, learning_rate=0.05, verbose=True):\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        loss_hist.append(loss.item())\n",
    "        if verbose:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "    \n",
    "    return model, loss_hist\n",
    "\n",
    "\n",
    "    for node, patch_list in enumerate(emb_problem.patch_index):\n",
    "\n",
    "    #prob=l2g.AlignmentProblem(patches)\n",
    "    #old_embedding=prob.get_aligned_embedding()\n",
    "    #embedding=embedding[nodes]\n",
    "    #old_embedding=old_embedding[nodes]\n",
    "    #error= l2g.utils.procrustes_error(embedding,old_embedding)\n",
    "\n",
    "    return embedding\n",
    "def get_aligned_emb_from_patches(patches, nodes, dim):\n",
    "    res, _ =alignment_train_model(emb_patches, dim, n_patches,device='cpu', \n",
    "    \n",
    "    \n",
    "    return emb\n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "\n",
    "\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from typing import Union\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.typing import SparseTensor\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_patch_embeddings(patch_data,model, dim, device):\n",
    "   \n",
    "    for i, patch in enumerate(patch_data):\n",
    "        print(i)\n",
    "\n",
    "        patch.to(device)\n",
    "        patch.to('cpu')\n",
    "       \n",
    "        patch_list.append(l2g.Patch(patch.nodes.numpy(), coordinates))\n",
    "    return patch_list\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_tot_model(patches, data, nodes, model, reducer, dim, device, optimizer,  epochs=50):\n",
    "    model.eval()\n",
    "    reducer.eval()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute patch embeddings patch_data, dim=2, hidden_dim=32\n",
    "        patch_embeddings, _ =GAE_patch_embeddings_no_train(patch_data, dim=128, hidden_dim=32, num_epochs=1, device=device, decoder=None, lr=0.01)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Get full graph embedding\n",
    "        print('Alignment')\n",
    "        full_graph_embedding = get_aligned_emb_from_patches(patch_embeddings, nodes, dim).to(device).float()\n",
    "\n",
    "        # Reduce embedding dimension\n",
    "        reduced_embedding = reducer(full_graph_embedding, data.edge_index.to(device))\n",
    "\n",
    "        # Compute loss using node labels\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        loss_hist.append(loss.item())\n",
    "\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        \n",
    "    return loss_hist #full_graph_embedding, reduced_embedding, patch_embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "gcn_model = GCN(in_channels = 17, out_channels = 128, hidden_channels=128, num_layers=1, dropout=0.0).to(device)\n",
    "dim_reducer = GCN(in_channels=128, out_channels=2, hidden_channels=128, num_layers=1, dropout=0.0).to(device)  # Reduce to 2D\n",
    "\n",
    "# Optimizer & Loss\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Example data (Replace with actual patches & graph data)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "patches=patch_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====== Graph Autoencoder (GAE) Model ======\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    for patch in patch_data:\n",
    "        if patch.x is None:\n",
    "        model.eval()\n",
    "        patch.to(device)\n",
    "        patch.to('cpu')\n",
    "        models.append(model)\n",
    "        patch_list.append(l2g.Patch(patch.nodes.numpy(), coordinates))\n",
    "    return patch_list, models\n",
    "\n",
    "# ====== Alignment Model ======\n",
    "\n",
    "        super().__init__()\n",
    "        [geotorch.orthogonal(self.transformation[i], 'weight') for i in range(n_patches)]\n",
    "        \n",
    "    \n",
    "        return transformed_emb\n",
    "\n",
    "    return loss\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_hist.append(loss.item())\n",
    "    \n",
    "    return model, loss_hist\n",
    "\n",
    "def alignment_eval_model(patch_emb, dim, n_patches, device=device):\n",
    "    model.eval()  # Keep evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # Prevents gradients from being computed\n",
    "\n",
    "    return model, loss.item()  # No training, so return final loss\n",
    "\n",
    "\n",
    "#def alignment_eval_model(patch_emb, dim, n_patches, device=device, num_epochs=10, learning_rate=0.05):\n",
    "    #patch_emb = [p.to(device) for p in patch_emb]\n",
    "    #model = Alignment_Model(dim, n_patches, device).to(device)\n",
    "    #model.eval()\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    #loss_hist = []\n",
    "    \n",
    "    #for epoch in tqdm(range(num_epochs)):\n",
    "      #  optimizer.zero_grad()\n",
    "       # transformed_patch_emb = model(patch_emb)\n",
    "       # loss = alignment_loss_function(transformed_patch_emb)\n",
    "       # loss.backward()\n",
    "       # optimizer.step()\n",
    "       # loss_hist.append(loss.item())\n",
    "    \n",
    "    #return model, loss_hist\n",
    "\n",
    "    \n",
    "    for node, patch_list in enumerate(emb_problem.patch_index):\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "    if train:\n",
    "    if eval_:\n",
    "    return emb\n",
    "\n",
    "# ====== Training, Validation, and Testing Functions ======\n",
    "\n",
    "    model.train()\n",
    "    reducer.train()\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute patch embeddings\n",
    "        \n",
    "        # Get full graph embedding\n",
    "\n",
    "        # Reduce embedding dimension\n",
    "\n",
    "        # Compute loss using node labels\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_hist.append(loss.item())\n",
    "\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "    \n",
    "    return loss_hist\n",
    "\n",
    "def validate_tot_model(patches, data, nodes, model, reducer, dim, device):\n",
    "    model.eval()\n",
    "    reducer.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "                                                           eval_=True).to(device).float()\n",
    "        \n",
    "        val_mask = data.val_mask.to(device)\n",
    "        y_val = data.y.to(device)\n",
    "        accuracy = (reduced_embedding[val_mask].argmax(dim=1) ==y_val[val_mask]).float().mean().item()\n",
    "    \n",
    "    return loss.item(), accuracy\n",
    "\n",
    "def test_model(patches, data, nodes, model, reducer, dim, device):\n",
    "    model.eval()\n",
    "    reducer.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        test_mask = data.test_mask.to(device)\n",
    "    \n",
    "    return loss.item(), accuracy\n",
    "\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "dim=64\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"lr\": [0.01],\n",
    "    \"hidden_dim\": [64],\n",
    "    \"epochs\": [ 60],\n",
    "    \"dropout\": [0.2]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "best_model = None\n",
    "best_params = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for params in product(*param_grid.values()):\n",
    "    # Unpack parameters\n",
    "    lr, hidden_dim, epochs, dropout = params\n",
    "    \n",
    "    # Initialize models\n",
    "    \n",
    "    # Optimizer\n",
    "    \n",
    "    # Train model\n",
    "    loss_history = train_tot_model(patches, data, nodes, gcn_model, dim_reducer, dim=dim, \n",
    "    \n",
    "    # Validate model\n",
    "    val_loss, val_acc = validate_tot_model(patches, data, nodes, gcn_model, dim_reducer, dim=dim, device=device)\n",
    "    \n",
    "    print(f\"Params: {params} -> Val Accuracy: {val_acc}\")\n",
    "    \n",
    "    # Store best model\n",
    "    if val_acc > best_accuracy:\n",
    "\n",
    "print(f\"Best Parameters: {best_params}, Best Accuracy: {best_accuracy}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "def test_tot_model(patches, data, nodes, model, reducer, dim, device):\n",
    "    model.eval()\n",
    "    reducer.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get embeddings\n",
    "        \n",
    "        # Compute loss\n",
    "        \n",
    "        # Get predictions\n",
    "        y_true = data.y[test_mask].cpu().numpy()\n",
    "        y_pred = reduced_embedding[test_mask].argmax(dim=1).cpu().numpy()\n",
    "        \n",
    "        # Compute metrics\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "        auc = roc_auc_score(y_true, y_pred) if len(set(y_true)) == 2 else \"N/A\"  # Only for binary classification\n",
    "        \n",
    "        print(f\"Test Loss: {loss.item()}\")\n",
    "        print(f\"Test Accuracy: {acc}\")\n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F1-score: {f1}\")\n",
    "        print(f\"ROC-AUC: {auc}\")\n",
    "\n",
    "    return loss.item(), acc, precision, recall, f1, auc\n",
    "\n",
    "\n",
    "model_32=best_model\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "    model.eval()\n",
    "    reducer.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get embeddings\n",
    "        \n",
    "        # Compute loss\n",
    "        \n",
    "        # Get predictions\n",
    "        \n",
    "        # Compute metrics\n",
    "        \n",
    "        print(f\"Test Loss: {loss.item()}\")\n",
    "        print(f\"Test Accuracy: {acc}\")\n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F1-score: {f1}\")\n",
    "        print(f\"ROC-AUC: {auc}\")\n",
    "\n",
    "    return loss.item(), acc, precision, recall, f1, auc\n",
    "loss, acc, precision, recall, f1, auc= test_tot_model(patches, data, nodes, \n",
    "\n",
    "\n",
    "losses.append(loss_history)\n",
    "models_dim.append(best_model)\n",
    "stats_dict={'loss': loss, 'acc': acc, 'prec':precision, 'recall': recall, 'f1': f1, 'auc':auc}\n",
    "stats.append(stats_dict)\n",
    "\n",
    "\n",
    "print(loss, acc, precision, recall, f1, auc)\n",
    "\n",
    "plt.plot(loss_history)\n",
    "\n",
    "Params: (0.001, 64, 100, 0.2) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 64, 100, 0.0) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 64, 50, 0.5) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 64, 50, 0.2) -> Val Accuracy: 0.9871153235435486\n",
    "\n",
    "Params: (0.001, 64, 50, 0.0) -> Val Accuracy: 0.9869195222854614\n",
    "\n",
    "Params: (0.001, 128, 150, 0.5) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 128, 150, 0.2) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 128, 150, 0.0) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 128, 100, 0.5) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 128, 100, 0.2) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 128, 100, 0.0) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 128, 50, 0.5) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 128, 50, 0.2) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 128, 50, 0.0) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 64, 150, 0.5) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 64, 150, 0.2) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 64, 150, 0.0) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "Params: (0.001, 64, 100, 0.5) -> Val Accuracy: 0.9873491525650024\n",
    "\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    reducer.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get embeddings\n",
    "        \n",
    "        # Compute loss\n",
    "        #test_mask = data.test_mask.to(device)\n",
    "        #y_val = data.y.to(device)\n",
    "        # Get predictions\n",
    "        \n",
    "        # Compute metrics\n",
    "        \n",
    "        print(f\"Test Loss: {loss.item()}\")\n",
    "        print(f\"Test Accuracy: {acc}\")\n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F1-score: {f1}\")\n",
    "        print(f\"ROC-AUC: {auc}\")\n",
    "\n",
    "    return loss.item(), acc, precision, recall, f1, auc\n",
    "\n",
    "# ====== Running the Training, Validation, and Testing ======\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "\n",
    "# Define optimizer\n",
    "\n",
    "# Train\n",
    "\n",
    "# Validate\n",
    "print(f\"Validation Loss: {val_loss}, Accuracy: {val_acc}\")\n",
    "\n",
    "# Test\n",
    "test_loss, test_acc = test_model(patches, data, nodes, gcn_model, dim_reducer, dim=dim, device=device)\n",
    "print(f\"Test Loss: {test_loss}, Accuracy: {test_acc}\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "    model.eval()\n",
    "    reducer.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get embeddings\n",
    "        \n",
    "        # Compute loss\n",
    "        # Get predictions\n",
    "        #test_mask = data.test_mask.to(device)\n",
    "        \n",
    "        # Compute metrics\n",
    "        \n",
    "        print(f\"Test Loss: {loss.item()}\")\n",
    "        print(f\"Test Accuracy: {acc}\")\n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F1-score: {f1}\")\n",
    "        print(f\"ROC-AUC: {auc}\")\n",
    "\n",
    "    return loss.item(), acc, precision, recall, f1, auc\n",
    "\n",
    "\n",
    "\n",
    "# Run best model on test set\n",
    "test_loss, test_acc, precision, recall, f1, auc = test_tot_model(patches, data, nodes, \n",
    "                                                                 gcn_model, dim_reducer, dim=dim, device=device)\n",
    "\n",
    "\n",
    "patches\n",
    "\n",
    "dimensions=[32,64,128]\n",
    "\n",
    "\n",
    "test_results_new, test_results_old, ERR, new_emb, old_emb= test_new_vs_old(data, dimensions, patches, neg_edges, device=device)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
