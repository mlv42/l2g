{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exact-turkey",
   "metadata": {},
   "source": [
    "# Embedding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pursuant-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.max_open_warning'] = 0\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "likely-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import embedding as emb\n",
    "import torch_geometric as tg\n",
    "import local2global as l2g\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "#ADDED\n",
    "#import patches as pt\n",
    "#import network as ntw \n",
    "import autograd.numpy as anp\n",
    "import pymanopt\n",
    "import pymanopt.manifolds\n",
    "import pymanopt.optimizers\n",
    "import random\n",
    "import local2global as l2g\n",
    "import local2global.example as ex\n",
    "import numpy as np\n",
    "\n",
    "def double_intersections_nodes(patches):\n",
    "    double_intersections=dict()\n",
    "    for i in range(len(patches)):\n",
    "        for j in range(i+1, len(patches)):\n",
    "            double_intersections[(i,j)]=list(set(patches[i].nodes.tolist()).intersection(set(patches[j].nodes.tolist())))\n",
    "    return double_intersections\n",
    "    \n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c3e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import patches as pt\n",
    "#import network as ntw \n",
    "import numpy as np\n",
    "import geotorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import local2global as l2g\n",
    "\n",
    "\n",
    "import local2global.example as ex\n",
    "import local2global_embedding\n",
    "from scipy.stats import ortho_group \n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.sparse import csr_matrix, csc_matrix, coo_matrix\n",
    "import random\n",
    "#import manopt_optimization as moptim\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric as tg\n",
    "from local2global_embedding.network import tgraph\n",
    "from local2global_embedding.patches import create_patch_data\n",
    "from local2global_embedding.clustering import louvain_clustering\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.sparse as ss\n",
    "import scipy.sparse.linalg as sl\n",
    "\n",
    "import raphtory as rp\n",
    "from raphtory import Graph as rgraph\n",
    "\n",
    "\n",
    "\n",
    "import local2global as l2g\n",
    "\n",
    "import local2global_embedding\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "\n",
    "#from Local2Global_embedding.local2global_embedding import  clustering\n",
    "import community\n",
    "#from Local2Global_embedding.local2global_embedding.network import graph\n",
    "from local2global_embedding.network import TGraph\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "\n",
    "from local2global import Patch\n",
    "#import Local2Global_embedding.local2global_embedding.embedding.svd as svd\n",
    "#import Local2Global_embedding.local2global_embedding.embedding.gae as gae\n",
    "#import Local2Global_embedding.local2global_embedding.patches as patches\n",
    "\n",
    "\n",
    "import torch_geometric as tg\n",
    "import torch_scatter as ts\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#import optuna\n",
    "#from optuna.trial import TrialState\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from google.colab import drive, files\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.transforms import LargestConnectedComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d835e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_components(data: tg.data.Data):\n",
    "    \"\"\"Find the (weakly)-connected components of graph data. Components are sorted by size, such that id=0 corresponds\n",
    "     to the largest connected component\"\"\"\n",
    "    edge_index = data.edge_index\n",
    "    is_undir = tg.utils.is_undirected(edge_index)\n",
    "    last_components = torch.full((data.num_nodes,), data.num_nodes, dtype=torch.long)\n",
    "    components = torch.arange(data.num_nodes, dtype=torch.long)\n",
    "    while not torch.equal(last_components, components):\n",
    "        last_components[:] = components\n",
    "        components = ts.scatter(last_components[edge_index[0]], edge_index[1], out=components, reduce='min')\n",
    "        if not is_undir:\n",
    "            components = ts.scatter(last_components[edge_index[1]], edge_index[0], out=components, reduce='min')\n",
    "    component_id, inverse, component_size = torch.unique(components, return_counts=True, return_inverse=True)\n",
    "    new_id = torch.argsort(component_size, descending=True)\n",
    "    return new_id[inverse]\n",
    "\n",
    "\n",
    "def largest_connected_component(data: tg.data.Data):\n",
    "    \"\"\"find largest connected component of data\"\"\"\n",
    "    components = connected_components(data)\n",
    "    nodes = torch.nonzero(components == 0).flatten()\n",
    "    return induced_subgraph(data, nodes)\n",
    "\n",
    "\n",
    "def induced_subgraph(data: tg.data.Data, nodes, extend_hops=0):\n",
    "    nodes = torch.as_tensor(nodes, dtype=torch.long)\n",
    "    if extend_hops > 0:\n",
    "        nodes, edge_index, node_map, edge_mask = tg.utils.k_hop_subgraph(nodes, num_hops=extend_hops,\n",
    "                                                                         edge_index=data.edge_index,\n",
    "                                                                         relabel_nodes=True)\n",
    "        edge_attr = data.edge_attr[edge_mask, :] if data.edge_attr is not None else None\n",
    "    else:\n",
    "        edge_index, edge_attr = tg.utils.subgraph(nodes, data.edge_index, data.edge_attr, relabel_nodes=True)\n",
    "\n",
    "    subgraph = tg.data.Data(edge_index=edge_index, edge_attr=edge_attr)\n",
    "    for key, value in data.__dict__.items():\n",
    "        if not key.startswith('edge'):\n",
    "            if hasattr(value, 'shape') and value.shape[0] == data.num_nodes:\n",
    "                setattr(subgraph, key, value[nodes])\n",
    "            else:\n",
    "                setattr(subgraph, key, value)\n",
    "    subgraph.nodes = nodes\n",
    "    subgraph.num_nodes = len(nodes)\n",
    "    return subgraph\n",
    "\n",
    "\n",
    "def conductance(graph: TGraph, source, target=None):\n",
    "    if target is None:\n",
    "        target_mask = torch.ones(graph.num_nodes, dtype=torch.bool, device=graph.device)\n",
    "        target_mask[source] = False\n",
    "    else:\n",
    "        target_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n",
    "        target_mask[target] = True\n",
    "    out = torch.cat([graph.adj(node) for node in source])\n",
    "    cond = torch.sum(target_mask[out]).float()\n",
    "    s_deg = graph.degree[source].sum()\n",
    "    t_deg = graph.num_edges-s_deg if target is None else graph.degree[target].sum()\n",
    "    cond /= torch.minimum(s_deg, t_deg)\n",
    "    return cond\n",
    "\n",
    "\n",
    "def speye(n, dtype=torch.float):\n",
    "    \"\"\"identity matrix of dimension n as sparse_coo_tensor.\"\"\"\n",
    "    return torch.sparse_coo_tensor(torch.tile(torch.arange(n, dtype=torch.long), (2, 1)),\n",
    "                                   torch.ones(n, dtype=dtype),\n",
    "                                   (n, n))\n",
    "\n",
    "\n",
    "class DistanceDecoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistanceDecoder, self).__init__()\n",
    "        self.dist = torch.nn.PairwiseDistance()\n",
    "\n",
    "    def forward(self, z, edge_index, sigmoid=True):\n",
    "        value = -self.dist(z[edge_index[0]], z[edge_index[1]])\n",
    "        return torch.sigmoid(value) if sigmoid else value\n",
    "\n",
    "    def forward_all(self, z, sigmoid=True):\n",
    "        adj = torch.cdist(z, z)\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\n",
    "\n",
    "\n",
    "class GAEconv(torch.nn.Module):\n",
    "    def __init__(self, dim, num_node_features, hidden_dim=32, cached=True, bias=True, add_self_loops=True, normalize=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = tg.nn.GCNConv(num_node_features, hidden_dim, cached=cached, bias=bias, add_self_loops=add_self_loops,\n",
    "                                   normalize=normalize)\n",
    "        self.conv2 = tg.nn.GCNConv(hidden_dim, dim, cached=cached, bias=bias, add_self_loops=add_self_loops,\n",
    "                                   normalize=normalize)\n",
    "\n",
    "    def forward(self, data):\n",
    "        edge_index = data.edge_index\n",
    "        x = F.relu(self.conv1(data.x, edge_index))\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "\n",
    "class VGAEconv(torch.nn.Module):\n",
    "    def __init__(self, dim, num_node_features, hidden_dim=32, cached=True, bias=True, add_self_loops=True, normalize=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = tg.nn.GCNConv(num_node_features, hidden_dim, cached=cached, bias=bias, add_self_loops=add_self_loops,\n",
    "                                   normalize=normalize)\n",
    "        self.mean_conv2 = tg.nn.GCNConv(hidden_dim, dim, cached=cached, bias=bias, add_self_loops=add_self_loops,\n",
    "                                        normalize=normalize)\n",
    "        self.var_conv2 = tg.nn.GCNConv(hidden_dim, dim, cached=cached, bias=bias, add_self_loops=add_self_loops,\n",
    "                                       normalize=normalize)\n",
    "\n",
    "    def forward(self, data: tg.data.Data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        mu = self.mean_conv2(x, edge_index)\n",
    "        sigma = self.var_conv2(x, edge_index)\n",
    "        return mu, sigma\n",
    "\n",
    "\n",
    "def VGAE_loss(model, data):\n",
    "    return model.recon_loss(model.encode(data), data.edge_index) + model.kl_loss() / data.num_nodes\n",
    "\n",
    "\n",
    "def VGAE_model(dim, hidden_dim, num_features, dist=False):\n",
    "    if dist:\n",
    "        return tg.nn.VGAE(encoder=VGAEconv(dim, num_node_features=num_features, hidden_dim=hidden_dim),\n",
    "                          decoder=DistanceDecoder())\n",
    "    else:\n",
    "        return tg.nn.VGAE(encoder=VGAEconv(dim, num_node_features=num_features, hidden_dim=hidden_dim))\n",
    "\n",
    "\n",
    "def lr_grid_search(data, model, loss_fun, validation_loss_fun, lr_grid=(0.1, 0.01, 0.005, 0.001),\n",
    "                   num_epochs=10, runs=1, verbose=True):\n",
    "    val_loss = torch.zeros((len(lr_grid), runs))\n",
    "    val_start = torch.zeros((len(lr_grid), runs))\n",
    "    for i, lr in enumerate(lr_grid):\n",
    "        for r in range(runs):\n",
    "            model.reset_parameters()\n",
    "            val_start[i, r] = validation_loss_fun(model, data)\n",
    "            model = train(data, model, loss_fun, num_epochs=num_epochs, lr=lr, verbose=verbose)\n",
    "            val_loss[i, r] = validation_loss_fun(model, data)\n",
    "    model.reset_parameters()\n",
    "    return lr_grid[torch.argmax(torch.mean(val_loss, 1))], val_loss, val_start\n",
    "\n",
    "\n",
    "def train(data, model, loss_fun, num_epochs=100, verbose=True, lr=0.01, logger=lambda loss: None):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    # schedule = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "    for e in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fun(model, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        logger(float(loss))\n",
    "        if verbose:\n",
    "            print(f'epoch {e}: loss={loss.item()}')\n",
    "        # schedule.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "def VGAE_patch_embeddings(patch_data, dim=2, hidden_dim=32, num_epochs=100, decoder=None, device='cpu', lr=0.01):\n",
    "    patch_list = []\n",
    "    models = []\n",
    "    for patch in patch_data:\n",
    "        #for i in range(len(patch)):#added this for loop and replace the commented part with this\n",
    "            #if patch[i].x is None:\n",
    "                #patch[i].x=speye(patch[i].num_nodes)\n",
    "        \n",
    "        \n",
    "        if patch.x is None:\n",
    "            patch.x = speye(patch.num_nodes)\n",
    "        print(f\"training patch with {patch.edge_index.shape[1]} edges\")   #added [i] to every patch\n",
    "        model = tg.nn.VGAE(encoder=VGAEconv(dim, patch.x.shape[1], hidden_dim=hidden_dim), decoder=decoder).to(device)\n",
    "        patch.to(device)\n",
    "\n",
    "        def loss_fun(model, data):\n",
    "            return model.recon_loss(model.encode(data), data.edge_index) + model.kl_loss() / data.num_nodes\n",
    "\n",
    "        model = train(patch, model, loss_fun, num_epochs=num_epochs, lr=lr)\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            coordinates = model.encode(patch).to('cpu').numpy()\n",
    "            models.append(model)\n",
    "            patch_list.append(l2g.Patch(patch.nodes.to('cpu').numpy(), coordinates))\n",
    "    return patch_list, models\n",
    "\n",
    "\n",
    "def GAE_patch_embeddings(patch_data, dim=2, hidden_dim=32, num_epochs=100, device='cpu', decoder=None, lr=0.01):\n",
    "    patch_list = []\n",
    "    models = []\n",
    "    for patch in patch_data:\n",
    "        if patch.x is None:\n",
    "            patch.x = speye(patch.num_nodes)\n",
    "        print(f\"training patch with {patch.edge_index.shape[1]} edges\")\n",
    "        model = tg.nn.GAE(encoder=GAEconv(dim, patch.x.shape[1], hidden_dim=hidden_dim), decoder=decoder).to(device)\n",
    "        patch.to(device)\n",
    "\n",
    "        def loss_fun(model, data):\n",
    "            return model.recon_loss(model.encode(data), data.edge_index)\n",
    "        model.train()\n",
    "        model = train(patch, model, loss_fun, num_epochs=num_epochs, lr=lr)\n",
    "        model.eval()\n",
    "        coordinates = model.encode(patch).to('cpu').data.numpy()\n",
    "        patch.to('cpu')\n",
    "        models.append(model)\n",
    "        patch_list.append(l2g.Patch(patch.nodes.numpy(), coordinates))\n",
    "    return patch_list, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53b2f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "novel-memorial",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = tg.datasets.Planetoid(name='Cora', root='/tmp/cora', split='full')[0]\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65f7fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from local2global_embedding.patches import create_patch_data\n",
    "from local2global_embedding.clustering import louvain_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ad1b08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patches: 15\n",
      "average patch degree: 3.7333333333333334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098fa0f0c71042178e338e826d32581b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "enlarging patch overlaps:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cc = largest_connected_component(data=test_data)\n",
    "cc.x=test_data.x[cc.nodes] \n",
    "cc.y=test_data.y[cc.nodes]\n",
    "test_data=cc\n",
    "\n",
    "TG=TGraph(edge_index=cc.edge_index, edge_attr=cc.edge_attr,  num_nodes=cc.num_nodes, ensure_sorted=True, undir=False)\n",
    "pt, pgraph= create_patch_data(TG, partition_tensor= louvain_clustering(TG),\n",
    "                                           min_overlap=90, target_overlap=200, verbose=True)\n",
    "patch_data = [induced_subgraph(cc, p) for p in pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "235da8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_edges = tg.utils.negative_sampling(test_data.edge_index, num_nodes=test_data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b2e229-7cb4-46be-a7aa-2b980e791f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447c624-aa7d-4119-bc7f-2c4d52a09863",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "430b00f0-5b47-47c9-878d-5879ec3bf8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_data=patch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0fb92ab-b773-4b37-a586-a5309261bb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(edge_index=[2, 2032], nodes=[547], num_nodes=547),\n",
       " Data(edge_index=[2, 1946], nodes=[525], num_nodes=525),\n",
       " Data(edge_index=[2, 1878], nodes=[462], num_nodes=462),\n",
       " Data(edge_index=[2, 2784], nodes=[699], num_nodes=699),\n",
       " Data(edge_index=[2, 1652], nodes=[446], num_nodes=446),\n",
       " Data(edge_index=[2, 840], nodes=[264], num_nodes=264),\n",
       " Data(edge_index=[2, 1460], nodes=[378], num_nodes=378),\n",
       " Data(edge_index=[2, 764], nodes=[216], num_nodes=216),\n",
       " Data(edge_index=[2, 950], nodes=[271], num_nodes=271),\n",
       " Data(edge_index=[2, 2922], nodes=[755], num_nodes=755),\n",
       " Data(edge_index=[2, 1698], nodes=[450], num_nodes=450),\n",
       " Data(edge_index=[2, 670], nodes=[207], num_nodes=207),\n",
       " Data(edge_index=[2, 1602], nodes=[448], num_nodes=448),\n",
       " Data(edge_index=[2, 1800], nodes=[443], num_nodes=443),\n",
       " Data(edge_index=[2, 1844], nodes=[489], num_nodes=489)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1958521c-bf6f-4f96-b5e1-9b3a3c439075",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-scottish",
   "metadata": {},
   "source": [
    "## Inner product embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "atomic-testing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training patch with 2032 edges\n",
      "epoch 0: loss=1.7243188619613647\n",
      "epoch 1: loss=1.632159948348999\n",
      "epoch 2: loss=1.611518383026123\n",
      "epoch 3: loss=1.5940577983856201\n",
      "epoch 4: loss=1.5413583517074585\n",
      "epoch 5: loss=1.5101364850997925\n",
      "epoch 6: loss=1.5186572074890137\n",
      "epoch 7: loss=1.483724594116211\n",
      "epoch 8: loss=1.4543147087097168\n",
      "epoch 9: loss=1.4352599382400513\n",
      "epoch 10: loss=1.4214564561843872\n",
      "epoch 11: loss=1.3983361721038818\n",
      "epoch 12: loss=1.3864978551864624\n",
      "epoch 13: loss=1.3725509643554688\n",
      "epoch 14: loss=1.3763784170150757\n",
      "epoch 15: loss=1.3573023080825806\n",
      "epoch 16: loss=1.3457894325256348\n",
      "epoch 17: loss=1.3432679176330566\n",
      "epoch 18: loss=1.318755865097046\n",
      "epoch 19: loss=1.3315213918685913\n",
      "epoch 20: loss=1.3213562965393066\n",
      "epoch 21: loss=1.3107296228408813\n",
      "epoch 22: loss=1.3025370836257935\n",
      "epoch 23: loss=1.29985511302948\n",
      "epoch 24: loss=1.288236379623413\n",
      "epoch 25: loss=1.2933447360992432\n",
      "epoch 26: loss=1.2741914987564087\n",
      "epoch 27: loss=1.273916482925415\n",
      "epoch 28: loss=1.2706875801086426\n",
      "epoch 29: loss=1.267153024673462\n",
      "epoch 30: loss=1.254530668258667\n",
      "epoch 31: loss=1.2487396001815796\n",
      "epoch 32: loss=1.2504746913909912\n",
      "epoch 33: loss=1.234586477279663\n",
      "epoch 34: loss=1.2253820896148682\n",
      "epoch 35: loss=1.226528286933899\n",
      "epoch 36: loss=1.218261957168579\n",
      "epoch 37: loss=1.1992640495300293\n",
      "epoch 38: loss=1.2027032375335693\n",
      "epoch 39: loss=1.18596613407135\n",
      "epoch 40: loss=1.1706739664077759\n",
      "epoch 41: loss=1.1764622926712036\n",
      "epoch 42: loss=1.166634440422058\n",
      "epoch 43: loss=1.1699519157409668\n",
      "epoch 44: loss=1.1367939710617065\n",
      "epoch 45: loss=1.1562964916229248\n",
      "epoch 46: loss=1.1236544847488403\n",
      "epoch 47: loss=1.1353334188461304\n",
      "epoch 48: loss=1.1245909929275513\n",
      "epoch 49: loss=1.155175805091858\n",
      "epoch 50: loss=1.1386919021606445\n",
      "epoch 51: loss=1.118059515953064\n",
      "epoch 52: loss=1.1574265956878662\n",
      "epoch 53: loss=1.1347087621688843\n",
      "epoch 54: loss=1.1199039220809937\n",
      "epoch 55: loss=1.1256192922592163\n",
      "epoch 56: loss=1.1226810216903687\n",
      "epoch 57: loss=1.116121768951416\n",
      "epoch 58: loss=1.122231125831604\n",
      "epoch 59: loss=1.1120259761810303\n",
      "epoch 60: loss=1.1101988554000854\n",
      "epoch 61: loss=1.1028647422790527\n",
      "epoch 62: loss=1.0978648662567139\n",
      "epoch 63: loss=1.0924478769302368\n",
      "epoch 64: loss=1.0737838745117188\n",
      "epoch 65: loss=1.0776134729385376\n",
      "epoch 66: loss=1.054781198501587\n",
      "epoch 67: loss=1.059133768081665\n",
      "epoch 68: loss=1.039174199104309\n",
      "epoch 69: loss=1.0428498983383179\n",
      "epoch 70: loss=1.0346535444259644\n",
      "epoch 71: loss=1.0147976875305176\n",
      "epoch 72: loss=1.0198074579238892\n",
      "epoch 73: loss=1.0487807989120483\n",
      "epoch 74: loss=1.0171476602554321\n",
      "epoch 75: loss=1.0444769859313965\n",
      "epoch 76: loss=1.0428855419158936\n",
      "epoch 77: loss=1.0192713737487793\n",
      "epoch 78: loss=1.023337960243225\n",
      "epoch 79: loss=0.9969361424446106\n",
      "epoch 80: loss=1.0290454626083374\n",
      "epoch 81: loss=1.0133662223815918\n",
      "epoch 82: loss=0.9926421046257019\n",
      "epoch 83: loss=0.9961645603179932\n",
      "epoch 84: loss=1.002244472503662\n",
      "epoch 85: loss=1.018186092376709\n",
      "epoch 86: loss=0.9947437047958374\n",
      "epoch 87: loss=0.9887910485267639\n",
      "epoch 88: loss=0.9956929683685303\n",
      "epoch 89: loss=0.9958977699279785\n",
      "epoch 90: loss=0.9848577976226807\n",
      "epoch 91: loss=0.9813826084136963\n",
      "epoch 92: loss=0.9880424737930298\n",
      "epoch 93: loss=0.9870749115943909\n",
      "epoch 94: loss=0.9872660040855408\n",
      "epoch 95: loss=0.9830299615859985\n",
      "epoch 96: loss=1.0132981538772583\n",
      "epoch 97: loss=0.9979392290115356\n",
      "epoch 98: loss=0.975010871887207\n",
      "epoch 99: loss=0.9754425287246704\n",
      "epoch 100: loss=0.9806257486343384\n",
      "epoch 101: loss=0.987816333770752\n",
      "epoch 102: loss=0.9946048259735107\n",
      "epoch 103: loss=0.9887948632240295\n",
      "epoch 104: loss=0.9920749068260193\n",
      "epoch 105: loss=0.9720825552940369\n",
      "epoch 106: loss=0.9869522452354431\n",
      "epoch 107: loss=0.9987186789512634\n",
      "epoch 108: loss=0.9915345311164856\n",
      "epoch 109: loss=0.9973779320716858\n",
      "epoch 110: loss=0.9716710448265076\n",
      "epoch 111: loss=0.9672271013259888\n",
      "epoch 112: loss=0.9535991549491882\n",
      "epoch 113: loss=0.9752472639083862\n",
      "epoch 114: loss=0.9714762568473816\n",
      "epoch 115: loss=0.9817614555358887\n",
      "epoch 116: loss=0.9743632078170776\n",
      "epoch 117: loss=0.9760134220123291\n",
      "epoch 118: loss=0.9770146608352661\n",
      "epoch 119: loss=0.9865286946296692\n",
      "epoch 120: loss=0.9870720505714417\n",
      "epoch 121: loss=0.9811056852340698\n",
      "epoch 122: loss=0.9483858346939087\n",
      "epoch 123: loss=0.9731252193450928\n",
      "epoch 124: loss=0.9995927214622498\n",
      "epoch 125: loss=1.0057162046432495\n",
      "epoch 126: loss=0.9559797048568726\n",
      "epoch 127: loss=0.9848843812942505\n",
      "epoch 128: loss=0.9676524996757507\n",
      "epoch 129: loss=0.9726659059524536\n",
      "epoch 130: loss=0.9689220786094666\n",
      "epoch 131: loss=0.9709499478340149\n",
      "epoch 132: loss=0.982877254486084\n",
      "epoch 133: loss=0.9591495394706726\n",
      "epoch 134: loss=0.9747946262359619\n",
      "epoch 135: loss=0.9609934091567993\n",
      "epoch 136: loss=0.9665641784667969\n",
      "epoch 137: loss=0.9799357056617737\n",
      "epoch 138: loss=0.954142689704895\n",
      "epoch 139: loss=0.9815142154693604\n",
      "epoch 140: loss=0.969957709312439\n",
      "epoch 141: loss=0.9753492474555969\n",
      "epoch 142: loss=0.9617491364479065\n",
      "epoch 143: loss=0.9603021740913391\n",
      "epoch 144: loss=0.946054995059967\n",
      "epoch 145: loss=0.977274477481842\n",
      "epoch 146: loss=0.9721213579177856\n",
      "epoch 147: loss=0.9709621071815491\n",
      "epoch 148: loss=0.9863656163215637\n",
      "epoch 149: loss=0.9741776585578918\n",
      "epoch 150: loss=0.9754164218902588\n",
      "epoch 151: loss=0.9760924577713013\n",
      "epoch 152: loss=0.9756357669830322\n",
      "epoch 153: loss=0.9439627528190613\n",
      "epoch 154: loss=0.9496971368789673\n",
      "epoch 155: loss=0.9629167318344116\n",
      "epoch 156: loss=0.9794777631759644\n",
      "epoch 157: loss=0.9988594651222229\n",
      "epoch 158: loss=0.9522517323493958\n",
      "epoch 159: loss=0.9600544571876526\n",
      "epoch 160: loss=0.9774234890937805\n",
      "epoch 161: loss=0.9642423391342163\n",
      "epoch 162: loss=0.9661556482315063\n",
      "epoch 163: loss=0.9661828875541687\n",
      "epoch 164: loss=0.9626062512397766\n",
      "epoch 165: loss=0.9775238633155823\n",
      "epoch 166: loss=0.9684271216392517\n",
      "epoch 167: loss=0.9484866857528687\n",
      "epoch 168: loss=0.9728997945785522\n",
      "epoch 169: loss=0.9702448844909668\n",
      "epoch 170: loss=0.9538617134094238\n",
      "epoch 171: loss=0.9642228484153748\n",
      "epoch 172: loss=0.9412687420845032\n",
      "epoch 173: loss=0.970590353012085\n",
      "epoch 174: loss=0.9653548002243042\n",
      "epoch 175: loss=0.9612047672271729\n",
      "epoch 176: loss=0.9642725586891174\n",
      "epoch 177: loss=0.9844596982002258\n",
      "epoch 178: loss=0.9535379409790039\n",
      "epoch 179: loss=0.9609673023223877\n",
      "epoch 180: loss=0.9651802778244019\n",
      "epoch 181: loss=0.9726824760437012\n",
      "epoch 182: loss=0.9718068838119507\n",
      "epoch 183: loss=0.9515076875686646\n",
      "epoch 184: loss=0.9502562880516052\n",
      "epoch 185: loss=0.9466102123260498\n",
      "epoch 186: loss=0.9700791835784912\n",
      "epoch 187: loss=0.9533723592758179\n",
      "epoch 188: loss=0.9628154635429382\n",
      "epoch 189: loss=0.9694211483001709\n",
      "epoch 190: loss=0.9689168334007263\n",
      "epoch 191: loss=0.9569519758224487\n",
      "epoch 192: loss=0.9623523354530334\n",
      "epoch 193: loss=0.9794200658798218\n",
      "epoch 194: loss=0.9628215432167053\n",
      "epoch 195: loss=0.9590953588485718\n",
      "epoch 196: loss=0.9358053207397461\n",
      "epoch 197: loss=0.9674269556999207\n",
      "epoch 198: loss=0.966823399066925\n",
      "epoch 199: loss=0.9557907581329346\n",
      "training patch with 1946 edges\n",
      "epoch 0: loss=1.8725885152816772\n",
      "epoch 1: loss=1.6987675428390503\n",
      "epoch 2: loss=1.6426445245742798\n",
      "epoch 3: loss=1.5313009023666382\n",
      "epoch 4: loss=1.547572135925293\n",
      "epoch 5: loss=1.5074738264083862\n",
      "epoch 6: loss=1.4631270170211792\n",
      "epoch 7: loss=1.4507170915603638\n",
      "epoch 8: loss=1.4430378675460815\n",
      "epoch 9: loss=1.4147918224334717\n",
      "epoch 10: loss=1.4067375659942627\n",
      "epoch 11: loss=1.4142439365386963\n",
      "epoch 12: loss=1.3932380676269531\n",
      "epoch 13: loss=1.3865052461624146\n",
      "epoch 14: loss=1.3831391334533691\n",
      "epoch 15: loss=1.3747694492340088\n",
      "epoch 16: loss=1.3690983057022095\n",
      "epoch 17: loss=1.358187198638916\n",
      "epoch 18: loss=1.360039234161377\n",
      "epoch 19: loss=1.354568600654602\n",
      "epoch 20: loss=1.3528883457183838\n",
      "epoch 21: loss=1.3439915180206299\n",
      "epoch 22: loss=1.354004144668579\n",
      "epoch 23: loss=1.3414902687072754\n",
      "epoch 24: loss=1.3312222957611084\n",
      "epoch 25: loss=1.337414026260376\n",
      "epoch 26: loss=1.3248416185379028\n",
      "epoch 27: loss=1.3256468772888184\n",
      "epoch 28: loss=1.3201038837432861\n",
      "epoch 29: loss=1.3146204948425293\n",
      "epoch 30: loss=1.3097822666168213\n",
      "epoch 31: loss=1.3111141920089722\n",
      "epoch 32: loss=1.3032809495925903\n",
      "epoch 33: loss=1.2977333068847656\n",
      "epoch 34: loss=1.2952805757522583\n",
      "epoch 35: loss=1.2897899150848389\n",
      "epoch 36: loss=1.2826842069625854\n",
      "epoch 37: loss=1.2833871841430664\n",
      "epoch 38: loss=1.269516110420227\n",
      "epoch 39: loss=1.264727234840393\n",
      "epoch 40: loss=1.2580708265304565\n",
      "epoch 41: loss=1.2477740049362183\n",
      "epoch 42: loss=1.2447972297668457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43: loss=1.2376641035079956\n",
      "epoch 44: loss=1.2266218662261963\n",
      "epoch 45: loss=1.208970069885254\n",
      "epoch 46: loss=1.1994282007217407\n",
      "epoch 47: loss=1.1935542821884155\n",
      "epoch 48: loss=1.1794607639312744\n",
      "epoch 49: loss=1.1667749881744385\n",
      "epoch 50: loss=1.1436814069747925\n",
      "epoch 51: loss=1.1270116567611694\n",
      "epoch 52: loss=1.1201107501983643\n",
      "epoch 53: loss=1.1431154012680054\n",
      "epoch 54: loss=1.1266615390777588\n",
      "epoch 55: loss=1.1390289068222046\n",
      "epoch 56: loss=1.1260184049606323\n",
      "epoch 57: loss=1.1066174507141113\n",
      "epoch 58: loss=1.1413722038269043\n",
      "epoch 59: loss=1.104918360710144\n",
      "epoch 60: loss=1.1219594478607178\n",
      "epoch 61: loss=1.0772724151611328\n",
      "epoch 62: loss=1.0986559391021729\n",
      "epoch 63: loss=1.0839557647705078\n",
      "epoch 64: loss=1.1045222282409668\n",
      "epoch 65: loss=1.0928564071655273\n",
      "epoch 66: loss=1.080430030822754\n",
      "epoch 67: loss=1.088850736618042\n",
      "epoch 68: loss=1.0731730461120605\n",
      "epoch 69: loss=1.07463538646698\n",
      "epoch 70: loss=1.0385866165161133\n",
      "epoch 71: loss=1.0433228015899658\n",
      "epoch 72: loss=1.0282671451568604\n",
      "epoch 73: loss=1.038467288017273\n",
      "epoch 74: loss=1.0297051668167114\n",
      "epoch 75: loss=0.9968386292457581\n",
      "epoch 76: loss=1.0221667289733887\n",
      "epoch 77: loss=0.9864621758460999\n",
      "epoch 78: loss=0.9935417771339417\n",
      "epoch 79: loss=1.0007723569869995\n",
      "epoch 80: loss=0.9931198954582214\n",
      "epoch 81: loss=0.999173104763031\n",
      "epoch 82: loss=1.0120882987976074\n",
      "epoch 83: loss=0.9980611801147461\n",
      "epoch 84: loss=0.9741340279579163\n",
      "epoch 85: loss=0.9670516848564148\n",
      "epoch 86: loss=1.0063987970352173\n",
      "epoch 87: loss=0.9916331768035889\n",
      "epoch 88: loss=0.993031919002533\n",
      "epoch 89: loss=0.9825983643531799\n",
      "epoch 90: loss=0.9687052965164185\n",
      "epoch 91: loss=0.9662153124809265\n",
      "epoch 92: loss=0.9806578755378723\n",
      "epoch 93: loss=0.9929832816123962\n",
      "epoch 94: loss=0.9792847037315369\n",
      "epoch 95: loss=0.9801905751228333\n",
      "epoch 96: loss=0.9739840626716614\n",
      "epoch 97: loss=0.9737924337387085\n",
      "epoch 98: loss=0.9887683391571045\n",
      "epoch 99: loss=0.9879336953163147\n",
      "epoch 100: loss=0.9825546741485596\n",
      "epoch 101: loss=0.9677553772926331\n",
      "epoch 102: loss=0.9654527902603149\n",
      "epoch 103: loss=0.9735777974128723\n",
      "epoch 104: loss=0.963028073310852\n",
      "epoch 105: loss=0.9690437316894531\n",
      "epoch 106: loss=0.9691098928451538\n",
      "epoch 107: loss=1.0027251243591309\n",
      "epoch 108: loss=0.9880096316337585\n",
      "epoch 109: loss=0.986858606338501\n",
      "epoch 110: loss=0.9642482399940491\n",
      "epoch 111: loss=0.9572916626930237\n",
      "epoch 112: loss=0.9696561098098755\n",
      "epoch 113: loss=0.9663872718811035\n",
      "epoch 114: loss=0.9631273746490479\n",
      "epoch 115: loss=0.9720914363861084\n",
      "epoch 116: loss=0.9759594798088074\n",
      "epoch 117: loss=0.9694662094116211\n",
      "epoch 118: loss=0.9710597991943359\n",
      "epoch 119: loss=0.9576553702354431\n",
      "epoch 120: loss=0.9532614350318909\n",
      "epoch 121: loss=0.9597472548484802\n",
      "epoch 122: loss=0.9642717838287354\n",
      "epoch 123: loss=0.9694968461990356\n",
      "epoch 124: loss=0.9545555114746094\n",
      "epoch 125: loss=0.9766305088996887\n",
      "epoch 126: loss=0.9534950256347656\n",
      "epoch 127: loss=0.9704143404960632\n",
      "epoch 128: loss=0.9751737713813782\n",
      "epoch 129: loss=0.9689158797264099\n",
      "epoch 130: loss=0.9556965827941895\n",
      "epoch 131: loss=0.9847351908683777\n",
      "epoch 132: loss=0.9580970406532288\n",
      "epoch 133: loss=0.9656221866607666\n",
      "epoch 134: loss=0.9627737402915955\n",
      "epoch 135: loss=0.9627218842506409\n",
      "epoch 136: loss=0.9722011089324951\n",
      "epoch 137: loss=0.9720285534858704\n",
      "epoch 138: loss=0.9592509269714355\n",
      "epoch 139: loss=0.9703717827796936\n",
      "epoch 140: loss=0.9586694240570068\n",
      "epoch 141: loss=0.9498147368431091\n",
      "epoch 142: loss=0.947659432888031\n",
      "epoch 143: loss=0.9384516477584839\n",
      "epoch 144: loss=0.9798903465270996\n",
      "epoch 145: loss=0.9748604893684387\n",
      "epoch 146: loss=0.9715168476104736\n",
      "epoch 147: loss=0.9743585586547852\n",
      "epoch 148: loss=0.9692251682281494\n",
      "epoch 149: loss=0.9528045058250427\n",
      "epoch 150: loss=0.9591217637062073\n",
      "epoch 151: loss=0.9674217700958252\n",
      "epoch 152: loss=0.9711939096450806\n",
      "epoch 153: loss=0.981573224067688\n",
      "epoch 154: loss=0.9734145402908325\n",
      "epoch 155: loss=0.9701383113861084\n",
      "epoch 156: loss=0.9604082703590393\n",
      "epoch 157: loss=0.9678289890289307\n",
      "epoch 158: loss=0.9392567276954651\n",
      "epoch 159: loss=0.9557015299797058\n",
      "epoch 160: loss=0.9594529867172241\n",
      "epoch 161: loss=0.9445196390151978\n",
      "epoch 162: loss=0.9697235822677612\n",
      "epoch 163: loss=0.9662775993347168\n",
      "epoch 164: loss=0.9750715494155884\n",
      "epoch 165: loss=0.9507379531860352\n",
      "epoch 166: loss=0.9753814935684204\n",
      "epoch 167: loss=0.9691800475120544\n",
      "epoch 168: loss=0.9511734843254089\n",
      "epoch 169: loss=0.9601248502731323\n",
      "epoch 170: loss=0.9702365398406982\n",
      "epoch 171: loss=0.9330294728279114\n",
      "epoch 172: loss=0.9288613200187683\n",
      "epoch 173: loss=0.9329324960708618\n",
      "epoch 174: loss=0.9417953491210938\n",
      "epoch 175: loss=0.9556477665901184\n",
      "epoch 176: loss=0.9756025671958923\n",
      "epoch 177: loss=0.9683635830879211\n",
      "epoch 178: loss=0.9496194124221802\n",
      "epoch 179: loss=0.9378867149353027\n",
      "epoch 180: loss=0.9519962668418884\n",
      "epoch 181: loss=0.9590448141098022\n",
      "epoch 182: loss=0.9618839621543884\n",
      "epoch 183: loss=0.9429421424865723\n",
      "epoch 184: loss=0.9541495442390442\n",
      "epoch 185: loss=0.9631098508834839\n",
      "epoch 186: loss=0.9549564719200134\n",
      "epoch 187: loss=0.9557314515113831\n",
      "epoch 188: loss=0.9580929279327393\n",
      "epoch 189: loss=0.9514997601509094\n",
      "epoch 190: loss=0.9441673159599304\n",
      "epoch 191: loss=0.9864501953125\n",
      "epoch 192: loss=0.9548764228820801\n",
      "epoch 193: loss=0.9712115526199341\n",
      "epoch 194: loss=0.9470410346984863\n",
      "epoch 195: loss=0.9412133693695068\n",
      "epoch 196: loss=0.9649994969367981\n",
      "epoch 197: loss=0.9596964716911316\n",
      "epoch 198: loss=0.9383282661437988\n",
      "epoch 199: loss=0.9908652901649475\n",
      "training patch with 1878 edges\n",
      "epoch 0: loss=1.7822340726852417\n",
      "epoch 1: loss=1.6992533206939697\n",
      "epoch 2: loss=1.5951652526855469\n",
      "epoch 3: loss=1.6390712261199951\n",
      "epoch 4: loss=1.5650774240493774\n",
      "epoch 5: loss=1.5354716777801514\n",
      "epoch 6: loss=1.5031691789627075\n",
      "epoch 7: loss=1.5022313594818115\n",
      "epoch 8: loss=1.4714560508728027\n",
      "epoch 9: loss=1.433992624282837\n",
      "epoch 10: loss=1.428549885749817\n",
      "epoch 11: loss=1.4112210273742676\n",
      "epoch 12: loss=1.40801203250885\n",
      "epoch 13: loss=1.3988807201385498\n",
      "epoch 14: loss=1.3909119367599487\n",
      "epoch 15: loss=1.3678381443023682\n",
      "epoch 16: loss=1.3607386350631714\n",
      "epoch 17: loss=1.3657450675964355\n",
      "epoch 18: loss=1.3597863912582397\n",
      "epoch 19: loss=1.3456071615219116\n",
      "epoch 20: loss=1.3428293466567993\n",
      "epoch 21: loss=1.3354188203811646\n",
      "epoch 22: loss=1.3392890691757202\n",
      "epoch 23: loss=1.3210817575454712\n",
      "epoch 24: loss=1.3266537189483643\n",
      "epoch 25: loss=1.317655324935913\n",
      "epoch 26: loss=1.3031686544418335\n",
      "epoch 27: loss=1.308751106262207\n",
      "epoch 28: loss=1.2994823455810547\n",
      "epoch 29: loss=1.2921984195709229\n",
      "epoch 30: loss=1.28932523727417\n",
      "epoch 31: loss=1.291914939880371\n",
      "epoch 32: loss=1.280059576034546\n",
      "epoch 33: loss=1.267782211303711\n",
      "epoch 34: loss=1.264424204826355\n",
      "epoch 35: loss=1.2578566074371338\n",
      "epoch 36: loss=1.2441396713256836\n",
      "epoch 37: loss=1.2353955507278442\n",
      "epoch 38: loss=1.234915852546692\n",
      "epoch 39: loss=1.2207460403442383\n",
      "epoch 40: loss=1.2140415906906128\n",
      "epoch 41: loss=1.1998069286346436\n",
      "epoch 42: loss=1.1884452104568481\n",
      "epoch 43: loss=1.1801378726959229\n",
      "epoch 44: loss=1.1634931564331055\n",
      "epoch 45: loss=1.1532140970230103\n",
      "epoch 46: loss=1.1490075588226318\n",
      "epoch 47: loss=1.1197617053985596\n",
      "epoch 48: loss=1.1427096128463745\n",
      "epoch 49: loss=1.1521447896957397\n",
      "epoch 50: loss=1.1407833099365234\n",
      "epoch 51: loss=1.1470617055892944\n",
      "epoch 52: loss=1.146682620048523\n",
      "epoch 53: loss=1.1462844610214233\n",
      "epoch 54: loss=1.1354387998580933\n",
      "epoch 55: loss=1.1359593868255615\n",
      "epoch 56: loss=1.1230833530426025\n",
      "epoch 57: loss=1.1334266662597656\n",
      "epoch 58: loss=1.1214661598205566\n",
      "epoch 59: loss=1.1162574291229248\n",
      "epoch 60: loss=1.0998430252075195\n",
      "epoch 61: loss=1.1142817735671997\n",
      "epoch 62: loss=1.1068910360336304\n",
      "epoch 63: loss=1.1036428213119507\n",
      "epoch 64: loss=1.1202888488769531\n",
      "epoch 65: loss=1.114730954170227\n",
      "epoch 66: loss=1.104509711265564\n",
      "epoch 67: loss=1.0911688804626465\n",
      "epoch 68: loss=1.097082257270813\n",
      "epoch 69: loss=1.1059983968734741\n",
      "epoch 70: loss=1.0922421216964722\n",
      "epoch 71: loss=1.090604305267334\n",
      "epoch 72: loss=1.100857138633728\n",
      "epoch 73: loss=1.0891789197921753\n",
      "epoch 74: loss=1.0965882539749146\n",
      "epoch 75: loss=1.089231014251709\n",
      "epoch 76: loss=1.0746411085128784\n",
      "epoch 77: loss=1.0684462785720825\n",
      "epoch 78: loss=1.0685765743255615\n",
      "epoch 79: loss=1.0758754014968872\n",
      "epoch 80: loss=1.0858526229858398\n",
      "epoch 81: loss=1.0446690320968628\n",
      "epoch 82: loss=1.0498625040054321\n",
      "epoch 83: loss=1.046147108078003\n",
      "epoch 84: loss=1.0219758749008179\n",
      "epoch 85: loss=1.0348796844482422\n",
      "epoch 86: loss=1.022102952003479\n",
      "epoch 87: loss=1.0238338708877563\n",
      "epoch 88: loss=1.0336264371871948\n",
      "epoch 89: loss=1.0312581062316895\n",
      "epoch 90: loss=1.0063283443450928\n",
      "epoch 91: loss=0.994579553604126\n",
      "epoch 92: loss=0.9993982911109924\n",
      "epoch 93: loss=0.9914108514785767\n",
      "epoch 94: loss=1.0047731399536133\n",
      "epoch 95: loss=1.0143795013427734\n",
      "epoch 96: loss=1.0084367990493774\n",
      "epoch 97: loss=1.0127763748168945\n",
      "epoch 98: loss=1.012300729751587\n",
      "epoch 99: loss=1.004664421081543\n",
      "epoch 100: loss=1.004307746887207\n",
      "epoch 101: loss=0.9992199540138245\n",
      "epoch 102: loss=1.010191798210144\n",
      "epoch 103: loss=0.9993501305580139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104: loss=0.9872140884399414\n",
      "epoch 105: loss=1.0012446641921997\n",
      "epoch 106: loss=0.9813932180404663\n",
      "epoch 107: loss=1.000144600868225\n",
      "epoch 108: loss=0.9732341170310974\n",
      "epoch 109: loss=0.9873720407485962\n",
      "epoch 110: loss=0.98686683177948\n",
      "epoch 111: loss=1.0179290771484375\n",
      "epoch 112: loss=0.9866254329681396\n",
      "epoch 113: loss=0.9879934191703796\n",
      "epoch 114: loss=0.9781863689422607\n",
      "epoch 115: loss=1.0040041208267212\n",
      "epoch 116: loss=0.9844132661819458\n",
      "epoch 117: loss=0.9974520802497864\n",
      "epoch 118: loss=0.999420702457428\n",
      "epoch 119: loss=0.994133710861206\n",
      "epoch 120: loss=0.9801547527313232\n",
      "epoch 121: loss=0.972014844417572\n",
      "epoch 122: loss=0.9843537211418152\n",
      "epoch 123: loss=0.9885801076889038\n",
      "epoch 124: loss=0.9905703663825989\n",
      "epoch 125: loss=1.003961205482483\n",
      "epoch 126: loss=0.9985594153404236\n",
      "epoch 127: loss=0.9856363534927368\n",
      "epoch 128: loss=0.9709442853927612\n",
      "epoch 129: loss=0.9765706658363342\n",
      "epoch 130: loss=0.9955944418907166\n",
      "epoch 131: loss=0.9637917280197144\n",
      "epoch 132: loss=0.9912206530570984\n",
      "epoch 133: loss=0.986440896987915\n",
      "epoch 134: loss=0.971648097038269\n",
      "epoch 135: loss=0.9755037426948547\n",
      "epoch 136: loss=0.968246579170227\n",
      "epoch 137: loss=0.981290876865387\n",
      "epoch 138: loss=1.0023366212844849\n",
      "epoch 139: loss=0.968187689781189\n",
      "epoch 140: loss=0.971904456615448\n",
      "epoch 141: loss=0.9715813398361206\n",
      "epoch 142: loss=0.9967369437217712\n",
      "epoch 143: loss=0.9723125100135803\n",
      "epoch 144: loss=0.9504531621932983\n",
      "epoch 145: loss=0.9598489999771118\n",
      "epoch 146: loss=0.9968829154968262\n",
      "epoch 147: loss=0.9806466698646545\n",
      "epoch 148: loss=0.9875208735466003\n",
      "epoch 149: loss=0.9787235856056213\n",
      "epoch 150: loss=0.9800204038619995\n",
      "epoch 151: loss=0.9668893814086914\n",
      "epoch 152: loss=0.988402783870697\n",
      "epoch 153: loss=0.9973281621932983\n",
      "epoch 154: loss=0.9593433141708374\n",
      "epoch 155: loss=0.9791508913040161\n",
      "epoch 156: loss=0.9834457635879517\n",
      "epoch 157: loss=0.9678078293800354\n",
      "epoch 158: loss=0.9815964102745056\n",
      "epoch 159: loss=0.983709990978241\n",
      "epoch 160: loss=0.976253092288971\n",
      "epoch 161: loss=0.9606744647026062\n",
      "epoch 162: loss=0.9589717388153076\n",
      "epoch 163: loss=0.9740651249885559\n",
      "epoch 164: loss=0.9690859317779541\n",
      "epoch 165: loss=0.9907177686691284\n",
      "epoch 166: loss=0.9679602384567261\n",
      "epoch 167: loss=0.9805426597595215\n",
      "epoch 168: loss=0.9722999930381775\n",
      "epoch 169: loss=0.9562532901763916\n",
      "epoch 170: loss=0.9976292252540588\n",
      "epoch 171: loss=0.97438645362854\n",
      "epoch 172: loss=0.972376823425293\n",
      "epoch 173: loss=0.9748009443283081\n",
      "epoch 174: loss=0.9567428827285767\n",
      "epoch 175: loss=0.9739989042282104\n",
      "epoch 176: loss=0.9582675695419312\n",
      "epoch 177: loss=0.9726153612136841\n",
      "epoch 178: loss=0.9562110900878906\n",
      "epoch 179: loss=0.9492929577827454\n",
      "epoch 180: loss=0.9597163796424866\n",
      "epoch 181: loss=0.96183842420578\n",
      "epoch 182: loss=1.0041264295578003\n",
      "epoch 183: loss=0.9582977294921875\n",
      "epoch 184: loss=0.9616824984550476\n",
      "epoch 185: loss=0.9702857136726379\n",
      "epoch 186: loss=0.9928184747695923\n",
      "epoch 187: loss=0.9716989398002625\n",
      "epoch 188: loss=0.9768219590187073\n",
      "epoch 189: loss=0.9596128463745117\n",
      "epoch 190: loss=0.9776903390884399\n",
      "epoch 191: loss=0.9907147288322449\n",
      "epoch 192: loss=0.9712715148925781\n",
      "epoch 193: loss=0.9685236811637878\n",
      "epoch 194: loss=0.9580446481704712\n",
      "epoch 195: loss=0.9574064016342163\n",
      "epoch 196: loss=0.9819880723953247\n",
      "epoch 197: loss=0.9545778036117554\n",
      "epoch 198: loss=0.9740273952484131\n",
      "epoch 199: loss=0.9774954915046692\n",
      "training patch with 2784 edges\n",
      "epoch 0: loss=1.7106624841690063\n",
      "epoch 1: loss=1.7033631801605225\n",
      "epoch 2: loss=1.6320533752441406\n",
      "epoch 3: loss=1.582197666168213\n",
      "epoch 4: loss=1.5491158962249756\n",
      "epoch 5: loss=1.5209827423095703\n",
      "epoch 6: loss=1.4955369234085083\n",
      "epoch 7: loss=1.436171054840088\n",
      "epoch 8: loss=1.4289638996124268\n",
      "epoch 9: loss=1.4105310440063477\n",
      "epoch 10: loss=1.4098381996154785\n",
      "epoch 11: loss=1.4002981185913086\n",
      "epoch 12: loss=1.3834162950515747\n",
      "epoch 13: loss=1.381209135055542\n",
      "epoch 14: loss=1.3712176084518433\n",
      "epoch 15: loss=1.3532298803329468\n",
      "epoch 16: loss=1.3415123224258423\n",
      "epoch 17: loss=1.3380773067474365\n",
      "epoch 18: loss=1.337770938873291\n",
      "epoch 19: loss=1.3248417377471924\n",
      "epoch 20: loss=1.3308824300765991\n",
      "epoch 21: loss=1.3186875581741333\n",
      "epoch 22: loss=1.3162318468093872\n",
      "epoch 23: loss=1.3173298835754395\n",
      "epoch 24: loss=1.3146145343780518\n",
      "epoch 25: loss=1.294974446296692\n",
      "epoch 26: loss=1.297981858253479\n",
      "epoch 27: loss=1.2930748462677002\n",
      "epoch 28: loss=1.2866997718811035\n",
      "epoch 29: loss=1.2828787565231323\n",
      "epoch 30: loss=1.2779796123504639\n",
      "epoch 31: loss=1.268837809562683\n",
      "epoch 32: loss=1.2651664018630981\n",
      "epoch 33: loss=1.2619421482086182\n",
      "epoch 34: loss=1.263491153717041\n",
      "epoch 35: loss=1.2471916675567627\n",
      "epoch 36: loss=1.256447672843933\n",
      "epoch 37: loss=1.2447810173034668\n",
      "epoch 38: loss=1.2411311864852905\n",
      "epoch 39: loss=1.2265448570251465\n",
      "epoch 40: loss=1.222280502319336\n",
      "epoch 41: loss=1.211780309677124\n",
      "epoch 42: loss=1.2087838649749756\n",
      "epoch 43: loss=1.2026574611663818\n",
      "epoch 44: loss=1.187620997428894\n",
      "epoch 45: loss=1.1824824810028076\n",
      "epoch 46: loss=1.1922388076782227\n",
      "epoch 47: loss=1.1645236015319824\n",
      "epoch 48: loss=1.1532655954360962\n",
      "epoch 49: loss=1.1422431468963623\n",
      "epoch 50: loss=1.1563860177993774\n",
      "epoch 51: loss=1.1361873149871826\n",
      "epoch 52: loss=1.1212393045425415\n",
      "epoch 53: loss=1.111254334449768\n",
      "epoch 54: loss=1.1075531244277954\n",
      "epoch 55: loss=1.1116544008255005\n",
      "epoch 56: loss=1.0964624881744385\n",
      "epoch 57: loss=1.0879852771759033\n",
      "epoch 58: loss=1.0720546245574951\n",
      "epoch 59: loss=1.0672427415847778\n",
      "epoch 60: loss=1.0646623373031616\n",
      "epoch 61: loss=1.0470292568206787\n",
      "epoch 62: loss=1.048799753189087\n",
      "epoch 63: loss=1.0381667613983154\n",
      "epoch 64: loss=1.0200337171554565\n",
      "epoch 65: loss=1.0102936029434204\n",
      "epoch 66: loss=1.0003422498703003\n",
      "epoch 67: loss=1.0152838230133057\n",
      "epoch 68: loss=1.006116271018982\n",
      "epoch 69: loss=0.994875431060791\n",
      "epoch 70: loss=1.0082173347473145\n",
      "epoch 71: loss=0.9938153624534607\n",
      "epoch 72: loss=1.0091661214828491\n",
      "epoch 73: loss=0.9898911714553833\n",
      "epoch 74: loss=0.9935664534568787\n",
      "epoch 75: loss=0.9980143308639526\n",
      "epoch 76: loss=1.0099717378616333\n",
      "epoch 77: loss=0.9871745109558105\n",
      "epoch 78: loss=0.9863477349281311\n",
      "epoch 79: loss=0.9728273749351501\n",
      "epoch 80: loss=0.9797675013542175\n",
      "epoch 81: loss=0.978132426738739\n",
      "epoch 82: loss=0.9699079990386963\n",
      "epoch 83: loss=0.9779993295669556\n",
      "epoch 84: loss=0.9928483963012695\n",
      "epoch 85: loss=0.9840320348739624\n",
      "epoch 86: loss=0.9641790390014648\n",
      "epoch 87: loss=0.9756640195846558\n",
      "epoch 88: loss=0.9886154532432556\n",
      "epoch 89: loss=0.9692859649658203\n",
      "epoch 90: loss=0.9618439078330994\n",
      "epoch 91: loss=0.9837729930877686\n",
      "epoch 92: loss=0.9818004965782166\n",
      "epoch 93: loss=0.964541494846344\n",
      "epoch 94: loss=0.990050196647644\n",
      "epoch 95: loss=0.9557235836982727\n",
      "epoch 96: loss=0.9678078889846802\n",
      "epoch 97: loss=0.9675383567810059\n",
      "epoch 98: loss=0.948354959487915\n",
      "epoch 99: loss=0.9824985265731812\n",
      "epoch 100: loss=0.9730933308601379\n",
      "epoch 101: loss=0.9753345847129822\n",
      "epoch 102: loss=0.9756129384040833\n",
      "epoch 103: loss=0.9790213108062744\n",
      "epoch 104: loss=0.9611883163452148\n",
      "epoch 105: loss=0.9784437417984009\n",
      "epoch 106: loss=0.9868819713592529\n",
      "epoch 107: loss=0.9621647000312805\n",
      "epoch 108: loss=0.9635651111602783\n",
      "epoch 109: loss=0.9576385021209717\n",
      "epoch 110: loss=0.9676438570022583\n",
      "epoch 111: loss=0.9790217876434326\n",
      "epoch 112: loss=0.9748421311378479\n",
      "epoch 113: loss=0.9641111493110657\n",
      "epoch 114: loss=0.9649819731712341\n",
      "epoch 115: loss=0.9687092304229736\n",
      "epoch 116: loss=0.9842902421951294\n",
      "epoch 117: loss=0.9773327112197876\n",
      "epoch 118: loss=0.980014443397522\n",
      "epoch 119: loss=0.9535738825798035\n",
      "epoch 120: loss=0.9744216203689575\n",
      "epoch 121: loss=0.974367618560791\n",
      "epoch 122: loss=0.9735849499702454\n",
      "epoch 123: loss=0.9719247221946716\n",
      "epoch 124: loss=0.9619969129562378\n",
      "epoch 125: loss=0.9680405259132385\n",
      "epoch 126: loss=0.9698077440261841\n",
      "epoch 127: loss=0.9684662818908691\n",
      "epoch 128: loss=0.954944372177124\n",
      "epoch 129: loss=0.96538245677948\n",
      "epoch 130: loss=0.9634373784065247\n",
      "epoch 131: loss=0.9534410834312439\n",
      "epoch 132: loss=0.9667037725448608\n",
      "epoch 133: loss=0.9810711145401001\n",
      "epoch 134: loss=0.9651262760162354\n",
      "epoch 135: loss=0.9661929607391357\n",
      "epoch 136: loss=0.9592909812927246\n",
      "epoch 137: loss=0.9654729962348938\n",
      "epoch 138: loss=0.9529205560684204\n",
      "epoch 139: loss=0.9683107137680054\n",
      "epoch 140: loss=0.9519952535629272\n",
      "epoch 141: loss=0.9516333341598511\n",
      "epoch 142: loss=0.9588257074356079\n",
      "epoch 143: loss=0.9948236346244812\n",
      "epoch 144: loss=0.9624336361885071\n",
      "epoch 145: loss=0.9692857265472412\n",
      "epoch 146: loss=0.9726933836936951\n",
      "epoch 147: loss=0.969883143901825\n",
      "epoch 148: loss=0.9475809335708618\n",
      "epoch 149: loss=0.9598708748817444\n",
      "epoch 150: loss=0.9574143886566162\n",
      "epoch 151: loss=0.9587566256523132\n",
      "epoch 152: loss=0.9774771928787231\n",
      "epoch 153: loss=0.9772970080375671\n",
      "epoch 154: loss=0.9671480059623718\n",
      "epoch 155: loss=0.9633991718292236\n",
      "epoch 156: loss=0.9585453867912292\n",
      "epoch 157: loss=0.9743086695671082\n",
      "epoch 158: loss=0.9654348492622375\n",
      "epoch 159: loss=0.9635372161865234\n",
      "epoch 160: loss=0.9678177833557129\n",
      "epoch 161: loss=0.9355343580245972\n",
      "epoch 162: loss=0.9536629319190979\n",
      "epoch 163: loss=0.9848846793174744\n",
      "epoch 164: loss=0.9662864208221436\n",
      "epoch 165: loss=0.9525670409202576\n",
      "epoch 166: loss=0.95771723985672\n",
      "epoch 167: loss=0.9586670994758606\n",
      "epoch 168: loss=0.9655494093894958\n",
      "epoch 169: loss=0.9649547934532166\n",
      "epoch 170: loss=0.9515069127082825\n",
      "epoch 171: loss=0.9606965780258179\n",
      "epoch 172: loss=0.9596479535102844\n",
      "epoch 173: loss=0.9791104793548584\n",
      "epoch 174: loss=0.9440515041351318\n",
      "epoch 175: loss=0.9771880507469177\n",
      "epoch 176: loss=0.9473192095756531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177: loss=0.9337664842605591\n",
      "epoch 178: loss=0.9707657098770142\n",
      "epoch 179: loss=0.942715585231781\n",
      "epoch 180: loss=0.9716030955314636\n",
      "epoch 181: loss=0.9520891308784485\n",
      "epoch 182: loss=0.9632971286773682\n",
      "epoch 183: loss=0.9528834819793701\n",
      "epoch 184: loss=0.9579883813858032\n",
      "epoch 185: loss=0.9478664398193359\n",
      "epoch 186: loss=0.9707210063934326\n",
      "epoch 187: loss=0.9624890685081482\n",
      "epoch 188: loss=0.9488144516944885\n",
      "epoch 189: loss=0.9722074270248413\n",
      "epoch 190: loss=0.9685782194137573\n",
      "epoch 191: loss=0.9489490389823914\n",
      "epoch 192: loss=0.9730926156044006\n",
      "epoch 193: loss=0.9695573449134827\n",
      "epoch 194: loss=0.9396728873252869\n",
      "epoch 195: loss=0.9506189227104187\n",
      "epoch 196: loss=0.9763022661209106\n",
      "epoch 197: loss=0.937048077583313\n",
      "epoch 198: loss=0.9661986827850342\n",
      "epoch 199: loss=0.9479267597198486\n",
      "training patch with 1652 edges\n",
      "epoch 0: loss=1.7342280149459839\n",
      "epoch 1: loss=1.6876510381698608\n",
      "epoch 2: loss=1.587348222732544\n",
      "epoch 3: loss=1.5689148902893066\n",
      "epoch 4: loss=1.5703543424606323\n",
      "epoch 5: loss=1.5444403886795044\n",
      "epoch 6: loss=1.5283637046813965\n",
      "epoch 7: loss=1.4897435903549194\n",
      "epoch 8: loss=1.461506962776184\n",
      "epoch 9: loss=1.443387746810913\n",
      "epoch 10: loss=1.426949381828308\n",
      "epoch 11: loss=1.4187036752700806\n",
      "epoch 12: loss=1.4062944650650024\n",
      "epoch 13: loss=1.397101879119873\n",
      "epoch 14: loss=1.3974031209945679\n",
      "epoch 15: loss=1.3854364156723022\n",
      "epoch 16: loss=1.368125557899475\n",
      "epoch 17: loss=1.3644014596939087\n",
      "epoch 18: loss=1.358948826789856\n",
      "epoch 19: loss=1.352667212486267\n",
      "epoch 20: loss=1.3418822288513184\n",
      "epoch 21: loss=1.3439143896102905\n",
      "epoch 22: loss=1.3576091527938843\n",
      "epoch 23: loss=1.3386867046356201\n",
      "epoch 24: loss=1.326678991317749\n",
      "epoch 25: loss=1.3062341213226318\n",
      "epoch 26: loss=1.3052620887756348\n",
      "epoch 27: loss=1.2972023487091064\n",
      "epoch 28: loss=1.3007255792617798\n",
      "epoch 29: loss=1.2887088060379028\n",
      "epoch 30: loss=1.2786412239074707\n",
      "epoch 31: loss=1.2691102027893066\n",
      "epoch 32: loss=1.2488161325454712\n",
      "epoch 33: loss=1.2322163581848145\n",
      "epoch 34: loss=1.2133541107177734\n",
      "epoch 35: loss=1.202194094657898\n",
      "epoch 36: loss=1.1982955932617188\n",
      "epoch 37: loss=1.163568377494812\n",
      "epoch 38: loss=1.1663599014282227\n",
      "epoch 39: loss=1.134871244430542\n",
      "epoch 40: loss=1.1321702003479004\n",
      "epoch 41: loss=1.1257747411727905\n",
      "epoch 42: loss=1.1002622842788696\n",
      "epoch 43: loss=1.1223955154418945\n",
      "epoch 44: loss=1.1387782096862793\n",
      "epoch 45: loss=1.1275465488433838\n",
      "epoch 46: loss=1.1212348937988281\n",
      "epoch 47: loss=1.0811294317245483\n",
      "epoch 48: loss=1.1015572547912598\n",
      "epoch 49: loss=1.0768587589263916\n",
      "epoch 50: loss=1.0915265083312988\n",
      "epoch 51: loss=1.0486668348312378\n",
      "epoch 52: loss=1.074318528175354\n",
      "epoch 53: loss=1.0609829425811768\n",
      "epoch 54: loss=1.0619598627090454\n",
      "epoch 55: loss=1.0572715997695923\n",
      "epoch 56: loss=1.0536231994628906\n",
      "epoch 57: loss=1.046414852142334\n",
      "epoch 58: loss=1.03426194190979\n",
      "epoch 59: loss=1.0393093824386597\n",
      "epoch 60: loss=1.0184835195541382\n",
      "epoch 61: loss=1.033044457435608\n",
      "epoch 62: loss=1.007680892944336\n",
      "epoch 63: loss=0.9919483065605164\n",
      "epoch 64: loss=1.0169504880905151\n",
      "epoch 65: loss=1.0183935165405273\n",
      "epoch 66: loss=1.0310662984848022\n",
      "epoch 67: loss=0.9997333288192749\n",
      "epoch 68: loss=1.0233725309371948\n",
      "epoch 69: loss=1.013620138168335\n",
      "epoch 70: loss=1.0038669109344482\n",
      "epoch 71: loss=0.9909154176712036\n",
      "epoch 72: loss=1.0186896324157715\n",
      "epoch 73: loss=0.9975992441177368\n",
      "epoch 74: loss=0.9985532760620117\n",
      "epoch 75: loss=1.0176188945770264\n",
      "epoch 76: loss=1.015566110610962\n",
      "epoch 77: loss=0.9855121374130249\n",
      "epoch 78: loss=0.9893888831138611\n",
      "epoch 79: loss=1.0168827772140503\n",
      "epoch 80: loss=1.0042017698287964\n",
      "epoch 81: loss=0.9815612435340881\n",
      "epoch 82: loss=0.987568736076355\n",
      "epoch 83: loss=0.9783352017402649\n",
      "epoch 84: loss=0.9906930923461914\n",
      "epoch 85: loss=0.9773101806640625\n",
      "epoch 86: loss=0.9731048941612244\n",
      "epoch 87: loss=0.9555798768997192\n",
      "epoch 88: loss=0.987126886844635\n",
      "epoch 89: loss=1.0030999183654785\n",
      "epoch 90: loss=0.9925804734230042\n",
      "epoch 91: loss=0.9915944337844849\n",
      "epoch 92: loss=0.9830628037452698\n",
      "epoch 93: loss=0.9860935211181641\n",
      "epoch 94: loss=0.9993162751197815\n",
      "epoch 95: loss=0.9812412858009338\n",
      "epoch 96: loss=0.9651854634284973\n",
      "epoch 97: loss=0.974098265171051\n",
      "epoch 98: loss=0.9748818278312683\n",
      "epoch 99: loss=0.9905722737312317\n",
      "epoch 100: loss=0.968718945980072\n",
      "epoch 101: loss=0.9699190258979797\n",
      "epoch 102: loss=0.9736957550048828\n",
      "epoch 103: loss=0.9707097411155701\n",
      "epoch 104: loss=0.9652798175811768\n",
      "epoch 105: loss=0.9643645286560059\n",
      "epoch 106: loss=0.9703474640846252\n",
      "epoch 107: loss=0.9698892831802368\n",
      "epoch 108: loss=0.9423195719718933\n",
      "epoch 109: loss=0.983122706413269\n",
      "epoch 110: loss=0.9549046754837036\n",
      "epoch 111: loss=0.9654550552368164\n",
      "epoch 112: loss=0.9524106979370117\n",
      "epoch 113: loss=0.9731870293617249\n",
      "epoch 114: loss=0.9793418645858765\n",
      "epoch 115: loss=0.9681861400604248\n",
      "epoch 116: loss=0.9680708050727844\n",
      "epoch 117: loss=0.9734760522842407\n",
      "epoch 118: loss=0.96676105260849\n",
      "epoch 119: loss=0.9752251505851746\n",
      "epoch 120: loss=0.9812718033790588\n",
      "epoch 121: loss=0.9924991130828857\n",
      "epoch 122: loss=0.9736073613166809\n",
      "epoch 123: loss=0.9547377824783325\n",
      "epoch 124: loss=0.9621288776397705\n",
      "epoch 125: loss=0.9563363790512085\n",
      "epoch 126: loss=0.9664838314056396\n",
      "epoch 127: loss=0.9443098306655884\n",
      "epoch 128: loss=0.9499348998069763\n",
      "epoch 129: loss=0.975884735584259\n",
      "epoch 130: loss=0.9833341240882874\n",
      "epoch 131: loss=0.9470595717430115\n",
      "epoch 132: loss=0.9633819460868835\n",
      "epoch 133: loss=0.9682149291038513\n",
      "epoch 134: loss=0.9678781032562256\n",
      "epoch 135: loss=0.9714691638946533\n",
      "epoch 136: loss=0.9679151773452759\n",
      "epoch 137: loss=0.9501302242279053\n",
      "epoch 138: loss=0.9863142967224121\n",
      "epoch 139: loss=0.9745675921440125\n",
      "epoch 140: loss=0.9635130763053894\n",
      "epoch 141: loss=0.9534446001052856\n",
      "epoch 142: loss=0.9637773633003235\n",
      "epoch 143: loss=0.9600429534912109\n",
      "epoch 144: loss=0.9619395732879639\n",
      "epoch 145: loss=0.9367392659187317\n",
      "epoch 146: loss=0.9563575983047485\n",
      "epoch 147: loss=0.9686498641967773\n",
      "epoch 148: loss=0.9793144464492798\n",
      "epoch 149: loss=0.9624103903770447\n",
      "epoch 150: loss=0.9594677686691284\n",
      "epoch 151: loss=0.9439329504966736\n",
      "epoch 152: loss=0.9522819519042969\n",
      "epoch 153: loss=0.9824380278587341\n",
      "epoch 154: loss=0.9315142631530762\n",
      "epoch 155: loss=0.9428983926773071\n",
      "epoch 156: loss=0.9700620770454407\n",
      "epoch 157: loss=0.9807235598564148\n",
      "epoch 158: loss=0.9487576484680176\n",
      "epoch 159: loss=0.9442225098609924\n",
      "epoch 160: loss=0.9629620909690857\n",
      "epoch 161: loss=0.9793395400047302\n",
      "epoch 162: loss=0.9595417976379395\n",
      "epoch 163: loss=0.9475357532501221\n",
      "epoch 164: loss=0.9595667719841003\n",
      "epoch 165: loss=0.966994047164917\n",
      "epoch 166: loss=0.9610676765441895\n",
      "epoch 167: loss=0.9474031925201416\n",
      "epoch 168: loss=0.9701648354530334\n",
      "epoch 169: loss=0.9645269513130188\n",
      "epoch 170: loss=0.9573329091072083\n",
      "epoch 171: loss=0.9402000308036804\n",
      "epoch 172: loss=0.9482398629188538\n",
      "epoch 173: loss=0.9531455636024475\n",
      "epoch 174: loss=0.9655553698539734\n",
      "epoch 175: loss=0.9441932439804077\n",
      "epoch 176: loss=0.9522550702095032\n",
      "epoch 177: loss=0.9513233304023743\n",
      "epoch 178: loss=0.9432737231254578\n",
      "epoch 179: loss=0.9662798643112183\n",
      "epoch 180: loss=0.9312485456466675\n",
      "epoch 181: loss=0.9878857731819153\n",
      "epoch 182: loss=0.9742178916931152\n",
      "epoch 183: loss=0.958762526512146\n",
      "epoch 184: loss=0.9378815293312073\n",
      "epoch 185: loss=0.9665407538414001\n",
      "epoch 186: loss=0.9413571953773499\n",
      "epoch 187: loss=0.9375260472297668\n",
      "epoch 188: loss=0.9687411785125732\n",
      "epoch 189: loss=0.9647523164749146\n",
      "epoch 190: loss=0.9699629545211792\n",
      "epoch 191: loss=0.9432419538497925\n",
      "epoch 192: loss=0.943392813205719\n",
      "epoch 193: loss=0.9221556186676025\n",
      "epoch 194: loss=0.9543616771697998\n",
      "epoch 195: loss=0.919191300868988\n",
      "epoch 196: loss=0.9725478291511536\n",
      "epoch 197: loss=0.9445198774337769\n",
      "epoch 198: loss=0.938380241394043\n",
      "epoch 199: loss=0.964039146900177\n",
      "training patch with 840 edges\n",
      "epoch 0: loss=1.801205039024353\n",
      "epoch 1: loss=1.6782976388931274\n",
      "epoch 2: loss=1.586847186088562\n",
      "epoch 3: loss=1.6042957305908203\n",
      "epoch 4: loss=1.5192149877548218\n",
      "epoch 5: loss=1.5015324354171753\n",
      "epoch 6: loss=1.517691731452942\n",
      "epoch 7: loss=1.4963468313217163\n",
      "epoch 8: loss=1.4424570798873901\n",
      "epoch 9: loss=1.4478428363800049\n",
      "epoch 10: loss=1.430171012878418\n",
      "epoch 11: loss=1.4377801418304443\n",
      "epoch 12: loss=1.3929224014282227\n",
      "epoch 13: loss=1.408657431602478\n",
      "epoch 14: loss=1.3984198570251465\n",
      "epoch 15: loss=1.3897987604141235\n",
      "epoch 16: loss=1.380564570426941\n",
      "epoch 17: loss=1.3836010694503784\n",
      "epoch 18: loss=1.367357611656189\n",
      "epoch 19: loss=1.3520019054412842\n",
      "epoch 20: loss=1.3334015607833862\n",
      "epoch 21: loss=1.3348158597946167\n",
      "epoch 22: loss=1.324108362197876\n",
      "epoch 23: loss=1.3247649669647217\n",
      "epoch 24: loss=1.3204329013824463\n",
      "epoch 25: loss=1.339145302772522\n",
      "epoch 26: loss=1.3142004013061523\n",
      "epoch 27: loss=1.3084830045700073\n",
      "epoch 28: loss=1.3137187957763672\n",
      "epoch 29: loss=1.2873692512512207\n",
      "epoch 30: loss=1.3022342920303345\n",
      "epoch 31: loss=1.2911468744277954\n",
      "epoch 32: loss=1.2773858308792114\n",
      "epoch 33: loss=1.280195951461792\n",
      "epoch 34: loss=1.2697712182998657\n",
      "epoch 35: loss=1.2515432834625244\n",
      "epoch 36: loss=1.256369709968567\n",
      "epoch 37: loss=1.2405567169189453\n",
      "epoch 38: loss=1.232010841369629\n",
      "epoch 39: loss=1.2230641841888428\n",
      "epoch 40: loss=1.2200872898101807\n",
      "epoch 41: loss=1.2161842584609985\n",
      "epoch 42: loss=1.2025725841522217\n",
      "epoch 43: loss=1.1686005592346191\n",
      "epoch 44: loss=1.1767643690109253\n",
      "epoch 45: loss=1.1506723165512085\n",
      "epoch 46: loss=1.140855312347412\n",
      "epoch 47: loss=1.1182243824005127\n",
      "epoch 48: loss=1.117915391921997\n",
      "epoch 49: loss=1.1107696294784546\n",
      "epoch 50: loss=1.082970380783081\n",
      "epoch 51: loss=1.0866572856903076\n",
      "epoch 52: loss=1.097664475440979\n",
      "epoch 53: loss=1.1192476749420166\n",
      "epoch 54: loss=1.0685899257659912\n",
      "epoch 55: loss=1.0579863786697388\n",
      "epoch 56: loss=1.0617226362228394\n",
      "epoch 57: loss=1.1181436777114868\n",
      "epoch 58: loss=1.0870741605758667\n",
      "epoch 59: loss=1.0613104104995728\n",
      "epoch 60: loss=1.0699983835220337\n",
      "epoch 61: loss=1.04654860496521\n",
      "epoch 62: loss=1.0713475942611694\n",
      "epoch 63: loss=1.0065728425979614\n",
      "epoch 64: loss=1.0418896675109863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65: loss=1.0360774993896484\n",
      "epoch 66: loss=1.0645073652267456\n",
      "epoch 67: loss=1.016201376914978\n",
      "epoch 68: loss=1.0295366048812866\n",
      "epoch 69: loss=1.0240541696548462\n",
      "epoch 70: loss=0.9927130341529846\n",
      "epoch 71: loss=1.01851487159729\n",
      "epoch 72: loss=1.0063074827194214\n",
      "epoch 73: loss=0.9777759313583374\n",
      "epoch 74: loss=0.9913766980171204\n",
      "epoch 75: loss=0.9913200736045837\n",
      "epoch 76: loss=0.9885441064834595\n",
      "epoch 77: loss=0.9883134961128235\n",
      "epoch 78: loss=0.9748944044113159\n",
      "epoch 79: loss=0.9995884299278259\n",
      "epoch 80: loss=0.9717932939529419\n",
      "epoch 81: loss=0.9474152326583862\n",
      "epoch 82: loss=0.9481330513954163\n",
      "epoch 83: loss=0.989234447479248\n",
      "epoch 84: loss=0.950275182723999\n",
      "epoch 85: loss=0.9965720772743225\n",
      "epoch 86: loss=0.9379376173019409\n",
      "epoch 87: loss=0.9888905882835388\n",
      "epoch 88: loss=0.9782651662826538\n",
      "epoch 89: loss=0.9635607004165649\n",
      "epoch 90: loss=0.9686891436576843\n",
      "epoch 91: loss=0.9837499260902405\n",
      "epoch 92: loss=0.9656471610069275\n",
      "epoch 93: loss=0.9365776181221008\n",
      "epoch 94: loss=0.9611781239509583\n",
      "epoch 95: loss=0.9550199508666992\n",
      "epoch 96: loss=0.9462114572525024\n",
      "epoch 97: loss=0.9691079258918762\n",
      "epoch 98: loss=0.9243221879005432\n",
      "epoch 99: loss=0.9623942375183105\n",
      "epoch 100: loss=0.9611244201660156\n",
      "epoch 101: loss=0.9568423628807068\n",
      "epoch 102: loss=0.9692072868347168\n",
      "epoch 103: loss=0.9825410842895508\n",
      "epoch 104: loss=0.9425343871116638\n",
      "epoch 105: loss=0.9630554914474487\n",
      "epoch 106: loss=0.943742036819458\n",
      "epoch 107: loss=0.9572734832763672\n",
      "epoch 108: loss=0.9613755941390991\n",
      "epoch 109: loss=0.9854049682617188\n",
      "epoch 110: loss=0.9497641921043396\n",
      "epoch 111: loss=0.9524583220481873\n",
      "epoch 112: loss=0.9490654468536377\n",
      "epoch 113: loss=0.9623422026634216\n",
      "epoch 114: loss=0.9629797339439392\n",
      "epoch 115: loss=0.9521905183792114\n",
      "epoch 116: loss=0.9534226655960083\n",
      "epoch 117: loss=0.9795757532119751\n",
      "epoch 118: loss=0.9941815733909607\n",
      "epoch 119: loss=0.9582971334457397\n",
      "epoch 120: loss=0.9706944227218628\n",
      "epoch 121: loss=0.9720129370689392\n",
      "epoch 122: loss=0.9836545586585999\n",
      "epoch 123: loss=0.9735992550849915\n",
      "epoch 124: loss=0.9856375455856323\n",
      "epoch 125: loss=0.9397188425064087\n",
      "epoch 126: loss=0.9468266367912292\n",
      "epoch 127: loss=0.9376353025436401\n",
      "epoch 128: loss=0.9707827568054199\n",
      "epoch 129: loss=0.9738879203796387\n",
      "epoch 130: loss=0.9396647810935974\n",
      "epoch 131: loss=0.9397402405738831\n",
      "epoch 132: loss=0.934881329536438\n",
      "epoch 133: loss=0.957804262638092\n",
      "epoch 134: loss=0.9736328721046448\n",
      "epoch 135: loss=0.9463869333267212\n",
      "epoch 136: loss=0.9296285510063171\n",
      "epoch 137: loss=0.9491841793060303\n",
      "epoch 138: loss=0.9388927817344666\n",
      "epoch 139: loss=0.9711636900901794\n",
      "epoch 140: loss=0.9621871709823608\n",
      "epoch 141: loss=0.974330484867096\n",
      "epoch 142: loss=0.9625855684280396\n",
      "epoch 143: loss=0.9286286234855652\n",
      "epoch 144: loss=0.9596242904663086\n",
      "epoch 145: loss=0.9796618819236755\n",
      "epoch 146: loss=0.9253568053245544\n",
      "epoch 147: loss=0.9524134993553162\n",
      "epoch 148: loss=0.962343692779541\n",
      "epoch 149: loss=0.9917026162147522\n",
      "epoch 150: loss=0.9224281311035156\n",
      "epoch 151: loss=0.9410668015480042\n",
      "epoch 152: loss=0.9328212738037109\n",
      "epoch 153: loss=0.9500344395637512\n",
      "epoch 154: loss=0.9183300733566284\n",
      "epoch 155: loss=0.9237280488014221\n",
      "epoch 156: loss=0.9277238249778748\n",
      "epoch 157: loss=0.9628112316131592\n",
      "epoch 158: loss=0.9286745190620422\n",
      "epoch 159: loss=0.9653123021125793\n",
      "epoch 160: loss=0.9432895183563232\n",
      "epoch 161: loss=0.960888147354126\n",
      "epoch 162: loss=0.9316195845603943\n",
      "epoch 163: loss=0.940867006778717\n",
      "epoch 164: loss=0.9693392515182495\n",
      "epoch 165: loss=0.9348888993263245\n",
      "epoch 166: loss=0.9432240724563599\n",
      "epoch 167: loss=0.9345219731330872\n",
      "epoch 168: loss=0.9671122431755066\n",
      "epoch 169: loss=0.9300577044487\n",
      "epoch 170: loss=0.9251508712768555\n",
      "epoch 171: loss=0.918015718460083\n",
      "epoch 172: loss=0.9420152902603149\n",
      "epoch 173: loss=0.9582476019859314\n",
      "epoch 174: loss=0.9398397207260132\n",
      "epoch 175: loss=0.9666401743888855\n",
      "epoch 176: loss=0.9597184062004089\n",
      "epoch 177: loss=0.9116942882537842\n",
      "epoch 178: loss=0.9321852922439575\n",
      "epoch 179: loss=0.9333183765411377\n",
      "epoch 180: loss=0.9348185062408447\n",
      "epoch 181: loss=0.95091712474823\n",
      "epoch 182: loss=0.9301577210426331\n",
      "epoch 183: loss=0.9356013536453247\n",
      "epoch 184: loss=0.9544975757598877\n",
      "epoch 185: loss=0.928343653678894\n",
      "epoch 186: loss=0.9837316274642944\n",
      "epoch 187: loss=0.9157079458236694\n",
      "epoch 188: loss=0.9501281380653381\n",
      "epoch 189: loss=0.9403283596038818\n",
      "epoch 190: loss=0.9584569931030273\n",
      "epoch 191: loss=0.9429114460945129\n",
      "epoch 192: loss=0.9440097212791443\n",
      "epoch 193: loss=0.9462368488311768\n",
      "epoch 194: loss=0.9244120121002197\n",
      "epoch 195: loss=0.9660362005233765\n",
      "epoch 196: loss=0.9387317895889282\n",
      "epoch 197: loss=0.9641473293304443\n",
      "epoch 198: loss=0.9420960545539856\n",
      "epoch 199: loss=0.9738507270812988\n",
      "training patch with 1460 edges\n",
      "epoch 0: loss=1.7529590129852295\n",
      "epoch 1: loss=1.6365431547164917\n",
      "epoch 2: loss=1.6048139333724976\n",
      "epoch 3: loss=1.5985403060913086\n",
      "epoch 4: loss=1.5870040655136108\n",
      "epoch 5: loss=1.5261424779891968\n",
      "epoch 6: loss=1.4910376071929932\n",
      "epoch 7: loss=1.4760018587112427\n",
      "epoch 8: loss=1.4380477666854858\n",
      "epoch 9: loss=1.441449761390686\n",
      "epoch 10: loss=1.435912013053894\n",
      "epoch 11: loss=1.41426420211792\n",
      "epoch 12: loss=1.3998280763626099\n",
      "epoch 13: loss=1.3952800035476685\n",
      "epoch 14: loss=1.3759748935699463\n",
      "epoch 15: loss=1.3705636262893677\n",
      "epoch 16: loss=1.3517098426818848\n",
      "epoch 17: loss=1.3372067213058472\n",
      "epoch 18: loss=1.3381367921829224\n",
      "epoch 19: loss=1.3198813199996948\n",
      "epoch 20: loss=1.3236401081085205\n",
      "epoch 21: loss=1.3226937055587769\n",
      "epoch 22: loss=1.3114017248153687\n",
      "epoch 23: loss=1.2856359481811523\n",
      "epoch 24: loss=1.2855733633041382\n",
      "epoch 25: loss=1.2765899896621704\n",
      "epoch 26: loss=1.2778772115707397\n",
      "epoch 27: loss=1.2761945724487305\n",
      "epoch 28: loss=1.2665091753005981\n",
      "epoch 29: loss=1.2651081085205078\n",
      "epoch 30: loss=1.2721461057662964\n",
      "epoch 31: loss=1.262261986732483\n",
      "epoch 32: loss=1.2553491592407227\n",
      "epoch 33: loss=1.2415521144866943\n",
      "epoch 34: loss=1.241132140159607\n",
      "epoch 35: loss=1.2284339666366577\n",
      "epoch 36: loss=1.2303102016448975\n",
      "epoch 37: loss=1.221492052078247\n",
      "epoch 38: loss=1.2311519384384155\n",
      "epoch 39: loss=1.222398281097412\n",
      "epoch 40: loss=1.2157304286956787\n",
      "epoch 41: loss=1.203979253768921\n",
      "epoch 42: loss=1.201451301574707\n",
      "epoch 43: loss=1.1951496601104736\n",
      "epoch 44: loss=1.1806060075759888\n",
      "epoch 45: loss=1.1890989542007446\n",
      "epoch 46: loss=1.167375087738037\n",
      "epoch 47: loss=1.1597641706466675\n",
      "epoch 48: loss=1.1502737998962402\n",
      "epoch 49: loss=1.134390950202942\n",
      "epoch 50: loss=1.1572185754776\n",
      "epoch 51: loss=1.1369762420654297\n",
      "epoch 52: loss=1.14781653881073\n",
      "epoch 53: loss=1.1454100608825684\n",
      "epoch 54: loss=1.1308705806732178\n",
      "epoch 55: loss=1.1096662282943726\n",
      "epoch 56: loss=1.1266324520111084\n",
      "epoch 57: loss=1.0940438508987427\n",
      "epoch 58: loss=1.0999985933303833\n",
      "epoch 59: loss=1.145652413368225\n",
      "epoch 60: loss=1.1230943202972412\n",
      "epoch 61: loss=1.1167842149734497\n",
      "epoch 62: loss=1.0992485284805298\n",
      "epoch 63: loss=1.1179280281066895\n",
      "epoch 64: loss=1.1287734508514404\n",
      "epoch 65: loss=1.1115525960922241\n",
      "epoch 66: loss=1.116951584815979\n",
      "epoch 67: loss=1.1098945140838623\n",
      "epoch 68: loss=1.0733221769332886\n",
      "epoch 69: loss=1.1015585660934448\n",
      "epoch 70: loss=1.0690840482711792\n",
      "epoch 71: loss=1.0647679567337036\n",
      "epoch 72: loss=1.0574191808700562\n",
      "epoch 73: loss=1.0649882555007935\n",
      "epoch 74: loss=1.0357110500335693\n",
      "epoch 75: loss=1.0285426378250122\n",
      "epoch 76: loss=1.033424973487854\n",
      "epoch 77: loss=1.0473960638046265\n",
      "epoch 78: loss=1.0072193145751953\n",
      "epoch 79: loss=1.0242654085159302\n",
      "epoch 80: loss=1.017366647720337\n",
      "epoch 81: loss=1.0246301889419556\n",
      "epoch 82: loss=1.0178991556167603\n",
      "epoch 83: loss=1.0338331460952759\n",
      "epoch 84: loss=1.004947543144226\n",
      "epoch 85: loss=1.01567804813385\n",
      "epoch 86: loss=1.0146199464797974\n",
      "epoch 87: loss=0.9922745227813721\n",
      "epoch 88: loss=0.9945938587188721\n",
      "epoch 89: loss=0.9993919730186462\n",
      "epoch 90: loss=0.9874570369720459\n",
      "epoch 91: loss=0.9707087874412537\n",
      "epoch 92: loss=0.9961730241775513\n",
      "epoch 93: loss=0.9743133187294006\n",
      "epoch 94: loss=1.0033185482025146\n",
      "epoch 95: loss=0.978754997253418\n",
      "epoch 96: loss=0.9916683435440063\n",
      "epoch 97: loss=0.9918335676193237\n",
      "epoch 98: loss=1.0006656646728516\n",
      "epoch 99: loss=0.9999997615814209\n",
      "epoch 100: loss=0.9900769591331482\n",
      "epoch 101: loss=0.9589551091194153\n",
      "epoch 102: loss=0.9687203168869019\n",
      "epoch 103: loss=0.9803381562232971\n",
      "epoch 104: loss=0.975110650062561\n",
      "epoch 105: loss=0.9530395865440369\n",
      "epoch 106: loss=0.9950233101844788\n",
      "epoch 107: loss=0.9571327567100525\n",
      "epoch 108: loss=0.9596273303031921\n",
      "epoch 109: loss=0.9843594431877136\n",
      "epoch 110: loss=0.9861137270927429\n",
      "epoch 111: loss=0.947108268737793\n",
      "epoch 112: loss=0.9836356043815613\n",
      "epoch 113: loss=0.9778458476066589\n",
      "epoch 114: loss=0.9597582221031189\n",
      "epoch 115: loss=1.0244698524475098\n",
      "epoch 116: loss=0.9776972532272339\n",
      "epoch 117: loss=0.971668541431427\n",
      "epoch 118: loss=0.9772684574127197\n",
      "epoch 119: loss=0.9751279354095459\n",
      "epoch 120: loss=0.9534502625465393\n",
      "epoch 121: loss=0.9608295559883118\n",
      "epoch 122: loss=0.973294734954834\n",
      "epoch 123: loss=0.9575541019439697\n",
      "epoch 124: loss=0.9761537909507751\n",
      "epoch 125: loss=0.9972016215324402\n",
      "epoch 126: loss=0.9631022810935974\n",
      "epoch 127: loss=0.9601361751556396\n",
      "epoch 128: loss=0.9607059359550476\n",
      "epoch 129: loss=0.941702663898468\n",
      "epoch 130: loss=0.9662684798240662\n",
      "epoch 131: loss=0.9756703972816467\n",
      "epoch 132: loss=0.9644954800605774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 133: loss=0.9660568833351135\n",
      "epoch 134: loss=0.9809668660163879\n",
      "epoch 135: loss=0.9763145446777344\n",
      "epoch 136: loss=0.943857729434967\n",
      "epoch 137: loss=0.9693209528923035\n",
      "epoch 138: loss=0.975113034248352\n",
      "epoch 139: loss=0.9885708689689636\n",
      "epoch 140: loss=0.9750410914421082\n",
      "epoch 141: loss=0.9776111245155334\n",
      "epoch 142: loss=0.963723361492157\n",
      "epoch 143: loss=0.966632604598999\n",
      "epoch 144: loss=0.9888356924057007\n",
      "epoch 145: loss=0.9785770773887634\n",
      "epoch 146: loss=0.9399605393409729\n",
      "epoch 147: loss=0.9716765880584717\n",
      "epoch 148: loss=0.9606712460517883\n",
      "epoch 149: loss=0.9694646596908569\n",
      "epoch 150: loss=0.9465963244438171\n",
      "epoch 151: loss=0.9475286602973938\n",
      "epoch 152: loss=0.9672245383262634\n",
      "epoch 153: loss=0.9912872314453125\n",
      "epoch 154: loss=0.9633947610855103\n",
      "epoch 155: loss=0.9718809127807617\n",
      "epoch 156: loss=0.9290706515312195\n",
      "epoch 157: loss=0.9667032957077026\n",
      "epoch 158: loss=0.9400699734687805\n",
      "epoch 159: loss=0.9602625370025635\n",
      "epoch 160: loss=0.9626091718673706\n",
      "epoch 161: loss=0.967613697052002\n",
      "epoch 162: loss=0.9704428911209106\n",
      "epoch 163: loss=0.9707063436508179\n",
      "epoch 164: loss=0.9603713750839233\n",
      "epoch 165: loss=0.946694552898407\n",
      "epoch 166: loss=0.9556541442871094\n",
      "epoch 167: loss=0.9699575304985046\n",
      "epoch 168: loss=0.9623047113418579\n",
      "epoch 169: loss=0.9673142433166504\n",
      "epoch 170: loss=0.9798945188522339\n",
      "epoch 171: loss=0.9398249387741089\n",
      "epoch 172: loss=0.9718613624572754\n",
      "epoch 173: loss=0.963640570640564\n",
      "epoch 174: loss=0.9635440111160278\n",
      "epoch 175: loss=0.9803615808486938\n",
      "epoch 176: loss=0.9571994543075562\n",
      "epoch 177: loss=0.9689521193504333\n",
      "epoch 178: loss=0.9694762825965881\n",
      "epoch 179: loss=0.9164479374885559\n",
      "epoch 180: loss=0.9457220435142517\n",
      "epoch 181: loss=0.9427393674850464\n",
      "epoch 182: loss=0.942558228969574\n",
      "epoch 183: loss=0.9736906290054321\n",
      "epoch 184: loss=0.9555456042289734\n",
      "epoch 185: loss=0.9598780870437622\n",
      "epoch 186: loss=0.969287633895874\n",
      "epoch 187: loss=0.9547418355941772\n",
      "epoch 188: loss=0.9493306875228882\n",
      "epoch 189: loss=0.9493744373321533\n",
      "epoch 190: loss=0.9468125104904175\n",
      "epoch 191: loss=0.9447591304779053\n",
      "epoch 192: loss=0.9427450895309448\n",
      "epoch 193: loss=0.9575234055519104\n",
      "epoch 194: loss=0.9433803558349609\n",
      "epoch 195: loss=0.9563477039337158\n",
      "epoch 196: loss=0.9626491665840149\n",
      "epoch 197: loss=0.9307401776313782\n",
      "epoch 198: loss=0.9552416801452637\n",
      "epoch 199: loss=0.9424428343772888\n",
      "training patch with 764 edges\n",
      "epoch 0: loss=1.8469394445419312\n",
      "epoch 1: loss=1.7322965860366821\n",
      "epoch 2: loss=1.6608620882034302\n",
      "epoch 3: loss=1.5048027038574219\n",
      "epoch 4: loss=1.5374436378479004\n",
      "epoch 5: loss=1.493626594543457\n",
      "epoch 6: loss=1.5111842155456543\n",
      "epoch 7: loss=1.4804648160934448\n",
      "epoch 8: loss=1.4381765127182007\n",
      "epoch 9: loss=1.4117766618728638\n",
      "epoch 10: loss=1.4157963991165161\n",
      "epoch 11: loss=1.3973628282546997\n",
      "epoch 12: loss=1.4231135845184326\n",
      "epoch 13: loss=1.3959037065505981\n",
      "epoch 14: loss=1.3839493989944458\n",
      "epoch 15: loss=1.3995530605316162\n",
      "epoch 16: loss=1.387413501739502\n",
      "epoch 17: loss=1.3811850547790527\n",
      "epoch 18: loss=1.375802755355835\n",
      "epoch 19: loss=1.369253396987915\n",
      "epoch 20: loss=1.367924451828003\n",
      "epoch 21: loss=1.3653768301010132\n",
      "epoch 22: loss=1.3534290790557861\n",
      "epoch 23: loss=1.351043701171875\n",
      "epoch 24: loss=1.3448437452316284\n",
      "epoch 25: loss=1.3248400688171387\n",
      "epoch 26: loss=1.319653034210205\n",
      "epoch 27: loss=1.3222068548202515\n",
      "epoch 28: loss=1.3087164163589478\n",
      "epoch 29: loss=1.2927427291870117\n",
      "epoch 30: loss=1.2709912061691284\n",
      "epoch 31: loss=1.2801913022994995\n",
      "epoch 32: loss=1.2728694677352905\n",
      "epoch 33: loss=1.2335996627807617\n",
      "epoch 34: loss=1.217239499092102\n",
      "epoch 35: loss=1.2012518644332886\n",
      "epoch 36: loss=1.1743720769882202\n",
      "epoch 37: loss=1.1449416875839233\n",
      "epoch 38: loss=1.1456196308135986\n",
      "epoch 39: loss=1.117228388786316\n",
      "epoch 40: loss=1.0846847295761108\n",
      "epoch 41: loss=1.0637794733047485\n",
      "epoch 42: loss=1.088188886642456\n",
      "epoch 43: loss=1.0885093212127686\n",
      "epoch 44: loss=1.082950234413147\n",
      "epoch 45: loss=1.0492695569992065\n",
      "epoch 46: loss=1.0302326679229736\n",
      "epoch 47: loss=1.0840647220611572\n",
      "epoch 48: loss=1.0508241653442383\n",
      "epoch 49: loss=1.0420286655426025\n",
      "epoch 50: loss=1.0266340970993042\n",
      "epoch 51: loss=1.0669400691986084\n",
      "epoch 52: loss=1.0351107120513916\n",
      "epoch 53: loss=1.0326300859451294\n",
      "epoch 54: loss=1.0270715951919556\n",
      "epoch 55: loss=1.062459111213684\n",
      "epoch 56: loss=1.054093837738037\n",
      "epoch 57: loss=1.0471481084823608\n",
      "epoch 58: loss=1.0339802503585815\n",
      "epoch 59: loss=1.0589830875396729\n",
      "epoch 60: loss=1.0363287925720215\n",
      "epoch 61: loss=1.0530123710632324\n",
      "epoch 62: loss=1.0143089294433594\n",
      "epoch 63: loss=1.0085076093673706\n",
      "epoch 64: loss=1.0412505865097046\n",
      "epoch 65: loss=1.0196783542633057\n",
      "epoch 66: loss=1.0447990894317627\n",
      "epoch 67: loss=1.0276504755020142\n",
      "epoch 68: loss=1.028165578842163\n",
      "epoch 69: loss=1.0097416639328003\n",
      "epoch 70: loss=1.0021920204162598\n",
      "epoch 71: loss=1.0008347034454346\n",
      "epoch 72: loss=0.9977551102638245\n",
      "epoch 73: loss=1.0320900678634644\n",
      "epoch 74: loss=0.9897550940513611\n",
      "epoch 75: loss=1.0219552516937256\n",
      "epoch 76: loss=1.0271577835083008\n",
      "epoch 77: loss=1.0222164392471313\n",
      "epoch 78: loss=0.9980881810188293\n",
      "epoch 79: loss=1.0259037017822266\n",
      "epoch 80: loss=1.025481104850769\n",
      "epoch 81: loss=1.0260932445526123\n",
      "epoch 82: loss=1.0535533428192139\n",
      "epoch 83: loss=1.0508029460906982\n",
      "epoch 84: loss=0.989165723323822\n",
      "epoch 85: loss=1.0223116874694824\n",
      "epoch 86: loss=1.0400328636169434\n",
      "epoch 87: loss=0.9936141967773438\n",
      "epoch 88: loss=1.0176737308502197\n",
      "epoch 89: loss=1.0305521488189697\n",
      "epoch 90: loss=0.9804989099502563\n",
      "epoch 91: loss=1.0027438402175903\n",
      "epoch 92: loss=1.002489447593689\n",
      "epoch 93: loss=1.0485548973083496\n",
      "epoch 94: loss=1.0405330657958984\n",
      "epoch 95: loss=0.9847768545150757\n",
      "epoch 96: loss=1.009539008140564\n",
      "epoch 97: loss=0.9982929825782776\n",
      "epoch 98: loss=1.0237008333206177\n",
      "epoch 99: loss=0.9737958312034607\n",
      "epoch 100: loss=0.9923402070999146\n",
      "epoch 101: loss=1.002002239227295\n",
      "epoch 102: loss=0.9923496246337891\n",
      "epoch 103: loss=1.0465633869171143\n",
      "epoch 104: loss=1.0044605731964111\n",
      "epoch 105: loss=0.970923900604248\n",
      "epoch 106: loss=0.9970096945762634\n",
      "epoch 107: loss=0.9835317730903625\n",
      "epoch 108: loss=1.0321259498596191\n",
      "epoch 109: loss=1.0292892456054688\n",
      "epoch 110: loss=1.0094592571258545\n",
      "epoch 111: loss=1.0027180910110474\n",
      "epoch 112: loss=0.9950743317604065\n",
      "epoch 113: loss=1.0020623207092285\n",
      "epoch 114: loss=1.0134299993515015\n",
      "epoch 115: loss=0.9945484399795532\n",
      "epoch 116: loss=0.9822875261306763\n",
      "epoch 117: loss=1.016648292541504\n",
      "epoch 118: loss=0.9992818832397461\n",
      "epoch 119: loss=0.957909882068634\n",
      "epoch 120: loss=1.0001322031021118\n",
      "epoch 121: loss=1.025006651878357\n",
      "epoch 122: loss=1.043771743774414\n",
      "epoch 123: loss=0.9988170266151428\n",
      "epoch 124: loss=1.0194809436798096\n",
      "epoch 125: loss=1.0068161487579346\n",
      "epoch 126: loss=1.023297667503357\n",
      "epoch 127: loss=0.9949804544448853\n",
      "epoch 128: loss=0.9910385012626648\n",
      "epoch 129: loss=1.0119781494140625\n",
      "epoch 130: loss=1.021908164024353\n",
      "epoch 131: loss=1.0177443027496338\n",
      "epoch 132: loss=0.9877640008926392\n",
      "epoch 133: loss=0.9826909303665161\n",
      "epoch 134: loss=1.0403099060058594\n",
      "epoch 135: loss=0.9898027777671814\n",
      "epoch 136: loss=0.9880735278129578\n",
      "epoch 137: loss=0.9749950170516968\n",
      "epoch 138: loss=0.9959858655929565\n",
      "epoch 139: loss=0.9845165610313416\n",
      "epoch 140: loss=1.015784740447998\n",
      "epoch 141: loss=1.029995322227478\n",
      "epoch 142: loss=1.0060960054397583\n",
      "epoch 143: loss=0.9964995384216309\n",
      "epoch 144: loss=0.9679824113845825\n",
      "epoch 145: loss=1.013134241104126\n",
      "epoch 146: loss=0.970361590385437\n",
      "epoch 147: loss=1.0083311796188354\n",
      "epoch 148: loss=0.9566393494606018\n",
      "epoch 149: loss=0.9914505481719971\n",
      "epoch 150: loss=1.0295201539993286\n",
      "epoch 151: loss=1.0055495500564575\n",
      "epoch 152: loss=0.9809458255767822\n",
      "epoch 153: loss=1.0154041051864624\n",
      "epoch 154: loss=1.0062319040298462\n",
      "epoch 155: loss=1.0208874940872192\n",
      "epoch 156: loss=0.9926759004592896\n",
      "epoch 157: loss=0.9784310460090637\n",
      "epoch 158: loss=1.039258360862732\n",
      "epoch 159: loss=1.0328617095947266\n",
      "epoch 160: loss=1.0015569925308228\n",
      "epoch 161: loss=0.9933129549026489\n",
      "epoch 162: loss=0.974553644657135\n",
      "epoch 163: loss=0.9717406034469604\n",
      "epoch 164: loss=1.0182877779006958\n",
      "epoch 165: loss=1.0138550996780396\n",
      "epoch 166: loss=0.9991695880889893\n",
      "epoch 167: loss=0.9828656315803528\n",
      "epoch 168: loss=1.0073304176330566\n",
      "epoch 169: loss=0.9796997308731079\n",
      "epoch 170: loss=0.9761099815368652\n",
      "epoch 171: loss=0.9759060144424438\n",
      "epoch 172: loss=0.9798809885978699\n",
      "epoch 173: loss=0.9687978029251099\n",
      "epoch 174: loss=1.01568603515625\n",
      "epoch 175: loss=1.0100350379943848\n",
      "epoch 176: loss=1.0024830102920532\n",
      "epoch 177: loss=0.9884494543075562\n",
      "epoch 178: loss=0.9848396182060242\n",
      "epoch 179: loss=1.0020264387130737\n",
      "epoch 180: loss=0.9714443683624268\n",
      "epoch 181: loss=0.9944496750831604\n",
      "epoch 182: loss=0.9852156043052673\n",
      "epoch 183: loss=0.9734377861022949\n",
      "epoch 184: loss=0.9792734384536743\n",
      "epoch 185: loss=1.022587537765503\n",
      "epoch 186: loss=0.9960119128227234\n",
      "epoch 187: loss=1.0002638101577759\n",
      "epoch 188: loss=1.0158392190933228\n",
      "epoch 189: loss=1.0107625722885132\n",
      "epoch 190: loss=0.9546378254890442\n",
      "epoch 191: loss=0.9542890191078186\n",
      "epoch 192: loss=0.9969391226768494\n",
      "epoch 193: loss=0.9818693995475769\n",
      "epoch 194: loss=1.004025936126709\n",
      "epoch 195: loss=0.9751891493797302\n",
      "epoch 196: loss=0.9803107380867004\n",
      "epoch 197: loss=0.9615689516067505\n",
      "epoch 198: loss=0.9746056795120239\n",
      "epoch 199: loss=0.9885316491127014\n",
      "training patch with 950 edges\n",
      "epoch 0: loss=1.7432827949523926\n",
      "epoch 1: loss=1.7015354633331299\n",
      "epoch 2: loss=1.6675204038619995\n",
      "epoch 3: loss=1.5492455959320068\n",
      "epoch 4: loss=1.5329341888427734\n",
      "epoch 5: loss=1.5174671411514282\n",
      "epoch 6: loss=1.50641930103302\n",
      "epoch 7: loss=1.4824025630950928\n",
      "epoch 8: loss=1.4452648162841797\n",
      "epoch 9: loss=1.4229309558868408\n",
      "epoch 10: loss=1.4045863151550293\n",
      "epoch 11: loss=1.4140442609786987\n",
      "epoch 12: loss=1.4058201313018799\n",
      "epoch 13: loss=1.398201584815979\n",
      "epoch 14: loss=1.3946541547775269\n",
      "epoch 15: loss=1.3836601972579956\n",
      "epoch 16: loss=1.383837342262268\n",
      "epoch 17: loss=1.385949969291687\n",
      "epoch 18: loss=1.3738634586334229\n",
      "epoch 19: loss=1.3584675788879395\n",
      "epoch 20: loss=1.3415149450302124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: loss=1.3312456607818604\n",
      "epoch 22: loss=1.3312115669250488\n",
      "epoch 23: loss=1.3235067129135132\n",
      "epoch 24: loss=1.340876579284668\n",
      "epoch 25: loss=1.3353629112243652\n",
      "epoch 26: loss=1.3008800745010376\n",
      "epoch 27: loss=1.3025559186935425\n",
      "epoch 28: loss=1.3017823696136475\n",
      "epoch 29: loss=1.2942415475845337\n",
      "epoch 30: loss=1.277106761932373\n",
      "epoch 31: loss=1.2835018634796143\n",
      "epoch 32: loss=1.2787327766418457\n",
      "epoch 33: loss=1.2749435901641846\n",
      "epoch 34: loss=1.2508660554885864\n",
      "epoch 35: loss=1.265893578529358\n",
      "epoch 36: loss=1.241459608078003\n",
      "epoch 37: loss=1.2267171144485474\n",
      "epoch 38: loss=1.2221081256866455\n",
      "epoch 39: loss=1.2310409545898438\n",
      "epoch 40: loss=1.1917622089385986\n",
      "epoch 41: loss=1.1871126890182495\n",
      "epoch 42: loss=1.1814943552017212\n",
      "epoch 43: loss=1.1641547679901123\n",
      "epoch 44: loss=1.1502195596694946\n",
      "epoch 45: loss=1.1372075080871582\n",
      "epoch 46: loss=1.1240781545639038\n",
      "epoch 47: loss=1.1549221277236938\n",
      "epoch 48: loss=1.152178168296814\n",
      "epoch 49: loss=1.1329643726348877\n",
      "epoch 50: loss=1.1493477821350098\n",
      "epoch 51: loss=1.1522186994552612\n",
      "epoch 52: loss=1.1311314105987549\n",
      "epoch 53: loss=1.1398133039474487\n",
      "epoch 54: loss=1.1576879024505615\n",
      "epoch 55: loss=1.1322503089904785\n",
      "epoch 56: loss=1.117676854133606\n",
      "epoch 57: loss=1.1218101978302002\n",
      "epoch 58: loss=1.130961537361145\n",
      "epoch 59: loss=1.1129320859909058\n",
      "epoch 60: loss=1.0845553874969482\n",
      "epoch 61: loss=1.099051833152771\n",
      "epoch 62: loss=1.078282356262207\n",
      "epoch 63: loss=1.1019593477249146\n",
      "epoch 64: loss=1.0964281558990479\n",
      "epoch 65: loss=1.0716856718063354\n",
      "epoch 66: loss=1.0836001634597778\n",
      "epoch 67: loss=1.0777368545532227\n",
      "epoch 68: loss=1.059088110923767\n",
      "epoch 69: loss=1.078574299812317\n",
      "epoch 70: loss=1.0756067037582397\n",
      "epoch 71: loss=1.03767728805542\n",
      "epoch 72: loss=1.0235400199890137\n",
      "epoch 73: loss=1.0163490772247314\n",
      "epoch 74: loss=1.0176502466201782\n",
      "epoch 75: loss=0.9851346611976624\n",
      "epoch 76: loss=0.9820654392242432\n",
      "epoch 77: loss=1.003796100616455\n",
      "epoch 78: loss=0.9690444469451904\n",
      "epoch 79: loss=0.9907181262969971\n",
      "epoch 80: loss=0.9844259023666382\n",
      "epoch 81: loss=1.02303946018219\n",
      "epoch 82: loss=1.002424716949463\n",
      "epoch 83: loss=1.0071083307266235\n",
      "epoch 84: loss=0.9881479144096375\n",
      "epoch 85: loss=1.0097814798355103\n",
      "epoch 86: loss=0.9756972789764404\n",
      "epoch 87: loss=0.9546831250190735\n",
      "epoch 88: loss=0.9630305767059326\n",
      "epoch 89: loss=0.9780074954032898\n",
      "epoch 90: loss=0.9845442771911621\n",
      "epoch 91: loss=0.9736967086791992\n",
      "epoch 92: loss=0.9790146946907043\n",
      "epoch 93: loss=0.9769865274429321\n",
      "epoch 94: loss=0.9897658824920654\n",
      "epoch 95: loss=0.9656546711921692\n",
      "epoch 96: loss=0.9939298629760742\n",
      "epoch 97: loss=0.9655742049217224\n",
      "epoch 98: loss=0.9857948422431946\n",
      "epoch 99: loss=0.9314479827880859\n",
      "epoch 100: loss=0.9491578936576843\n",
      "epoch 101: loss=0.9780362844467163\n",
      "epoch 102: loss=0.9652673602104187\n",
      "epoch 103: loss=0.9662452936172485\n",
      "epoch 104: loss=0.9610671997070312\n",
      "epoch 105: loss=0.9850274920463562\n",
      "epoch 106: loss=0.9790717363357544\n",
      "epoch 107: loss=0.9866870045661926\n",
      "epoch 108: loss=0.9887682199478149\n",
      "epoch 109: loss=0.9779987335205078\n",
      "epoch 110: loss=0.9542895555496216\n",
      "epoch 111: loss=0.9928833246231079\n",
      "epoch 112: loss=0.9897728562355042\n",
      "epoch 113: loss=0.9456324577331543\n",
      "epoch 114: loss=0.9725959300994873\n",
      "epoch 115: loss=0.9219745993614197\n",
      "epoch 116: loss=0.9567846655845642\n",
      "epoch 117: loss=0.9866100549697876\n",
      "epoch 118: loss=0.9762795567512512\n",
      "epoch 119: loss=0.9509838223457336\n",
      "epoch 120: loss=0.9641721844673157\n",
      "epoch 121: loss=0.9641678333282471\n",
      "epoch 122: loss=0.9857034087181091\n",
      "epoch 123: loss=0.9570901989936829\n",
      "epoch 124: loss=0.9683316946029663\n",
      "epoch 125: loss=0.9580898284912109\n",
      "epoch 126: loss=0.9600459933280945\n",
      "epoch 127: loss=0.9495556950569153\n",
      "epoch 128: loss=0.9523576498031616\n",
      "epoch 129: loss=0.9528376460075378\n",
      "epoch 130: loss=0.9445045590400696\n",
      "epoch 131: loss=0.9744612574577332\n",
      "epoch 132: loss=0.9706162214279175\n",
      "epoch 133: loss=0.9734437465667725\n",
      "epoch 134: loss=0.9722747206687927\n",
      "epoch 135: loss=0.963520348072052\n",
      "epoch 136: loss=0.9414219260215759\n",
      "epoch 137: loss=0.957578182220459\n",
      "epoch 138: loss=0.9481480717658997\n",
      "epoch 139: loss=0.9642313718795776\n",
      "epoch 140: loss=0.9443985223770142\n",
      "epoch 141: loss=0.9503137469291687\n",
      "epoch 142: loss=0.9913837909698486\n",
      "epoch 143: loss=0.9448298215866089\n",
      "epoch 144: loss=0.9566848874092102\n",
      "epoch 145: loss=0.9241588711738586\n",
      "epoch 146: loss=0.9543265104293823\n",
      "epoch 147: loss=0.9620293378829956\n",
      "epoch 148: loss=0.9839540123939514\n",
      "epoch 149: loss=0.9242883920669556\n",
      "epoch 150: loss=0.9667052030563354\n",
      "epoch 151: loss=0.96796715259552\n",
      "epoch 152: loss=0.951262354850769\n",
      "epoch 153: loss=0.9533372521400452\n",
      "epoch 154: loss=0.9843010902404785\n",
      "epoch 155: loss=0.9493227005004883\n",
      "epoch 156: loss=0.9761572480201721\n",
      "epoch 157: loss=0.9402700662612915\n",
      "epoch 158: loss=0.9608705639839172\n",
      "epoch 159: loss=0.962247371673584\n",
      "epoch 160: loss=0.9654362797737122\n",
      "epoch 161: loss=0.944215714931488\n",
      "epoch 162: loss=0.9423313140869141\n",
      "epoch 163: loss=0.97016841173172\n",
      "epoch 164: loss=0.9879608154296875\n",
      "epoch 165: loss=0.9610493183135986\n",
      "epoch 166: loss=0.95770263671875\n",
      "epoch 167: loss=0.9534465670585632\n",
      "epoch 168: loss=0.9508704543113708\n",
      "epoch 169: loss=0.9565607309341431\n",
      "epoch 170: loss=0.9489731788635254\n",
      "epoch 171: loss=0.9824984669685364\n",
      "epoch 172: loss=0.9399763345718384\n",
      "epoch 173: loss=0.9659742116928101\n",
      "epoch 174: loss=0.9437667727470398\n",
      "epoch 175: loss=0.9788499474525452\n",
      "epoch 176: loss=0.9507631659507751\n",
      "epoch 177: loss=0.9704205989837646\n",
      "epoch 178: loss=0.9520174264907837\n",
      "epoch 179: loss=0.9388052821159363\n",
      "epoch 180: loss=0.9591830372810364\n",
      "epoch 181: loss=0.9583756923675537\n",
      "epoch 182: loss=0.9520160555839539\n",
      "epoch 183: loss=0.9426665306091309\n",
      "epoch 184: loss=0.9648357629776001\n",
      "epoch 185: loss=0.9242558479309082\n",
      "epoch 186: loss=0.9427008032798767\n",
      "epoch 187: loss=0.9781158566474915\n",
      "epoch 188: loss=0.9771674275398254\n",
      "epoch 189: loss=0.9565957188606262\n",
      "epoch 190: loss=0.9514767527580261\n",
      "epoch 191: loss=0.9557505249977112\n",
      "epoch 192: loss=0.9700213074684143\n",
      "epoch 193: loss=0.9450060129165649\n",
      "epoch 194: loss=0.9835576415061951\n",
      "epoch 195: loss=0.9484228491783142\n",
      "epoch 196: loss=0.964242696762085\n",
      "epoch 197: loss=0.971533477306366\n",
      "epoch 198: loss=0.9443413019180298\n",
      "epoch 199: loss=0.9594669342041016\n",
      "training patch with 2922 edges\n",
      "epoch 0: loss=1.826587200164795\n",
      "epoch 1: loss=1.7128515243530273\n",
      "epoch 2: loss=1.6576974391937256\n",
      "epoch 3: loss=1.614275574684143\n",
      "epoch 4: loss=1.551459550857544\n",
      "epoch 5: loss=1.520317554473877\n",
      "epoch 6: loss=1.5019220113754272\n",
      "epoch 7: loss=1.4897682666778564\n",
      "epoch 8: loss=1.4467674493789673\n",
      "epoch 9: loss=1.4559341669082642\n",
      "epoch 10: loss=1.4281924962997437\n",
      "epoch 11: loss=1.4201440811157227\n",
      "epoch 12: loss=1.4124321937561035\n",
      "epoch 13: loss=1.395052433013916\n",
      "epoch 14: loss=1.3871246576309204\n",
      "epoch 15: loss=1.380490779876709\n",
      "epoch 16: loss=1.3767222166061401\n",
      "epoch 17: loss=1.3550008535385132\n",
      "epoch 18: loss=1.3538271188735962\n",
      "epoch 19: loss=1.350178837776184\n",
      "epoch 20: loss=1.3571559190750122\n",
      "epoch 21: loss=1.3444901704788208\n",
      "epoch 22: loss=1.3397059440612793\n",
      "epoch 23: loss=1.3406206369400024\n",
      "epoch 24: loss=1.344828486442566\n",
      "epoch 25: loss=1.3194714784622192\n",
      "epoch 26: loss=1.3232502937316895\n",
      "epoch 27: loss=1.3124297857284546\n",
      "epoch 28: loss=1.3112189769744873\n",
      "epoch 29: loss=1.3165897130966187\n",
      "epoch 30: loss=1.3096038103103638\n",
      "epoch 31: loss=1.303542971611023\n",
      "epoch 32: loss=1.294874668121338\n",
      "epoch 33: loss=1.2941895723342896\n",
      "epoch 34: loss=1.2854748964309692\n",
      "epoch 35: loss=1.2827485799789429\n",
      "epoch 36: loss=1.2784937620162964\n",
      "epoch 37: loss=1.2725595235824585\n",
      "epoch 38: loss=1.2751158475875854\n",
      "epoch 39: loss=1.2646671533584595\n",
      "epoch 40: loss=1.2568745613098145\n",
      "epoch 41: loss=1.2424317598342896\n",
      "epoch 42: loss=1.2380456924438477\n",
      "epoch 43: loss=1.2393466234207153\n",
      "epoch 44: loss=1.233662724494934\n",
      "epoch 45: loss=1.2218806743621826\n",
      "epoch 46: loss=1.2193100452423096\n",
      "epoch 47: loss=1.212173342704773\n",
      "epoch 48: loss=1.1906274557113647\n",
      "epoch 49: loss=1.1868373155593872\n",
      "epoch 50: loss=1.17650306224823\n",
      "epoch 51: loss=1.1649701595306396\n",
      "epoch 52: loss=1.1523337364196777\n",
      "epoch 53: loss=1.142726182937622\n",
      "epoch 54: loss=1.1241716146469116\n",
      "epoch 55: loss=1.1122198104858398\n",
      "epoch 56: loss=1.1147996187210083\n",
      "epoch 57: loss=1.0984587669372559\n",
      "epoch 58: loss=1.0978881120681763\n",
      "epoch 59: loss=1.0869195461273193\n",
      "epoch 60: loss=1.0806702375411987\n",
      "epoch 61: loss=1.0688135623931885\n",
      "epoch 62: loss=1.0687251091003418\n",
      "epoch 63: loss=1.0639854669570923\n",
      "epoch 64: loss=1.0653727054595947\n",
      "epoch 65: loss=1.059753656387329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66: loss=1.06574285030365\n",
      "epoch 67: loss=1.0508238077163696\n",
      "epoch 68: loss=1.056668996810913\n",
      "epoch 69: loss=1.0316697359085083\n",
      "epoch 70: loss=1.0238103866577148\n",
      "epoch 71: loss=1.0132369995117188\n",
      "epoch 72: loss=1.0239392518997192\n",
      "epoch 73: loss=1.004417061805725\n",
      "epoch 74: loss=1.0237464904785156\n",
      "epoch 75: loss=1.0343583822250366\n",
      "epoch 76: loss=1.009037733078003\n",
      "epoch 77: loss=0.9945571422576904\n",
      "epoch 78: loss=1.0141962766647339\n",
      "epoch 79: loss=1.0020349025726318\n",
      "epoch 80: loss=1.0212372541427612\n",
      "epoch 81: loss=1.005260944366455\n",
      "epoch 82: loss=0.9964708089828491\n",
      "epoch 83: loss=1.0050524473190308\n",
      "epoch 84: loss=1.0117896795272827\n",
      "epoch 85: loss=1.001702070236206\n",
      "epoch 86: loss=1.0037637948989868\n",
      "epoch 87: loss=0.9903850555419922\n",
      "epoch 88: loss=0.9740118384361267\n",
      "epoch 89: loss=0.9975845217704773\n",
      "epoch 90: loss=0.9907179474830627\n",
      "epoch 91: loss=0.9864047765731812\n",
      "epoch 92: loss=0.9908843040466309\n",
      "epoch 93: loss=0.9769662022590637\n",
      "epoch 94: loss=0.9973914623260498\n",
      "epoch 95: loss=0.9922934770584106\n",
      "epoch 96: loss=0.9930897355079651\n",
      "epoch 97: loss=0.9830418229103088\n",
      "epoch 98: loss=0.9779248833656311\n",
      "epoch 99: loss=0.9760330319404602\n",
      "epoch 100: loss=0.9828231930732727\n",
      "epoch 101: loss=0.9727187752723694\n",
      "epoch 102: loss=0.9871480464935303\n",
      "epoch 103: loss=0.9781774878501892\n",
      "epoch 104: loss=0.9777378439903259\n",
      "epoch 105: loss=0.9967859983444214\n",
      "epoch 106: loss=0.987334668636322\n",
      "epoch 107: loss=0.9749822616577148\n",
      "epoch 108: loss=0.9895557761192322\n",
      "epoch 109: loss=0.9914931654930115\n",
      "epoch 110: loss=0.9795210957527161\n",
      "epoch 111: loss=0.9855033159255981\n",
      "epoch 112: loss=0.9661596417427063\n",
      "epoch 113: loss=0.9764349460601807\n",
      "epoch 114: loss=0.9578417539596558\n",
      "epoch 115: loss=0.9726318120956421\n",
      "epoch 116: loss=0.9498554468154907\n",
      "epoch 117: loss=0.9806814789772034\n",
      "epoch 118: loss=0.9712689518928528\n",
      "epoch 119: loss=0.9673400521278381\n",
      "epoch 120: loss=0.9840908646583557\n",
      "epoch 121: loss=0.9689841866493225\n",
      "epoch 122: loss=0.9812771081924438\n",
      "epoch 123: loss=0.9890706539154053\n",
      "epoch 124: loss=0.9808233976364136\n",
      "epoch 125: loss=0.9485270380973816\n",
      "epoch 126: loss=0.984710156917572\n",
      "epoch 127: loss=0.9967164993286133\n",
      "epoch 128: loss=0.9809679388999939\n",
      "epoch 129: loss=0.9668269753456116\n",
      "epoch 130: loss=0.9729515910148621\n",
      "epoch 131: loss=0.9731832146644592\n",
      "epoch 132: loss=0.970584511756897\n",
      "epoch 133: loss=0.9578555822372437\n",
      "epoch 134: loss=0.9807608723640442\n",
      "epoch 135: loss=0.979076623916626\n",
      "epoch 136: loss=0.9631814956665039\n",
      "epoch 137: loss=0.9757616519927979\n",
      "epoch 138: loss=0.9707770347595215\n",
      "epoch 139: loss=0.9672142863273621\n",
      "epoch 140: loss=0.9633225798606873\n",
      "epoch 141: loss=0.9768019318580627\n",
      "epoch 142: loss=0.9535535573959351\n",
      "epoch 143: loss=0.9633179306983948\n",
      "epoch 144: loss=0.95492023229599\n",
      "epoch 145: loss=0.9399122595787048\n",
      "epoch 146: loss=0.9842697381973267\n",
      "epoch 147: loss=0.9835667610168457\n",
      "epoch 148: loss=0.954492449760437\n",
      "epoch 149: loss=0.9614996314048767\n",
      "epoch 150: loss=0.9693382978439331\n",
      "epoch 151: loss=0.9710444808006287\n",
      "epoch 152: loss=0.971552312374115\n",
      "epoch 153: loss=0.9683259725570679\n",
      "epoch 154: loss=0.9670690298080444\n",
      "epoch 155: loss=0.9598384499549866\n",
      "epoch 156: loss=0.9686840772628784\n",
      "epoch 157: loss=0.9648964405059814\n",
      "epoch 158: loss=0.959494948387146\n",
      "epoch 159: loss=0.9757058024406433\n",
      "epoch 160: loss=0.9557889699935913\n",
      "epoch 161: loss=0.9567645192146301\n",
      "epoch 162: loss=0.950190544128418\n",
      "epoch 163: loss=0.9586725234985352\n",
      "epoch 164: loss=0.9678712487220764\n",
      "epoch 165: loss=0.9600350856781006\n",
      "epoch 166: loss=0.9745269417762756\n",
      "epoch 167: loss=0.9644262194633484\n",
      "epoch 168: loss=0.9572655558586121\n",
      "epoch 169: loss=0.9744922518730164\n",
      "epoch 170: loss=0.9614613056182861\n",
      "epoch 171: loss=0.9699294567108154\n",
      "epoch 172: loss=0.9810516238212585\n",
      "epoch 173: loss=0.9672480821609497\n",
      "epoch 174: loss=0.9662685394287109\n",
      "epoch 175: loss=0.9719669818878174\n",
      "epoch 176: loss=0.9744455218315125\n",
      "epoch 177: loss=0.9715502858161926\n",
      "epoch 178: loss=0.9802769422531128\n",
      "epoch 179: loss=0.9535834193229675\n",
      "epoch 180: loss=0.9631146788597107\n",
      "epoch 181: loss=0.9698905944824219\n",
      "epoch 182: loss=0.9774924516677856\n",
      "epoch 183: loss=0.9663979411125183\n",
      "epoch 184: loss=0.9704223871231079\n",
      "epoch 185: loss=0.9731354713439941\n",
      "epoch 186: loss=0.9639373421669006\n",
      "epoch 187: loss=0.958679735660553\n",
      "epoch 188: loss=0.9749280214309692\n",
      "epoch 189: loss=0.9751240611076355\n",
      "epoch 190: loss=0.9541037678718567\n",
      "epoch 191: loss=0.9623172879219055\n",
      "epoch 192: loss=0.9758670926094055\n",
      "epoch 193: loss=0.9703889489173889\n",
      "epoch 194: loss=0.978571891784668\n",
      "epoch 195: loss=0.9608272314071655\n",
      "epoch 196: loss=0.9614083766937256\n",
      "epoch 197: loss=0.9705412983894348\n",
      "epoch 198: loss=0.9734721779823303\n",
      "epoch 199: loss=0.9545971751213074\n",
      "training patch with 1698 edges\n",
      "epoch 0: loss=1.7989444732666016\n",
      "epoch 1: loss=1.6580833196640015\n",
      "epoch 2: loss=1.6060845851898193\n",
      "epoch 3: loss=1.5594435930252075\n",
      "epoch 4: loss=1.570083498954773\n",
      "epoch 5: loss=1.5163438320159912\n",
      "epoch 6: loss=1.504317283630371\n",
      "epoch 7: loss=1.461361050605774\n",
      "epoch 8: loss=1.4431936740875244\n",
      "epoch 9: loss=1.4336951971054077\n",
      "epoch 10: loss=1.4126981496810913\n",
      "epoch 11: loss=1.4035909175872803\n",
      "epoch 12: loss=1.411877155303955\n",
      "epoch 13: loss=1.4037359952926636\n",
      "epoch 14: loss=1.3880966901779175\n",
      "epoch 15: loss=1.3925923109054565\n",
      "epoch 16: loss=1.381987452507019\n",
      "epoch 17: loss=1.3879019021987915\n",
      "epoch 18: loss=1.3731740713119507\n",
      "epoch 19: loss=1.3604153394699097\n",
      "epoch 20: loss=1.357670545578003\n",
      "epoch 21: loss=1.3525261878967285\n",
      "epoch 22: loss=1.3353012800216675\n",
      "epoch 23: loss=1.3438007831573486\n",
      "epoch 24: loss=1.336465835571289\n",
      "epoch 25: loss=1.3267557621002197\n",
      "epoch 26: loss=1.312334656715393\n",
      "epoch 27: loss=1.3055968284606934\n",
      "epoch 28: loss=1.2925465106964111\n",
      "epoch 29: loss=1.2790803909301758\n",
      "epoch 30: loss=1.2591712474822998\n",
      "epoch 31: loss=1.2361220121383667\n",
      "epoch 32: loss=1.2116144895553589\n",
      "epoch 33: loss=1.19210946559906\n",
      "epoch 34: loss=1.163730263710022\n",
      "epoch 35: loss=1.1555991172790527\n",
      "epoch 36: loss=1.1250241994857788\n",
      "epoch 37: loss=1.1223652362823486\n",
      "epoch 38: loss=1.10257887840271\n",
      "epoch 39: loss=1.1190465688705444\n",
      "epoch 40: loss=1.1425817012786865\n",
      "epoch 41: loss=1.1049381494522095\n",
      "epoch 42: loss=1.085289716720581\n",
      "epoch 43: loss=1.1016489267349243\n",
      "epoch 44: loss=1.1151633262634277\n",
      "epoch 45: loss=1.1156843900680542\n",
      "epoch 46: loss=1.0603443384170532\n",
      "epoch 47: loss=1.0907080173492432\n",
      "epoch 48: loss=1.062608242034912\n",
      "epoch 49: loss=1.0801388025283813\n",
      "epoch 50: loss=1.054587483406067\n",
      "epoch 51: loss=1.0706993341445923\n",
      "epoch 52: loss=1.0669101476669312\n",
      "epoch 53: loss=1.0500695705413818\n",
      "epoch 54: loss=1.0416274070739746\n",
      "epoch 55: loss=1.0304819345474243\n",
      "epoch 56: loss=1.047487497329712\n",
      "epoch 57: loss=1.0243420600891113\n",
      "epoch 58: loss=1.021106481552124\n",
      "epoch 59: loss=1.0141184329986572\n",
      "epoch 60: loss=1.0084257125854492\n",
      "epoch 61: loss=1.006559133529663\n",
      "epoch 62: loss=1.0259476900100708\n",
      "epoch 63: loss=0.973637044429779\n",
      "epoch 64: loss=0.9989286661148071\n",
      "epoch 65: loss=1.0132781267166138\n",
      "epoch 66: loss=0.996088445186615\n",
      "epoch 67: loss=1.0111420154571533\n",
      "epoch 68: loss=1.0183919668197632\n",
      "epoch 69: loss=0.9934971332550049\n",
      "epoch 70: loss=0.9984070658683777\n",
      "epoch 71: loss=0.959379255771637\n",
      "epoch 72: loss=1.0171371698379517\n",
      "epoch 73: loss=1.001538872718811\n",
      "epoch 74: loss=0.977520227432251\n",
      "epoch 75: loss=0.9850187301635742\n",
      "epoch 76: loss=0.9910674691200256\n",
      "epoch 77: loss=0.9889707565307617\n",
      "epoch 78: loss=0.984499990940094\n",
      "epoch 79: loss=0.978205680847168\n",
      "epoch 80: loss=0.9816977381706238\n",
      "epoch 81: loss=1.00215482711792\n",
      "epoch 82: loss=0.988283634185791\n",
      "epoch 83: loss=0.9781091809272766\n",
      "epoch 84: loss=0.9786556959152222\n",
      "epoch 85: loss=0.9954907894134521\n",
      "epoch 86: loss=1.001774549484253\n",
      "epoch 87: loss=0.9754732251167297\n",
      "epoch 88: loss=0.9722631573677063\n",
      "epoch 89: loss=0.9837096929550171\n",
      "epoch 90: loss=0.980883777141571\n",
      "epoch 91: loss=0.9746169447898865\n",
      "epoch 92: loss=0.9676727056503296\n",
      "epoch 93: loss=0.9850386381149292\n",
      "epoch 94: loss=0.9751672744750977\n",
      "epoch 95: loss=0.987884521484375\n",
      "epoch 96: loss=0.9725264310836792\n",
      "epoch 97: loss=0.9803693294525146\n",
      "epoch 98: loss=1.0060292482376099\n",
      "epoch 99: loss=1.0049439668655396\n",
      "epoch 100: loss=0.9726477861404419\n",
      "epoch 101: loss=0.9629036784172058\n",
      "epoch 102: loss=0.9840594530105591\n",
      "epoch 103: loss=0.9713331460952759\n",
      "epoch 104: loss=0.9673579931259155\n",
      "epoch 105: loss=0.9558568000793457\n",
      "epoch 106: loss=0.9882549047470093\n",
      "epoch 107: loss=0.9740792512893677\n",
      "epoch 108: loss=0.9730722308158875\n",
      "epoch 109: loss=0.9809322357177734\n",
      "epoch 110: loss=0.9854039549827576\n",
      "epoch 111: loss=0.9872300028800964\n",
      "epoch 112: loss=0.9641813039779663\n",
      "epoch 113: loss=0.9617693424224854\n",
      "epoch 114: loss=0.9847052097320557\n",
      "epoch 115: loss=0.9836902618408203\n",
      "epoch 116: loss=1.0089020729064941\n",
      "epoch 117: loss=0.993257462978363\n",
      "epoch 118: loss=0.9899670481681824\n",
      "epoch 119: loss=0.9955999851226807\n",
      "epoch 120: loss=0.9757252931594849\n",
      "epoch 121: loss=0.9784701466560364\n",
      "epoch 122: loss=0.9889215230941772\n",
      "epoch 123: loss=0.9869192838668823\n",
      "epoch 124: loss=0.9813811182975769\n",
      "epoch 125: loss=0.9724084138870239\n",
      "epoch 126: loss=0.9868224859237671\n",
      "epoch 127: loss=0.9743149280548096\n",
      "epoch 128: loss=0.9756292104721069\n",
      "epoch 129: loss=0.965382993221283\n",
      "epoch 130: loss=0.992496907711029\n",
      "epoch 131: loss=0.9814384579658508\n",
      "epoch 132: loss=0.9717502593994141\n",
      "epoch 133: loss=0.9966280460357666\n",
      "epoch 134: loss=0.9727752208709717\n",
      "epoch 135: loss=0.9681166410446167\n",
      "epoch 136: loss=0.9704920649528503\n",
      "epoch 137: loss=0.9889758825302124\n",
      "epoch 138: loss=0.9801403880119324\n",
      "epoch 139: loss=0.9573791027069092\n",
      "epoch 140: loss=0.9848378896713257\n",
      "epoch 141: loss=0.9845762848854065\n",
      "epoch 142: loss=0.98406982421875\n",
      "epoch 143: loss=0.9916794896125793\n",
      "epoch 144: loss=0.9825822114944458\n",
      "epoch 145: loss=0.968339204788208\n",
      "epoch 146: loss=0.9854909777641296\n",
      "epoch 147: loss=0.9939627051353455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148: loss=0.988488495349884\n",
      "epoch 149: loss=0.9793978929519653\n",
      "epoch 150: loss=0.9693446159362793\n",
      "epoch 151: loss=0.9558926820755005\n",
      "epoch 152: loss=0.9606722593307495\n",
      "epoch 153: loss=0.9503278136253357\n",
      "epoch 154: loss=0.9876106977462769\n",
      "epoch 155: loss=0.9843312501907349\n",
      "epoch 156: loss=0.975551187992096\n",
      "epoch 157: loss=0.9797118306159973\n",
      "epoch 158: loss=0.9860350489616394\n",
      "epoch 159: loss=0.975692868232727\n",
      "epoch 160: loss=0.9802927374839783\n",
      "epoch 161: loss=0.9833927154541016\n",
      "epoch 162: loss=0.9936062693595886\n",
      "epoch 163: loss=0.9763416647911072\n",
      "epoch 164: loss=0.9889683127403259\n",
      "epoch 165: loss=0.947036862373352\n",
      "epoch 166: loss=0.9720444679260254\n",
      "epoch 167: loss=0.9619520902633667\n",
      "epoch 168: loss=0.9686275124549866\n",
      "epoch 169: loss=0.9697490930557251\n",
      "epoch 170: loss=0.9815670251846313\n",
      "epoch 171: loss=0.9784315824508667\n",
      "epoch 172: loss=0.9790658354759216\n",
      "epoch 173: loss=0.9688547253608704\n",
      "epoch 174: loss=0.9813115000724792\n",
      "epoch 175: loss=0.981040358543396\n",
      "epoch 176: loss=0.9626297950744629\n",
      "epoch 177: loss=0.9723234176635742\n",
      "epoch 178: loss=0.9699402451515198\n",
      "epoch 179: loss=0.9652062058448792\n",
      "epoch 180: loss=0.9699791669845581\n",
      "epoch 181: loss=0.9724662899971008\n",
      "epoch 182: loss=0.967194139957428\n",
      "epoch 183: loss=0.9723734259605408\n",
      "epoch 184: loss=0.9855762720108032\n",
      "epoch 185: loss=0.9581091403961182\n",
      "epoch 186: loss=0.9844508767127991\n",
      "epoch 187: loss=0.9603694677352905\n",
      "epoch 188: loss=0.9697932600975037\n",
      "epoch 189: loss=0.9529465436935425\n",
      "epoch 190: loss=0.9771744012832642\n",
      "epoch 191: loss=0.95494145154953\n",
      "epoch 192: loss=0.9699978232383728\n",
      "epoch 193: loss=0.9695543646812439\n",
      "epoch 194: loss=0.9725742936134338\n",
      "epoch 195: loss=0.9804596304893494\n",
      "epoch 196: loss=0.9614771604537964\n",
      "epoch 197: loss=0.9801598191261292\n",
      "epoch 198: loss=0.9664668440818787\n",
      "epoch 199: loss=0.9585247039794922\n",
      "training patch with 670 edges\n",
      "epoch 0: loss=1.9938427209854126\n",
      "epoch 1: loss=1.7777290344238281\n",
      "epoch 2: loss=1.5864055156707764\n",
      "epoch 3: loss=1.5846461057662964\n",
      "epoch 4: loss=1.4835267066955566\n",
      "epoch 5: loss=1.503354787826538\n",
      "epoch 6: loss=1.469812035560608\n",
      "epoch 7: loss=1.4582208395004272\n",
      "epoch 8: loss=1.433946132659912\n",
      "epoch 9: loss=1.416132926940918\n",
      "epoch 10: loss=1.4148716926574707\n",
      "epoch 11: loss=1.4138234853744507\n",
      "epoch 12: loss=1.4034689664840698\n",
      "epoch 13: loss=1.4131609201431274\n",
      "epoch 14: loss=1.4010204076766968\n",
      "epoch 15: loss=1.3985037803649902\n",
      "epoch 16: loss=1.3868317604064941\n",
      "epoch 17: loss=1.3939225673675537\n",
      "epoch 18: loss=1.3859089612960815\n",
      "epoch 19: loss=1.3790429830551147\n",
      "epoch 20: loss=1.3791791200637817\n",
      "epoch 21: loss=1.3729934692382812\n",
      "epoch 22: loss=1.37063729763031\n",
      "epoch 23: loss=1.376721739768982\n",
      "epoch 24: loss=1.3764640092849731\n",
      "epoch 25: loss=1.3642525672912598\n",
      "epoch 26: loss=1.3550724983215332\n",
      "epoch 27: loss=1.346693992614746\n",
      "epoch 28: loss=1.3492627143859863\n",
      "epoch 29: loss=1.350649356842041\n",
      "epoch 30: loss=1.3440476655960083\n",
      "epoch 31: loss=1.3335864543914795\n",
      "epoch 32: loss=1.3298269510269165\n",
      "epoch 33: loss=1.3262605667114258\n",
      "epoch 34: loss=1.3279813528060913\n",
      "epoch 35: loss=1.31440269947052\n",
      "epoch 36: loss=1.3012077808380127\n",
      "epoch 37: loss=1.2964876890182495\n",
      "epoch 38: loss=1.2765414714813232\n",
      "epoch 39: loss=1.2805112600326538\n",
      "epoch 40: loss=1.2607461214065552\n",
      "epoch 41: loss=1.2537107467651367\n",
      "epoch 42: loss=1.2475312948226929\n",
      "epoch 43: loss=1.2225277423858643\n",
      "epoch 44: loss=1.2421733140945435\n",
      "epoch 45: loss=1.2157212495803833\n",
      "epoch 46: loss=1.17485773563385\n",
      "epoch 47: loss=1.179809331893921\n",
      "epoch 48: loss=1.1874750852584839\n",
      "epoch 49: loss=1.1654101610183716\n",
      "epoch 50: loss=1.1762936115264893\n",
      "epoch 51: loss=1.140313744544983\n",
      "epoch 52: loss=1.1156575679779053\n",
      "epoch 53: loss=1.1080964803695679\n",
      "epoch 54: loss=1.051936388015747\n",
      "epoch 55: loss=1.1726127862930298\n",
      "epoch 56: loss=1.0811142921447754\n",
      "epoch 57: loss=1.0854986906051636\n",
      "epoch 58: loss=1.075784683227539\n",
      "epoch 59: loss=1.0829524993896484\n",
      "epoch 60: loss=1.0940101146697998\n",
      "epoch 61: loss=1.0547151565551758\n",
      "epoch 62: loss=1.0561312437057495\n",
      "epoch 63: loss=1.0283315181732178\n",
      "epoch 64: loss=1.0550459623336792\n",
      "epoch 65: loss=1.0309821367263794\n",
      "epoch 66: loss=1.0061320066452026\n",
      "epoch 67: loss=1.0074485540390015\n",
      "epoch 68: loss=1.0170701742172241\n",
      "epoch 69: loss=1.0147141218185425\n",
      "epoch 70: loss=1.028299331665039\n",
      "epoch 71: loss=0.9903483986854553\n",
      "epoch 72: loss=1.0322452783584595\n",
      "epoch 73: loss=1.0282753705978394\n",
      "epoch 74: loss=1.015307068824768\n",
      "epoch 75: loss=0.993794858455658\n",
      "epoch 76: loss=1.0381840467453003\n",
      "epoch 77: loss=1.005645990371704\n",
      "epoch 78: loss=1.033738136291504\n",
      "epoch 79: loss=0.9967038035392761\n",
      "epoch 80: loss=1.0036741495132446\n",
      "epoch 81: loss=1.0139561891555786\n",
      "epoch 82: loss=1.012032389640808\n",
      "epoch 83: loss=1.01703941822052\n",
      "epoch 84: loss=1.0069751739501953\n",
      "epoch 85: loss=1.019501805305481\n",
      "epoch 86: loss=0.9973465800285339\n",
      "epoch 87: loss=1.0070750713348389\n",
      "epoch 88: loss=0.9686793684959412\n",
      "epoch 89: loss=0.9774170517921448\n",
      "epoch 90: loss=0.9900413155555725\n",
      "epoch 91: loss=0.9628326296806335\n",
      "epoch 92: loss=0.9981124997138977\n",
      "epoch 93: loss=0.9871296882629395\n",
      "epoch 94: loss=0.9766721129417419\n",
      "epoch 95: loss=1.0427082777023315\n",
      "epoch 96: loss=1.0088469982147217\n",
      "epoch 97: loss=0.9991670250892639\n",
      "epoch 98: loss=1.0254021883010864\n",
      "epoch 99: loss=1.0307847261428833\n",
      "epoch 100: loss=0.9957942962646484\n",
      "epoch 101: loss=0.9815760254859924\n",
      "epoch 102: loss=0.9516500234603882\n",
      "epoch 103: loss=0.9915552139282227\n",
      "epoch 104: loss=0.9977943301200867\n",
      "epoch 105: loss=0.9706750512123108\n",
      "epoch 106: loss=0.9911245703697205\n",
      "epoch 107: loss=0.965819776058197\n",
      "epoch 108: loss=1.0039422512054443\n",
      "epoch 109: loss=1.006434679031372\n",
      "epoch 110: loss=1.0272616147994995\n",
      "epoch 111: loss=1.0165919065475464\n",
      "epoch 112: loss=1.0048247575759888\n",
      "epoch 113: loss=1.022019624710083\n",
      "epoch 114: loss=0.9907761812210083\n",
      "epoch 115: loss=1.0452182292938232\n",
      "epoch 116: loss=0.9838542342185974\n",
      "epoch 117: loss=1.0011309385299683\n",
      "epoch 118: loss=0.9741657972335815\n",
      "epoch 119: loss=0.9749010801315308\n",
      "epoch 120: loss=1.0053523778915405\n",
      "epoch 121: loss=0.9879776835441589\n",
      "epoch 122: loss=0.9929612278938293\n",
      "epoch 123: loss=1.0129536390304565\n",
      "epoch 124: loss=1.0193562507629395\n",
      "epoch 125: loss=1.0133981704711914\n",
      "epoch 126: loss=1.003040075302124\n",
      "epoch 127: loss=0.9888037443161011\n",
      "epoch 128: loss=1.016676664352417\n",
      "epoch 129: loss=0.9924806356430054\n",
      "epoch 130: loss=0.9623773097991943\n",
      "epoch 131: loss=0.9858356714248657\n",
      "epoch 132: loss=1.0381284952163696\n",
      "epoch 133: loss=0.9774710536003113\n",
      "epoch 134: loss=1.002923846244812\n",
      "epoch 135: loss=0.9999186992645264\n",
      "epoch 136: loss=1.0145655870437622\n",
      "epoch 137: loss=0.9918100237846375\n",
      "epoch 138: loss=1.0073515176773071\n",
      "epoch 139: loss=0.9821420907974243\n",
      "epoch 140: loss=0.9962193369865417\n",
      "epoch 141: loss=1.0013676881790161\n",
      "epoch 142: loss=0.989895761013031\n",
      "epoch 143: loss=0.9808482527732849\n",
      "epoch 144: loss=1.0343507528305054\n",
      "epoch 145: loss=0.9905581474304199\n",
      "epoch 146: loss=1.0133382081985474\n",
      "epoch 147: loss=1.0454230308532715\n",
      "epoch 148: loss=0.994932234287262\n",
      "epoch 149: loss=1.0263123512268066\n",
      "epoch 150: loss=1.0129115581512451\n",
      "epoch 151: loss=0.9702560901641846\n",
      "epoch 152: loss=0.9816337823867798\n",
      "epoch 153: loss=1.033762812614441\n",
      "epoch 154: loss=1.0495802164077759\n",
      "epoch 155: loss=0.9427978992462158\n",
      "epoch 156: loss=1.0160140991210938\n",
      "epoch 157: loss=0.9702688455581665\n",
      "epoch 158: loss=0.9877361059188843\n",
      "epoch 159: loss=1.0096334218978882\n",
      "epoch 160: loss=0.9557494521141052\n",
      "epoch 161: loss=0.9781897664070129\n",
      "epoch 162: loss=0.9418109059333801\n",
      "epoch 163: loss=0.9966310858726501\n",
      "epoch 164: loss=0.988002359867096\n",
      "epoch 165: loss=0.9874584078788757\n",
      "epoch 166: loss=0.9821519255638123\n",
      "epoch 167: loss=0.9924200177192688\n",
      "epoch 168: loss=1.0150011777877808\n",
      "epoch 169: loss=0.9676256775856018\n",
      "epoch 170: loss=0.9811184406280518\n",
      "epoch 171: loss=0.9833064675331116\n",
      "epoch 172: loss=0.9995870590209961\n",
      "epoch 173: loss=0.9813646078109741\n",
      "epoch 174: loss=0.9817030429840088\n",
      "epoch 175: loss=0.9539347290992737\n",
      "epoch 176: loss=0.9948230385780334\n",
      "epoch 177: loss=0.9954065680503845\n",
      "epoch 178: loss=0.9592494964599609\n",
      "epoch 179: loss=1.0173602104187012\n",
      "epoch 180: loss=0.9567539691925049\n",
      "epoch 181: loss=0.9623377919197083\n",
      "epoch 182: loss=1.0129528045654297\n",
      "epoch 183: loss=1.009603500366211\n",
      "epoch 184: loss=1.0000382661819458\n",
      "epoch 185: loss=0.9822314977645874\n",
      "epoch 186: loss=0.9373622536659241\n",
      "epoch 187: loss=0.9887042045593262\n",
      "epoch 188: loss=0.9811699390411377\n",
      "epoch 189: loss=0.9702796936035156\n",
      "epoch 190: loss=0.9722589254379272\n",
      "epoch 191: loss=0.9597161412239075\n",
      "epoch 192: loss=0.9798716306686401\n",
      "epoch 193: loss=0.9758402705192566\n",
      "epoch 194: loss=1.0033737421035767\n",
      "epoch 195: loss=1.0251266956329346\n",
      "epoch 196: loss=1.006335735321045\n",
      "epoch 197: loss=1.0279699563980103\n",
      "epoch 198: loss=0.9697849154472351\n",
      "epoch 199: loss=1.0211690664291382\n",
      "training patch with 1602 edges\n",
      "epoch 0: loss=1.7695719003677368\n",
      "epoch 1: loss=1.7824184894561768\n",
      "epoch 2: loss=1.644235372543335\n",
      "epoch 3: loss=1.604785680770874\n",
      "epoch 4: loss=1.6301418542861938\n",
      "epoch 5: loss=1.5736165046691895\n",
      "epoch 6: loss=1.5048643350601196\n",
      "epoch 7: loss=1.489249348640442\n",
      "epoch 8: loss=1.496483325958252\n",
      "epoch 9: loss=1.449357509613037\n",
      "epoch 10: loss=1.4688198566436768\n",
      "epoch 11: loss=1.4364292621612549\n",
      "epoch 12: loss=1.4236547946929932\n",
      "epoch 13: loss=1.4091644287109375\n",
      "epoch 14: loss=1.391970157623291\n",
      "epoch 15: loss=1.4098937511444092\n",
      "epoch 16: loss=1.3949638605117798\n",
      "epoch 17: loss=1.3775204420089722\n",
      "epoch 18: loss=1.3721281290054321\n",
      "epoch 19: loss=1.3874335289001465\n",
      "epoch 20: loss=1.3692317008972168\n",
      "epoch 21: loss=1.367836833000183\n",
      "epoch 22: loss=1.3611228466033936\n",
      "epoch 23: loss=1.3572826385498047\n",
      "epoch 24: loss=1.357387900352478\n",
      "epoch 25: loss=1.3650459051132202\n",
      "epoch 26: loss=1.3614680767059326\n",
      "epoch 27: loss=1.3443275690078735\n",
      "epoch 28: loss=1.3416410684585571\n",
      "epoch 29: loss=1.3341021537780762\n",
      "epoch 30: loss=1.3328921794891357\n",
      "epoch 31: loss=1.3211175203323364\n",
      "epoch 32: loss=1.3301819562911987\n",
      "epoch 33: loss=1.3234797716140747\n",
      "epoch 34: loss=1.3178105354309082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35: loss=1.316788911819458\n",
      "epoch 36: loss=1.3120273351669312\n",
      "epoch 37: loss=1.307877779006958\n",
      "epoch 38: loss=1.3012804985046387\n",
      "epoch 39: loss=1.286802887916565\n",
      "epoch 40: loss=1.2885971069335938\n",
      "epoch 41: loss=1.2918729782104492\n",
      "epoch 42: loss=1.2775810956954956\n",
      "epoch 43: loss=1.2686982154846191\n",
      "epoch 44: loss=1.270656943321228\n",
      "epoch 45: loss=1.253581166267395\n",
      "epoch 46: loss=1.248507022857666\n",
      "epoch 47: loss=1.2415443658828735\n",
      "epoch 48: loss=1.2125471830368042\n",
      "epoch 49: loss=1.2053217887878418\n",
      "epoch 50: loss=1.1970685720443726\n",
      "epoch 51: loss=1.1858251094818115\n",
      "epoch 52: loss=1.180923581123352\n",
      "epoch 53: loss=1.1594321727752686\n",
      "epoch 54: loss=1.1553620100021362\n",
      "epoch 55: loss=1.1397331953048706\n",
      "epoch 56: loss=1.12147057056427\n",
      "epoch 57: loss=1.1595511436462402\n",
      "epoch 58: loss=1.135593056678772\n",
      "epoch 59: loss=1.104264736175537\n",
      "epoch 60: loss=1.1057476997375488\n",
      "epoch 61: loss=1.1258119344711304\n",
      "epoch 62: loss=1.0887477397918701\n",
      "epoch 63: loss=1.1092456579208374\n",
      "epoch 64: loss=1.0937858819961548\n",
      "epoch 65: loss=1.112119197845459\n",
      "epoch 66: loss=1.1003471612930298\n",
      "epoch 67: loss=1.09841787815094\n",
      "epoch 68: loss=1.088400959968567\n",
      "epoch 69: loss=1.0476956367492676\n",
      "epoch 70: loss=1.0670623779296875\n",
      "epoch 71: loss=1.0552009344100952\n",
      "epoch 72: loss=1.052390217781067\n",
      "epoch 73: loss=1.0582913160324097\n",
      "epoch 74: loss=1.0517319440841675\n",
      "epoch 75: loss=1.0266362428665161\n",
      "epoch 76: loss=1.0236622095108032\n",
      "epoch 77: loss=1.042028784751892\n",
      "epoch 78: loss=1.031742811203003\n",
      "epoch 79: loss=1.0223796367645264\n",
      "epoch 80: loss=1.0164377689361572\n",
      "epoch 81: loss=1.0352354049682617\n",
      "epoch 82: loss=1.0173214673995972\n",
      "epoch 83: loss=1.0199861526489258\n",
      "epoch 84: loss=1.0291259288787842\n",
      "epoch 85: loss=0.9987918734550476\n",
      "epoch 86: loss=0.9758451581001282\n",
      "epoch 87: loss=1.0194913148880005\n",
      "epoch 88: loss=1.035645842552185\n",
      "epoch 89: loss=1.000369906425476\n",
      "epoch 90: loss=1.021686315536499\n",
      "epoch 91: loss=1.0004059076309204\n",
      "epoch 92: loss=0.9940103888511658\n",
      "epoch 93: loss=0.9796686768531799\n",
      "epoch 94: loss=0.9725964665412903\n",
      "epoch 95: loss=0.9932924509048462\n",
      "epoch 96: loss=0.9785452485084534\n",
      "epoch 97: loss=1.0009572505950928\n",
      "epoch 98: loss=0.9791425466537476\n",
      "epoch 99: loss=0.9814353585243225\n",
      "epoch 100: loss=0.9863588809967041\n",
      "epoch 101: loss=1.0038245916366577\n",
      "epoch 102: loss=0.999830424785614\n",
      "epoch 103: loss=0.9774110317230225\n",
      "epoch 104: loss=0.9654937982559204\n",
      "epoch 105: loss=0.998809278011322\n",
      "epoch 106: loss=0.9918625354766846\n",
      "epoch 107: loss=0.9967526793479919\n",
      "epoch 108: loss=0.9663589000701904\n",
      "epoch 109: loss=0.9738366007804871\n",
      "epoch 110: loss=0.9754438996315002\n",
      "epoch 111: loss=1.0114777088165283\n",
      "epoch 112: loss=0.9914720058441162\n",
      "epoch 113: loss=0.9952777624130249\n",
      "epoch 114: loss=0.9794740676879883\n",
      "epoch 115: loss=0.9867913126945496\n",
      "epoch 116: loss=0.9597547054290771\n",
      "epoch 117: loss=0.9678224921226501\n",
      "epoch 118: loss=0.9835209846496582\n",
      "epoch 119: loss=0.9710896611213684\n",
      "epoch 120: loss=0.9560518264770508\n",
      "epoch 121: loss=0.9548203349113464\n",
      "epoch 122: loss=0.9748479127883911\n",
      "epoch 123: loss=0.9613346457481384\n",
      "epoch 124: loss=0.9724061489105225\n",
      "epoch 125: loss=0.986223578453064\n",
      "epoch 126: loss=0.9209498763084412\n",
      "epoch 127: loss=0.9662408828735352\n",
      "epoch 128: loss=0.9709804654121399\n",
      "epoch 129: loss=0.9577434659004211\n",
      "epoch 130: loss=0.9685660004615784\n",
      "epoch 131: loss=0.9577579498291016\n",
      "epoch 132: loss=0.9661470055580139\n",
      "epoch 133: loss=0.961031436920166\n",
      "epoch 134: loss=0.9413191676139832\n",
      "epoch 135: loss=0.9749327898025513\n",
      "epoch 136: loss=0.9488252401351929\n",
      "epoch 137: loss=0.9468294978141785\n",
      "epoch 138: loss=0.9940611720085144\n",
      "epoch 139: loss=0.9669228196144104\n",
      "epoch 140: loss=0.9921770095825195\n",
      "epoch 141: loss=0.9452000856399536\n",
      "epoch 142: loss=0.9491089582443237\n",
      "epoch 143: loss=0.9939074516296387\n",
      "epoch 144: loss=0.9763152003288269\n",
      "epoch 145: loss=0.9466860294342041\n",
      "epoch 146: loss=0.9983587861061096\n",
      "epoch 147: loss=0.9795145988464355\n",
      "epoch 148: loss=0.9393507242202759\n",
      "epoch 149: loss=0.9464098215103149\n",
      "epoch 150: loss=1.0079210996627808\n",
      "epoch 151: loss=0.9852593541145325\n",
      "epoch 152: loss=1.0183790922164917\n",
      "epoch 153: loss=0.9491038918495178\n",
      "epoch 154: loss=0.9860095381736755\n",
      "epoch 155: loss=0.981747567653656\n",
      "epoch 156: loss=0.9602369666099548\n",
      "epoch 157: loss=0.9457481503486633\n",
      "epoch 158: loss=0.9789722561836243\n",
      "epoch 159: loss=0.9738790392875671\n",
      "epoch 160: loss=0.9522348642349243\n",
      "epoch 161: loss=0.9690269231796265\n",
      "epoch 162: loss=0.95168137550354\n",
      "epoch 163: loss=0.9821785688400269\n",
      "epoch 164: loss=0.9679252505302429\n",
      "epoch 165: loss=0.9556502103805542\n",
      "epoch 166: loss=0.9759339690208435\n",
      "epoch 167: loss=0.9695518612861633\n",
      "epoch 168: loss=0.9574182629585266\n",
      "epoch 169: loss=0.9650189876556396\n",
      "epoch 170: loss=0.9754165410995483\n",
      "epoch 171: loss=0.9934415221214294\n",
      "epoch 172: loss=0.94754958152771\n",
      "epoch 173: loss=0.9746997952461243\n",
      "epoch 174: loss=0.9841930270195007\n",
      "epoch 175: loss=0.976318895816803\n",
      "epoch 176: loss=0.9688721895217896\n",
      "epoch 177: loss=0.9863981008529663\n",
      "epoch 178: loss=0.9806963205337524\n",
      "epoch 179: loss=0.9833634495735168\n",
      "epoch 180: loss=0.9646713733673096\n",
      "epoch 181: loss=0.9755485653877258\n",
      "epoch 182: loss=0.9834631681442261\n",
      "epoch 183: loss=0.9612020254135132\n",
      "epoch 184: loss=0.9764956831932068\n",
      "epoch 185: loss=0.9519336819648743\n",
      "epoch 186: loss=0.9697234630584717\n",
      "epoch 187: loss=0.9944064021110535\n",
      "epoch 188: loss=0.9667971134185791\n",
      "epoch 189: loss=0.9789542555809021\n",
      "epoch 190: loss=0.9520414471626282\n",
      "epoch 191: loss=0.9723196625709534\n",
      "epoch 192: loss=0.9580956101417542\n",
      "epoch 193: loss=0.9526636600494385\n",
      "epoch 194: loss=0.9743379354476929\n",
      "epoch 195: loss=0.9624407887458801\n",
      "epoch 196: loss=0.9637696146965027\n",
      "epoch 197: loss=0.9521436095237732\n",
      "epoch 198: loss=0.968952476978302\n",
      "epoch 199: loss=0.9812541007995605\n",
      "training patch with 1800 edges\n",
      "epoch 0: loss=1.8230966329574585\n",
      "epoch 1: loss=1.710518479347229\n",
      "epoch 2: loss=1.6809768676757812\n",
      "epoch 3: loss=1.5537983179092407\n",
      "epoch 4: loss=1.5311496257781982\n",
      "epoch 5: loss=1.479813814163208\n",
      "epoch 6: loss=1.494827151298523\n",
      "epoch 7: loss=1.4418365955352783\n",
      "epoch 8: loss=1.4188780784606934\n",
      "epoch 9: loss=1.4134817123413086\n",
      "epoch 10: loss=1.4087533950805664\n",
      "epoch 11: loss=1.4063161611557007\n",
      "epoch 12: loss=1.4025590419769287\n",
      "epoch 13: loss=1.3927316665649414\n",
      "epoch 14: loss=1.398673176765442\n",
      "epoch 15: loss=1.3914331197738647\n",
      "epoch 16: loss=1.3850188255310059\n",
      "epoch 17: loss=1.3724982738494873\n",
      "epoch 18: loss=1.3669812679290771\n",
      "epoch 19: loss=1.3634018898010254\n",
      "epoch 20: loss=1.3626347780227661\n",
      "epoch 21: loss=1.3452099561691284\n",
      "epoch 22: loss=1.3630443811416626\n",
      "epoch 23: loss=1.3620778322219849\n",
      "epoch 24: loss=1.3496674299240112\n",
      "epoch 25: loss=1.3376564979553223\n",
      "epoch 26: loss=1.33637535572052\n",
      "epoch 27: loss=1.3274611234664917\n",
      "epoch 28: loss=1.3302422761917114\n",
      "epoch 29: loss=1.3216630220413208\n",
      "epoch 30: loss=1.319737434387207\n",
      "epoch 31: loss=1.3139287233352661\n",
      "epoch 32: loss=1.3098633289337158\n",
      "epoch 33: loss=1.298958659172058\n",
      "epoch 34: loss=1.3061548471450806\n",
      "epoch 35: loss=1.3042385578155518\n",
      "epoch 36: loss=1.2927967309951782\n",
      "epoch 37: loss=1.2856673002243042\n",
      "epoch 38: loss=1.2862964868545532\n",
      "epoch 39: loss=1.2831659317016602\n",
      "epoch 40: loss=1.2741425037384033\n",
      "epoch 41: loss=1.2666172981262207\n",
      "epoch 42: loss=1.2550443410873413\n",
      "epoch 43: loss=1.2536780834197998\n",
      "epoch 44: loss=1.2498196363449097\n",
      "epoch 45: loss=1.2558000087738037\n",
      "epoch 46: loss=1.2268339395523071\n",
      "epoch 47: loss=1.2206392288208008\n",
      "epoch 48: loss=1.2200111150741577\n",
      "epoch 49: loss=1.213255524635315\n",
      "epoch 50: loss=1.2010246515274048\n",
      "epoch 51: loss=1.1994658708572388\n",
      "epoch 52: loss=1.1800899505615234\n",
      "epoch 53: loss=1.1880981922149658\n",
      "epoch 54: loss=1.189129114151001\n",
      "epoch 55: loss=1.1601024866104126\n",
      "epoch 56: loss=1.143153190612793\n",
      "epoch 57: loss=1.150153636932373\n",
      "epoch 58: loss=1.1560641527175903\n",
      "epoch 59: loss=1.1352617740631104\n",
      "epoch 60: loss=1.1689448356628418\n",
      "epoch 61: loss=1.1616616249084473\n",
      "epoch 62: loss=1.1646229028701782\n",
      "epoch 63: loss=1.1616944074630737\n",
      "epoch 64: loss=1.1518059968948364\n",
      "epoch 65: loss=1.1619110107421875\n",
      "epoch 66: loss=1.1697683334350586\n",
      "epoch 67: loss=1.1422940492630005\n",
      "epoch 68: loss=1.1633714437484741\n",
      "epoch 69: loss=1.159171462059021\n",
      "epoch 70: loss=1.146249771118164\n",
      "epoch 71: loss=1.1264194250106812\n",
      "epoch 72: loss=1.1510820388793945\n",
      "epoch 73: loss=1.1337567567825317\n",
      "epoch 74: loss=1.1057922840118408\n",
      "epoch 75: loss=1.128853440284729\n",
      "epoch 76: loss=1.1291303634643555\n",
      "epoch 77: loss=1.1161357164382935\n",
      "epoch 78: loss=1.106616497039795\n",
      "epoch 79: loss=1.108507513999939\n",
      "epoch 80: loss=1.0986027717590332\n",
      "epoch 81: loss=1.1022840738296509\n",
      "epoch 82: loss=1.0878913402557373\n",
      "epoch 83: loss=1.0833348035812378\n",
      "epoch 84: loss=1.086356520652771\n",
      "epoch 85: loss=1.0703495740890503\n",
      "epoch 86: loss=1.0587977170944214\n",
      "epoch 87: loss=1.0742802619934082\n",
      "epoch 88: loss=1.0750408172607422\n",
      "epoch 89: loss=1.0530627965927124\n",
      "epoch 90: loss=1.053112506866455\n",
      "epoch 91: loss=1.0543735027313232\n",
      "epoch 92: loss=1.0410163402557373\n",
      "epoch 93: loss=1.0806235074996948\n",
      "epoch 94: loss=1.051902413368225\n",
      "epoch 95: loss=1.0567537546157837\n",
      "epoch 96: loss=1.0528353452682495\n",
      "epoch 97: loss=1.0403374433517456\n",
      "epoch 98: loss=1.046380877494812\n",
      "epoch 99: loss=1.053332805633545\n",
      "epoch 100: loss=1.0292906761169434\n",
      "epoch 101: loss=1.0426453351974487\n",
      "epoch 102: loss=1.0301772356033325\n",
      "epoch 103: loss=1.0084044933319092\n",
      "epoch 104: loss=1.003668189048767\n",
      "epoch 105: loss=1.0294227600097656\n",
      "epoch 106: loss=1.0269919633865356\n",
      "epoch 107: loss=1.0071579217910767\n",
      "epoch 108: loss=1.022982120513916\n",
      "epoch 109: loss=1.0345127582550049\n",
      "epoch 110: loss=1.0329643487930298\n",
      "epoch 111: loss=1.0133390426635742\n",
      "epoch 112: loss=1.0473275184631348\n",
      "epoch 113: loss=1.0240001678466797\n",
      "epoch 114: loss=1.0155715942382812\n",
      "epoch 115: loss=1.0170228481292725\n",
      "epoch 116: loss=1.0041046142578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117: loss=1.0183721780776978\n",
      "epoch 118: loss=1.0204812288284302\n",
      "epoch 119: loss=0.9957618713378906\n",
      "epoch 120: loss=1.0046775341033936\n",
      "epoch 121: loss=0.9991852045059204\n",
      "epoch 122: loss=0.9960452318191528\n",
      "epoch 123: loss=1.0134131908416748\n",
      "epoch 124: loss=0.9944544434547424\n",
      "epoch 125: loss=0.9915669560432434\n",
      "epoch 126: loss=1.0051946640014648\n",
      "epoch 127: loss=1.002321720123291\n",
      "epoch 128: loss=1.0123167037963867\n",
      "epoch 129: loss=0.9958204627037048\n",
      "epoch 130: loss=1.010258436203003\n",
      "epoch 131: loss=1.0248215198516846\n",
      "epoch 132: loss=1.0144680738449097\n",
      "epoch 133: loss=1.0020498037338257\n",
      "epoch 134: loss=1.0085821151733398\n",
      "epoch 135: loss=0.9908104538917542\n",
      "epoch 136: loss=0.9995095133781433\n",
      "epoch 137: loss=1.0041853189468384\n",
      "epoch 138: loss=0.9825147986412048\n",
      "epoch 139: loss=0.99178546667099\n",
      "epoch 140: loss=1.000339388847351\n",
      "epoch 141: loss=0.9849673509597778\n",
      "epoch 142: loss=0.996453583240509\n",
      "epoch 143: loss=0.9952039122581482\n",
      "epoch 144: loss=1.0150893926620483\n",
      "epoch 145: loss=0.9923689961433411\n",
      "epoch 146: loss=0.9802836775779724\n",
      "epoch 147: loss=0.9943975806236267\n",
      "epoch 148: loss=0.9977182745933533\n",
      "epoch 149: loss=0.991153359413147\n",
      "epoch 150: loss=0.977642297744751\n",
      "epoch 151: loss=0.9894356727600098\n",
      "epoch 152: loss=1.0127496719360352\n",
      "epoch 153: loss=1.0043494701385498\n",
      "epoch 154: loss=1.0115337371826172\n",
      "epoch 155: loss=0.9848388433456421\n",
      "epoch 156: loss=0.9803164601325989\n",
      "epoch 157: loss=0.9933993220329285\n",
      "epoch 158: loss=0.9775813221931458\n",
      "epoch 159: loss=0.9812986254692078\n",
      "epoch 160: loss=1.0003522634506226\n",
      "epoch 161: loss=0.9864054918289185\n",
      "epoch 162: loss=0.9983181357383728\n",
      "epoch 163: loss=0.9914464354515076\n",
      "epoch 164: loss=0.9816750884056091\n",
      "epoch 165: loss=0.9879060983657837\n",
      "epoch 166: loss=0.9977394342422485\n",
      "epoch 167: loss=0.9961592555046082\n",
      "epoch 168: loss=0.9817817807197571\n",
      "epoch 169: loss=0.971392810344696\n",
      "epoch 170: loss=1.0113525390625\n",
      "epoch 171: loss=0.9879021644592285\n",
      "epoch 172: loss=0.9904897809028625\n",
      "epoch 173: loss=1.003998875617981\n",
      "epoch 174: loss=1.0062127113342285\n",
      "epoch 175: loss=0.9936782121658325\n",
      "epoch 176: loss=0.9927082061767578\n",
      "epoch 177: loss=0.9894760251045227\n",
      "epoch 178: loss=1.0284532308578491\n",
      "epoch 179: loss=1.000210165977478\n",
      "epoch 180: loss=1.0121028423309326\n",
      "epoch 181: loss=0.9933017492294312\n",
      "epoch 182: loss=0.9850388765335083\n",
      "epoch 183: loss=0.9634783267974854\n",
      "epoch 184: loss=0.9898374676704407\n",
      "epoch 185: loss=0.9832013249397278\n",
      "epoch 186: loss=0.9783313870429993\n",
      "epoch 187: loss=0.9689956307411194\n",
      "epoch 188: loss=0.994421124458313\n",
      "epoch 189: loss=0.985826313495636\n",
      "epoch 190: loss=0.9848257899284363\n",
      "epoch 191: loss=0.9644157290458679\n",
      "epoch 192: loss=0.9930972456932068\n",
      "epoch 193: loss=0.9758313894271851\n",
      "epoch 194: loss=0.9991381168365479\n",
      "epoch 195: loss=0.9787859320640564\n",
      "epoch 196: loss=0.9883220195770264\n",
      "epoch 197: loss=0.9900477528572083\n",
      "epoch 198: loss=0.9883022904396057\n",
      "epoch 199: loss=0.9774129390716553\n",
      "training patch with 1844 edges\n",
      "epoch 0: loss=1.702926516532898\n",
      "epoch 1: loss=1.6537145376205444\n",
      "epoch 2: loss=1.635807752609253\n",
      "epoch 3: loss=1.5730791091918945\n",
      "epoch 4: loss=1.5065395832061768\n",
      "epoch 5: loss=1.4859955310821533\n",
      "epoch 6: loss=1.4647563695907593\n",
      "epoch 7: loss=1.4597513675689697\n",
      "epoch 8: loss=1.4277517795562744\n",
      "epoch 9: loss=1.4239497184753418\n",
      "epoch 10: loss=1.3938848972320557\n",
      "epoch 11: loss=1.3965879678726196\n",
      "epoch 12: loss=1.3726478815078735\n",
      "epoch 13: loss=1.3652842044830322\n",
      "epoch 14: loss=1.3383876085281372\n",
      "epoch 15: loss=1.3289567232131958\n",
      "epoch 16: loss=1.333528995513916\n",
      "epoch 17: loss=1.314778208732605\n",
      "epoch 18: loss=1.328436017036438\n",
      "epoch 19: loss=1.2998301982879639\n",
      "epoch 20: loss=1.2872473001480103\n",
      "epoch 21: loss=1.295716643333435\n",
      "epoch 22: loss=1.2796558141708374\n",
      "epoch 23: loss=1.2768356800079346\n",
      "epoch 24: loss=1.2615528106689453\n",
      "epoch 25: loss=1.2635716199874878\n",
      "epoch 26: loss=1.2402414083480835\n",
      "epoch 27: loss=1.2327874898910522\n",
      "epoch 28: loss=1.2095351219177246\n",
      "epoch 29: loss=1.198090672492981\n",
      "epoch 30: loss=1.1772710084915161\n",
      "epoch 31: loss=1.1594666242599487\n",
      "epoch 32: loss=1.1315544843673706\n",
      "epoch 33: loss=1.106632113456726\n",
      "epoch 34: loss=1.0921592712402344\n",
      "epoch 35: loss=1.0824494361877441\n",
      "epoch 36: loss=1.061667799949646\n",
      "epoch 37: loss=1.0461660623550415\n",
      "epoch 38: loss=1.043926477432251\n",
      "epoch 39: loss=1.0284627676010132\n",
      "epoch 40: loss=1.0480222702026367\n",
      "epoch 41: loss=1.0506290197372437\n",
      "epoch 42: loss=1.0561106204986572\n",
      "epoch 43: loss=1.030884861946106\n",
      "epoch 44: loss=1.0071425437927246\n",
      "epoch 45: loss=1.0130469799041748\n",
      "epoch 46: loss=0.987183690071106\n",
      "epoch 47: loss=0.980057954788208\n",
      "epoch 48: loss=0.9930952191352844\n",
      "epoch 49: loss=1.0210107564926147\n",
      "epoch 50: loss=1.0196504592895508\n",
      "epoch 51: loss=0.9984663128852844\n",
      "epoch 52: loss=1.0036121606826782\n",
      "epoch 53: loss=0.9946305751800537\n",
      "epoch 54: loss=0.9767964482307434\n",
      "epoch 55: loss=1.008237600326538\n",
      "epoch 56: loss=0.9862287640571594\n",
      "epoch 57: loss=0.9901195764541626\n",
      "epoch 58: loss=0.9855861067771912\n",
      "epoch 59: loss=0.9825323224067688\n",
      "epoch 60: loss=1.0025439262390137\n",
      "epoch 61: loss=0.9760938882827759\n",
      "epoch 62: loss=0.9856535196304321\n",
      "epoch 63: loss=0.9836866855621338\n",
      "epoch 64: loss=0.9818503260612488\n",
      "epoch 65: loss=0.9560884237289429\n",
      "epoch 66: loss=0.9596067667007446\n",
      "epoch 67: loss=0.9781343340873718\n",
      "epoch 68: loss=0.9784637093544006\n",
      "epoch 69: loss=0.9851639270782471\n",
      "epoch 70: loss=0.9605972766876221\n",
      "epoch 71: loss=0.9705417156219482\n",
      "epoch 72: loss=0.9603342413902283\n",
      "epoch 73: loss=0.97513347864151\n",
      "epoch 74: loss=0.9803107380867004\n",
      "epoch 75: loss=0.9551687240600586\n",
      "epoch 76: loss=0.9819760918617249\n",
      "epoch 77: loss=0.9998883008956909\n",
      "epoch 78: loss=0.9575197100639343\n",
      "epoch 79: loss=0.9821522831916809\n",
      "epoch 80: loss=0.9692605137825012\n",
      "epoch 81: loss=0.988351047039032\n",
      "epoch 82: loss=0.9456231594085693\n",
      "epoch 83: loss=0.9625943899154663\n",
      "epoch 84: loss=0.9892090559005737\n",
      "epoch 85: loss=0.9663069248199463\n",
      "epoch 86: loss=0.9786558151245117\n",
      "epoch 87: loss=0.9501242637634277\n",
      "epoch 88: loss=0.9711931943893433\n",
      "epoch 89: loss=0.9820755124092102\n",
      "epoch 90: loss=0.9462326169013977\n",
      "epoch 91: loss=0.9881110191345215\n",
      "epoch 92: loss=0.9564525485038757\n",
      "epoch 93: loss=0.9582194685935974\n",
      "epoch 94: loss=0.9734818935394287\n",
      "epoch 95: loss=0.9750537872314453\n",
      "epoch 96: loss=0.969455361366272\n",
      "epoch 97: loss=0.9792757034301758\n",
      "epoch 98: loss=0.9622380137443542\n",
      "epoch 99: loss=0.9713922739028931\n",
      "epoch 100: loss=0.9766824245452881\n",
      "epoch 101: loss=0.958092987537384\n",
      "epoch 102: loss=0.9767665266990662\n",
      "epoch 103: loss=0.9743223786354065\n",
      "epoch 104: loss=0.9585423469543457\n",
      "epoch 105: loss=0.9446136355400085\n",
      "epoch 106: loss=0.9767578840255737\n",
      "epoch 107: loss=0.9662562608718872\n",
      "epoch 108: loss=0.9808870553970337\n",
      "epoch 109: loss=0.9591962099075317\n",
      "epoch 110: loss=0.9580113291740417\n",
      "epoch 111: loss=0.9528538584709167\n",
      "epoch 112: loss=0.9818499088287354\n",
      "epoch 113: loss=0.9604438543319702\n",
      "epoch 114: loss=0.9397377967834473\n",
      "epoch 115: loss=0.9597295522689819\n",
      "epoch 116: loss=0.9644168615341187\n",
      "epoch 117: loss=0.9706281423568726\n",
      "epoch 118: loss=0.96162348985672\n",
      "epoch 119: loss=0.9652338624000549\n",
      "epoch 120: loss=0.9652684926986694\n",
      "epoch 121: loss=0.965151309967041\n",
      "epoch 122: loss=0.9827280044555664\n",
      "epoch 123: loss=0.9619148373603821\n",
      "epoch 124: loss=0.9751054048538208\n",
      "epoch 125: loss=0.9607983231544495\n",
      "epoch 126: loss=0.9587541222572327\n",
      "epoch 127: loss=0.9849601984024048\n",
      "epoch 128: loss=0.9503769278526306\n",
      "epoch 129: loss=0.9717410206794739\n",
      "epoch 130: loss=0.9578161239624023\n",
      "epoch 131: loss=0.9362726211547852\n",
      "epoch 132: loss=0.9626253247261047\n",
      "epoch 133: loss=0.9678865671157837\n",
      "epoch 134: loss=0.9641413688659668\n",
      "epoch 135: loss=0.9654318690299988\n",
      "epoch 136: loss=0.9592773914337158\n",
      "epoch 137: loss=0.9325886964797974\n",
      "epoch 138: loss=0.9442296028137207\n",
      "epoch 139: loss=0.9606078863143921\n",
      "epoch 140: loss=0.9459894299507141\n",
      "epoch 141: loss=0.957990288734436\n",
      "epoch 142: loss=0.9646221399307251\n",
      "epoch 143: loss=0.9697592854499817\n",
      "epoch 144: loss=0.9638814926147461\n",
      "epoch 145: loss=0.9750633239746094\n",
      "epoch 146: loss=0.9857742786407471\n",
      "epoch 147: loss=0.9664645791053772\n",
      "epoch 148: loss=0.9609596133232117\n",
      "epoch 149: loss=0.9530265927314758\n",
      "epoch 150: loss=0.9674661159515381\n",
      "epoch 151: loss=0.9327465295791626\n",
      "epoch 152: loss=0.9465076923370361\n",
      "epoch 153: loss=0.9573673605918884\n",
      "epoch 154: loss=0.9731122255325317\n",
      "epoch 155: loss=0.9486884474754333\n",
      "epoch 156: loss=0.9390342235565186\n",
      "epoch 157: loss=0.9742417931556702\n",
      "epoch 158: loss=0.9532628655433655\n",
      "epoch 159: loss=0.9670132398605347\n",
      "epoch 160: loss=0.9622564315795898\n",
      "epoch 161: loss=0.9597054123878479\n",
      "epoch 162: loss=0.9727384448051453\n",
      "epoch 163: loss=0.9517599940299988\n",
      "epoch 164: loss=0.9543396234512329\n",
      "epoch 165: loss=0.9668613076210022\n",
      "epoch 166: loss=0.965207576751709\n",
      "epoch 167: loss=0.9939897656440735\n",
      "epoch 168: loss=0.9426693916320801\n",
      "epoch 169: loss=0.9495766162872314\n",
      "epoch 170: loss=0.9650165438652039\n",
      "epoch 171: loss=0.9591118693351746\n",
      "epoch 172: loss=0.9598236680030823\n",
      "epoch 173: loss=0.9430323839187622\n",
      "epoch 174: loss=0.9811195731163025\n",
      "epoch 175: loss=0.961373507976532\n",
      "epoch 176: loss=0.937850832939148\n",
      "epoch 177: loss=0.9138292074203491\n",
      "epoch 178: loss=0.9346113801002502\n",
      "epoch 179: loss=0.9567075371742249\n",
      "epoch 180: loss=0.943576455116272\n",
      "epoch 181: loss=0.9536660313606262\n",
      "epoch 182: loss=0.9531592130661011\n",
      "epoch 183: loss=0.9500432014465332\n",
      "epoch 184: loss=0.9413926601409912\n",
      "epoch 185: loss=0.9585466384887695\n",
      "epoch 186: loss=0.9483211636543274\n",
      "epoch 187: loss=0.9556726217269897\n",
      "epoch 188: loss=0.9552400708198547\n",
      "epoch 189: loss=0.949276864528656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190: loss=0.9514940977096558\n",
      "epoch 191: loss=0.9640604257583618\n",
      "epoch 192: loss=0.9531933665275574\n",
      "epoch 193: loss=0.9486161470413208\n",
      "epoch 194: loss=0.9496850371360779\n",
      "epoch 195: loss=0.9752622842788696\n",
      "epoch 196: loss=0.957108199596405\n",
      "epoch 197: loss=0.9521901607513428\n",
      "epoch 198: loss=0.9514334201812744\n",
      "epoch 199: loss=0.9380388855934143\n",
      "epoch 0: loss=1.8456562757492065\n",
      "epoch 1: loss=1.549060344696045\n",
      "epoch 2: loss=1.4568008184432983\n",
      "epoch 3: loss=1.4095110893249512\n",
      "epoch 4: loss=1.376611590385437\n",
      "epoch 5: loss=1.3643499612808228\n",
      "epoch 6: loss=1.3522616624832153\n",
      "epoch 7: loss=1.3418574333190918\n",
      "epoch 8: loss=1.3327921628952026\n",
      "epoch 9: loss=1.3188669681549072\n",
      "epoch 10: loss=1.301016092300415\n",
      "epoch 11: loss=1.2831889390945435\n",
      "epoch 12: loss=1.2552622556686401\n",
      "epoch 13: loss=1.2218995094299316\n",
      "epoch 14: loss=1.2012784481048584\n",
      "epoch 15: loss=1.168204426765442\n",
      "epoch 16: loss=1.1605054140090942\n",
      "epoch 17: loss=1.1494297981262207\n",
      "epoch 18: loss=1.1525391340255737\n",
      "epoch 19: loss=1.1675647497177124\n",
      "epoch 20: loss=1.154984951019287\n",
      "epoch 21: loss=1.1479488611221313\n",
      "epoch 22: loss=1.1373445987701416\n",
      "epoch 23: loss=1.119409203529358\n",
      "epoch 24: loss=1.09519624710083\n",
      "epoch 25: loss=1.088783621788025\n",
      "epoch 26: loss=1.0842543840408325\n",
      "epoch 27: loss=1.0865797996520996\n",
      "epoch 28: loss=1.081427812576294\n",
      "epoch 29: loss=1.070237159729004\n",
      "epoch 30: loss=1.0556626319885254\n",
      "epoch 31: loss=1.046831488609314\n",
      "epoch 32: loss=1.0378497838974\n",
      "epoch 33: loss=1.026960015296936\n",
      "epoch 34: loss=1.032815933227539\n",
      "epoch 35: loss=1.0272830724716187\n",
      "epoch 36: loss=1.0381807088851929\n",
      "epoch 37: loss=1.0242470502853394\n",
      "epoch 38: loss=1.0143121480941772\n",
      "epoch 39: loss=1.0201849937438965\n",
      "epoch 40: loss=1.018904447555542\n",
      "epoch 41: loss=1.0078485012054443\n",
      "epoch 42: loss=1.0239678621292114\n",
      "epoch 43: loss=1.0167491436004639\n",
      "epoch 44: loss=1.0093469619750977\n",
      "epoch 45: loss=1.0073140859603882\n",
      "epoch 46: loss=1.0042558908462524\n",
      "epoch 47: loss=1.0021560192108154\n",
      "epoch 48: loss=0.9989139437675476\n",
      "epoch 49: loss=0.9977728724479675\n",
      "epoch 50: loss=1.003066062927246\n",
      "epoch 51: loss=1.00336754322052\n",
      "epoch 52: loss=1.0059586763381958\n",
      "epoch 53: loss=0.992257833480835\n",
      "epoch 54: loss=1.0026886463165283\n",
      "epoch 55: loss=0.9933679103851318\n",
      "epoch 56: loss=1.0036627054214478\n",
      "epoch 57: loss=1.0052146911621094\n",
      "epoch 58: loss=0.9941497445106506\n",
      "epoch 59: loss=0.9956337213516235\n",
      "epoch 60: loss=0.9861522316932678\n",
      "epoch 61: loss=0.984625518321991\n",
      "epoch 62: loss=0.9935656785964966\n",
      "epoch 63: loss=0.9903770089149475\n",
      "epoch 64: loss=0.9980444312095642\n",
      "epoch 65: loss=0.9856150150299072\n",
      "epoch 66: loss=0.9893607497215271\n",
      "epoch 67: loss=0.9965746402740479\n",
      "epoch 68: loss=0.9865004420280457\n",
      "epoch 69: loss=0.9904041886329651\n",
      "epoch 70: loss=0.9930784702301025\n",
      "epoch 71: loss=0.9888758659362793\n",
      "epoch 72: loss=0.9921472668647766\n",
      "epoch 73: loss=0.9869457483291626\n",
      "epoch 74: loss=0.9894931316375732\n",
      "epoch 75: loss=0.9861739277839661\n",
      "epoch 76: loss=0.9848528504371643\n",
      "epoch 77: loss=0.985429584980011\n",
      "epoch 78: loss=0.985312283039093\n",
      "epoch 79: loss=0.9914186000823975\n",
      "epoch 80: loss=0.9778960347175598\n",
      "epoch 81: loss=0.9826282262802124\n",
      "epoch 82: loss=0.9791219830513\n",
      "epoch 83: loss=0.9937080144882202\n",
      "epoch 84: loss=0.9786978363990784\n",
      "epoch 85: loss=0.9895259737968445\n",
      "epoch 86: loss=0.9898420572280884\n",
      "epoch 87: loss=0.9912096261978149\n",
      "epoch 88: loss=0.9904568195343018\n",
      "epoch 89: loss=0.9836075305938721\n",
      "epoch 90: loss=0.9888648986816406\n",
      "epoch 91: loss=0.9847899675369263\n",
      "epoch 92: loss=0.9935932159423828\n",
      "epoch 93: loss=0.9895163178443909\n",
      "epoch 94: loss=0.9805342555046082\n",
      "epoch 95: loss=0.9795854687690735\n",
      "epoch 96: loss=0.9922590851783752\n",
      "epoch 97: loss=0.9807504415512085\n",
      "epoch 98: loss=0.974942147731781\n",
      "epoch 99: loss=0.9824547171592712\n",
      "epoch 100: loss=0.9848133325576782\n",
      "epoch 101: loss=0.9694964289665222\n",
      "epoch 102: loss=0.9923707246780396\n",
      "epoch 103: loss=0.9806602597236633\n",
      "epoch 104: loss=0.9853272438049316\n",
      "epoch 105: loss=0.9875208735466003\n",
      "epoch 106: loss=0.9815029501914978\n",
      "epoch 107: loss=0.9863258600234985\n",
      "epoch 108: loss=0.9813131093978882\n",
      "epoch 109: loss=0.9849276542663574\n",
      "epoch 110: loss=0.9754358530044556\n",
      "epoch 111: loss=0.9757689237594604\n",
      "epoch 112: loss=0.9847065210342407\n",
      "epoch 113: loss=0.9865554571151733\n",
      "epoch 114: loss=0.9704746007919312\n",
      "epoch 115: loss=0.986712634563446\n",
      "epoch 116: loss=0.9827151894569397\n",
      "epoch 117: loss=0.9795374274253845\n",
      "epoch 118: loss=0.989543080329895\n",
      "epoch 119: loss=0.9906310439109802\n",
      "epoch 120: loss=0.9756567478179932\n",
      "epoch 121: loss=0.9805341362953186\n",
      "epoch 122: loss=0.9785129427909851\n",
      "epoch 123: loss=0.9950599074363708\n",
      "epoch 124: loss=0.9859091639518738\n",
      "epoch 125: loss=0.9885163903236389\n",
      "epoch 126: loss=0.9798743724822998\n",
      "epoch 127: loss=0.9747684001922607\n",
      "epoch 128: loss=0.9830383658409119\n",
      "epoch 129: loss=0.9785804748535156\n",
      "epoch 130: loss=0.9825195074081421\n",
      "epoch 131: loss=0.9748653769493103\n",
      "epoch 132: loss=0.9854820370674133\n",
      "epoch 133: loss=0.9828165769577026\n",
      "epoch 134: loss=0.9838189482688904\n",
      "epoch 135: loss=0.980952799320221\n",
      "epoch 136: loss=0.9811814427375793\n",
      "epoch 137: loss=0.9833904504776001\n",
      "epoch 138: loss=0.9815744161605835\n",
      "epoch 139: loss=0.9842808246612549\n",
      "epoch 140: loss=0.9753947257995605\n",
      "epoch 141: loss=0.9797441363334656\n",
      "epoch 142: loss=0.9840563535690308\n",
      "epoch 143: loss=0.9792940020561218\n",
      "epoch 144: loss=0.9758709073066711\n",
      "epoch 145: loss=0.9846752285957336\n",
      "epoch 146: loss=0.9775874018669128\n",
      "epoch 147: loss=0.978450357913971\n",
      "epoch 148: loss=0.9691579341888428\n",
      "epoch 149: loss=0.9755651950836182\n",
      "epoch 150: loss=0.978648841381073\n",
      "epoch 151: loss=0.9770394563674927\n",
      "epoch 152: loss=0.9830266237258911\n",
      "epoch 153: loss=0.9770300388336182\n",
      "epoch 154: loss=0.9723261594772339\n",
      "epoch 155: loss=0.9711110591888428\n",
      "epoch 156: loss=0.977852463722229\n",
      "epoch 157: loss=0.9745848178863525\n",
      "epoch 158: loss=0.9738967418670654\n",
      "epoch 159: loss=0.9789360761642456\n",
      "epoch 160: loss=0.9858490228652954\n",
      "epoch 161: loss=0.9646134376525879\n",
      "epoch 162: loss=0.9801563620567322\n",
      "epoch 163: loss=0.9819441437721252\n",
      "epoch 164: loss=0.9772710204124451\n",
      "epoch 165: loss=0.978919506072998\n",
      "epoch 166: loss=0.9816858172416687\n",
      "epoch 167: loss=0.9716686606407166\n",
      "epoch 168: loss=0.9745852947235107\n",
      "epoch 169: loss=0.9789109826087952\n",
      "epoch 170: loss=0.9792557954788208\n",
      "epoch 171: loss=0.9770802855491638\n",
      "epoch 172: loss=0.9762837290763855\n",
      "epoch 173: loss=0.969215452671051\n",
      "epoch 174: loss=0.9789742827415466\n",
      "epoch 175: loss=0.9779601097106934\n",
      "epoch 176: loss=0.9814563393592834\n",
      "epoch 177: loss=0.9806694984436035\n",
      "epoch 178: loss=0.9873181581497192\n",
      "epoch 179: loss=0.9894536137580872\n",
      "epoch 180: loss=0.9721238613128662\n",
      "epoch 181: loss=0.976519763469696\n",
      "epoch 182: loss=0.9696634411811829\n",
      "epoch 183: loss=0.9725625514984131\n",
      "epoch 184: loss=0.9830459356307983\n",
      "epoch 185: loss=0.9828684329986572\n",
      "epoch 186: loss=0.9706413745880127\n",
      "epoch 187: loss=0.974982738494873\n",
      "epoch 188: loss=0.9823707938194275\n",
      "epoch 189: loss=0.978870689868927\n",
      "epoch 190: loss=0.9743193984031677\n",
      "epoch 191: loss=0.9761210680007935\n",
      "epoch 192: loss=0.9784462451934814\n",
      "epoch 193: loss=0.978036642074585\n",
      "epoch 194: loss=0.9822512865066528\n",
      "epoch 195: loss=0.967837393283844\n",
      "epoch 196: loss=0.974351167678833\n",
      "epoch 197: loss=0.9799970984458923\n",
      "epoch 198: loss=0.9791696071624756\n",
      "epoch 199: loss=0.9791244268417358\n"
     ]
    }
   ],
   "source": [
    "patches_ip, models_ip =VGAE_patch_embeddings(clustered_data, num_epochs=200)\n",
    "\n",
    "\n",
    "full_model_ip = tg.nn.VGAE(encoder=VGAEconv(2, test_data.num_node_features))\n",
    "full_model_ip = train(test_data, full_model_ip,\n",
    "                   loss_fun=lambda model, data: model.recon_loss(model.encode(data), data.edge_index) + model.kl_loss()/data.num_nodes,\n",
    "                   num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98e50d9-e58c-49d6-b89f-8f785da9b7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adolescent-tuition",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de8587c95674b7aaa4fa613c28183a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute relative transformations:   0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8622b391b13493e9a717aec2d886eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute mean embedding:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028db0c696574c868dc8bd3892df1fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute relative transformations:   0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f43cf6bf86486e92f80c88eabed8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute relative transformations:   0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f98132b92074e819e0ac10b88252764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute mean embedding:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    coord_ip = full_model_ip.encode(test_data).numpy()\n",
    "prob_ip = l2g.utils.WeightedAlignmentProblem(patches_ip)\n",
    "stitched_ip = prob_ip.get_aligned_embedding(scale=False)\n",
    "prob_ip_s = l2g.utils.WeightedAlignmentProblem(patches_ip)\n",
    "stitched_ip_scaled = prob_ip_s.get_aligned_embedding(scale=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66572cb1-5d4c-4517-b124-53876909d1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312e041-4a8e-44c6-8e94-5ece8d8dc68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stable-advancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model (inner product)\n",
      " AUC: 0.938, AP: 0.928\n",
      "Patched (inner product, no scaling)\n",
      " AUC: 0.849, AP: 0.851\n",
      "Patched (inner product, scaling)\n",
      " AUC: 0.848, AP: 0.85\n"
     ]
    }
   ],
   "source": [
    "#plt.figure()\n",
    "#plt.scatter(coord_ip[:, 0], coord_ip[:, 1], c=test_data.y, s=0.5)\n",
    "auc, ap = full_model_ip.test(torch.tensor(coord_ip), test_data.edge_index, neg_edges)\n",
    "print(f'Full model (inner product)\\n AUC: {auc:.3}, AP: {ap:.3}')\n",
    "\n",
    "#plt.figure()\n",
    "#plt.scatter(stitched_ip[:, 0], stitched_ip[:, 1], c=test_data.y, s=0.5)\n",
    "auc, ap = full_model_ip.test(torch.tensor(stitched_ip), test_data.edge_index, neg_edges)\n",
    "print(f'Patched (inner product, no scaling)\\n AUC: {auc:.3}, AP: {ap:.3}')\n",
    "\n",
    "#plt.figure()\n",
    "#plt.scatter(stitched_ip_scaled[:, 0], stitched_ip_scaled[:, 1], c=test_data.y, s=0.5)\n",
    "auc, ap = full_model_ip.test(torch.tensor(stitched_ip_scaled), test_data.edge_index, neg_edges)\n",
    "print(f'Patched (inner product, scaling)\\n AUC: {auc:.3}, AP: {ap:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-gallery",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "manufactured-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_intersections_nodes(patches):\n",
    "    double_intersections = dict()\n",
    "    for i in range(len(patches)):\n",
    "        for j in range(i+1, len(patches)):\n",
    "            double_intersections[(i,j)]=list(set(patches[i].nodes.tolist()).intersection(set(patches[j].nodes.tolist())))\n",
    "    return double_intersections\n",
    "\n",
    "def preprocess_graphs(list_of_patches, nodes_dict):\n",
    "    emb_list = []\n",
    "    for i in range(len(list_of_patches)-1):\n",
    "        emb_list.append([torch.tensor(list_of_patches[i].get_coordinates(list(nodes_dict[i,i+1]))),\n",
    "                         torch.tensor(list_of_patches[i+1].get_coordinates(list(nodes_dict[i,i+1])))])\n",
    "    emb_list = list(itertools.chain.from_iterable(emb_list))\n",
    "    return emb_list    \n",
    "\n",
    "def get_embedding(patches, result):\n",
    "    n=len(patches)\n",
    "    rot=[result.transformation[i].weight.to('cpu').detach().numpy() for i in range(n)]\n",
    "    shift=[result.transformation[i].bias.to('cpu').detach().numpy() for i in range(n)]\n",
    "\n",
    "    emb_problem = l2g.AlignmentProblem(patches)\n",
    "    embedding = np.empty((emb_problem.n_nodes, emb_problem.dim))\n",
    "    for node, patch_list in enumerate(emb_problem.patch_index):\n",
    "        embedding[node] = np.mean([emb_problem.patches[p].get_coordinate(node)@rot[i] + shift[i] for i, p in enumerate(patch_list)], axis=0)\n",
    "\n",
    "    #prob=l2g.AlignmentProblem(patches)\n",
    "    #old_embedding=prob.get_aligned_embedding()\n",
    "    #embedding=embedding[nodes]\n",
    "    #old_embedding=old_embedding[nodes]\n",
    "    #error= l2g.utils.procrustes_error(embedding,old_embedding)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import geotorch\n",
    "\n",
    "\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, dim, n_patches, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.transformation = nn.ParameterList([nn.Linear(dim, dim).to(device) for _ in range(n_patches)])\n",
    "        [geotorch.orthogonal(self.transformation[i], 'weight') for i in range(n_patches)]\n",
    "    \n",
    "    def forward(self, patch_emb):\n",
    "        m = len(patch_emb)\n",
    "        transformations = [self.transformation[0]] + [item for i in range(1, len(self.transformation)-1) for item in (self.transformation[i], self.transformation[i])] + [self.transformation[-1]]\n",
    "        transformed_emb = [transformations[i](patch_emb[i]) for i in range(m)]\n",
    "        return transformed_emb\n",
    "\n",
    "def loss_function(transformed_emb):\n",
    "    m = len(transformed_emb)\n",
    "    diff = [transformed_emb[i] - transformed_emb[i+1] for i in range(0, m-1, 2)]\n",
    "    loss = sum([torch.norm(d) ** 2 for d in diff])\n",
    "    return loss\n",
    "\n",
    "def train_model(patch_emb, dim, n_patches, num_epochs=100, learning_rate=0.05):\n",
    "    #device = get_device()\n",
    "    patch_emb = [p.to(device) for p in patch_emb]\n",
    "    \n",
    "    model = Model(dim, n_patches, device).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_hist = []\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        transformed_patch_emb = model(patch_emb)\n",
    "        loss = loss_function(transformed_patch_emb)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        loss_hist.append(loss.item())\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "    \n",
    "    return model, loss_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "907bef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = double_intersections_nodes(patches_ip)\n",
    "emb_patches = preprocess_graphs(patches_ip, nodes)\n",
    "n_patches=len(patches_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab2e5bc6-ff32-4129-9fa2-32aa0165575b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73792b093dc4bba9efc28b6cdbb8173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 4699.0556640625\n",
      "Epoch 10, Loss: 1783.2232666015625\n",
      "Epoch 20, Loss: 1433.77490234375\n",
      "Epoch 30, Loss: 1368.1026611328125\n",
      "Epoch 40, Loss: 1329.916748046875\n",
      "Epoch 50, Loss: 1323.81787109375\n",
      "Epoch 60, Loss: 1319.9105224609375\n",
      "Epoch 70, Loss: 1317.864501953125\n",
      "Epoch 80, Loss: 1317.092529296875\n",
      "Epoch 90, Loss: 1316.8154296875\n"
     ]
    }
   ],
   "source": [
    "res, loss_hist= train_model(emb_patches, dim, n_patches , num_epochs=100, learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "circular-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb=get_embedding(patches_ip, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "korean-tennessee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model (inner product)\n",
      " AUC: 0.605, AP: 0.614\n"
     ]
    }
   ],
   "source": [
    "auc, ap = full_model_ip.test(torch.tensor(emb), test_data.edge_index, neg_edges)\n",
    "print(f'New model (inner product)\\n AUC: {auc:.3}, AP: {ap:.3}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "strong-ireland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training patch with 2032 edges\n",
      "epoch 0: loss=3.3986566066741943\n",
      "epoch 1: loss=3.3478448390960693\n",
      "epoch 2: loss=3.1182992458343506\n",
      "epoch 3: loss=3.0222055912017822\n",
      "epoch 4: loss=2.786128520965576\n",
      "epoch 5: loss=2.6789097785949707\n",
      "epoch 6: loss=2.639350652694702\n",
      "epoch 7: loss=2.3458974361419678\n",
      "epoch 8: loss=2.287757635116577\n",
      "epoch 9: loss=2.0472328662872314\n",
      "epoch 10: loss=1.8978854417800903\n",
      "epoch 11: loss=1.8305450677871704\n",
      "epoch 12: loss=1.6323258876800537\n",
      "epoch 13: loss=1.5871329307556152\n",
      "epoch 14: loss=1.561279535293579\n",
      "epoch 15: loss=1.4889137744903564\n",
      "epoch 16: loss=1.5075721740722656\n",
      "epoch 17: loss=1.4364111423492432\n",
      "epoch 18: loss=1.3854860067367554\n",
      "epoch 19: loss=1.3832141160964966\n",
      "epoch 20: loss=1.359315276145935\n",
      "epoch 21: loss=1.361457347869873\n",
      "epoch 22: loss=1.3499833345413208\n",
      "epoch 23: loss=1.3336818218231201\n",
      "epoch 24: loss=1.3332680463790894\n",
      "epoch 25: loss=1.329282283782959\n",
      "epoch 26: loss=1.3155933618545532\n",
      "epoch 27: loss=1.325365662574768\n",
      "epoch 28: loss=1.3127660751342773\n",
      "epoch 29: loss=1.3099515438079834\n",
      "epoch 30: loss=1.2907847166061401\n",
      "epoch 31: loss=1.2916473150253296\n",
      "epoch 32: loss=1.2782785892486572\n",
      "epoch 33: loss=1.285176157951355\n",
      "epoch 34: loss=1.2742661237716675\n",
      "epoch 35: loss=1.279009461402893\n",
      "epoch 36: loss=1.25907564163208\n",
      "epoch 37: loss=1.2541195154190063\n",
      "epoch 38: loss=1.24245285987854\n",
      "epoch 39: loss=1.2385655641555786\n",
      "epoch 40: loss=1.2347221374511719\n",
      "epoch 41: loss=1.2016210556030273\n",
      "epoch 42: loss=1.2108900547027588\n",
      "epoch 43: loss=1.1914736032485962\n",
      "epoch 44: loss=1.19107186794281\n",
      "epoch 45: loss=1.1748648881912231\n",
      "epoch 46: loss=1.1703242063522339\n",
      "epoch 47: loss=1.1433110237121582\n",
      "epoch 48: loss=1.15187668800354\n",
      "epoch 49: loss=1.139025330543518\n",
      "epoch 50: loss=1.1307307481765747\n",
      "epoch 51: loss=1.1182670593261719\n",
      "epoch 52: loss=1.1159327030181885\n",
      "epoch 53: loss=1.1461753845214844\n",
      "epoch 54: loss=1.1082302331924438\n",
      "epoch 55: loss=1.0878510475158691\n",
      "epoch 56: loss=1.0560033321380615\n",
      "epoch 57: loss=1.0817577838897705\n",
      "epoch 58: loss=1.0521827936172485\n",
      "epoch 59: loss=1.044847011566162\n",
      "epoch 60: loss=1.022097110748291\n",
      "epoch 61: loss=1.0162668228149414\n",
      "epoch 62: loss=1.0166677236557007\n",
      "epoch 63: loss=1.0146784782409668\n",
      "epoch 64: loss=0.9673284292221069\n",
      "epoch 65: loss=0.9862117767333984\n",
      "epoch 66: loss=0.9811248183250427\n",
      "epoch 67: loss=0.9913969039916992\n",
      "epoch 68: loss=0.999406099319458\n",
      "epoch 69: loss=0.9807332158088684\n",
      "epoch 70: loss=0.9702467322349548\n",
      "epoch 71: loss=0.9678412079811096\n",
      "epoch 72: loss=0.9663588404655457\n",
      "epoch 73: loss=0.9661292433738708\n",
      "epoch 74: loss=0.965549111366272\n",
      "epoch 75: loss=0.9695611596107483\n",
      "epoch 76: loss=0.9627381563186646\n",
      "epoch 77: loss=0.9618081450462341\n",
      "epoch 78: loss=0.9554892778396606\n",
      "epoch 79: loss=0.9722707271575928\n",
      "epoch 80: loss=0.9452443718910217\n",
      "epoch 81: loss=0.9206898212432861\n",
      "epoch 82: loss=0.9241206049919128\n",
      "epoch 83: loss=0.948207676410675\n",
      "epoch 84: loss=0.9305312037467957\n",
      "epoch 85: loss=0.9418383836746216\n",
      "epoch 86: loss=0.9252393245697021\n",
      "epoch 87: loss=0.948740541934967\n",
      "epoch 88: loss=0.9274307489395142\n",
      "epoch 89: loss=0.9539600014686584\n",
      "epoch 90: loss=0.9403617978096008\n",
      "epoch 91: loss=0.9522979259490967\n",
      "epoch 92: loss=0.943972647190094\n",
      "epoch 93: loss=0.9238986372947693\n",
      "epoch 94: loss=0.9294298887252808\n",
      "epoch 95: loss=0.9408095479011536\n",
      "epoch 96: loss=0.9312076568603516\n",
      "epoch 97: loss=0.917633056640625\n",
      "epoch 98: loss=0.9237460494041443\n",
      "epoch 99: loss=0.9408178329467773\n",
      "epoch 100: loss=0.9277515411376953\n",
      "epoch 101: loss=0.9228026270866394\n",
      "epoch 102: loss=0.9346860647201538\n",
      "epoch 103: loss=0.9322148561477661\n",
      "epoch 104: loss=0.9134368300437927\n",
      "epoch 105: loss=0.9259742498397827\n",
      "epoch 106: loss=0.9309713840484619\n",
      "epoch 107: loss=0.9424291253089905\n",
      "epoch 108: loss=0.9302740693092346\n",
      "epoch 109: loss=0.9337574243545532\n",
      "epoch 110: loss=0.925343930721283\n",
      "epoch 111: loss=0.9174159169197083\n",
      "epoch 112: loss=0.9080336093902588\n",
      "epoch 113: loss=0.9167980551719666\n",
      "epoch 114: loss=0.9142067432403564\n",
      "epoch 115: loss=0.9257335662841797\n",
      "epoch 116: loss=0.9232568144798279\n",
      "epoch 117: loss=0.9134875535964966\n",
      "epoch 118: loss=0.9385697841644287\n",
      "epoch 119: loss=0.918965756893158\n",
      "epoch 120: loss=0.9176397919654846\n",
      "epoch 121: loss=0.8948994874954224\n",
      "epoch 122: loss=0.9130292534828186\n",
      "epoch 123: loss=0.9244248867034912\n",
      "epoch 124: loss=0.9183933138847351\n",
      "epoch 125: loss=0.9211835265159607\n",
      "epoch 126: loss=0.924261212348938\n",
      "epoch 127: loss=0.8955169916152954\n",
      "epoch 128: loss=0.936127781867981\n",
      "epoch 129: loss=0.9132879376411438\n",
      "epoch 130: loss=0.9192285537719727\n",
      "epoch 131: loss=0.8817396759986877\n",
      "epoch 132: loss=0.9179198741912842\n",
      "epoch 133: loss=0.883258581161499\n",
      "epoch 134: loss=0.8906058669090271\n",
      "epoch 135: loss=0.900551974773407\n",
      "epoch 136: loss=0.9136109948158264\n",
      "epoch 137: loss=0.9124456644058228\n",
      "epoch 138: loss=0.9228256344795227\n",
      "epoch 139: loss=0.912152886390686\n",
      "epoch 140: loss=0.9034538269042969\n",
      "epoch 141: loss=0.8971573710441589\n",
      "epoch 142: loss=0.8950457572937012\n",
      "epoch 143: loss=0.9419010281562805\n",
      "epoch 144: loss=0.8898561596870422\n",
      "epoch 145: loss=0.896370530128479\n",
      "epoch 146: loss=0.8994952440261841\n",
      "epoch 147: loss=0.9165447950363159\n",
      "epoch 148: loss=0.8944765329360962\n",
      "epoch 149: loss=0.9288416504859924\n",
      "epoch 150: loss=0.9181343913078308\n",
      "epoch 151: loss=0.8929480314254761\n",
      "epoch 152: loss=0.9162759780883789\n",
      "epoch 153: loss=0.8938548564910889\n",
      "epoch 154: loss=0.9045794010162354\n",
      "epoch 155: loss=0.9079468250274658\n",
      "epoch 156: loss=0.8886159062385559\n",
      "epoch 157: loss=0.8940913677215576\n",
      "epoch 158: loss=0.8918119668960571\n",
      "epoch 159: loss=0.8890284299850464\n",
      "epoch 160: loss=0.8905895352363586\n",
      "epoch 161: loss=0.8934768438339233\n",
      "epoch 162: loss=0.8922643661499023\n",
      "epoch 163: loss=0.9082589745521545\n",
      "epoch 164: loss=0.8905492424964905\n",
      "epoch 165: loss=0.8914177417755127\n",
      "epoch 166: loss=0.911305844783783\n",
      "epoch 167: loss=0.8750871419906616\n",
      "epoch 168: loss=0.8956592082977295\n",
      "epoch 169: loss=0.8939154148101807\n",
      "epoch 170: loss=0.9062256813049316\n",
      "epoch 171: loss=0.875501275062561\n",
      "epoch 172: loss=0.8910947442054749\n",
      "epoch 173: loss=0.9002783298492432\n",
      "epoch 174: loss=0.8987183570861816\n",
      "epoch 175: loss=0.8921379446983337\n",
      "epoch 176: loss=0.8843399286270142\n",
      "epoch 177: loss=0.8951221704483032\n",
      "epoch 178: loss=0.898686408996582\n",
      "epoch 179: loss=0.8888776898384094\n",
      "epoch 180: loss=0.8964067697525024\n",
      "epoch 181: loss=0.8829064965248108\n",
      "epoch 182: loss=0.8766719698905945\n",
      "epoch 183: loss=0.8990126252174377\n",
      "epoch 184: loss=0.8708677291870117\n",
      "epoch 185: loss=0.9267522096633911\n",
      "epoch 186: loss=0.8912375569343567\n",
      "epoch 187: loss=0.8891805410385132\n",
      "epoch 188: loss=0.8895967602729797\n",
      "epoch 189: loss=0.886431097984314\n",
      "epoch 190: loss=0.8900703191757202\n",
      "epoch 191: loss=0.8905832171440125\n",
      "epoch 192: loss=0.8797573447227478\n",
      "epoch 193: loss=0.8780282735824585\n",
      "epoch 194: loss=0.8742375373840332\n",
      "epoch 195: loss=0.887730598449707\n",
      "epoch 196: loss=0.8812634348869324\n",
      "epoch 197: loss=0.87702876329422\n",
      "epoch 198: loss=0.8758993148803711\n",
      "epoch 199: loss=0.8859375715255737\n",
      "training patch with 1946 edges\n",
      "epoch 0: loss=3.3687479496002197\n",
      "epoch 1: loss=3.3890275955200195\n",
      "epoch 2: loss=3.335858106613159\n",
      "epoch 3: loss=3.106818437576294\n",
      "epoch 4: loss=2.8721115589141846\n",
      "epoch 5: loss=2.6796703338623047\n",
      "epoch 6: loss=2.6918299198150635\n",
      "epoch 7: loss=2.3969240188598633\n",
      "epoch 8: loss=2.2318921089172363\n",
      "epoch 9: loss=2.196902275085449\n",
      "epoch 10: loss=1.977555274963379\n",
      "epoch 11: loss=1.8798435926437378\n",
      "epoch 12: loss=1.7172870635986328\n",
      "epoch 13: loss=1.66472327709198\n",
      "epoch 14: loss=1.5696258544921875\n",
      "epoch 15: loss=1.5434499979019165\n",
      "epoch 16: loss=1.4615309238433838\n",
      "epoch 17: loss=1.4637678861618042\n",
      "epoch 18: loss=1.4356404542922974\n",
      "epoch 19: loss=1.416940689086914\n",
      "epoch 20: loss=1.4210833311080933\n",
      "epoch 21: loss=1.3836991786956787\n",
      "epoch 22: loss=1.3774703741073608\n",
      "epoch 23: loss=1.3712961673736572\n",
      "epoch 24: loss=1.3634010553359985\n",
      "epoch 25: loss=1.3640064001083374\n",
      "epoch 26: loss=1.3554089069366455\n",
      "epoch 27: loss=1.353399634361267\n",
      "epoch 28: loss=1.3450261354446411\n",
      "epoch 29: loss=1.348363995552063\n",
      "epoch 30: loss=1.3476488590240479\n",
      "epoch 31: loss=1.3530598878860474\n",
      "epoch 32: loss=1.3336354494094849\n",
      "epoch 33: loss=1.3316080570220947\n",
      "epoch 34: loss=1.3213564157485962\n",
      "epoch 35: loss=1.3137104511260986\n",
      "epoch 36: loss=1.301976203918457\n",
      "epoch 37: loss=1.2973634004592896\n",
      "epoch 38: loss=1.2868443727493286\n",
      "epoch 39: loss=1.2644309997558594\n",
      "epoch 40: loss=1.2533046007156372\n",
      "epoch 41: loss=1.2380319833755493\n",
      "epoch 42: loss=1.2181997299194336\n",
      "epoch 43: loss=1.1976408958435059\n",
      "epoch 44: loss=1.179038166999817\n",
      "epoch 45: loss=1.1470386981964111\n",
      "epoch 46: loss=1.1483259201049805\n",
      "epoch 47: loss=1.0946611166000366\n",
      "epoch 48: loss=1.0944777727127075\n",
      "epoch 49: loss=1.066516637802124\n",
      "epoch 50: loss=1.0866690874099731\n",
      "epoch 51: loss=1.0428296327590942\n",
      "epoch 52: loss=1.041506052017212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53: loss=1.0591739416122437\n",
      "epoch 54: loss=1.0511671304702759\n",
      "epoch 55: loss=1.0481287240982056\n",
      "epoch 56: loss=1.0398125648498535\n",
      "epoch 57: loss=1.063916802406311\n",
      "epoch 58: loss=1.0496491193771362\n",
      "epoch 59: loss=1.036171793937683\n",
      "epoch 60: loss=1.0133086442947388\n",
      "epoch 61: loss=1.0467957258224487\n",
      "epoch 62: loss=1.0132426023483276\n",
      "epoch 63: loss=1.0251315832138062\n",
      "epoch 64: loss=1.0098947286605835\n",
      "epoch 65: loss=1.0038303136825562\n",
      "epoch 66: loss=1.0002106428146362\n",
      "epoch 67: loss=1.0126560926437378\n",
      "epoch 68: loss=1.0007076263427734\n",
      "epoch 69: loss=0.9903979897499084\n",
      "epoch 70: loss=0.9946185350418091\n",
      "epoch 71: loss=0.9904890060424805\n",
      "epoch 72: loss=0.9816367030143738\n",
      "epoch 73: loss=0.9899682402610779\n",
      "epoch 74: loss=0.9736414551734924\n",
      "epoch 75: loss=0.9569082856178284\n",
      "epoch 76: loss=0.9526605606079102\n",
      "epoch 77: loss=0.9550020098686218\n",
      "epoch 78: loss=0.9710550308227539\n",
      "epoch 79: loss=0.9711295366287231\n",
      "epoch 80: loss=0.9272361993789673\n",
      "epoch 81: loss=0.9533448815345764\n",
      "epoch 82: loss=0.9285088777542114\n",
      "epoch 83: loss=0.9681129455566406\n",
      "epoch 84: loss=0.9591484665870667\n",
      "epoch 85: loss=0.947607159614563\n",
      "epoch 86: loss=0.9570174217224121\n",
      "epoch 87: loss=0.9466882944107056\n",
      "epoch 88: loss=0.956561267375946\n",
      "epoch 89: loss=0.9318141937255859\n",
      "epoch 90: loss=0.9137637615203857\n",
      "epoch 91: loss=0.9193111658096313\n",
      "epoch 92: loss=0.9373319149017334\n",
      "epoch 93: loss=0.9402835965156555\n",
      "epoch 94: loss=0.9178252816200256\n",
      "epoch 95: loss=0.9185072779655457\n",
      "epoch 96: loss=0.9275954365730286\n",
      "epoch 97: loss=0.9086032509803772\n",
      "epoch 98: loss=0.9143096208572388\n",
      "epoch 99: loss=0.9101686477661133\n",
      "epoch 100: loss=0.9202293157577515\n",
      "epoch 101: loss=0.9422844052314758\n",
      "epoch 102: loss=0.9099125862121582\n",
      "epoch 103: loss=0.9326568245887756\n",
      "epoch 104: loss=0.9160251617431641\n",
      "epoch 105: loss=0.9118526577949524\n",
      "epoch 106: loss=0.9168520569801331\n",
      "epoch 107: loss=0.9159944653511047\n",
      "epoch 108: loss=0.8992737531661987\n",
      "epoch 109: loss=0.9178789854049683\n",
      "epoch 110: loss=0.9033544659614563\n",
      "epoch 111: loss=0.913379430770874\n",
      "epoch 112: loss=0.9255011677742004\n",
      "epoch 113: loss=0.8944522738456726\n",
      "epoch 114: loss=0.9029918313026428\n",
      "epoch 115: loss=0.9051970839500427\n",
      "epoch 116: loss=0.9187021851539612\n",
      "epoch 117: loss=0.9308797717094421\n",
      "epoch 118: loss=0.8795844316482544\n",
      "epoch 119: loss=0.8977992534637451\n",
      "epoch 120: loss=0.9147374033927917\n",
      "epoch 121: loss=0.9162026047706604\n",
      "epoch 122: loss=0.8788524866104126\n",
      "epoch 123: loss=0.9053370356559753\n",
      "epoch 124: loss=0.8941001296043396\n",
      "epoch 125: loss=0.8915729522705078\n",
      "epoch 126: loss=0.8768599629402161\n",
      "epoch 127: loss=0.8971524834632874\n",
      "epoch 128: loss=0.9044744372367859\n",
      "epoch 129: loss=0.8945618271827698\n",
      "epoch 130: loss=0.9031283259391785\n",
      "epoch 131: loss=0.9098073244094849\n",
      "epoch 132: loss=0.883060097694397\n",
      "epoch 133: loss=0.8913248181343079\n",
      "epoch 134: loss=0.8898594379425049\n",
      "epoch 135: loss=0.896332323551178\n",
      "epoch 136: loss=0.8853292465209961\n",
      "epoch 137: loss=0.8993814587593079\n",
      "epoch 138: loss=0.8975809812545776\n",
      "epoch 139: loss=0.8794060945510864\n",
      "epoch 140: loss=0.8699139952659607\n",
      "epoch 141: loss=0.9277074337005615\n",
      "epoch 142: loss=0.8981621265411377\n",
      "epoch 143: loss=0.902339518070221\n",
      "epoch 144: loss=0.900488018989563\n",
      "epoch 145: loss=0.9031739830970764\n",
      "epoch 146: loss=0.8939839601516724\n",
      "epoch 147: loss=0.9097338914871216\n",
      "epoch 148: loss=0.8911957740783691\n",
      "epoch 149: loss=0.8984445929527283\n",
      "epoch 150: loss=0.8769161105155945\n",
      "epoch 151: loss=0.9145797491073608\n",
      "epoch 152: loss=0.8851370215415955\n",
      "epoch 153: loss=0.8769192099571228\n",
      "epoch 154: loss=0.8903347253799438\n",
      "epoch 155: loss=0.8952096700668335\n",
      "epoch 156: loss=0.9123911261558533\n",
      "epoch 157: loss=0.8908478021621704\n",
      "epoch 158: loss=0.8910825252532959\n",
      "epoch 159: loss=0.9048771262168884\n",
      "epoch 160: loss=0.8869607448577881\n",
      "epoch 161: loss=0.8930703997612\n",
      "epoch 162: loss=0.8915733695030212\n",
      "epoch 163: loss=0.8868682384490967\n",
      "epoch 164: loss=0.8798431754112244\n",
      "epoch 165: loss=0.8859363794326782\n",
      "epoch 166: loss=0.882025957107544\n",
      "epoch 167: loss=0.8788427114486694\n",
      "epoch 168: loss=0.8877865672111511\n",
      "epoch 169: loss=0.9006839394569397\n",
      "epoch 170: loss=0.8890153169631958\n",
      "epoch 171: loss=0.9162110090255737\n",
      "epoch 172: loss=0.8708803653717041\n",
      "epoch 173: loss=0.909876823425293\n",
      "epoch 174: loss=0.8937027454376221\n",
      "epoch 175: loss=0.8861719965934753\n",
      "epoch 176: loss=0.8954111337661743\n",
      "epoch 177: loss=0.8935946226119995\n",
      "epoch 178: loss=0.9013910889625549\n",
      "epoch 179: loss=0.9053692817687988\n",
      "epoch 180: loss=0.8975294232368469\n",
      "epoch 181: loss=0.8833639025688171\n",
      "epoch 182: loss=0.8789926767349243\n",
      "epoch 183: loss=0.8926557302474976\n",
      "epoch 184: loss=0.8941931128501892\n",
      "epoch 185: loss=0.8853141665458679\n",
      "epoch 186: loss=0.8844084143638611\n",
      "epoch 187: loss=0.8781542181968689\n",
      "epoch 188: loss=0.8874865770339966\n",
      "epoch 189: loss=0.8916370868682861\n",
      "epoch 190: loss=0.8865233659744263\n",
      "epoch 191: loss=0.8896441459655762\n",
      "epoch 192: loss=0.872450053691864\n",
      "epoch 193: loss=0.87815922498703\n",
      "epoch 194: loss=0.8977301120758057\n",
      "epoch 195: loss=0.8746265769004822\n",
      "epoch 196: loss=0.8987619280815125\n",
      "epoch 197: loss=0.8572285175323486\n",
      "epoch 198: loss=0.881453812122345\n",
      "epoch 199: loss=0.8983136415481567\n",
      "training patch with 1878 edges\n",
      "epoch 0: loss=3.4200921058654785\n",
      "epoch 1: loss=3.304189682006836\n",
      "epoch 2: loss=3.2900989055633545\n",
      "epoch 3: loss=3.1666812896728516\n",
      "epoch 4: loss=2.900487184524536\n",
      "epoch 5: loss=2.9027657508850098\n",
      "epoch 6: loss=2.647120475769043\n",
      "epoch 7: loss=2.452362060546875\n",
      "epoch 8: loss=2.3462655544281006\n",
      "epoch 9: loss=2.2759697437286377\n",
      "epoch 10: loss=2.046947717666626\n",
      "epoch 11: loss=1.917863368988037\n",
      "epoch 12: loss=1.8191778659820557\n",
      "epoch 13: loss=1.7153892517089844\n",
      "epoch 14: loss=1.68137526512146\n",
      "epoch 15: loss=1.5835844278335571\n",
      "epoch 16: loss=1.5069153308868408\n",
      "epoch 17: loss=1.4925307035446167\n",
      "epoch 18: loss=1.453253984451294\n",
      "epoch 19: loss=1.4440217018127441\n",
      "epoch 20: loss=1.4042930603027344\n",
      "epoch 21: loss=1.4030767679214478\n",
      "epoch 22: loss=1.3704723119735718\n",
      "epoch 23: loss=1.3716650009155273\n",
      "epoch 24: loss=1.3556432723999023\n",
      "epoch 25: loss=1.3581348657608032\n",
      "epoch 26: loss=1.3425211906433105\n",
      "epoch 27: loss=1.3418487310409546\n",
      "epoch 28: loss=1.3396269083023071\n",
      "epoch 29: loss=1.3356502056121826\n",
      "epoch 30: loss=1.3248722553253174\n",
      "epoch 31: loss=1.3122740983963013\n",
      "epoch 32: loss=1.3140941858291626\n",
      "epoch 33: loss=1.3042902946472168\n",
      "epoch 34: loss=1.2992534637451172\n",
      "epoch 35: loss=1.2925723791122437\n",
      "epoch 36: loss=1.2741652727127075\n",
      "epoch 37: loss=1.2717831134796143\n",
      "epoch 38: loss=1.257617473602295\n",
      "epoch 39: loss=1.2368501424789429\n",
      "epoch 40: loss=1.219856858253479\n",
      "epoch 41: loss=1.2070167064666748\n",
      "epoch 42: loss=1.1881355047225952\n",
      "epoch 43: loss=1.1588975191116333\n",
      "epoch 44: loss=1.1514379978179932\n",
      "epoch 45: loss=1.1461228132247925\n",
      "epoch 46: loss=1.1373109817504883\n",
      "epoch 47: loss=1.1150658130645752\n",
      "epoch 48: loss=1.1060600280761719\n",
      "epoch 49: loss=1.0878225564956665\n",
      "epoch 50: loss=1.1344963312149048\n",
      "epoch 51: loss=1.118023157119751\n",
      "epoch 52: loss=1.1088980436325073\n",
      "epoch 53: loss=1.1010278463363647\n",
      "epoch 54: loss=1.0861905813217163\n",
      "epoch 55: loss=1.0852100849151611\n",
      "epoch 56: loss=1.0907272100448608\n",
      "epoch 57: loss=1.0749762058258057\n",
      "epoch 58: loss=1.0718733072280884\n",
      "epoch 59: loss=1.0252786874771118\n",
      "epoch 60: loss=1.0452048778533936\n",
      "epoch 61: loss=1.0538455247879028\n",
      "epoch 62: loss=1.0203897953033447\n",
      "epoch 63: loss=1.039564609527588\n",
      "epoch 64: loss=1.045811653137207\n",
      "epoch 65: loss=1.021361231803894\n",
      "epoch 66: loss=1.0106210708618164\n",
      "epoch 67: loss=1.037254810333252\n",
      "epoch 68: loss=1.0182178020477295\n",
      "epoch 69: loss=1.0206867456436157\n",
      "epoch 70: loss=1.0010151863098145\n",
      "epoch 71: loss=1.0187914371490479\n",
      "epoch 72: loss=0.9937333464622498\n",
      "epoch 73: loss=1.0261178016662598\n",
      "epoch 74: loss=0.9870297908782959\n",
      "epoch 75: loss=1.037917971611023\n",
      "epoch 76: loss=1.0234313011169434\n",
      "epoch 77: loss=0.9964830875396729\n",
      "epoch 78: loss=1.0015705823898315\n",
      "epoch 79: loss=0.9948410391807556\n",
      "epoch 80: loss=1.0132614374160767\n",
      "epoch 81: loss=0.998815655708313\n",
      "epoch 82: loss=0.9951055645942688\n",
      "epoch 83: loss=0.9948641061782837\n",
      "epoch 84: loss=0.9911984205245972\n",
      "epoch 85: loss=0.9817265272140503\n",
      "epoch 86: loss=0.9795954823493958\n",
      "epoch 87: loss=0.973530113697052\n",
      "epoch 88: loss=0.9902044534683228\n",
      "epoch 89: loss=0.9656317830085754\n",
      "epoch 90: loss=0.9823339581489563\n",
      "epoch 91: loss=0.9550263285636902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92: loss=0.9796119332313538\n",
      "epoch 93: loss=0.9735143780708313\n",
      "epoch 94: loss=0.9653749465942383\n",
      "epoch 95: loss=0.9909051656723022\n",
      "epoch 96: loss=0.9891476035118103\n",
      "epoch 97: loss=0.9546013474464417\n",
      "epoch 98: loss=0.9512089490890503\n",
      "epoch 99: loss=0.965653121471405\n",
      "epoch 100: loss=0.9599363803863525\n",
      "epoch 101: loss=0.968749463558197\n",
      "epoch 102: loss=0.9492027759552002\n",
      "epoch 103: loss=0.945140540599823\n",
      "epoch 104: loss=0.9745830297470093\n",
      "epoch 105: loss=0.9548458456993103\n",
      "epoch 106: loss=0.9567510485649109\n",
      "epoch 107: loss=0.9442875981330872\n",
      "epoch 108: loss=0.9578222036361694\n",
      "epoch 109: loss=0.9630523920059204\n",
      "epoch 110: loss=0.9302175045013428\n",
      "epoch 111: loss=0.9309954047203064\n",
      "epoch 112: loss=0.9214199185371399\n",
      "epoch 113: loss=0.9646043181419373\n",
      "epoch 114: loss=0.9367775917053223\n",
      "epoch 115: loss=0.9267193675041199\n",
      "epoch 116: loss=0.9538291692733765\n",
      "epoch 117: loss=0.9515711069107056\n",
      "epoch 118: loss=0.9531995058059692\n",
      "epoch 119: loss=0.9468303918838501\n",
      "epoch 120: loss=0.9355005025863647\n",
      "epoch 121: loss=0.961205780506134\n",
      "epoch 122: loss=0.9070069193840027\n",
      "epoch 123: loss=0.9331015348434448\n",
      "epoch 124: loss=0.9201701879501343\n",
      "epoch 125: loss=0.9488807916641235\n",
      "epoch 126: loss=0.9445245265960693\n",
      "epoch 127: loss=0.9273241758346558\n",
      "epoch 128: loss=0.9356628656387329\n",
      "epoch 129: loss=0.9390721321105957\n",
      "epoch 130: loss=0.9422113299369812\n",
      "epoch 131: loss=0.9287827014923096\n",
      "epoch 132: loss=0.937472403049469\n",
      "epoch 133: loss=0.9257415533065796\n",
      "epoch 134: loss=0.9340644478797913\n",
      "epoch 135: loss=0.915070116519928\n",
      "epoch 136: loss=0.9389185309410095\n",
      "epoch 137: loss=0.9374462962150574\n",
      "epoch 138: loss=0.9250037670135498\n",
      "epoch 139: loss=0.9474496841430664\n",
      "epoch 140: loss=0.9241623878479004\n",
      "epoch 141: loss=0.9235395193099976\n",
      "epoch 142: loss=0.9169729948043823\n",
      "epoch 143: loss=0.9349818229675293\n",
      "epoch 144: loss=0.9165826439857483\n",
      "epoch 145: loss=0.9470335841178894\n",
      "epoch 146: loss=0.9083138108253479\n",
      "epoch 147: loss=0.9211063981056213\n",
      "epoch 148: loss=0.9194902777671814\n",
      "epoch 149: loss=0.9397302269935608\n",
      "epoch 150: loss=0.9389641880989075\n",
      "epoch 151: loss=0.9242188334465027\n",
      "epoch 152: loss=0.9099251627922058\n",
      "epoch 153: loss=0.919624388217926\n",
      "epoch 154: loss=0.8907465934753418\n",
      "epoch 155: loss=0.9363189339637756\n",
      "epoch 156: loss=0.9255180358886719\n",
      "epoch 157: loss=0.9225369095802307\n",
      "epoch 158: loss=0.9153709411621094\n",
      "epoch 159: loss=0.9193973541259766\n",
      "epoch 160: loss=0.9164465665817261\n",
      "epoch 161: loss=0.9240763783454895\n",
      "epoch 162: loss=0.9249447584152222\n",
      "epoch 163: loss=0.9376657009124756\n",
      "epoch 164: loss=0.9309514164924622\n",
      "epoch 165: loss=0.9267918467521667\n",
      "epoch 166: loss=0.9199485182762146\n",
      "epoch 167: loss=0.9135037064552307\n",
      "epoch 168: loss=0.9047618508338928\n",
      "epoch 169: loss=0.901957631111145\n",
      "epoch 170: loss=0.9289957880973816\n",
      "epoch 171: loss=0.9305194616317749\n",
      "epoch 172: loss=0.9173762798309326\n",
      "epoch 173: loss=0.9295303821563721\n",
      "epoch 174: loss=0.9262247085571289\n",
      "epoch 175: loss=0.9166157245635986\n",
      "epoch 176: loss=0.8860547542572021\n",
      "epoch 177: loss=0.9058126211166382\n",
      "epoch 178: loss=0.8994091749191284\n",
      "epoch 179: loss=0.8974498510360718\n",
      "epoch 180: loss=0.9422299861907959\n",
      "epoch 181: loss=0.903570294380188\n",
      "epoch 182: loss=0.9104065895080566\n",
      "epoch 183: loss=0.931714653968811\n",
      "epoch 184: loss=0.9139359593391418\n",
      "epoch 185: loss=0.9144191741943359\n",
      "epoch 186: loss=0.9037072658538818\n",
      "epoch 187: loss=0.9116269946098328\n",
      "epoch 188: loss=0.9085723161697388\n",
      "epoch 189: loss=0.9294162392616272\n",
      "epoch 190: loss=0.9093193411827087\n",
      "epoch 191: loss=0.9398596286773682\n",
      "epoch 192: loss=0.9372437596321106\n",
      "epoch 193: loss=0.8999596834182739\n",
      "epoch 194: loss=0.9157341122627258\n",
      "epoch 195: loss=0.8915050625801086\n",
      "epoch 196: loss=0.9284796118736267\n",
      "epoch 197: loss=0.911222517490387\n",
      "epoch 198: loss=0.913436770439148\n",
      "epoch 199: loss=0.9169654846191406\n",
      "training patch with 2784 edges\n",
      "epoch 0: loss=3.5697238445281982\n",
      "epoch 1: loss=3.3005285263061523\n",
      "epoch 2: loss=3.233283281326294\n",
      "epoch 3: loss=2.8856990337371826\n",
      "epoch 4: loss=2.8876752853393555\n",
      "epoch 5: loss=2.6595146656036377\n",
      "epoch 6: loss=2.500821828842163\n",
      "epoch 7: loss=2.348468542098999\n",
      "epoch 8: loss=2.1169068813323975\n",
      "epoch 9: loss=2.085080862045288\n",
      "epoch 10: loss=1.9825574159622192\n",
      "epoch 11: loss=1.795971155166626\n",
      "epoch 12: loss=1.6609536409378052\n",
      "epoch 13: loss=1.6695247888565063\n",
      "epoch 14: loss=1.5898717641830444\n",
      "epoch 15: loss=1.5202809572219849\n",
      "epoch 16: loss=1.4652043581008911\n",
      "epoch 17: loss=1.455504059791565\n",
      "epoch 18: loss=1.4232091903686523\n",
      "epoch 19: loss=1.394186019897461\n",
      "epoch 20: loss=1.3778342008590698\n",
      "epoch 21: loss=1.368322730064392\n",
      "epoch 22: loss=1.3562209606170654\n",
      "epoch 23: loss=1.3465704917907715\n",
      "epoch 24: loss=1.348361611366272\n",
      "epoch 25: loss=1.3279763460159302\n",
      "epoch 26: loss=1.3170204162597656\n",
      "epoch 27: loss=1.3155220746994019\n",
      "epoch 28: loss=1.3091861009597778\n",
      "epoch 29: loss=1.3015016317367554\n",
      "epoch 30: loss=1.2967315912246704\n",
      "epoch 31: loss=1.3027925491333008\n",
      "epoch 32: loss=1.2839399576187134\n",
      "epoch 33: loss=1.276549220085144\n",
      "epoch 34: loss=1.280574083328247\n",
      "epoch 35: loss=1.2629467248916626\n",
      "epoch 36: loss=1.2703847885131836\n",
      "epoch 37: loss=1.2642930746078491\n",
      "epoch 38: loss=1.257699728012085\n",
      "epoch 39: loss=1.2554831504821777\n",
      "epoch 40: loss=1.2397757768630981\n",
      "epoch 41: loss=1.214180827140808\n",
      "epoch 42: loss=1.2284939289093018\n",
      "epoch 43: loss=1.2044110298156738\n",
      "epoch 44: loss=1.1972795724868774\n",
      "epoch 45: loss=1.182713508605957\n",
      "epoch 46: loss=1.1781928539276123\n",
      "epoch 47: loss=1.1685281991958618\n",
      "epoch 48: loss=1.1438379287719727\n",
      "epoch 49: loss=1.1447221040725708\n",
      "epoch 50: loss=1.1254758834838867\n",
      "epoch 51: loss=1.131985068321228\n",
      "epoch 52: loss=1.109681487083435\n",
      "epoch 53: loss=1.1224758625030518\n",
      "epoch 54: loss=1.110671877861023\n",
      "epoch 55: loss=1.0943526029586792\n",
      "epoch 56: loss=1.0958905220031738\n",
      "epoch 57: loss=1.0802935361862183\n",
      "epoch 58: loss=1.07037353515625\n",
      "epoch 59: loss=1.0695817470550537\n",
      "epoch 60: loss=1.0382566452026367\n",
      "epoch 61: loss=1.0416979789733887\n",
      "epoch 62: loss=1.01863431930542\n",
      "epoch 63: loss=1.0375077724456787\n",
      "epoch 64: loss=1.0363404750823975\n",
      "epoch 65: loss=1.0471384525299072\n",
      "epoch 66: loss=1.0261660814285278\n",
      "epoch 67: loss=1.0265649557113647\n",
      "epoch 68: loss=1.034930944442749\n",
      "epoch 69: loss=1.0193698406219482\n",
      "epoch 70: loss=1.0292634963989258\n",
      "epoch 71: loss=1.0150916576385498\n",
      "epoch 72: loss=1.0272314548492432\n",
      "epoch 73: loss=1.0097073316574097\n",
      "epoch 74: loss=1.0059287548065186\n",
      "epoch 75: loss=1.0145740509033203\n",
      "epoch 76: loss=0.9984081387519836\n",
      "epoch 77: loss=0.9976365566253662\n",
      "epoch 78: loss=0.9984428882598877\n",
      "epoch 79: loss=0.9924755096435547\n",
      "epoch 80: loss=0.9922977685928345\n",
      "epoch 81: loss=0.96817946434021\n",
      "epoch 82: loss=0.9817912578582764\n",
      "epoch 83: loss=0.9886431097984314\n",
      "epoch 84: loss=0.9932060241699219\n",
      "epoch 85: loss=0.9843576550483704\n",
      "epoch 86: loss=0.9991405606269836\n",
      "epoch 87: loss=0.9707481861114502\n",
      "epoch 88: loss=0.9772652387619019\n",
      "epoch 89: loss=0.9717833399772644\n",
      "epoch 90: loss=0.9623029828071594\n",
      "epoch 91: loss=0.9631109833717346\n",
      "epoch 92: loss=0.9657007455825806\n",
      "epoch 93: loss=0.9690233469009399\n",
      "epoch 94: loss=0.9682281017303467\n",
      "epoch 95: loss=0.9668498635292053\n",
      "epoch 96: loss=0.9738141894340515\n",
      "epoch 97: loss=0.9512516856193542\n",
      "epoch 98: loss=0.9585522413253784\n",
      "epoch 99: loss=0.9521657824516296\n",
      "epoch 100: loss=0.9591807723045349\n",
      "epoch 101: loss=0.9694332480430603\n",
      "epoch 102: loss=0.9604636430740356\n",
      "epoch 103: loss=0.9635016322135925\n",
      "epoch 104: loss=0.963733434677124\n",
      "epoch 105: loss=0.9570239782333374\n",
      "epoch 106: loss=0.9536075592041016\n",
      "epoch 107: loss=0.9583215713500977\n",
      "epoch 108: loss=0.9462182521820068\n",
      "epoch 109: loss=0.9532260894775391\n",
      "epoch 110: loss=0.958956778049469\n",
      "epoch 111: loss=0.9755275249481201\n",
      "epoch 112: loss=0.9590750336647034\n",
      "epoch 113: loss=0.9366819858551025\n",
      "epoch 114: loss=0.9567766189575195\n",
      "epoch 115: loss=0.9368106126785278\n",
      "epoch 116: loss=0.9317464232444763\n",
      "epoch 117: loss=0.9496673941612244\n",
      "epoch 118: loss=0.9351670742034912\n",
      "epoch 119: loss=0.9368974566459656\n",
      "epoch 120: loss=0.9391301870346069\n",
      "epoch 121: loss=0.9472600817680359\n",
      "epoch 122: loss=0.9432436227798462\n",
      "epoch 123: loss=0.930172324180603\n",
      "epoch 124: loss=0.9377627372741699\n",
      "epoch 125: loss=0.9340511560440063\n",
      "epoch 126: loss=0.9379266500473022\n",
      "epoch 127: loss=0.905401885509491\n",
      "epoch 128: loss=0.9265642762184143\n",
      "epoch 129: loss=0.9414809346199036\n",
      "epoch 130: loss=0.9372541904449463\n",
      "epoch 131: loss=0.9273262023925781\n",
      "epoch 132: loss=0.916520357131958\n",
      "epoch 133: loss=0.9284250140190125\n",
      "epoch 134: loss=0.9238960146903992\n",
      "epoch 135: loss=0.9236589074134827\n",
      "epoch 136: loss=0.941173791885376\n",
      "epoch 137: loss=0.9396728873252869\n",
      "epoch 138: loss=0.9240367412567139\n",
      "epoch 139: loss=0.9207947254180908\n",
      "epoch 140: loss=0.9137054085731506\n",
      "epoch 141: loss=0.926068127155304\n",
      "epoch 142: loss=0.91567063331604\n",
      "epoch 143: loss=0.9039626121520996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144: loss=0.9074097275733948\n",
      "epoch 145: loss=0.9052301049232483\n",
      "epoch 146: loss=0.9069111943244934\n",
      "epoch 147: loss=0.9075474143028259\n",
      "epoch 148: loss=0.9242653250694275\n",
      "epoch 149: loss=0.8997429013252258\n",
      "epoch 150: loss=0.907029390335083\n",
      "epoch 151: loss=0.907759428024292\n",
      "epoch 152: loss=0.9084305763244629\n",
      "epoch 153: loss=0.9078860282897949\n",
      "epoch 154: loss=0.9151200652122498\n",
      "epoch 155: loss=0.9135448336601257\n",
      "epoch 156: loss=0.9152041673660278\n",
      "epoch 157: loss=0.9068751931190491\n",
      "epoch 158: loss=0.9098508358001709\n",
      "epoch 159: loss=0.9080380797386169\n",
      "epoch 160: loss=0.9173400402069092\n",
      "epoch 161: loss=0.9130635857582092\n",
      "epoch 162: loss=0.8963544368743896\n",
      "epoch 163: loss=0.8896448612213135\n",
      "epoch 164: loss=0.8959211111068726\n",
      "epoch 165: loss=0.8915961980819702\n",
      "epoch 166: loss=0.9092096090316772\n",
      "epoch 167: loss=0.9052610397338867\n",
      "epoch 168: loss=0.9030297994613647\n",
      "epoch 169: loss=0.8976718187332153\n",
      "epoch 170: loss=0.9126006960868835\n",
      "epoch 171: loss=0.901109516620636\n",
      "epoch 172: loss=0.8880115747451782\n",
      "epoch 173: loss=0.8998830318450928\n",
      "epoch 174: loss=0.8904776573181152\n",
      "epoch 175: loss=0.8818722367286682\n",
      "epoch 176: loss=0.892193078994751\n",
      "epoch 177: loss=0.8835853338241577\n",
      "epoch 178: loss=0.8785160183906555\n",
      "epoch 179: loss=0.8947184681892395\n",
      "epoch 180: loss=0.8884788155555725\n",
      "epoch 181: loss=0.8933411240577698\n",
      "epoch 182: loss=0.8968209624290466\n",
      "epoch 183: loss=0.9063779711723328\n",
      "epoch 184: loss=0.8808151483535767\n",
      "epoch 185: loss=0.8943275809288025\n",
      "epoch 186: loss=0.8940610289573669\n",
      "epoch 187: loss=0.8942893147468567\n",
      "epoch 188: loss=0.8859573602676392\n",
      "epoch 189: loss=0.8807933926582336\n",
      "epoch 190: loss=0.9017022848129272\n",
      "epoch 191: loss=0.9106576442718506\n",
      "epoch 192: loss=0.8937190771102905\n",
      "epoch 193: loss=0.8972660303115845\n",
      "epoch 194: loss=0.8837411403656006\n",
      "epoch 195: loss=0.8884119987487793\n",
      "epoch 196: loss=0.9000986814498901\n",
      "epoch 197: loss=0.8889279365539551\n",
      "epoch 198: loss=0.8830323815345764\n",
      "epoch 199: loss=0.8972469568252563\n",
      "training patch with 1652 edges\n",
      "epoch 0: loss=3.5234274864196777\n",
      "epoch 1: loss=3.488743782043457\n",
      "epoch 2: loss=3.214043140411377\n",
      "epoch 3: loss=3.0980100631713867\n",
      "epoch 4: loss=3.0117106437683105\n",
      "epoch 5: loss=3.050363779067993\n",
      "epoch 6: loss=2.8742587566375732\n",
      "epoch 7: loss=2.677931070327759\n",
      "epoch 8: loss=2.5847327709198\n",
      "epoch 9: loss=2.416746139526367\n",
      "epoch 10: loss=2.400484085083008\n",
      "epoch 11: loss=2.298696517944336\n",
      "epoch 12: loss=2.073380947113037\n",
      "epoch 13: loss=1.9695457220077515\n",
      "epoch 14: loss=1.9160476922988892\n",
      "epoch 15: loss=1.852250099182129\n",
      "epoch 16: loss=1.7607526779174805\n",
      "epoch 17: loss=1.623811960220337\n",
      "epoch 18: loss=1.6758499145507812\n",
      "epoch 19: loss=1.5509604215621948\n",
      "epoch 20: loss=1.5367848873138428\n",
      "epoch 21: loss=1.4732969999313354\n",
      "epoch 22: loss=1.444901704788208\n",
      "epoch 23: loss=1.4403749704360962\n",
      "epoch 24: loss=1.414718747138977\n",
      "epoch 25: loss=1.3989819288253784\n",
      "epoch 26: loss=1.3842730522155762\n",
      "epoch 27: loss=1.3766676187515259\n",
      "epoch 28: loss=1.358856201171875\n",
      "epoch 29: loss=1.3618619441986084\n",
      "epoch 30: loss=1.3557748794555664\n",
      "epoch 31: loss=1.3534784317016602\n",
      "epoch 32: loss=1.340627908706665\n",
      "epoch 33: loss=1.3375381231307983\n",
      "epoch 34: loss=1.332563877105713\n",
      "epoch 35: loss=1.3373254537582397\n",
      "epoch 36: loss=1.3132050037384033\n",
      "epoch 37: loss=1.3113213777542114\n",
      "epoch 38: loss=1.319391131401062\n",
      "epoch 39: loss=1.3045403957366943\n",
      "epoch 40: loss=1.3106225728988647\n",
      "epoch 41: loss=1.2800118923187256\n",
      "epoch 42: loss=1.268136978149414\n",
      "epoch 43: loss=1.2621517181396484\n",
      "epoch 44: loss=1.2446184158325195\n",
      "epoch 45: loss=1.2223135232925415\n",
      "epoch 46: loss=1.2140064239501953\n",
      "epoch 47: loss=1.2036281824111938\n",
      "epoch 48: loss=1.172996997833252\n",
      "epoch 49: loss=1.162225604057312\n",
      "epoch 50: loss=1.1218205690383911\n",
      "epoch 51: loss=1.1025687456130981\n",
      "epoch 52: loss=1.1007850170135498\n",
      "epoch 53: loss=1.09842050075531\n",
      "epoch 54: loss=1.0787492990493774\n",
      "epoch 55: loss=1.0685162544250488\n",
      "epoch 56: loss=1.0798405408859253\n",
      "epoch 57: loss=1.0502970218658447\n",
      "epoch 58: loss=1.0786763429641724\n",
      "epoch 59: loss=1.0809074640274048\n",
      "epoch 60: loss=1.0692147016525269\n",
      "epoch 61: loss=1.0810774564743042\n",
      "epoch 62: loss=1.0430538654327393\n",
      "epoch 63: loss=1.0603011846542358\n",
      "epoch 64: loss=1.0796970129013062\n",
      "epoch 65: loss=1.0073963403701782\n",
      "epoch 66: loss=1.0274569988250732\n",
      "epoch 67: loss=1.0132930278778076\n",
      "epoch 68: loss=1.0287364721298218\n",
      "epoch 69: loss=1.0225987434387207\n",
      "epoch 70: loss=1.0118812322616577\n",
      "epoch 71: loss=1.0212032794952393\n",
      "epoch 72: loss=1.0026074647903442\n",
      "epoch 73: loss=0.9819275140762329\n",
      "epoch 74: loss=1.0006023645401\n",
      "epoch 75: loss=1.0064557790756226\n",
      "epoch 76: loss=1.0009962320327759\n",
      "epoch 77: loss=0.9842728972434998\n",
      "epoch 78: loss=0.9727029204368591\n",
      "epoch 79: loss=0.9691504240036011\n",
      "epoch 80: loss=0.9826816320419312\n",
      "epoch 81: loss=0.983637273311615\n",
      "epoch 82: loss=0.9745194315910339\n",
      "epoch 83: loss=0.9660305380821228\n",
      "epoch 84: loss=0.9671605229377747\n",
      "epoch 85: loss=0.9706889390945435\n",
      "epoch 86: loss=0.9400981664657593\n",
      "epoch 87: loss=0.9559484720230103\n",
      "epoch 88: loss=0.9560544490814209\n",
      "epoch 89: loss=0.965792179107666\n",
      "epoch 90: loss=0.9847177267074585\n",
      "epoch 91: loss=0.9549570679664612\n",
      "epoch 92: loss=0.9752404093742371\n",
      "epoch 93: loss=0.99470454454422\n",
      "epoch 94: loss=0.9392899870872498\n",
      "epoch 95: loss=0.935221254825592\n",
      "epoch 96: loss=0.959079384803772\n",
      "epoch 97: loss=0.9607734680175781\n",
      "epoch 98: loss=0.9586086273193359\n",
      "epoch 99: loss=0.9439963698387146\n",
      "epoch 100: loss=0.9288313388824463\n",
      "epoch 101: loss=0.9438446760177612\n",
      "epoch 102: loss=0.9347978830337524\n",
      "epoch 103: loss=0.9572772979736328\n",
      "epoch 104: loss=0.9345126152038574\n",
      "epoch 105: loss=0.9592441320419312\n",
      "epoch 106: loss=0.9251720309257507\n",
      "epoch 107: loss=0.922691822052002\n",
      "epoch 108: loss=0.9338598847389221\n",
      "epoch 109: loss=0.9493493437767029\n",
      "epoch 110: loss=0.9307917356491089\n",
      "epoch 111: loss=0.9687080979347229\n",
      "epoch 112: loss=0.9585301876068115\n",
      "epoch 113: loss=0.9388543367385864\n",
      "epoch 114: loss=0.9380541443824768\n",
      "epoch 115: loss=0.9399846792221069\n",
      "epoch 116: loss=0.9159937500953674\n",
      "epoch 117: loss=0.9094191789627075\n",
      "epoch 118: loss=0.9288907051086426\n",
      "epoch 119: loss=0.929825484752655\n",
      "epoch 120: loss=0.9321480393409729\n",
      "epoch 121: loss=0.9173598289489746\n",
      "epoch 122: loss=0.932206392288208\n",
      "epoch 123: loss=0.9143611192703247\n",
      "epoch 124: loss=0.9018309116363525\n",
      "epoch 125: loss=0.9345777630805969\n",
      "epoch 126: loss=0.9405773878097534\n",
      "epoch 127: loss=0.8852524161338806\n",
      "epoch 128: loss=0.9354952573776245\n",
      "epoch 129: loss=0.9306811690330505\n",
      "epoch 130: loss=0.9136995077133179\n",
      "epoch 131: loss=0.9377262592315674\n",
      "epoch 132: loss=0.928001880645752\n",
      "epoch 133: loss=0.9104061126708984\n",
      "epoch 134: loss=0.911423921585083\n",
      "epoch 135: loss=0.9136484265327454\n",
      "epoch 136: loss=0.931244432926178\n",
      "epoch 137: loss=0.9180696606636047\n",
      "epoch 138: loss=0.9025176763534546\n",
      "epoch 139: loss=0.9430013298988342\n",
      "epoch 140: loss=0.9524986743927002\n",
      "epoch 141: loss=0.9326761960983276\n",
      "epoch 142: loss=0.9198383688926697\n",
      "epoch 143: loss=0.9201527237892151\n",
      "epoch 144: loss=0.9265015721321106\n",
      "epoch 145: loss=0.9280930757522583\n",
      "epoch 146: loss=0.9131213426589966\n",
      "epoch 147: loss=0.930476725101471\n",
      "epoch 148: loss=0.93113112449646\n",
      "epoch 149: loss=0.901248037815094\n",
      "epoch 150: loss=0.9150175452232361\n",
      "epoch 151: loss=0.9086595773696899\n",
      "epoch 152: loss=0.9097687005996704\n",
      "epoch 153: loss=0.9045575857162476\n",
      "epoch 154: loss=0.9125848412513733\n",
      "epoch 155: loss=0.911706805229187\n",
      "epoch 156: loss=0.8873782753944397\n",
      "epoch 157: loss=0.9028217792510986\n",
      "epoch 158: loss=0.9229808449745178\n",
      "epoch 159: loss=0.8945571780204773\n",
      "epoch 160: loss=0.910136342048645\n",
      "epoch 161: loss=0.9084107279777527\n",
      "epoch 162: loss=0.912195086479187\n",
      "epoch 163: loss=0.8991451263427734\n",
      "epoch 164: loss=0.8896194100379944\n",
      "epoch 165: loss=0.9122090339660645\n",
      "epoch 166: loss=0.9095470905303955\n",
      "epoch 167: loss=0.8980264663696289\n",
      "epoch 168: loss=0.8905177116394043\n",
      "epoch 169: loss=0.8915510177612305\n",
      "epoch 170: loss=0.9230191707611084\n",
      "epoch 171: loss=0.9076253175735474\n",
      "epoch 172: loss=0.8909252882003784\n",
      "epoch 173: loss=0.8818694353103638\n",
      "epoch 174: loss=0.8882455229759216\n",
      "epoch 175: loss=0.9058321714401245\n",
      "epoch 176: loss=0.9087876081466675\n",
      "epoch 177: loss=0.8786108493804932\n",
      "epoch 178: loss=0.8818069696426392\n",
      "epoch 179: loss=0.8998371958732605\n",
      "epoch 180: loss=0.9018204808235168\n",
      "epoch 181: loss=0.9133985042572021\n",
      "epoch 182: loss=0.8893274068832397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 183: loss=0.9138327240943909\n",
      "epoch 184: loss=0.8824769258499146\n",
      "epoch 185: loss=0.8821443915367126\n",
      "epoch 186: loss=0.8823468089103699\n",
      "epoch 187: loss=0.8808212876319885\n",
      "epoch 188: loss=0.8851411938667297\n",
      "epoch 189: loss=0.9017014503479004\n",
      "epoch 190: loss=0.9011037349700928\n",
      "epoch 191: loss=0.894504964351654\n",
      "epoch 192: loss=0.8674469590187073\n",
      "epoch 193: loss=0.8915278315544128\n",
      "epoch 194: loss=0.8866019248962402\n",
      "epoch 195: loss=0.9048728346824646\n",
      "epoch 196: loss=0.9082432389259338\n",
      "epoch 197: loss=0.9145575165748596\n",
      "epoch 198: loss=0.8844689726829529\n",
      "epoch 199: loss=0.9054481387138367\n",
      "training patch with 840 edges\n",
      "epoch 0: loss=3.4604809284210205\n",
      "epoch 1: loss=3.301443099975586\n",
      "epoch 2: loss=3.4059319496154785\n",
      "epoch 3: loss=2.813950300216675\n",
      "epoch 4: loss=2.950381278991699\n",
      "epoch 5: loss=2.628608465194702\n",
      "epoch 6: loss=2.55922269821167\n",
      "epoch 7: loss=2.312016010284424\n",
      "epoch 8: loss=2.2743308544158936\n",
      "epoch 9: loss=2.1523783206939697\n",
      "epoch 10: loss=2.123608112335205\n",
      "epoch 11: loss=1.9578747749328613\n",
      "epoch 12: loss=1.79491126537323\n",
      "epoch 13: loss=1.6866111755371094\n",
      "epoch 14: loss=1.6627471446990967\n",
      "epoch 15: loss=1.5984983444213867\n",
      "epoch 16: loss=1.5776233673095703\n",
      "epoch 17: loss=1.5127679109573364\n",
      "epoch 18: loss=1.4584386348724365\n",
      "epoch 19: loss=1.4342522621154785\n",
      "epoch 20: loss=1.4329062700271606\n",
      "epoch 21: loss=1.386466145515442\n",
      "epoch 22: loss=1.3860087394714355\n",
      "epoch 23: loss=1.384305477142334\n",
      "epoch 24: loss=1.4058438539505005\n",
      "epoch 25: loss=1.3698408603668213\n",
      "epoch 26: loss=1.3784599304199219\n",
      "epoch 27: loss=1.3743162155151367\n",
      "epoch 28: loss=1.3368022441864014\n",
      "epoch 29: loss=1.3503901958465576\n",
      "epoch 30: loss=1.346179485321045\n",
      "epoch 31: loss=1.3151875734329224\n",
      "epoch 32: loss=1.316470980644226\n",
      "epoch 33: loss=1.321211338043213\n",
      "epoch 34: loss=1.2947043180465698\n",
      "epoch 35: loss=1.3036590814590454\n",
      "epoch 36: loss=1.283282995223999\n",
      "epoch 37: loss=1.2666188478469849\n",
      "epoch 38: loss=1.261770486831665\n",
      "epoch 39: loss=1.2413345575332642\n",
      "epoch 40: loss=1.2271449565887451\n",
      "epoch 41: loss=1.2210792303085327\n",
      "epoch 42: loss=1.1739946603775024\n",
      "epoch 43: loss=1.1568111181259155\n",
      "epoch 44: loss=1.1392669677734375\n",
      "epoch 45: loss=1.1282769441604614\n",
      "epoch 46: loss=1.1259123086929321\n",
      "epoch 47: loss=1.0682084560394287\n",
      "epoch 48: loss=1.092685580253601\n",
      "epoch 49: loss=1.0874414443969727\n",
      "epoch 50: loss=1.0737559795379639\n",
      "epoch 51: loss=1.090747356414795\n",
      "epoch 52: loss=1.1132887601852417\n",
      "epoch 53: loss=1.0071457624435425\n",
      "epoch 54: loss=1.0476640462875366\n",
      "epoch 55: loss=1.0863869190216064\n",
      "epoch 56: loss=1.0224113464355469\n",
      "epoch 57: loss=1.0355100631713867\n",
      "epoch 58: loss=1.0150572061538696\n",
      "epoch 59: loss=1.0088683366775513\n",
      "epoch 60: loss=1.0083786249160767\n",
      "epoch 61: loss=1.0221401453018188\n",
      "epoch 62: loss=0.9761414527893066\n",
      "epoch 63: loss=1.0010854005813599\n",
      "epoch 64: loss=0.9874107241630554\n",
      "epoch 65: loss=1.0095810890197754\n",
      "epoch 66: loss=0.9871304035186768\n",
      "epoch 67: loss=0.9834961295127869\n",
      "epoch 68: loss=0.9836157560348511\n",
      "epoch 69: loss=0.9923086166381836\n",
      "epoch 70: loss=0.9767062664031982\n",
      "epoch 71: loss=0.9833086133003235\n",
      "epoch 72: loss=0.9791315197944641\n",
      "epoch 73: loss=0.9818800687789917\n",
      "epoch 74: loss=0.994122326374054\n",
      "epoch 75: loss=0.959086537361145\n",
      "epoch 76: loss=0.9711123108863831\n",
      "epoch 77: loss=0.9534155130386353\n",
      "epoch 78: loss=0.9511964321136475\n",
      "epoch 79: loss=0.9768880605697632\n",
      "epoch 80: loss=0.9813984036445618\n",
      "epoch 81: loss=0.9615935683250427\n",
      "epoch 82: loss=0.9727638959884644\n",
      "epoch 83: loss=0.9769547581672668\n",
      "epoch 84: loss=0.9737519025802612\n",
      "epoch 85: loss=0.9867257475852966\n",
      "epoch 86: loss=0.9824745655059814\n",
      "epoch 87: loss=0.9637727737426758\n",
      "epoch 88: loss=0.9336029291152954\n",
      "epoch 89: loss=0.955664873123169\n",
      "epoch 90: loss=0.9513556957244873\n",
      "epoch 91: loss=0.9575693011283875\n",
      "epoch 92: loss=0.9706164002418518\n",
      "epoch 93: loss=0.964927077293396\n",
      "epoch 94: loss=0.9600978493690491\n",
      "epoch 95: loss=0.9482302069664001\n",
      "epoch 96: loss=0.9528601169586182\n",
      "epoch 97: loss=0.944164514541626\n",
      "epoch 98: loss=0.9382783770561218\n",
      "epoch 99: loss=0.954919159412384\n",
      "epoch 100: loss=0.9384419918060303\n",
      "epoch 101: loss=0.9593992233276367\n",
      "epoch 102: loss=0.9375830292701721\n",
      "epoch 103: loss=0.9468657970428467\n",
      "epoch 104: loss=0.9645075798034668\n",
      "epoch 105: loss=0.9419447779655457\n",
      "epoch 106: loss=0.9105883836746216\n",
      "epoch 107: loss=0.9679861664772034\n",
      "epoch 108: loss=0.9818273186683655\n",
      "epoch 109: loss=0.9290931224822998\n",
      "epoch 110: loss=0.94586181640625\n",
      "epoch 111: loss=0.954890251159668\n",
      "epoch 112: loss=0.9390878081321716\n",
      "epoch 113: loss=0.9748213291168213\n",
      "epoch 114: loss=0.9349275827407837\n",
      "epoch 115: loss=0.9321513772010803\n",
      "epoch 116: loss=0.9303870797157288\n",
      "epoch 117: loss=0.9640618562698364\n",
      "epoch 118: loss=0.9241888523101807\n",
      "epoch 119: loss=0.9306079149246216\n",
      "epoch 120: loss=0.898558497428894\n",
      "epoch 121: loss=0.9045510292053223\n",
      "epoch 122: loss=0.9103737473487854\n",
      "epoch 123: loss=0.9336831569671631\n",
      "epoch 124: loss=0.9080306887626648\n",
      "epoch 125: loss=0.9185918569564819\n",
      "epoch 126: loss=0.9363160133361816\n",
      "epoch 127: loss=0.9302892684936523\n",
      "epoch 128: loss=0.921046257019043\n",
      "epoch 129: loss=0.937308132648468\n",
      "epoch 130: loss=0.9561880230903625\n",
      "epoch 131: loss=0.9555933475494385\n",
      "epoch 132: loss=0.9362078905105591\n",
      "epoch 133: loss=0.9163577556610107\n",
      "epoch 134: loss=0.9527094960212708\n",
      "epoch 135: loss=0.9297497868537903\n",
      "epoch 136: loss=0.9346988797187805\n",
      "epoch 137: loss=0.8973342180252075\n",
      "epoch 138: loss=0.9594454169273376\n",
      "epoch 139: loss=0.9243708252906799\n",
      "epoch 140: loss=0.9489338397979736\n",
      "epoch 141: loss=0.9436680674552917\n",
      "epoch 142: loss=0.9300249218940735\n",
      "epoch 143: loss=0.9503450393676758\n",
      "epoch 144: loss=0.9568608999252319\n",
      "epoch 145: loss=0.9289772510528564\n",
      "epoch 146: loss=0.9221685528755188\n",
      "epoch 147: loss=0.9219484329223633\n",
      "epoch 148: loss=0.9444739818572998\n",
      "epoch 149: loss=0.8985488414764404\n",
      "epoch 150: loss=0.9404527544975281\n",
      "epoch 151: loss=0.9184449911117554\n",
      "epoch 152: loss=0.9039627313613892\n",
      "epoch 153: loss=0.9284077882766724\n",
      "epoch 154: loss=0.9346749782562256\n",
      "epoch 155: loss=0.9145781397819519\n",
      "epoch 156: loss=0.9182775020599365\n",
      "epoch 157: loss=0.930472731590271\n",
      "epoch 158: loss=0.9294329285621643\n",
      "epoch 159: loss=0.939315676689148\n",
      "epoch 160: loss=0.9300795197486877\n",
      "epoch 161: loss=0.9348078370094299\n",
      "epoch 162: loss=0.9058276414871216\n",
      "epoch 163: loss=0.9178208112716675\n",
      "epoch 164: loss=0.9066131711006165\n",
      "epoch 165: loss=0.9388689398765564\n",
      "epoch 166: loss=0.9124108552932739\n",
      "epoch 167: loss=0.9669978022575378\n",
      "epoch 168: loss=0.9037330150604248\n",
      "epoch 169: loss=0.8827702403068542\n",
      "epoch 170: loss=0.924130380153656\n",
      "epoch 171: loss=0.8966485261917114\n",
      "epoch 172: loss=0.9041650891304016\n",
      "epoch 173: loss=0.9250534772872925\n",
      "epoch 174: loss=0.9403495192527771\n",
      "epoch 175: loss=0.9108797311782837\n",
      "epoch 176: loss=0.893586277961731\n",
      "epoch 177: loss=0.8985040187835693\n",
      "epoch 178: loss=0.9024048447608948\n",
      "epoch 179: loss=0.9198976755142212\n",
      "epoch 180: loss=0.9280507564544678\n",
      "epoch 181: loss=0.9152898788452148\n",
      "epoch 182: loss=0.9533945918083191\n",
      "epoch 183: loss=0.9675018787384033\n",
      "epoch 184: loss=0.9402887225151062\n",
      "epoch 185: loss=0.9260600209236145\n",
      "epoch 186: loss=0.9208201169967651\n",
      "epoch 187: loss=0.900260329246521\n",
      "epoch 188: loss=0.9415532350540161\n",
      "epoch 189: loss=0.9480554461479187\n",
      "epoch 190: loss=0.9071447849273682\n",
      "epoch 191: loss=0.920493483543396\n",
      "epoch 192: loss=0.9044582843780518\n",
      "epoch 193: loss=0.9365267753601074\n",
      "epoch 194: loss=0.8984071016311646\n",
      "epoch 195: loss=0.8866353034973145\n",
      "epoch 196: loss=0.9092796444892883\n",
      "epoch 197: loss=0.9032062292098999\n",
      "epoch 198: loss=0.9207374453544617\n",
      "epoch 199: loss=0.9020969867706299\n",
      "training patch with 1460 edges\n",
      "epoch 0: loss=3.6916356086730957\n",
      "epoch 1: loss=3.462928533554077\n",
      "epoch 2: loss=3.4047799110412598\n",
      "epoch 3: loss=3.1301777362823486\n",
      "epoch 4: loss=2.892392158508301\n",
      "epoch 5: loss=2.795081853866577\n",
      "epoch 6: loss=2.6889426708221436\n",
      "epoch 7: loss=2.521660089492798\n",
      "epoch 8: loss=2.3941922187805176\n",
      "epoch 9: loss=2.2406837940216064\n",
      "epoch 10: loss=2.1408402919769287\n",
      "epoch 11: loss=2.018555164337158\n",
      "epoch 12: loss=1.9469507932662964\n",
      "epoch 13: loss=1.8477870225906372\n",
      "epoch 14: loss=1.7360124588012695\n",
      "epoch 15: loss=1.6298093795776367\n",
      "epoch 16: loss=1.6110695600509644\n",
      "epoch 17: loss=1.5356465578079224\n",
      "epoch 18: loss=1.4725573062896729\n",
      "epoch 19: loss=1.4544564485549927\n",
      "epoch 20: loss=1.4160743951797485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: loss=1.409946322441101\n",
      "epoch 22: loss=1.4027186632156372\n",
      "epoch 23: loss=1.365415334701538\n",
      "epoch 24: loss=1.366999864578247\n",
      "epoch 25: loss=1.3473654985427856\n",
      "epoch 26: loss=1.3343591690063477\n",
      "epoch 27: loss=1.3353300094604492\n",
      "epoch 28: loss=1.329161524772644\n",
      "epoch 29: loss=1.3417024612426758\n",
      "epoch 30: loss=1.329026699066162\n",
      "epoch 31: loss=1.3088845014572144\n",
      "epoch 32: loss=1.309170126914978\n",
      "epoch 33: loss=1.3146394491195679\n",
      "epoch 34: loss=1.3099133968353271\n",
      "epoch 35: loss=1.310732126235962\n",
      "epoch 36: loss=1.2876461744308472\n",
      "epoch 37: loss=1.2941749095916748\n",
      "epoch 38: loss=1.2952231168746948\n",
      "epoch 39: loss=1.2806625366210938\n",
      "epoch 40: loss=1.2801589965820312\n",
      "epoch 41: loss=1.2656595706939697\n",
      "epoch 42: loss=1.2464839220046997\n",
      "epoch 43: loss=1.2495156526565552\n",
      "epoch 44: loss=1.220668077468872\n",
      "epoch 45: loss=1.2327216863632202\n",
      "epoch 46: loss=1.2083030939102173\n",
      "epoch 47: loss=1.1956703662872314\n",
      "epoch 48: loss=1.1903184652328491\n",
      "epoch 49: loss=1.1618403196334839\n",
      "epoch 50: loss=1.1569678783416748\n",
      "epoch 51: loss=1.1287692785263062\n",
      "epoch 52: loss=1.115358591079712\n",
      "epoch 53: loss=1.1214271783828735\n",
      "epoch 54: loss=1.1091747283935547\n",
      "epoch 55: loss=1.093417763710022\n",
      "epoch 56: loss=1.09210205078125\n",
      "epoch 57: loss=1.1006337404251099\n",
      "epoch 58: loss=1.074636459350586\n",
      "epoch 59: loss=1.0685348510742188\n",
      "epoch 60: loss=1.0658295154571533\n",
      "epoch 61: loss=1.0521947145462036\n",
      "epoch 62: loss=1.0644268989562988\n",
      "epoch 63: loss=1.0237795114517212\n",
      "epoch 64: loss=1.0175082683563232\n",
      "epoch 65: loss=1.0469536781311035\n",
      "epoch 66: loss=1.01776123046875\n",
      "epoch 67: loss=1.021255612373352\n",
      "epoch 68: loss=0.9904404282569885\n",
      "epoch 69: loss=1.0113829374313354\n",
      "epoch 70: loss=0.9923150539398193\n",
      "epoch 71: loss=0.9994139671325684\n",
      "epoch 72: loss=0.975157618522644\n",
      "epoch 73: loss=0.9822307229042053\n",
      "epoch 74: loss=0.9914918541908264\n",
      "epoch 75: loss=0.9980462789535522\n",
      "epoch 76: loss=0.9723672866821289\n",
      "epoch 77: loss=0.9776928424835205\n",
      "epoch 78: loss=0.9761970639228821\n",
      "epoch 79: loss=0.9796818494796753\n",
      "epoch 80: loss=0.9417025446891785\n",
      "epoch 81: loss=0.954024612903595\n",
      "epoch 82: loss=0.9936542510986328\n",
      "epoch 83: loss=0.9641590714454651\n",
      "epoch 84: loss=0.9811270833015442\n",
      "epoch 85: loss=0.9643484354019165\n",
      "epoch 86: loss=0.9576415419578552\n",
      "epoch 87: loss=0.9794609546661377\n",
      "epoch 88: loss=0.9713324308395386\n",
      "epoch 89: loss=0.969887912273407\n",
      "epoch 90: loss=0.976533055305481\n",
      "epoch 91: loss=0.9725598692893982\n",
      "epoch 92: loss=0.9756543040275574\n",
      "epoch 93: loss=0.9851621985435486\n",
      "epoch 94: loss=0.940684974193573\n",
      "epoch 95: loss=0.9758673310279846\n",
      "epoch 96: loss=0.9603712558746338\n",
      "epoch 97: loss=0.9684042930603027\n",
      "epoch 98: loss=0.983940064907074\n",
      "epoch 99: loss=0.9541419148445129\n",
      "epoch 100: loss=0.9432589411735535\n",
      "epoch 101: loss=0.9624409079551697\n",
      "epoch 102: loss=0.9587405323982239\n",
      "epoch 103: loss=0.9336900115013123\n",
      "epoch 104: loss=0.9429340958595276\n",
      "epoch 105: loss=0.9678500294685364\n",
      "epoch 106: loss=0.9364908933639526\n",
      "epoch 107: loss=0.9438403248786926\n",
      "epoch 108: loss=0.940342366695404\n",
      "epoch 109: loss=0.9463695883750916\n",
      "epoch 110: loss=0.9356388449668884\n",
      "epoch 111: loss=0.9259592294692993\n",
      "epoch 112: loss=0.9307894110679626\n",
      "epoch 113: loss=0.9321825504302979\n",
      "epoch 114: loss=0.9336026906967163\n",
      "epoch 115: loss=0.9565675854682922\n",
      "epoch 116: loss=0.943642795085907\n",
      "epoch 117: loss=0.9383144974708557\n",
      "epoch 118: loss=0.9279971122741699\n",
      "epoch 119: loss=0.9237761497497559\n",
      "epoch 120: loss=0.9582113027572632\n",
      "epoch 121: loss=0.9373276233673096\n",
      "epoch 122: loss=0.9347853064537048\n",
      "epoch 123: loss=0.9199491739273071\n",
      "epoch 124: loss=0.9501110911369324\n",
      "epoch 125: loss=0.9229159355163574\n",
      "epoch 126: loss=0.93815016746521\n",
      "epoch 127: loss=0.9117435812950134\n",
      "epoch 128: loss=0.9336267113685608\n",
      "epoch 129: loss=0.9802936315536499\n",
      "epoch 130: loss=0.9235585331916809\n",
      "epoch 131: loss=0.9638535976409912\n",
      "epoch 132: loss=0.9348109364509583\n",
      "epoch 133: loss=0.9585949182510376\n",
      "epoch 134: loss=0.925538182258606\n",
      "epoch 135: loss=0.9353064894676208\n",
      "epoch 136: loss=0.9359973669052124\n",
      "epoch 137: loss=0.928099513053894\n",
      "epoch 138: loss=0.9207413196563721\n",
      "epoch 139: loss=0.9084484577178955\n",
      "epoch 140: loss=0.9004515409469604\n",
      "epoch 141: loss=0.9320537447929382\n",
      "epoch 142: loss=0.9254189729690552\n",
      "epoch 143: loss=0.9322683811187744\n",
      "epoch 144: loss=0.9362292289733887\n",
      "epoch 145: loss=0.9365001916885376\n",
      "epoch 146: loss=0.9254940748214722\n",
      "epoch 147: loss=0.9332917332649231\n",
      "epoch 148: loss=0.9263091087341309\n",
      "epoch 149: loss=0.9298262596130371\n",
      "epoch 150: loss=0.908833920955658\n",
      "epoch 151: loss=0.9074351787567139\n",
      "epoch 152: loss=0.9239406585693359\n",
      "epoch 153: loss=0.9322410225868225\n",
      "epoch 154: loss=0.9156444668769836\n",
      "epoch 155: loss=0.9283206462860107\n",
      "epoch 156: loss=0.9213588833808899\n",
      "epoch 157: loss=0.9408234357833862\n",
      "epoch 158: loss=0.8970813155174255\n",
      "epoch 159: loss=0.9483235478401184\n",
      "epoch 160: loss=0.8989035487174988\n",
      "epoch 161: loss=0.9032353162765503\n",
      "epoch 162: loss=0.923906683921814\n",
      "epoch 163: loss=0.9024636149406433\n",
      "epoch 164: loss=0.9226675033569336\n",
      "epoch 165: loss=0.9228779077529907\n",
      "epoch 166: loss=0.8985638618469238\n",
      "epoch 167: loss=0.9252842664718628\n",
      "epoch 168: loss=0.9164730310440063\n",
      "epoch 169: loss=0.9076269268989563\n",
      "epoch 170: loss=0.9306817054748535\n",
      "epoch 171: loss=0.9250220656394958\n",
      "epoch 172: loss=0.9062895178794861\n",
      "epoch 173: loss=0.9139975309371948\n",
      "epoch 174: loss=0.9033705592155457\n",
      "epoch 175: loss=0.9004034996032715\n",
      "epoch 176: loss=0.9192256331443787\n",
      "epoch 177: loss=0.8998751640319824\n",
      "epoch 178: loss=0.9319579005241394\n",
      "epoch 179: loss=0.9224873781204224\n",
      "epoch 180: loss=0.9242174625396729\n",
      "epoch 181: loss=0.9142930507659912\n",
      "epoch 182: loss=0.9257733821868896\n",
      "epoch 183: loss=0.9079973697662354\n",
      "epoch 184: loss=0.9037113189697266\n",
      "epoch 185: loss=0.9369077682495117\n",
      "epoch 186: loss=0.9056570529937744\n",
      "epoch 187: loss=0.9352688193321228\n",
      "epoch 188: loss=0.9130850434303284\n",
      "epoch 189: loss=0.8983660340309143\n",
      "epoch 190: loss=0.9176759123802185\n",
      "epoch 191: loss=0.9026826620101929\n",
      "epoch 192: loss=0.8901063799858093\n",
      "epoch 193: loss=0.8770785927772522\n",
      "epoch 194: loss=0.9094856381416321\n",
      "epoch 195: loss=0.904750645160675\n",
      "epoch 196: loss=0.9257383346557617\n",
      "epoch 197: loss=0.8916375041007996\n",
      "epoch 198: loss=0.9047555327415466\n",
      "epoch 199: loss=0.9088543653488159\n",
      "training patch with 764 edges\n",
      "epoch 0: loss=3.3367600440979004\n",
      "epoch 1: loss=3.34503436088562\n",
      "epoch 2: loss=3.14577579498291\n",
      "epoch 3: loss=3.004837989807129\n",
      "epoch 4: loss=2.6310670375823975\n",
      "epoch 5: loss=2.97615909576416\n",
      "epoch 6: loss=2.5418589115142822\n",
      "epoch 7: loss=2.2841720581054688\n",
      "epoch 8: loss=2.2239372730255127\n",
      "epoch 9: loss=2.015303373336792\n",
      "epoch 10: loss=1.889133095741272\n",
      "epoch 11: loss=1.858089566230774\n",
      "epoch 12: loss=1.7222672700881958\n",
      "epoch 13: loss=1.6075396537780762\n",
      "epoch 14: loss=1.5122716426849365\n",
      "epoch 15: loss=1.5299880504608154\n",
      "epoch 16: loss=1.4845085144042969\n",
      "epoch 17: loss=1.4999147653579712\n",
      "epoch 18: loss=1.4401391744613647\n",
      "epoch 19: loss=1.4426451921463013\n",
      "epoch 20: loss=1.425399899482727\n",
      "epoch 21: loss=1.4292231798171997\n",
      "epoch 22: loss=1.4197081327438354\n",
      "epoch 23: loss=1.401311993598938\n",
      "epoch 24: loss=1.4323844909667969\n",
      "epoch 25: loss=1.4031270742416382\n",
      "epoch 26: loss=1.3939263820648193\n",
      "epoch 27: loss=1.3784005641937256\n",
      "epoch 28: loss=1.3690630197525024\n",
      "epoch 29: loss=1.3684107065200806\n",
      "epoch 30: loss=1.345966100692749\n",
      "epoch 31: loss=1.3407765626907349\n",
      "epoch 32: loss=1.3342854976654053\n",
      "epoch 33: loss=1.3155866861343384\n",
      "epoch 34: loss=1.2968891859054565\n",
      "epoch 35: loss=1.2629179954528809\n",
      "epoch 36: loss=1.2659579515457153\n",
      "epoch 37: loss=1.2434778213500977\n",
      "epoch 38: loss=1.228424072265625\n",
      "epoch 39: loss=1.2031832933425903\n",
      "epoch 40: loss=1.209588646888733\n",
      "epoch 41: loss=1.1703625917434692\n",
      "epoch 42: loss=1.1368415355682373\n",
      "epoch 43: loss=1.1938507556915283\n",
      "epoch 44: loss=1.1457892656326294\n",
      "epoch 45: loss=1.1172972917556763\n",
      "epoch 46: loss=1.1122404336929321\n",
      "epoch 47: loss=1.1247406005859375\n",
      "epoch 48: loss=1.0995845794677734\n",
      "epoch 49: loss=1.0837087631225586\n",
      "epoch 50: loss=1.0675599575042725\n",
      "epoch 51: loss=1.1000300645828247\n",
      "epoch 52: loss=1.0158945322036743\n",
      "epoch 53: loss=1.053385615348816\n",
      "epoch 54: loss=1.02126944065094\n",
      "epoch 55: loss=1.0444154739379883\n",
      "epoch 56: loss=1.0381710529327393\n",
      "epoch 57: loss=1.0739566087722778\n",
      "epoch 58: loss=1.0435811281204224\n",
      "epoch 59: loss=1.057041049003601\n",
      "epoch 60: loss=1.056739330291748\n",
      "epoch 61: loss=1.037310242652893\n",
      "epoch 62: loss=1.0181519985198975\n",
      "epoch 63: loss=1.027550458908081\n",
      "epoch 64: loss=1.0565849542617798\n",
      "epoch 65: loss=1.0047813653945923\n",
      "epoch 66: loss=1.0110485553741455\n",
      "epoch 67: loss=1.0079988241195679\n",
      "epoch 68: loss=1.0248217582702637\n",
      "epoch 69: loss=1.0036368370056152\n",
      "epoch 70: loss=1.0215033292770386\n",
      "epoch 71: loss=1.043976068496704\n",
      "epoch 72: loss=0.9752940535545349\n",
      "epoch 73: loss=0.991368293762207\n",
      "epoch 74: loss=0.9995425343513489\n",
      "epoch 75: loss=1.05198335647583\n",
      "epoch 76: loss=1.0054681301116943\n",
      "epoch 77: loss=1.018159031867981\n",
      "epoch 78: loss=1.0704758167266846\n",
      "epoch 79: loss=1.024080753326416\n",
      "epoch 80: loss=1.0392050743103027\n",
      "epoch 81: loss=0.975732684135437\n",
      "epoch 82: loss=1.0126614570617676\n",
      "epoch 83: loss=0.9828017950057983\n",
      "epoch 84: loss=1.0047589540481567\n",
      "epoch 85: loss=1.0230567455291748\n",
      "epoch 86: loss=1.0226836204528809\n",
      "epoch 87: loss=1.0154069662094116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88: loss=0.9948784112930298\n",
      "epoch 89: loss=1.0078822374343872\n",
      "epoch 90: loss=1.0126291513442993\n",
      "epoch 91: loss=0.99781733751297\n",
      "epoch 92: loss=0.9892934560775757\n",
      "epoch 93: loss=1.0313811302185059\n",
      "epoch 94: loss=0.9840373992919922\n",
      "epoch 95: loss=0.9648672342300415\n",
      "epoch 96: loss=0.9857882857322693\n",
      "epoch 97: loss=1.011049747467041\n",
      "epoch 98: loss=0.9984176158905029\n",
      "epoch 99: loss=0.9715820550918579\n",
      "epoch 100: loss=1.0331453084945679\n",
      "epoch 101: loss=0.9804840087890625\n",
      "epoch 102: loss=0.9761210680007935\n",
      "epoch 103: loss=0.9580686092376709\n",
      "epoch 104: loss=1.0315344333648682\n",
      "epoch 105: loss=0.9895340204238892\n",
      "epoch 106: loss=0.9950416088104248\n",
      "epoch 107: loss=0.9741066098213196\n",
      "epoch 108: loss=0.9944552779197693\n",
      "epoch 109: loss=1.0205062627792358\n",
      "epoch 110: loss=0.9904329776763916\n",
      "epoch 111: loss=0.9242121577262878\n",
      "epoch 112: loss=0.9939509034156799\n",
      "epoch 113: loss=0.9989476203918457\n",
      "epoch 114: loss=1.0128718614578247\n",
      "epoch 115: loss=1.0417871475219727\n",
      "epoch 116: loss=0.9803323745727539\n",
      "epoch 117: loss=0.9560040831565857\n",
      "epoch 118: loss=0.9926949739456177\n",
      "epoch 119: loss=0.9668465256690979\n",
      "epoch 120: loss=0.9871097803115845\n",
      "epoch 121: loss=0.9514130353927612\n",
      "epoch 122: loss=0.9895088076591492\n",
      "epoch 123: loss=0.990796685218811\n",
      "epoch 124: loss=0.9670605659484863\n",
      "epoch 125: loss=0.980151891708374\n",
      "epoch 126: loss=0.9725277423858643\n",
      "epoch 127: loss=0.9751927852630615\n",
      "epoch 128: loss=0.967046856880188\n",
      "epoch 129: loss=0.956649661064148\n",
      "epoch 130: loss=0.9541736245155334\n",
      "epoch 131: loss=0.9835121035575867\n",
      "epoch 132: loss=0.9743009209632874\n",
      "epoch 133: loss=0.9764053225517273\n",
      "epoch 134: loss=0.9548352956771851\n",
      "epoch 135: loss=0.9491013288497925\n",
      "epoch 136: loss=0.9662147760391235\n",
      "epoch 137: loss=0.9461519718170166\n",
      "epoch 138: loss=0.9774398803710938\n",
      "epoch 139: loss=0.946607232093811\n",
      "epoch 140: loss=0.9712260961532593\n",
      "epoch 141: loss=0.9550928473472595\n",
      "epoch 142: loss=0.9905062913894653\n",
      "epoch 143: loss=0.9696632623672485\n",
      "epoch 144: loss=0.972470760345459\n",
      "epoch 145: loss=0.9937120079994202\n",
      "epoch 146: loss=0.9357718229293823\n",
      "epoch 147: loss=0.9679089188575745\n",
      "epoch 148: loss=0.9893707036972046\n",
      "epoch 149: loss=0.9381083846092224\n",
      "epoch 150: loss=0.9598855376243591\n",
      "epoch 151: loss=0.974204421043396\n",
      "epoch 152: loss=0.9923057556152344\n",
      "epoch 153: loss=0.9569931626319885\n",
      "epoch 154: loss=0.9756601452827454\n",
      "epoch 155: loss=1.0072659254074097\n",
      "epoch 156: loss=0.92586350440979\n",
      "epoch 157: loss=0.9736485481262207\n",
      "epoch 158: loss=0.9607723951339722\n",
      "epoch 159: loss=0.9781283736228943\n",
      "epoch 160: loss=0.9642568230628967\n",
      "epoch 161: loss=0.9538779854774475\n",
      "epoch 162: loss=0.9441577196121216\n",
      "epoch 163: loss=0.9619622230529785\n",
      "epoch 164: loss=0.964974582195282\n",
      "epoch 165: loss=0.9171798825263977\n",
      "epoch 166: loss=0.9355334043502808\n",
      "epoch 167: loss=0.9586069583892822\n",
      "epoch 168: loss=0.9357751607894897\n",
      "epoch 169: loss=1.0072672367095947\n",
      "epoch 170: loss=0.9532462358474731\n",
      "epoch 171: loss=0.9470869302749634\n",
      "epoch 172: loss=0.9304627776145935\n",
      "epoch 173: loss=0.9679778814315796\n",
      "epoch 174: loss=0.9452124238014221\n",
      "epoch 175: loss=0.9429664015769958\n",
      "epoch 176: loss=0.9299973845481873\n",
      "epoch 177: loss=0.9501510858535767\n",
      "epoch 178: loss=0.9600709080696106\n",
      "epoch 179: loss=0.9623749852180481\n",
      "epoch 180: loss=0.9458783268928528\n",
      "epoch 181: loss=0.9579173922538757\n",
      "epoch 182: loss=0.9818499088287354\n",
      "epoch 183: loss=0.9600666761398315\n",
      "epoch 184: loss=0.953559935092926\n",
      "epoch 185: loss=0.9187939167022705\n",
      "epoch 186: loss=0.9482565522193909\n",
      "epoch 187: loss=0.9508838653564453\n",
      "epoch 188: loss=0.9596290588378906\n",
      "epoch 189: loss=0.9287366271018982\n",
      "epoch 190: loss=0.9154444336891174\n",
      "epoch 191: loss=0.9255132079124451\n",
      "epoch 192: loss=0.925211489200592\n",
      "epoch 193: loss=0.9464418292045593\n",
      "epoch 194: loss=0.9551345109939575\n",
      "epoch 195: loss=0.9465100765228271\n",
      "epoch 196: loss=0.9201998710632324\n",
      "epoch 197: loss=0.9424001574516296\n",
      "epoch 198: loss=0.9225690364837646\n",
      "epoch 199: loss=0.951696515083313\n",
      "training patch with 950 edges\n",
      "epoch 0: loss=3.720088005065918\n",
      "epoch 1: loss=3.4242069721221924\n",
      "epoch 2: loss=2.9949045181274414\n",
      "epoch 3: loss=3.1892824172973633\n",
      "epoch 4: loss=3.053675651550293\n",
      "epoch 5: loss=2.721151828765869\n",
      "epoch 6: loss=2.724055051803589\n",
      "epoch 7: loss=2.454516649246216\n",
      "epoch 8: loss=2.3765175342559814\n",
      "epoch 9: loss=2.1696505546569824\n",
      "epoch 10: loss=2.1373209953308105\n",
      "epoch 11: loss=2.0176079273223877\n",
      "epoch 12: loss=1.7911934852600098\n",
      "epoch 13: loss=1.7860162258148193\n",
      "epoch 14: loss=1.6856225728988647\n",
      "epoch 15: loss=1.5985532999038696\n",
      "epoch 16: loss=1.5418972969055176\n",
      "epoch 17: loss=1.5353819131851196\n",
      "epoch 18: loss=1.4753737449645996\n",
      "epoch 19: loss=1.4266629219055176\n",
      "epoch 20: loss=1.424772024154663\n",
      "epoch 21: loss=1.3807317018508911\n",
      "epoch 22: loss=1.3798249959945679\n",
      "epoch 23: loss=1.3779737949371338\n",
      "epoch 24: loss=1.3595985174179077\n",
      "epoch 25: loss=1.3633372783660889\n",
      "epoch 26: loss=1.3595082759857178\n",
      "epoch 27: loss=1.3480981588363647\n",
      "epoch 28: loss=1.3551390171051025\n",
      "epoch 29: loss=1.3420357704162598\n",
      "epoch 30: loss=1.3353091478347778\n",
      "epoch 31: loss=1.315834879875183\n",
      "epoch 32: loss=1.311255931854248\n",
      "epoch 33: loss=1.2955347299575806\n",
      "epoch 34: loss=1.29107666015625\n",
      "epoch 35: loss=1.274186372756958\n",
      "epoch 36: loss=1.2513296604156494\n",
      "epoch 37: loss=1.2430148124694824\n",
      "epoch 38: loss=1.2056654691696167\n",
      "epoch 39: loss=1.1885229349136353\n",
      "epoch 40: loss=1.1610982418060303\n",
      "epoch 41: loss=1.144195556640625\n",
      "epoch 42: loss=1.1599907875061035\n",
      "epoch 43: loss=1.129099726676941\n",
      "epoch 44: loss=1.1198087930679321\n",
      "epoch 45: loss=1.1230905055999756\n",
      "epoch 46: loss=1.0987672805786133\n",
      "epoch 47: loss=1.127203345298767\n",
      "epoch 48: loss=1.1208312511444092\n",
      "epoch 49: loss=1.1165748834609985\n",
      "epoch 50: loss=1.0815304517745972\n",
      "epoch 51: loss=1.0767369270324707\n",
      "epoch 52: loss=1.0777963399887085\n",
      "epoch 53: loss=1.078701376914978\n",
      "epoch 54: loss=1.0336506366729736\n",
      "epoch 55: loss=1.0460160970687866\n",
      "epoch 56: loss=1.0398342609405518\n",
      "epoch 57: loss=1.0259578227996826\n",
      "epoch 58: loss=1.0565012693405151\n",
      "epoch 59: loss=1.0543886423110962\n",
      "epoch 60: loss=1.0427738428115845\n",
      "epoch 61: loss=1.0552228689193726\n",
      "epoch 62: loss=1.0270384550094604\n",
      "epoch 63: loss=1.0498268604278564\n",
      "epoch 64: loss=1.0442723035812378\n",
      "epoch 65: loss=1.0406830310821533\n",
      "epoch 66: loss=1.0188250541687012\n",
      "epoch 67: loss=1.0075225830078125\n",
      "epoch 68: loss=1.0181092023849487\n",
      "epoch 69: loss=1.0190054178237915\n",
      "epoch 70: loss=0.9726977944374084\n",
      "epoch 71: loss=1.0253732204437256\n",
      "epoch 72: loss=1.0198113918304443\n",
      "epoch 73: loss=1.0322356224060059\n",
      "epoch 74: loss=0.9957101345062256\n",
      "epoch 75: loss=0.97525554895401\n",
      "epoch 76: loss=0.9930475354194641\n",
      "epoch 77: loss=0.9853656888008118\n",
      "epoch 78: loss=1.0055820941925049\n",
      "epoch 79: loss=1.0028996467590332\n",
      "epoch 80: loss=0.9640154242515564\n",
      "epoch 81: loss=1.0068111419677734\n",
      "epoch 82: loss=0.9879540801048279\n",
      "epoch 83: loss=0.9909254908561707\n",
      "epoch 84: loss=0.9999110102653503\n",
      "epoch 85: loss=0.9983118772506714\n",
      "epoch 86: loss=0.9939202666282654\n",
      "epoch 87: loss=1.0285801887512207\n",
      "epoch 88: loss=0.9667068123817444\n",
      "epoch 89: loss=0.9717665910720825\n",
      "epoch 90: loss=0.9646135568618774\n",
      "epoch 91: loss=0.9528425931930542\n",
      "epoch 92: loss=0.997522234916687\n",
      "epoch 93: loss=0.9441702961921692\n",
      "epoch 94: loss=0.9658132791519165\n",
      "epoch 95: loss=0.9770713448524475\n",
      "epoch 96: loss=0.9159313440322876\n",
      "epoch 97: loss=0.966745138168335\n",
      "epoch 98: loss=0.9449214935302734\n",
      "epoch 99: loss=0.9569658637046814\n",
      "epoch 100: loss=0.9616532921791077\n",
      "epoch 101: loss=0.948021411895752\n",
      "epoch 102: loss=0.9522271752357483\n",
      "epoch 103: loss=0.9719632267951965\n",
      "epoch 104: loss=0.9543818831443787\n",
      "epoch 105: loss=0.947461724281311\n",
      "epoch 106: loss=0.9602692723274231\n",
      "epoch 107: loss=0.9636741876602173\n",
      "epoch 108: loss=0.9828956127166748\n",
      "epoch 109: loss=0.9877055883407593\n",
      "epoch 110: loss=0.9246902465820312\n",
      "epoch 111: loss=0.9216275215148926\n",
      "epoch 112: loss=0.9597049951553345\n",
      "epoch 113: loss=0.9315366148948669\n",
      "epoch 114: loss=0.962670087814331\n",
      "epoch 115: loss=0.919366717338562\n",
      "epoch 116: loss=0.939448893070221\n",
      "epoch 117: loss=0.9799352884292603\n",
      "epoch 118: loss=0.9833921194076538\n",
      "epoch 119: loss=0.9788572788238525\n",
      "epoch 120: loss=0.9343392252922058\n",
      "epoch 121: loss=0.9732835292816162\n",
      "epoch 122: loss=0.9503510594367981\n",
      "epoch 123: loss=0.9414160847663879\n",
      "epoch 124: loss=0.9400709867477417\n",
      "epoch 125: loss=0.9555274844169617\n",
      "epoch 126: loss=0.9461398720741272\n",
      "epoch 127: loss=0.9434688091278076\n",
      "epoch 128: loss=0.9501656293869019\n",
      "epoch 129: loss=0.9431576728820801\n",
      "epoch 130: loss=0.9693925380706787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131: loss=0.9358357787132263\n",
      "epoch 132: loss=0.9083746075630188\n",
      "epoch 133: loss=0.9393647909164429\n",
      "epoch 134: loss=0.9828271865844727\n",
      "epoch 135: loss=0.9299856424331665\n",
      "epoch 136: loss=0.9210565686225891\n",
      "epoch 137: loss=0.9823822975158691\n",
      "epoch 138: loss=0.9379072785377502\n",
      "epoch 139: loss=0.9433542490005493\n",
      "epoch 140: loss=0.945783257484436\n",
      "epoch 141: loss=0.94046550989151\n",
      "epoch 142: loss=0.9406839609146118\n",
      "epoch 143: loss=0.912475049495697\n",
      "epoch 144: loss=0.9713327884674072\n",
      "epoch 145: loss=0.9788255095481873\n",
      "epoch 146: loss=0.9429653882980347\n",
      "epoch 147: loss=0.965003252029419\n",
      "epoch 148: loss=0.9321985840797424\n",
      "epoch 149: loss=0.9376527070999146\n",
      "epoch 150: loss=0.9492974281311035\n",
      "epoch 151: loss=0.9441171288490295\n",
      "epoch 152: loss=0.9362340569496155\n",
      "epoch 153: loss=0.9390416145324707\n",
      "epoch 154: loss=0.9555574059486389\n",
      "epoch 155: loss=0.9301636219024658\n",
      "epoch 156: loss=0.9392398595809937\n",
      "epoch 157: loss=0.9615236520767212\n",
      "epoch 158: loss=0.9406017065048218\n",
      "epoch 159: loss=0.939686119556427\n",
      "epoch 160: loss=0.9336374402046204\n",
      "epoch 161: loss=0.9737526774406433\n",
      "epoch 162: loss=0.9154404997825623\n",
      "epoch 163: loss=0.9427534341812134\n",
      "epoch 164: loss=0.9708813428878784\n",
      "epoch 165: loss=0.9124937057495117\n",
      "epoch 166: loss=0.926121711730957\n",
      "epoch 167: loss=0.9418291449546814\n",
      "epoch 168: loss=0.9073079824447632\n",
      "epoch 169: loss=0.9163763523101807\n",
      "epoch 170: loss=0.9004288911819458\n",
      "epoch 171: loss=0.9259568452835083\n",
      "epoch 172: loss=0.9470634460449219\n",
      "epoch 173: loss=0.9745048880577087\n",
      "epoch 174: loss=0.9313663244247437\n",
      "epoch 175: loss=0.9727014303207397\n",
      "epoch 176: loss=0.9232643842697144\n",
      "epoch 177: loss=0.9102504849433899\n",
      "epoch 178: loss=0.9222095012664795\n",
      "epoch 179: loss=0.9427306056022644\n",
      "epoch 180: loss=0.9207425713539124\n",
      "epoch 181: loss=0.9141459465026855\n",
      "epoch 182: loss=0.9254229068756104\n",
      "epoch 183: loss=0.921425998210907\n",
      "epoch 184: loss=0.9195369482040405\n",
      "epoch 185: loss=0.9209727048873901\n",
      "epoch 186: loss=0.9242781400680542\n",
      "epoch 187: loss=0.9529016017913818\n",
      "epoch 188: loss=0.9195836186408997\n",
      "epoch 189: loss=0.9030440449714661\n",
      "epoch 190: loss=0.9163388609886169\n",
      "epoch 191: loss=0.9193187355995178\n",
      "epoch 192: loss=0.9192104935646057\n",
      "epoch 193: loss=0.9106619954109192\n",
      "epoch 194: loss=0.93231600522995\n",
      "epoch 195: loss=0.9230570793151855\n",
      "epoch 196: loss=0.9115390777587891\n",
      "epoch 197: loss=0.926246166229248\n",
      "epoch 198: loss=0.9153750538825989\n",
      "epoch 199: loss=0.9238641858100891\n",
      "training patch with 2922 edges\n",
      "epoch 0: loss=3.4523773193359375\n",
      "epoch 1: loss=3.1950366497039795\n",
      "epoch 2: loss=3.0912556648254395\n",
      "epoch 3: loss=3.0128369331359863\n",
      "epoch 4: loss=2.667686939239502\n",
      "epoch 5: loss=2.7222628593444824\n",
      "epoch 6: loss=2.5797977447509766\n",
      "epoch 7: loss=2.332075357437134\n",
      "epoch 8: loss=2.292893648147583\n",
      "epoch 9: loss=2.114655017852783\n",
      "epoch 10: loss=1.9933980703353882\n",
      "epoch 11: loss=1.8529117107391357\n",
      "epoch 12: loss=1.738155484199524\n",
      "epoch 13: loss=1.6770122051239014\n",
      "epoch 14: loss=1.5669625997543335\n",
      "epoch 15: loss=1.546241283416748\n",
      "epoch 16: loss=1.4652942419052124\n",
      "epoch 17: loss=1.4317504167556763\n",
      "epoch 18: loss=1.4151312112808228\n",
      "epoch 19: loss=1.410933017730713\n",
      "epoch 20: loss=1.3675203323364258\n",
      "epoch 21: loss=1.3748650550842285\n",
      "epoch 22: loss=1.3536264896392822\n",
      "epoch 23: loss=1.3380126953125\n",
      "epoch 24: loss=1.3387922048568726\n",
      "epoch 25: loss=1.3204904794692993\n",
      "epoch 26: loss=1.3135838508605957\n",
      "epoch 27: loss=1.3134703636169434\n",
      "epoch 28: loss=1.307381272315979\n",
      "epoch 29: loss=1.2973442077636719\n",
      "epoch 30: loss=1.2890191078186035\n",
      "epoch 31: loss=1.280285120010376\n",
      "epoch 32: loss=1.2640423774719238\n",
      "epoch 33: loss=1.254956603050232\n",
      "epoch 34: loss=1.246091365814209\n",
      "epoch 35: loss=1.2299063205718994\n",
      "epoch 36: loss=1.2219250202178955\n",
      "epoch 37: loss=1.2077316045761108\n",
      "epoch 38: loss=1.1945444345474243\n",
      "epoch 39: loss=1.1745513677597046\n",
      "epoch 40: loss=1.1536720991134644\n",
      "epoch 41: loss=1.1268281936645508\n",
      "epoch 42: loss=1.09880793094635\n",
      "epoch 43: loss=1.0739446878433228\n",
      "epoch 44: loss=1.0710457563400269\n",
      "epoch 45: loss=1.0440869331359863\n",
      "epoch 46: loss=1.0461647510528564\n",
      "epoch 47: loss=1.0218346118927002\n",
      "epoch 48: loss=1.0009065866470337\n",
      "epoch 49: loss=1.0039194822311401\n",
      "epoch 50: loss=1.0150048732757568\n",
      "epoch 51: loss=1.0338224172592163\n",
      "epoch 52: loss=0.9963698983192444\n",
      "epoch 53: loss=0.9922876954078674\n",
      "epoch 54: loss=0.9912975430488586\n",
      "epoch 55: loss=1.0001153945922852\n",
      "epoch 56: loss=0.9992014169692993\n",
      "epoch 57: loss=0.9670637845993042\n",
      "epoch 58: loss=0.952573299407959\n",
      "epoch 59: loss=0.960896909236908\n",
      "epoch 60: loss=0.9709210395812988\n",
      "epoch 61: loss=0.9600908160209656\n",
      "epoch 62: loss=0.9481905102729797\n",
      "epoch 63: loss=0.9438998103141785\n",
      "epoch 64: loss=0.9280093908309937\n",
      "epoch 65: loss=0.9464144110679626\n",
      "epoch 66: loss=0.9411914944648743\n",
      "epoch 67: loss=0.9238727688789368\n",
      "epoch 68: loss=0.9448968172073364\n",
      "epoch 69: loss=0.9270161986351013\n",
      "epoch 70: loss=0.9276123046875\n",
      "epoch 71: loss=0.9274305105209351\n",
      "epoch 72: loss=0.907357394695282\n",
      "epoch 73: loss=0.9155724048614502\n",
      "epoch 74: loss=0.917848527431488\n",
      "epoch 75: loss=0.9104006290435791\n",
      "epoch 76: loss=0.9206013083457947\n",
      "epoch 77: loss=0.9087169170379639\n",
      "epoch 78: loss=0.9084385633468628\n",
      "epoch 79: loss=0.9105056524276733\n",
      "epoch 80: loss=0.9111789464950562\n",
      "epoch 81: loss=0.8965801000595093\n",
      "epoch 82: loss=0.9179202318191528\n",
      "epoch 83: loss=0.8978090286254883\n",
      "epoch 84: loss=0.9142560362815857\n",
      "epoch 85: loss=0.9002030491828918\n",
      "epoch 86: loss=0.881864607334137\n",
      "epoch 87: loss=0.9032958149909973\n",
      "epoch 88: loss=0.9107990264892578\n",
      "epoch 89: loss=0.8795381188392639\n",
      "epoch 90: loss=0.8931493163108826\n",
      "epoch 91: loss=0.9218135476112366\n",
      "epoch 92: loss=0.927722692489624\n",
      "epoch 93: loss=0.8778560161590576\n",
      "epoch 94: loss=0.908911406993866\n",
      "epoch 95: loss=0.8888127207756042\n",
      "epoch 96: loss=0.9054445028305054\n",
      "epoch 97: loss=0.9102166891098022\n",
      "epoch 98: loss=0.8838571906089783\n",
      "epoch 99: loss=0.906440258026123\n",
      "epoch 100: loss=0.9088501930236816\n",
      "epoch 101: loss=0.9015316963195801\n",
      "epoch 102: loss=0.8866817951202393\n",
      "epoch 103: loss=0.8967251777648926\n",
      "epoch 104: loss=0.8996862769126892\n",
      "epoch 105: loss=0.8994665741920471\n",
      "epoch 106: loss=0.883110761642456\n",
      "epoch 107: loss=0.8901975154876709\n",
      "epoch 108: loss=0.8883476257324219\n",
      "epoch 109: loss=0.8867821097373962\n",
      "epoch 110: loss=0.8870560526847839\n",
      "epoch 111: loss=0.8776531219482422\n",
      "epoch 112: loss=0.8875083327293396\n",
      "epoch 113: loss=0.8680763244628906\n",
      "epoch 114: loss=0.8849694132804871\n",
      "epoch 115: loss=0.8982427716255188\n",
      "epoch 116: loss=0.8927461504936218\n",
      "epoch 117: loss=0.8724853992462158\n",
      "epoch 118: loss=0.8915258049964905\n",
      "epoch 119: loss=0.8878988027572632\n",
      "epoch 120: loss=0.8744521141052246\n",
      "epoch 121: loss=0.8791443705558777\n",
      "epoch 122: loss=0.8751750588417053\n",
      "epoch 123: loss=0.8881092071533203\n",
      "epoch 124: loss=0.8962379693984985\n",
      "epoch 125: loss=0.9008705019950867\n",
      "epoch 126: loss=0.8896886110305786\n",
      "epoch 127: loss=0.8775140047073364\n",
      "epoch 128: loss=0.8785363435745239\n",
      "epoch 129: loss=0.8885155320167542\n",
      "epoch 130: loss=0.8775401711463928\n",
      "epoch 131: loss=0.8781517744064331\n",
      "epoch 132: loss=0.8734725117683411\n",
      "epoch 133: loss=0.8827401995658875\n",
      "epoch 134: loss=0.8729658722877502\n",
      "epoch 135: loss=0.8831705451011658\n",
      "epoch 136: loss=0.8843591213226318\n",
      "epoch 137: loss=0.8823997378349304\n",
      "epoch 138: loss=0.8642891049385071\n",
      "epoch 139: loss=0.8824760317802429\n",
      "epoch 140: loss=0.8706378936767578\n",
      "epoch 141: loss=0.8647192120552063\n",
      "epoch 142: loss=0.8667968511581421\n",
      "epoch 143: loss=0.8505420088768005\n",
      "epoch 144: loss=0.8768508434295654\n",
      "epoch 145: loss=0.8690089583396912\n",
      "epoch 146: loss=0.8809623718261719\n",
      "epoch 147: loss=0.8813697099685669\n",
      "epoch 148: loss=0.8665628433227539\n",
      "epoch 149: loss=0.8760246634483337\n",
      "epoch 150: loss=0.8735442161560059\n",
      "epoch 151: loss=0.8691794276237488\n",
      "epoch 152: loss=0.8732461929321289\n",
      "epoch 153: loss=0.8834874033927917\n",
      "epoch 154: loss=0.8522564768791199\n",
      "epoch 155: loss=0.873424768447876\n",
      "epoch 156: loss=0.8696455359458923\n",
      "epoch 157: loss=0.8982119560241699\n",
      "epoch 158: loss=0.8687310218811035\n",
      "epoch 159: loss=0.8574262261390686\n",
      "epoch 160: loss=0.8543925881385803\n",
      "epoch 161: loss=0.8671099543571472\n",
      "epoch 162: loss=0.8642209768295288\n",
      "epoch 163: loss=0.8545010685920715\n",
      "epoch 164: loss=0.8603818416595459\n",
      "epoch 165: loss=0.8382480144500732\n",
      "epoch 166: loss=0.871432900428772\n",
      "epoch 167: loss=0.8615387678146362\n",
      "epoch 168: loss=0.8544341921806335\n",
      "epoch 169: loss=0.8576498627662659\n",
      "epoch 170: loss=0.8595795035362244\n",
      "epoch 171: loss=0.8649378418922424\n",
      "epoch 172: loss=0.8611083030700684\n",
      "epoch 173: loss=0.858927845954895\n",
      "epoch 174: loss=0.856814980506897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 175: loss=0.8634317517280579\n",
      "epoch 176: loss=0.8765566945075989\n",
      "epoch 177: loss=0.8672898411750793\n",
      "epoch 178: loss=0.8694071173667908\n",
      "epoch 179: loss=0.8726522922515869\n",
      "epoch 180: loss=0.8513546586036682\n",
      "epoch 181: loss=0.8517888784408569\n",
      "epoch 182: loss=0.8653855323791504\n",
      "epoch 183: loss=0.8687834739685059\n",
      "epoch 184: loss=0.8562811017036438\n",
      "epoch 185: loss=0.8387676477432251\n",
      "epoch 186: loss=0.8500394225120544\n",
      "epoch 187: loss=0.8612136840820312\n",
      "epoch 188: loss=0.8656240701675415\n",
      "epoch 189: loss=0.865398645401001\n",
      "epoch 190: loss=0.8471773266792297\n",
      "epoch 191: loss=0.8508503437042236\n",
      "epoch 192: loss=0.8721508979797363\n",
      "epoch 193: loss=0.8419848084449768\n",
      "epoch 194: loss=0.8584167957305908\n",
      "epoch 195: loss=0.8406509757041931\n",
      "epoch 196: loss=0.8601792454719543\n",
      "epoch 197: loss=0.8502452373504639\n",
      "epoch 198: loss=0.8550387024879456\n",
      "epoch 199: loss=0.8427844047546387\n",
      "training patch with 1698 edges\n",
      "epoch 0: loss=3.3845043182373047\n",
      "epoch 1: loss=3.3330328464508057\n",
      "epoch 2: loss=3.203937292098999\n",
      "epoch 3: loss=3.2136874198913574\n",
      "epoch 4: loss=2.985956907272339\n",
      "epoch 5: loss=2.8394827842712402\n",
      "epoch 6: loss=2.667470932006836\n",
      "epoch 7: loss=2.557800054550171\n",
      "epoch 8: loss=2.3827781677246094\n",
      "epoch 9: loss=2.2766530513763428\n",
      "epoch 10: loss=2.164379119873047\n",
      "epoch 11: loss=1.999236822128296\n",
      "epoch 12: loss=1.8780277967453003\n",
      "epoch 13: loss=1.756054401397705\n",
      "epoch 14: loss=1.6878963708877563\n",
      "epoch 15: loss=1.633486032485962\n",
      "epoch 16: loss=1.5655988454818726\n",
      "epoch 17: loss=1.5188242197036743\n",
      "epoch 18: loss=1.468002438545227\n",
      "epoch 19: loss=1.4695580005645752\n",
      "epoch 20: loss=1.4483753442764282\n",
      "epoch 21: loss=1.4403146505355835\n",
      "epoch 22: loss=1.4046963453292847\n",
      "epoch 23: loss=1.4150612354278564\n",
      "epoch 24: loss=1.4204996824264526\n",
      "epoch 25: loss=1.4038485288619995\n",
      "epoch 26: loss=1.3880650997161865\n",
      "epoch 27: loss=1.390955924987793\n",
      "epoch 28: loss=1.381339192390442\n",
      "epoch 29: loss=1.3744927644729614\n",
      "epoch 30: loss=1.3723487854003906\n",
      "epoch 31: loss=1.3670175075531006\n",
      "epoch 32: loss=1.3576740026474\n",
      "epoch 33: loss=1.3588733673095703\n",
      "epoch 34: loss=1.343519926071167\n",
      "epoch 35: loss=1.3442022800445557\n",
      "epoch 36: loss=1.3275996446609497\n",
      "epoch 37: loss=1.3239465951919556\n",
      "epoch 38: loss=1.3041231632232666\n",
      "epoch 39: loss=1.2979261875152588\n",
      "epoch 40: loss=1.2850109338760376\n",
      "epoch 41: loss=1.2710574865341187\n",
      "epoch 42: loss=1.2486393451690674\n",
      "epoch 43: loss=1.223138689994812\n",
      "epoch 44: loss=1.210464358329773\n",
      "epoch 45: loss=1.184903860092163\n",
      "epoch 46: loss=1.1616750955581665\n",
      "epoch 47: loss=1.1489988565444946\n",
      "epoch 48: loss=1.1028530597686768\n",
      "epoch 49: loss=1.0787500143051147\n",
      "epoch 50: loss=1.070955514907837\n",
      "epoch 51: loss=1.0773286819458008\n",
      "epoch 52: loss=1.079010248184204\n",
      "epoch 53: loss=1.0554945468902588\n",
      "epoch 54: loss=1.0528680086135864\n",
      "epoch 55: loss=1.0518443584442139\n",
      "epoch 56: loss=1.049605131149292\n",
      "epoch 57: loss=1.0265573263168335\n",
      "epoch 58: loss=1.0311999320983887\n",
      "epoch 59: loss=1.0181708335876465\n",
      "epoch 60: loss=1.036728024482727\n",
      "epoch 61: loss=1.0069880485534668\n",
      "epoch 62: loss=0.9936696290969849\n",
      "epoch 63: loss=1.0211808681488037\n",
      "epoch 64: loss=0.9872683882713318\n",
      "epoch 65: loss=0.9896554946899414\n",
      "epoch 66: loss=0.9658364057540894\n",
      "epoch 67: loss=0.9992790818214417\n",
      "epoch 68: loss=0.9873321652412415\n",
      "epoch 69: loss=0.9626642465591431\n",
      "epoch 70: loss=1.008861780166626\n",
      "epoch 71: loss=0.9848275780677795\n",
      "epoch 72: loss=0.9930534362792969\n",
      "epoch 73: loss=0.9620151519775391\n",
      "epoch 74: loss=0.9775109887123108\n",
      "epoch 75: loss=0.976719319820404\n",
      "epoch 76: loss=0.967105507850647\n",
      "epoch 77: loss=0.9933866858482361\n",
      "epoch 78: loss=0.962306559085846\n",
      "epoch 79: loss=0.9719086289405823\n",
      "epoch 80: loss=0.9587583541870117\n",
      "epoch 81: loss=0.9861243367195129\n",
      "epoch 82: loss=0.9563027620315552\n",
      "epoch 83: loss=0.946063220500946\n",
      "epoch 84: loss=0.94976407289505\n",
      "epoch 85: loss=0.9655176401138306\n",
      "epoch 86: loss=0.9436783790588379\n",
      "epoch 87: loss=0.9421018362045288\n",
      "epoch 88: loss=0.9462724328041077\n",
      "epoch 89: loss=0.9412199258804321\n",
      "epoch 90: loss=0.9418526887893677\n",
      "epoch 91: loss=0.956363320350647\n",
      "epoch 92: loss=0.9471127390861511\n",
      "epoch 93: loss=0.9752973318099976\n",
      "epoch 94: loss=0.9550948739051819\n",
      "epoch 95: loss=0.9519416689872742\n",
      "epoch 96: loss=0.9352091550827026\n",
      "epoch 97: loss=0.943560004234314\n",
      "epoch 98: loss=0.9617255926132202\n",
      "epoch 99: loss=0.9605607390403748\n",
      "epoch 100: loss=0.9273827075958252\n",
      "epoch 101: loss=0.9274914860725403\n",
      "epoch 102: loss=0.9478588700294495\n",
      "epoch 103: loss=0.9267224669456482\n",
      "epoch 104: loss=0.9426817893981934\n",
      "epoch 105: loss=0.9372886419296265\n",
      "epoch 106: loss=0.9432194828987122\n",
      "epoch 107: loss=0.9298844933509827\n",
      "epoch 108: loss=0.9200819730758667\n",
      "epoch 109: loss=0.9175432920455933\n",
      "epoch 110: loss=0.9568807482719421\n",
      "epoch 111: loss=0.9574268460273743\n",
      "epoch 112: loss=0.944449782371521\n",
      "epoch 113: loss=0.9466191530227661\n",
      "epoch 114: loss=0.9361390471458435\n",
      "epoch 115: loss=0.9366089701652527\n",
      "epoch 116: loss=0.937920093536377\n",
      "epoch 117: loss=0.9150133728981018\n",
      "epoch 118: loss=0.9261904358863831\n",
      "epoch 119: loss=0.9723995923995972\n",
      "epoch 120: loss=0.9105368852615356\n",
      "epoch 121: loss=0.9056267738342285\n",
      "epoch 122: loss=0.9314734935760498\n",
      "epoch 123: loss=0.9082149267196655\n",
      "epoch 124: loss=0.9228892922401428\n",
      "epoch 125: loss=0.9152582883834839\n",
      "epoch 126: loss=0.9401010274887085\n",
      "epoch 127: loss=0.9194003939628601\n",
      "epoch 128: loss=0.9306612610816956\n",
      "epoch 129: loss=0.9245445728302002\n",
      "epoch 130: loss=0.9198428988456726\n",
      "epoch 131: loss=0.9210991859436035\n",
      "epoch 132: loss=0.9189140200614929\n",
      "epoch 133: loss=0.9102059602737427\n",
      "epoch 134: loss=0.9228295087814331\n",
      "epoch 135: loss=0.9066253304481506\n",
      "epoch 136: loss=0.9307287335395813\n",
      "epoch 137: loss=0.9155241250991821\n",
      "epoch 138: loss=0.9185187816619873\n",
      "epoch 139: loss=0.9214447736740112\n",
      "epoch 140: loss=0.9125669598579407\n",
      "epoch 141: loss=0.9164322018623352\n",
      "epoch 142: loss=0.9084284901618958\n",
      "epoch 143: loss=0.9039722681045532\n",
      "epoch 144: loss=0.9060738682746887\n",
      "epoch 145: loss=0.9000371098518372\n",
      "epoch 146: loss=0.915618896484375\n",
      "epoch 147: loss=0.9018637537956238\n",
      "epoch 148: loss=0.9473122954368591\n",
      "epoch 149: loss=0.906710147857666\n",
      "epoch 150: loss=0.907942533493042\n",
      "epoch 151: loss=0.8770564794540405\n",
      "epoch 152: loss=0.9075669050216675\n",
      "epoch 153: loss=0.9192492961883545\n",
      "epoch 154: loss=0.9007821679115295\n",
      "epoch 155: loss=0.904069185256958\n",
      "epoch 156: loss=0.8905391693115234\n",
      "epoch 157: loss=0.8902055621147156\n",
      "epoch 158: loss=0.8778917789459229\n",
      "epoch 159: loss=0.9270160794258118\n",
      "epoch 160: loss=0.9010133743286133\n",
      "epoch 161: loss=0.9031587839126587\n",
      "epoch 162: loss=0.8883328437805176\n",
      "epoch 163: loss=0.8886236548423767\n",
      "epoch 164: loss=0.914334237575531\n",
      "epoch 165: loss=0.8878377079963684\n",
      "epoch 166: loss=0.9120631814002991\n",
      "epoch 167: loss=0.888524055480957\n",
      "epoch 168: loss=0.8814191222190857\n",
      "epoch 169: loss=0.8998568058013916\n",
      "epoch 170: loss=0.875154972076416\n",
      "epoch 171: loss=0.8950310945510864\n",
      "epoch 172: loss=0.9016425609588623\n",
      "epoch 173: loss=0.8883970975875854\n",
      "epoch 174: loss=0.8789466023445129\n",
      "epoch 175: loss=0.8934638500213623\n",
      "epoch 176: loss=0.8857954740524292\n",
      "epoch 177: loss=0.9160268306732178\n",
      "epoch 178: loss=0.8856291174888611\n",
      "epoch 179: loss=0.9053133130073547\n",
      "epoch 180: loss=0.89698725938797\n",
      "epoch 181: loss=0.8914910554885864\n",
      "epoch 182: loss=0.8822669982910156\n",
      "epoch 183: loss=0.8880866169929504\n",
      "epoch 184: loss=0.8974703550338745\n",
      "epoch 185: loss=0.8781262040138245\n",
      "epoch 186: loss=0.8833980560302734\n",
      "epoch 187: loss=0.8958099484443665\n",
      "epoch 188: loss=0.9137601852416992\n",
      "epoch 189: loss=0.8794069290161133\n",
      "epoch 190: loss=0.8924604058265686\n",
      "epoch 191: loss=0.8705538511276245\n",
      "epoch 192: loss=0.8898070454597473\n",
      "epoch 193: loss=0.9076729416847229\n",
      "epoch 194: loss=0.9051994681358337\n",
      "epoch 195: loss=0.8996227979660034\n",
      "epoch 196: loss=0.8612483143806458\n",
      "epoch 197: loss=0.881289005279541\n",
      "epoch 198: loss=0.8919193148612976\n",
      "epoch 199: loss=0.9026484489440918\n",
      "training patch with 670 edges\n",
      "epoch 0: loss=3.4607720375061035\n",
      "epoch 1: loss=3.448460578918457\n",
      "epoch 2: loss=3.081422805786133\n",
      "epoch 3: loss=3.1376285552978516\n",
      "epoch 4: loss=3.1986076831817627\n",
      "epoch 5: loss=2.4946234226226807\n",
      "epoch 6: loss=2.6203994750976562\n",
      "epoch 7: loss=2.3370065689086914\n",
      "epoch 8: loss=2.324877977371216\n",
      "epoch 9: loss=2.1469826698303223\n",
      "epoch 10: loss=2.033752918243408\n",
      "epoch 11: loss=1.8623461723327637\n",
      "epoch 12: loss=1.768913984298706\n",
      "epoch 13: loss=1.6429204940795898\n",
      "epoch 14: loss=1.6572502851486206\n",
      "epoch 15: loss=1.5601881742477417\n",
      "epoch 16: loss=1.5509907007217407\n",
      "epoch 17: loss=1.5077569484710693\n",
      "epoch 18: loss=1.4732741117477417\n",
      "epoch 19: loss=1.4386407136917114\n",
      "epoch 20: loss=1.4435992240905762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: loss=1.4371616840362549\n",
      "epoch 22: loss=1.4488859176635742\n",
      "epoch 23: loss=1.4336459636688232\n",
      "epoch 24: loss=1.4505287408828735\n",
      "epoch 25: loss=1.4154404401779175\n",
      "epoch 26: loss=1.4132190942764282\n",
      "epoch 27: loss=1.4096519947052002\n",
      "epoch 28: loss=1.4221515655517578\n",
      "epoch 29: loss=1.4078532457351685\n",
      "epoch 30: loss=1.4255715608596802\n",
      "epoch 31: loss=1.4043607711791992\n",
      "epoch 32: loss=1.3828818798065186\n",
      "epoch 33: loss=1.391711711883545\n",
      "epoch 34: loss=1.3850125074386597\n",
      "epoch 35: loss=1.369911789894104\n",
      "epoch 36: loss=1.3540253639221191\n",
      "epoch 37: loss=1.3394463062286377\n",
      "epoch 38: loss=1.3230946063995361\n",
      "epoch 39: loss=1.3032304048538208\n",
      "epoch 40: loss=1.292325735092163\n",
      "epoch 41: loss=1.2697557210922241\n",
      "epoch 42: loss=1.2369308471679688\n",
      "epoch 43: loss=1.210784673690796\n",
      "epoch 44: loss=1.1722438335418701\n",
      "epoch 45: loss=1.1507166624069214\n",
      "epoch 46: loss=1.131935477256775\n",
      "epoch 47: loss=1.1265732049942017\n",
      "epoch 48: loss=1.159786581993103\n",
      "epoch 49: loss=1.12692391872406\n",
      "epoch 50: loss=1.106581211090088\n",
      "epoch 51: loss=1.1065651178359985\n",
      "epoch 52: loss=1.0732429027557373\n",
      "epoch 53: loss=1.0595921277999878\n",
      "epoch 54: loss=1.0771567821502686\n",
      "epoch 55: loss=1.0311585664749146\n",
      "epoch 56: loss=1.1165677309036255\n",
      "epoch 57: loss=1.047583818435669\n",
      "epoch 58: loss=1.0581921339035034\n",
      "epoch 59: loss=1.0308579206466675\n",
      "epoch 60: loss=1.078382968902588\n",
      "epoch 61: loss=1.0580607652664185\n",
      "epoch 62: loss=0.9860017895698547\n",
      "epoch 63: loss=0.9898281693458557\n",
      "epoch 64: loss=1.031965970993042\n",
      "epoch 65: loss=1.0095914602279663\n",
      "epoch 66: loss=1.0257360935211182\n",
      "epoch 67: loss=0.9986728429794312\n",
      "epoch 68: loss=1.003719449043274\n",
      "epoch 69: loss=1.049454927444458\n",
      "epoch 70: loss=0.9920082688331604\n",
      "epoch 71: loss=1.0110535621643066\n",
      "epoch 72: loss=1.0476785898208618\n",
      "epoch 73: loss=1.03730309009552\n",
      "epoch 74: loss=1.0562105178833008\n",
      "epoch 75: loss=1.036976933479309\n",
      "epoch 76: loss=1.0544044971466064\n",
      "epoch 77: loss=1.0189118385314941\n",
      "epoch 78: loss=0.9944636821746826\n",
      "epoch 79: loss=1.006780982017517\n",
      "epoch 80: loss=0.9910446405410767\n",
      "epoch 81: loss=0.9521195888519287\n",
      "epoch 82: loss=1.0635614395141602\n",
      "epoch 83: loss=1.0197347402572632\n",
      "epoch 84: loss=0.9956848621368408\n",
      "epoch 85: loss=0.9468751549720764\n",
      "epoch 86: loss=0.9717753529548645\n",
      "epoch 87: loss=0.9887090921401978\n",
      "epoch 88: loss=0.9924233555793762\n",
      "epoch 89: loss=1.036331057548523\n",
      "epoch 90: loss=0.9868021011352539\n",
      "epoch 91: loss=0.997770369052887\n",
      "epoch 92: loss=1.0145652294158936\n",
      "epoch 93: loss=0.9837895035743713\n",
      "epoch 94: loss=1.006939172744751\n",
      "epoch 95: loss=0.9762481451034546\n",
      "epoch 96: loss=0.9898269176483154\n",
      "epoch 97: loss=0.9896520376205444\n",
      "epoch 98: loss=0.9944533109664917\n",
      "epoch 99: loss=0.9761424660682678\n",
      "epoch 100: loss=1.02035391330719\n",
      "epoch 101: loss=0.9534177184104919\n",
      "epoch 102: loss=0.962683916091919\n",
      "epoch 103: loss=0.9167009592056274\n",
      "epoch 104: loss=0.9525030255317688\n",
      "epoch 105: loss=0.9936673641204834\n",
      "epoch 106: loss=1.0197985172271729\n",
      "epoch 107: loss=0.9719465970993042\n",
      "epoch 108: loss=1.0018409490585327\n",
      "epoch 109: loss=0.9942551255226135\n",
      "epoch 110: loss=0.9577130079269409\n",
      "epoch 111: loss=1.031998872756958\n",
      "epoch 112: loss=0.9854040145874023\n",
      "epoch 113: loss=0.9457009434700012\n",
      "epoch 114: loss=0.9913675785064697\n",
      "epoch 115: loss=0.9755948185920715\n",
      "epoch 116: loss=0.9545632004737854\n",
      "epoch 117: loss=0.9609732031822205\n",
      "epoch 118: loss=0.9766323566436768\n",
      "epoch 119: loss=1.0243414640426636\n",
      "epoch 120: loss=0.9851157069206238\n",
      "epoch 121: loss=0.9747055768966675\n",
      "epoch 122: loss=0.9591626524925232\n",
      "epoch 123: loss=0.9465914964675903\n",
      "epoch 124: loss=0.9765661954879761\n",
      "epoch 125: loss=0.9457061290740967\n",
      "epoch 126: loss=0.9027132391929626\n",
      "epoch 127: loss=0.9811961650848389\n",
      "epoch 128: loss=0.9617418646812439\n",
      "epoch 129: loss=0.9624084830284119\n",
      "epoch 130: loss=0.9746525287628174\n",
      "epoch 131: loss=0.9804928302764893\n",
      "epoch 132: loss=0.9299575686454773\n",
      "epoch 133: loss=0.9878625869750977\n",
      "epoch 134: loss=0.9536573886871338\n",
      "epoch 135: loss=1.0068819522857666\n",
      "epoch 136: loss=0.976971447467804\n",
      "epoch 137: loss=0.9253111481666565\n",
      "epoch 138: loss=0.9591859579086304\n",
      "epoch 139: loss=0.9753220677375793\n",
      "epoch 140: loss=0.9814339280128479\n",
      "epoch 141: loss=0.9438288807868958\n",
      "epoch 142: loss=0.9552872180938721\n",
      "epoch 143: loss=0.9653508067131042\n",
      "epoch 144: loss=0.9854601621627808\n",
      "epoch 145: loss=0.9364473819732666\n",
      "epoch 146: loss=0.9821158647537231\n",
      "epoch 147: loss=0.9392794370651245\n",
      "epoch 148: loss=0.9481233954429626\n",
      "epoch 149: loss=0.9699375629425049\n",
      "epoch 150: loss=0.9435564279556274\n",
      "epoch 151: loss=0.9859954118728638\n",
      "epoch 152: loss=0.9378343224525452\n",
      "epoch 153: loss=0.9579808712005615\n",
      "epoch 154: loss=0.944103479385376\n",
      "epoch 155: loss=0.9700743556022644\n",
      "epoch 156: loss=0.9498172998428345\n",
      "epoch 157: loss=0.954362690448761\n",
      "epoch 158: loss=0.9268041253089905\n",
      "epoch 159: loss=0.9476385116577148\n",
      "epoch 160: loss=0.8939438462257385\n",
      "epoch 161: loss=0.9696037173271179\n",
      "epoch 162: loss=0.9513360261917114\n",
      "epoch 163: loss=0.9847888946533203\n",
      "epoch 164: loss=0.917427659034729\n",
      "epoch 165: loss=0.9513159394264221\n",
      "epoch 166: loss=0.953246533870697\n",
      "epoch 167: loss=0.9205161929130554\n",
      "epoch 168: loss=0.974921464920044\n",
      "epoch 169: loss=0.951786458492279\n",
      "epoch 170: loss=0.9354673027992249\n",
      "epoch 171: loss=0.9356767535209656\n",
      "epoch 172: loss=0.958221435546875\n",
      "epoch 173: loss=0.9587824940681458\n",
      "epoch 174: loss=0.9478261470794678\n",
      "epoch 175: loss=0.9231534004211426\n",
      "epoch 176: loss=0.9422358274459839\n",
      "epoch 177: loss=0.9772393703460693\n",
      "epoch 178: loss=0.941507875919342\n",
      "epoch 179: loss=0.931808352470398\n",
      "epoch 180: loss=0.9399508833885193\n",
      "epoch 181: loss=0.9369472861289978\n",
      "epoch 182: loss=0.9665120840072632\n",
      "epoch 183: loss=0.9615556597709656\n",
      "epoch 184: loss=0.9566081762313843\n",
      "epoch 185: loss=0.9438540935516357\n",
      "epoch 186: loss=0.9416695833206177\n",
      "epoch 187: loss=0.9414256811141968\n",
      "epoch 188: loss=0.9822015166282654\n",
      "epoch 189: loss=0.931649386882782\n",
      "epoch 190: loss=0.9468380808830261\n",
      "epoch 191: loss=0.9480469822883606\n",
      "epoch 192: loss=0.9883846044540405\n",
      "epoch 193: loss=0.9569244384765625\n",
      "epoch 194: loss=0.9195833206176758\n",
      "epoch 195: loss=0.9703821539878845\n",
      "epoch 196: loss=0.9372209310531616\n",
      "epoch 197: loss=0.9572185277938843\n",
      "epoch 198: loss=0.9542911052703857\n",
      "epoch 199: loss=0.9193565845489502\n",
      "training patch with 1602 edges\n",
      "epoch 0: loss=3.2816944122314453\n",
      "epoch 1: loss=3.3266189098358154\n",
      "epoch 2: loss=3.2698171138763428\n",
      "epoch 3: loss=2.8997535705566406\n",
      "epoch 4: loss=2.998676300048828\n",
      "epoch 5: loss=2.755157947540283\n",
      "epoch 6: loss=2.721222162246704\n",
      "epoch 7: loss=2.430756092071533\n",
      "epoch 8: loss=2.256962537765503\n",
      "epoch 9: loss=2.0857441425323486\n",
      "epoch 10: loss=1.8935037851333618\n",
      "epoch 11: loss=1.8442866802215576\n",
      "epoch 12: loss=1.7203298807144165\n",
      "epoch 13: loss=1.6627718210220337\n",
      "epoch 14: loss=1.5827786922454834\n",
      "epoch 15: loss=1.552950382232666\n",
      "epoch 16: loss=1.4676254987716675\n",
      "epoch 17: loss=1.4366388320922852\n",
      "epoch 18: loss=1.4160314798355103\n",
      "epoch 19: loss=1.3991949558258057\n",
      "epoch 20: loss=1.3952412605285645\n",
      "epoch 21: loss=1.3958083391189575\n",
      "epoch 22: loss=1.3744831085205078\n",
      "epoch 23: loss=1.3698910474777222\n",
      "epoch 24: loss=1.3779057264328003\n",
      "epoch 25: loss=1.3692337274551392\n",
      "epoch 26: loss=1.3538494110107422\n",
      "epoch 27: loss=1.3435204029083252\n",
      "epoch 28: loss=1.347719669342041\n",
      "epoch 29: loss=1.3367663621902466\n",
      "epoch 30: loss=1.3387222290039062\n",
      "epoch 31: loss=1.3241392374038696\n",
      "epoch 32: loss=1.3231090307235718\n",
      "epoch 33: loss=1.315887451171875\n",
      "epoch 34: loss=1.2943514585494995\n",
      "epoch 35: loss=1.2837843894958496\n",
      "epoch 36: loss=1.2583446502685547\n",
      "epoch 37: loss=1.2411400079727173\n",
      "epoch 38: loss=1.2255550622940063\n",
      "epoch 39: loss=1.2182445526123047\n",
      "epoch 40: loss=1.1920697689056396\n",
      "epoch 41: loss=1.157454252243042\n",
      "epoch 42: loss=1.1633745431900024\n",
      "epoch 43: loss=1.1512951850891113\n",
      "epoch 44: loss=1.1590930223464966\n",
      "epoch 45: loss=1.1077173948287964\n",
      "epoch 46: loss=1.1283955574035645\n",
      "epoch 47: loss=1.0928773880004883\n",
      "epoch 48: loss=1.110241174697876\n",
      "epoch 49: loss=1.0676275491714478\n",
      "epoch 50: loss=1.0659257173538208\n",
      "epoch 51: loss=1.0585378408432007\n",
      "epoch 52: loss=1.066879391670227\n",
      "epoch 53: loss=1.0337947607040405\n",
      "epoch 54: loss=1.0313525199890137\n",
      "epoch 55: loss=1.0216425657272339\n",
      "epoch 56: loss=1.0172069072723389\n",
      "epoch 57: loss=1.0249443054199219\n",
      "epoch 58: loss=0.9970095753669739\n",
      "epoch 59: loss=1.014406442642212\n",
      "epoch 60: loss=0.9903848767280579\n",
      "epoch 61: loss=0.9921071529388428\n",
      "epoch 62: loss=0.9669005870819092\n",
      "epoch 63: loss=0.9796975255012512\n",
      "epoch 64: loss=0.974738597869873\n",
      "epoch 65: loss=0.9463690519332886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66: loss=0.9939759969711304\n",
      "epoch 67: loss=0.9633857607841492\n",
      "epoch 68: loss=0.9759173393249512\n",
      "epoch 69: loss=0.9531869888305664\n",
      "epoch 70: loss=0.9496245384216309\n",
      "epoch 71: loss=0.9471972584724426\n",
      "epoch 72: loss=0.9662213325500488\n",
      "epoch 73: loss=0.9413415789604187\n",
      "epoch 74: loss=0.948114275932312\n",
      "epoch 75: loss=0.9461660981178284\n",
      "epoch 76: loss=0.9575576782226562\n",
      "epoch 77: loss=0.9711524248123169\n",
      "epoch 78: loss=0.9705931544303894\n",
      "epoch 79: loss=0.9518739581108093\n",
      "epoch 80: loss=0.9327069520950317\n",
      "epoch 81: loss=0.9405860304832458\n",
      "epoch 82: loss=0.9250226616859436\n",
      "epoch 83: loss=0.939687192440033\n",
      "epoch 84: loss=0.9291385412216187\n",
      "epoch 85: loss=0.9406977295875549\n",
      "epoch 86: loss=0.9330518245697021\n",
      "epoch 87: loss=0.93400639295578\n",
      "epoch 88: loss=0.9301878213882446\n",
      "epoch 89: loss=0.9229356050491333\n",
      "epoch 90: loss=0.901610791683197\n",
      "epoch 91: loss=0.9176260232925415\n",
      "epoch 92: loss=0.9415115714073181\n",
      "epoch 93: loss=0.921329140663147\n",
      "epoch 94: loss=0.9442545771598816\n",
      "epoch 95: loss=0.9451326131820679\n",
      "epoch 96: loss=0.90011066198349\n",
      "epoch 97: loss=0.9258762001991272\n",
      "epoch 98: loss=0.9447745084762573\n",
      "epoch 99: loss=0.9230430722236633\n",
      "epoch 100: loss=0.900210976600647\n",
      "epoch 101: loss=0.9262111783027649\n",
      "epoch 102: loss=0.9186675548553467\n",
      "epoch 103: loss=0.9290933012962341\n",
      "epoch 104: loss=0.9016286730766296\n",
      "epoch 105: loss=0.9181752800941467\n",
      "epoch 106: loss=0.913962185382843\n",
      "epoch 107: loss=0.9219589233398438\n",
      "epoch 108: loss=0.9366652369499207\n",
      "epoch 109: loss=0.9112697839736938\n",
      "epoch 110: loss=0.912358820438385\n",
      "epoch 111: loss=0.8962257504463196\n",
      "epoch 112: loss=0.9026123881340027\n",
      "epoch 113: loss=0.9027727246284485\n",
      "epoch 114: loss=0.9332802295684814\n",
      "epoch 115: loss=0.9144837856292725\n",
      "epoch 116: loss=0.9164649844169617\n",
      "epoch 117: loss=0.9250389337539673\n",
      "epoch 118: loss=0.8912720084190369\n",
      "epoch 119: loss=0.911555826663971\n",
      "epoch 120: loss=0.9070572257041931\n",
      "epoch 121: loss=0.9096832871437073\n",
      "epoch 122: loss=0.9136523008346558\n",
      "epoch 123: loss=0.8795730471611023\n",
      "epoch 124: loss=0.914787769317627\n",
      "epoch 125: loss=0.9158424139022827\n",
      "epoch 126: loss=0.9094197750091553\n",
      "epoch 127: loss=0.9228914380073547\n",
      "epoch 128: loss=0.9118912220001221\n",
      "epoch 129: loss=0.9180848002433777\n",
      "epoch 130: loss=0.902544379234314\n",
      "epoch 131: loss=0.9439527988433838\n",
      "epoch 132: loss=0.8894786834716797\n",
      "epoch 133: loss=0.9261121153831482\n",
      "epoch 134: loss=0.9395253658294678\n",
      "epoch 135: loss=0.8916524648666382\n",
      "epoch 136: loss=0.8951488733291626\n",
      "epoch 137: loss=0.9117120504379272\n",
      "epoch 138: loss=0.907562792301178\n",
      "epoch 139: loss=0.9092659950256348\n",
      "epoch 140: loss=0.9037830829620361\n",
      "epoch 141: loss=0.9121874570846558\n",
      "epoch 142: loss=0.8968747854232788\n",
      "epoch 143: loss=0.8969268202781677\n",
      "epoch 144: loss=0.9033026099205017\n",
      "epoch 145: loss=0.910116970539093\n",
      "epoch 146: loss=0.906848669052124\n",
      "epoch 147: loss=0.889075756072998\n",
      "epoch 148: loss=0.8994841575622559\n",
      "epoch 149: loss=0.8935061693191528\n",
      "epoch 150: loss=0.8931271433830261\n",
      "epoch 151: loss=0.9093153476715088\n",
      "epoch 152: loss=0.9009288549423218\n",
      "epoch 153: loss=0.9124027490615845\n",
      "epoch 154: loss=0.9166600704193115\n",
      "epoch 155: loss=0.9220236539840698\n",
      "epoch 156: loss=0.9006349444389343\n",
      "epoch 157: loss=0.8844999074935913\n",
      "epoch 158: loss=0.9132843017578125\n",
      "epoch 159: loss=0.8801947236061096\n",
      "epoch 160: loss=0.9117878079414368\n",
      "epoch 161: loss=0.8987898230552673\n",
      "epoch 162: loss=0.9110950231552124\n",
      "epoch 163: loss=0.8899064064025879\n",
      "epoch 164: loss=0.8729972839355469\n",
      "epoch 165: loss=0.8949995040893555\n",
      "epoch 166: loss=0.8878482580184937\n",
      "epoch 167: loss=0.9072412252426147\n",
      "epoch 168: loss=0.912437915802002\n",
      "epoch 169: loss=0.8984136581420898\n",
      "epoch 170: loss=0.8987597227096558\n",
      "epoch 171: loss=0.8742311000823975\n",
      "epoch 172: loss=0.8722748756408691\n",
      "epoch 173: loss=0.9083108305931091\n",
      "epoch 174: loss=0.8840789794921875\n",
      "epoch 175: loss=0.9003759026527405\n",
      "epoch 176: loss=0.8692780137062073\n",
      "epoch 177: loss=0.9017915725708008\n",
      "epoch 178: loss=0.8807347416877747\n",
      "epoch 179: loss=0.9179988503456116\n",
      "epoch 180: loss=0.8927217721939087\n",
      "epoch 181: loss=0.8953542709350586\n",
      "epoch 182: loss=0.889980137348175\n",
      "epoch 183: loss=0.9132547974586487\n",
      "epoch 184: loss=0.8854934573173523\n",
      "epoch 185: loss=0.8817196488380432\n",
      "epoch 186: loss=0.9126386046409607\n",
      "epoch 187: loss=0.8753818869590759\n",
      "epoch 188: loss=0.9030465483665466\n",
      "epoch 189: loss=0.9019092917442322\n",
      "epoch 190: loss=0.878187358379364\n",
      "epoch 191: loss=0.9042273759841919\n",
      "epoch 192: loss=0.8854576349258423\n",
      "epoch 193: loss=0.902056097984314\n",
      "epoch 194: loss=0.8923996686935425\n",
      "epoch 195: loss=0.8794844150543213\n",
      "epoch 196: loss=0.9007910490036011\n",
      "epoch 197: loss=0.9130622148513794\n",
      "epoch 198: loss=0.8898373246192932\n",
      "epoch 199: loss=0.8794974088668823\n",
      "training patch with 1800 edges\n",
      "epoch 0: loss=3.3758652210235596\n",
      "epoch 1: loss=3.214909791946411\n",
      "epoch 2: loss=3.121464490890503\n",
      "epoch 3: loss=3.133349895477295\n",
      "epoch 4: loss=2.803499460220337\n",
      "epoch 5: loss=2.6579432487487793\n",
      "epoch 6: loss=2.4228286743164062\n",
      "epoch 7: loss=2.314948081970215\n",
      "epoch 8: loss=2.096787214279175\n",
      "epoch 9: loss=2.038444757461548\n",
      "epoch 10: loss=1.8879903554916382\n",
      "epoch 11: loss=1.776955485343933\n",
      "epoch 12: loss=1.7327067852020264\n",
      "epoch 13: loss=1.6004236936569214\n",
      "epoch 14: loss=1.5203903913497925\n",
      "epoch 15: loss=1.5078752040863037\n",
      "epoch 16: loss=1.4633793830871582\n",
      "epoch 17: loss=1.434352159500122\n",
      "epoch 18: loss=1.426754117012024\n",
      "epoch 19: loss=1.4139959812164307\n",
      "epoch 20: loss=1.4001063108444214\n",
      "epoch 21: loss=1.3877320289611816\n",
      "epoch 22: loss=1.3875080347061157\n",
      "epoch 23: loss=1.3788973093032837\n",
      "epoch 24: loss=1.3643505573272705\n",
      "epoch 25: loss=1.3465944528579712\n",
      "epoch 26: loss=1.3469934463500977\n",
      "epoch 27: loss=1.3462437391281128\n",
      "epoch 28: loss=1.3345447778701782\n",
      "epoch 29: loss=1.3351097106933594\n",
      "epoch 30: loss=1.336768388748169\n",
      "epoch 31: loss=1.3197555541992188\n",
      "epoch 32: loss=1.3152251243591309\n",
      "epoch 33: loss=1.3050206899642944\n",
      "epoch 34: loss=1.2897281646728516\n",
      "epoch 35: loss=1.2891157865524292\n",
      "epoch 36: loss=1.2829171419143677\n",
      "epoch 37: loss=1.2682311534881592\n",
      "epoch 38: loss=1.2510676383972168\n",
      "epoch 39: loss=1.2370147705078125\n",
      "epoch 40: loss=1.2363364696502686\n",
      "epoch 41: loss=1.2163580656051636\n",
      "epoch 42: loss=1.2179659605026245\n",
      "epoch 43: loss=1.209762692451477\n",
      "epoch 44: loss=1.1922032833099365\n",
      "epoch 45: loss=1.1658661365509033\n",
      "epoch 46: loss=1.182534098625183\n",
      "epoch 47: loss=1.150284767150879\n",
      "epoch 48: loss=1.1542069911956787\n",
      "epoch 49: loss=1.1593544483184814\n",
      "epoch 50: loss=1.149971842765808\n",
      "epoch 51: loss=1.1420814990997314\n",
      "epoch 52: loss=1.0880264043807983\n",
      "epoch 53: loss=1.07966148853302\n",
      "epoch 54: loss=1.0482244491577148\n",
      "epoch 55: loss=1.0553675889968872\n",
      "epoch 56: loss=1.0434696674346924\n",
      "epoch 57: loss=1.0498719215393066\n",
      "epoch 58: loss=1.0373457670211792\n",
      "epoch 59: loss=0.9913541078567505\n",
      "epoch 60: loss=1.0079632997512817\n",
      "epoch 61: loss=1.0117052793502808\n",
      "epoch 62: loss=0.9942833781242371\n",
      "epoch 63: loss=1.0036851167678833\n",
      "epoch 64: loss=0.9851820468902588\n",
      "epoch 65: loss=0.9791586995124817\n",
      "epoch 66: loss=0.941128671169281\n",
      "epoch 67: loss=0.9932020902633667\n",
      "epoch 68: loss=0.9853858947753906\n",
      "epoch 69: loss=0.9864972829818726\n",
      "epoch 70: loss=0.9764513969421387\n",
      "epoch 71: loss=0.9599305391311646\n",
      "epoch 72: loss=0.9754605293273926\n",
      "epoch 73: loss=0.9549704194068909\n",
      "epoch 74: loss=0.9832744002342224\n",
      "epoch 75: loss=0.9414879083633423\n",
      "epoch 76: loss=0.9581524729728699\n",
      "epoch 77: loss=0.9373483657836914\n",
      "epoch 78: loss=0.9757022857666016\n",
      "epoch 79: loss=0.9460512399673462\n",
      "epoch 80: loss=0.9427275061607361\n",
      "epoch 81: loss=0.9495866894721985\n",
      "epoch 82: loss=0.9728035926818848\n",
      "epoch 83: loss=0.9323756098747253\n",
      "epoch 84: loss=0.9411163330078125\n",
      "epoch 85: loss=0.944667398929596\n",
      "epoch 86: loss=0.9580395817756653\n",
      "epoch 87: loss=0.9265109896659851\n",
      "epoch 88: loss=0.9510340690612793\n",
      "epoch 89: loss=0.9479907751083374\n",
      "epoch 90: loss=0.9384074211120605\n",
      "epoch 91: loss=0.9508956074714661\n",
      "epoch 92: loss=0.9451930522918701\n",
      "epoch 93: loss=0.9486584067344666\n",
      "epoch 94: loss=0.9511216282844543\n",
      "epoch 95: loss=0.9539549946784973\n",
      "epoch 96: loss=0.9513775706291199\n",
      "epoch 97: loss=0.9557451009750366\n",
      "epoch 98: loss=0.9399819374084473\n",
      "epoch 99: loss=0.9427049160003662\n",
      "epoch 100: loss=0.9595029950141907\n",
      "epoch 101: loss=0.949765682220459\n",
      "epoch 102: loss=0.9344310760498047\n",
      "epoch 103: loss=0.9242363572120667\n",
      "epoch 104: loss=0.9114673733711243\n",
      "epoch 105: loss=0.9247789978981018\n",
      "epoch 106: loss=0.9418581128120422\n",
      "epoch 107: loss=0.9410874843597412\n",
      "epoch 108: loss=0.9329236149787903\n",
      "epoch 109: loss=0.9276794791221619\n",
      "epoch 110: loss=0.9498412609100342\n",
      "epoch 111: loss=0.9480932950973511\n",
      "epoch 112: loss=0.911483883857727\n",
      "epoch 113: loss=0.917071521282196\n",
      "epoch 114: loss=0.9346935749053955\n",
      "epoch 115: loss=0.9475091099739075\n",
      "epoch 116: loss=0.9136834144592285\n",
      "epoch 117: loss=0.9382761120796204\n",
      "epoch 118: loss=0.9414164423942566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119: loss=0.909012496471405\n",
      "epoch 120: loss=0.9387112855911255\n",
      "epoch 121: loss=0.9406588673591614\n",
      "epoch 122: loss=0.9376590847969055\n",
      "epoch 123: loss=0.9400224685668945\n",
      "epoch 124: loss=0.9288190007209778\n",
      "epoch 125: loss=0.9402958154678345\n",
      "epoch 126: loss=0.9477483034133911\n",
      "epoch 127: loss=0.9266743063926697\n",
      "epoch 128: loss=0.9300194978713989\n",
      "epoch 129: loss=0.9244211912155151\n",
      "epoch 130: loss=0.927985429763794\n",
      "epoch 131: loss=0.9466507434844971\n",
      "epoch 132: loss=0.9479127526283264\n",
      "epoch 133: loss=0.9291657209396362\n",
      "epoch 134: loss=0.9090836644172668\n",
      "epoch 135: loss=0.933090329170227\n",
      "epoch 136: loss=0.9581242799758911\n",
      "epoch 137: loss=0.9242550730705261\n",
      "epoch 138: loss=0.9127496480941772\n",
      "epoch 139: loss=0.9246949553489685\n",
      "epoch 140: loss=0.9148895144462585\n",
      "epoch 141: loss=0.9238080382347107\n",
      "epoch 142: loss=0.9503453969955444\n",
      "epoch 143: loss=0.9275956749916077\n",
      "epoch 144: loss=0.9045442342758179\n",
      "epoch 145: loss=0.9337207078933716\n",
      "epoch 146: loss=0.928469717502594\n",
      "epoch 147: loss=0.9177358150482178\n",
      "epoch 148: loss=0.9434967637062073\n",
      "epoch 149: loss=0.905811071395874\n",
      "epoch 150: loss=0.8935327529907227\n",
      "epoch 151: loss=0.9281209111213684\n",
      "epoch 152: loss=0.8828463554382324\n",
      "epoch 153: loss=0.928735613822937\n",
      "epoch 154: loss=0.9293949604034424\n",
      "epoch 155: loss=0.9087045788764954\n",
      "epoch 156: loss=0.934024453163147\n",
      "epoch 157: loss=0.9165827035903931\n",
      "epoch 158: loss=0.9202790260314941\n",
      "epoch 159: loss=0.9269003868103027\n",
      "epoch 160: loss=0.9047813415527344\n",
      "epoch 161: loss=0.8947167992591858\n",
      "epoch 162: loss=0.9253119230270386\n",
      "epoch 163: loss=0.9150601625442505\n",
      "epoch 164: loss=0.9049935340881348\n",
      "epoch 165: loss=0.9115496873855591\n",
      "epoch 166: loss=0.9167962074279785\n",
      "epoch 167: loss=0.9019266963005066\n",
      "epoch 168: loss=0.9192675948143005\n",
      "epoch 169: loss=0.9319421648979187\n",
      "epoch 170: loss=0.9057738780975342\n",
      "epoch 171: loss=0.9115225076675415\n",
      "epoch 172: loss=0.9341813921928406\n",
      "epoch 173: loss=0.9024438261985779\n",
      "epoch 174: loss=0.8987226486206055\n",
      "epoch 175: loss=0.9273313283920288\n",
      "epoch 176: loss=0.9200980067253113\n",
      "epoch 177: loss=0.9189170002937317\n",
      "epoch 178: loss=0.9282528162002563\n",
      "epoch 179: loss=0.9052678346633911\n",
      "epoch 180: loss=0.906981885433197\n",
      "epoch 181: loss=0.9116131067276001\n",
      "epoch 182: loss=0.9015787839889526\n",
      "epoch 183: loss=0.9130167961120605\n",
      "epoch 184: loss=0.9054221510887146\n",
      "epoch 185: loss=0.8962053060531616\n",
      "epoch 186: loss=0.8973274827003479\n",
      "epoch 187: loss=0.9251946210861206\n",
      "epoch 188: loss=0.9333207011222839\n",
      "epoch 189: loss=0.9079111218452454\n",
      "epoch 190: loss=0.9182193875312805\n",
      "epoch 191: loss=0.9155654907226562\n",
      "epoch 192: loss=0.8911016583442688\n",
      "epoch 193: loss=0.9138763546943665\n",
      "epoch 194: loss=0.9170691967010498\n",
      "epoch 195: loss=0.920316219329834\n",
      "epoch 196: loss=0.9034004807472229\n",
      "epoch 197: loss=0.9099600315093994\n",
      "epoch 198: loss=0.9115071892738342\n",
      "epoch 199: loss=0.8969846367835999\n",
      "training patch with 1844 edges\n",
      "epoch 0: loss=3.467456340789795\n",
      "epoch 1: loss=3.309380292892456\n",
      "epoch 2: loss=3.214357614517212\n",
      "epoch 3: loss=2.7521588802337646\n",
      "epoch 4: loss=2.9321231842041016\n",
      "epoch 5: loss=2.6186716556549072\n",
      "epoch 6: loss=2.5088984966278076\n",
      "epoch 7: loss=2.358656883239746\n",
      "epoch 8: loss=2.2289745807647705\n",
      "epoch 9: loss=2.030039072036743\n",
      "epoch 10: loss=1.9936208724975586\n",
      "epoch 11: loss=1.8086867332458496\n",
      "epoch 12: loss=1.750780701637268\n",
      "epoch 13: loss=1.6720097064971924\n",
      "epoch 14: loss=1.586035966873169\n",
      "epoch 15: loss=1.4892804622650146\n",
      "epoch 16: loss=1.4998525381088257\n",
      "epoch 17: loss=1.4593806266784668\n",
      "epoch 18: loss=1.4239599704742432\n",
      "epoch 19: loss=1.3973016738891602\n",
      "epoch 20: loss=1.3899174928665161\n",
      "epoch 21: loss=1.367968201637268\n",
      "epoch 22: loss=1.3698008060455322\n",
      "epoch 23: loss=1.3649163246154785\n",
      "epoch 24: loss=1.339060664176941\n",
      "epoch 25: loss=1.334126591682434\n",
      "epoch 26: loss=1.3338587284088135\n",
      "epoch 27: loss=1.3268073797225952\n",
      "epoch 28: loss=1.3280017375946045\n",
      "epoch 29: loss=1.324137568473816\n",
      "epoch 30: loss=1.3209177255630493\n",
      "epoch 31: loss=1.310956358909607\n",
      "epoch 32: loss=1.2923110723495483\n",
      "epoch 33: loss=1.2994632720947266\n",
      "epoch 34: loss=1.2913321256637573\n",
      "epoch 35: loss=1.278764009475708\n",
      "epoch 36: loss=1.2637447118759155\n",
      "epoch 37: loss=1.2564246654510498\n",
      "epoch 38: loss=1.2430813312530518\n",
      "epoch 39: loss=1.218200445175171\n",
      "epoch 40: loss=1.1964225769042969\n",
      "epoch 41: loss=1.180382490158081\n",
      "epoch 42: loss=1.1604772806167603\n",
      "epoch 43: loss=1.14811372756958\n",
      "epoch 44: loss=1.1082786321640015\n",
      "epoch 45: loss=1.091457486152649\n",
      "epoch 46: loss=1.0611377954483032\n",
      "epoch 47: loss=1.0467606782913208\n",
      "epoch 48: loss=1.0599571466445923\n",
      "epoch 49: loss=1.0389271974563599\n",
      "epoch 50: loss=1.0202693939208984\n",
      "epoch 51: loss=1.055956244468689\n",
      "epoch 52: loss=1.033685326576233\n",
      "epoch 53: loss=1.045219898223877\n",
      "epoch 54: loss=1.0451362133026123\n",
      "epoch 55: loss=1.046578288078308\n",
      "epoch 56: loss=0.9929205179214478\n",
      "epoch 57: loss=1.0255249738693237\n",
      "epoch 58: loss=1.0133289098739624\n",
      "epoch 59: loss=1.0089830160140991\n",
      "epoch 60: loss=0.9914665222167969\n",
      "epoch 61: loss=0.9802628755569458\n",
      "epoch 62: loss=1.0021876096725464\n",
      "epoch 63: loss=0.9701387882232666\n",
      "epoch 64: loss=0.9631444811820984\n",
      "epoch 65: loss=0.9656303524971008\n",
      "epoch 66: loss=0.9542790055274963\n",
      "epoch 67: loss=0.9533832669258118\n",
      "epoch 68: loss=0.9808807373046875\n",
      "epoch 69: loss=0.9485257863998413\n",
      "epoch 70: loss=0.9450346231460571\n",
      "epoch 71: loss=0.9567457437515259\n",
      "epoch 72: loss=0.9729737639427185\n",
      "epoch 73: loss=0.9460305571556091\n",
      "epoch 74: loss=0.9447084665298462\n",
      "epoch 75: loss=0.9667547941207886\n",
      "epoch 76: loss=0.930251955986023\n",
      "epoch 77: loss=0.9402996897697449\n",
      "epoch 78: loss=0.9452961087226868\n",
      "epoch 79: loss=0.9444610476493835\n",
      "epoch 80: loss=0.9442665576934814\n",
      "epoch 81: loss=0.96555095911026\n",
      "epoch 82: loss=0.9356159567832947\n",
      "epoch 83: loss=0.9299185872077942\n",
      "epoch 84: loss=0.9279322624206543\n",
      "epoch 85: loss=0.9486338496208191\n",
      "epoch 86: loss=0.9325110912322998\n",
      "epoch 87: loss=0.9414518475532532\n",
      "epoch 88: loss=0.9293476939201355\n",
      "epoch 89: loss=0.9470346570014954\n",
      "epoch 90: loss=0.9453089237213135\n",
      "epoch 91: loss=0.9420823454856873\n",
      "epoch 92: loss=0.905269980430603\n",
      "epoch 93: loss=0.9298169016838074\n",
      "epoch 94: loss=0.9098333120346069\n",
      "epoch 95: loss=0.9259771704673767\n",
      "epoch 96: loss=0.9194663763046265\n",
      "epoch 97: loss=0.9235196113586426\n",
      "epoch 98: loss=0.9143831729888916\n",
      "epoch 99: loss=0.9299180507659912\n",
      "epoch 100: loss=0.9081237316131592\n",
      "epoch 101: loss=0.9371045827865601\n",
      "epoch 102: loss=0.9226055145263672\n",
      "epoch 103: loss=0.9306756854057312\n",
      "epoch 104: loss=0.9226630330085754\n",
      "epoch 105: loss=0.9117052555084229\n",
      "epoch 106: loss=0.9061122536659241\n",
      "epoch 107: loss=0.9181085824966431\n",
      "epoch 108: loss=0.917973518371582\n",
      "epoch 109: loss=0.9132115244865417\n",
      "epoch 110: loss=0.9118636846542358\n",
      "epoch 111: loss=0.9012130498886108\n",
      "epoch 112: loss=0.8876200318336487\n",
      "epoch 113: loss=0.9293910264968872\n",
      "epoch 114: loss=0.9065977334976196\n",
      "epoch 115: loss=0.9125585556030273\n",
      "epoch 116: loss=0.900670051574707\n",
      "epoch 117: loss=0.9195334911346436\n",
      "epoch 118: loss=0.9193357229232788\n",
      "epoch 119: loss=0.8840723633766174\n",
      "epoch 120: loss=0.9243447184562683\n",
      "epoch 121: loss=0.8808379173278809\n",
      "epoch 122: loss=0.9020585417747498\n",
      "epoch 123: loss=0.8959854245185852\n",
      "epoch 124: loss=0.9044929146766663\n",
      "epoch 125: loss=0.9202351570129395\n",
      "epoch 126: loss=0.8832231760025024\n",
      "epoch 127: loss=0.8927425146102905\n",
      "epoch 128: loss=0.9098917841911316\n",
      "epoch 129: loss=0.9038635492324829\n",
      "epoch 130: loss=0.9168652296066284\n",
      "epoch 131: loss=0.8838489651679993\n",
      "epoch 132: loss=0.9076204299926758\n",
      "epoch 133: loss=0.9016711711883545\n",
      "epoch 134: loss=0.8865675926208496\n",
      "epoch 135: loss=0.9038606286048889\n",
      "epoch 136: loss=0.9132012128829956\n",
      "epoch 137: loss=0.9036734700202942\n",
      "epoch 138: loss=0.9117484092712402\n",
      "epoch 139: loss=0.885410726070404\n",
      "epoch 140: loss=0.9074556827545166\n",
      "epoch 141: loss=0.9088128209114075\n",
      "epoch 142: loss=0.9090655446052551\n",
      "epoch 143: loss=0.8986576199531555\n",
      "epoch 144: loss=0.906489372253418\n",
      "epoch 145: loss=0.9284019470214844\n",
      "epoch 146: loss=0.8966718912124634\n",
      "epoch 147: loss=0.8967185020446777\n",
      "epoch 148: loss=0.892992377281189\n",
      "epoch 149: loss=0.9053792953491211\n",
      "epoch 150: loss=0.9083734154701233\n",
      "epoch 151: loss=0.9042240977287292\n",
      "epoch 152: loss=0.90107661485672\n",
      "epoch 153: loss=0.8967079520225525\n",
      "epoch 154: loss=0.8954064846038818\n",
      "epoch 155: loss=0.8848428130149841\n",
      "epoch 156: loss=0.8622478246688843\n",
      "epoch 157: loss=0.9012699723243713\n",
      "epoch 158: loss=0.8824562430381775\n",
      "epoch 159: loss=0.8890026807785034\n",
      "epoch 160: loss=0.8933642506599426\n",
      "epoch 161: loss=0.9147337675094604\n",
      "epoch 162: loss=0.8976168036460876\n",
      "epoch 163: loss=0.8738217949867249\n",
      "epoch 164: loss=0.8990765810012817\n",
      "epoch 165: loss=0.909058690071106\n",
      "epoch 166: loss=0.9021538496017456\n",
      "epoch 167: loss=0.8926494121551514\n",
      "epoch 168: loss=0.8865166306495667\n",
      "epoch 169: loss=0.9018818140029907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170: loss=0.8827523589134216\n",
      "epoch 171: loss=0.885736346244812\n",
      "epoch 172: loss=0.8910410404205322\n",
      "epoch 173: loss=0.897077202796936\n",
      "epoch 174: loss=0.8827683329582214\n",
      "epoch 175: loss=0.8848662376403809\n",
      "epoch 176: loss=0.8867868781089783\n",
      "epoch 177: loss=0.8913647532463074\n",
      "epoch 178: loss=0.8931645154953003\n",
      "epoch 179: loss=0.8785247802734375\n",
      "epoch 180: loss=0.8896768689155579\n",
      "epoch 181: loss=0.889502763748169\n",
      "epoch 182: loss=0.8477816581726074\n",
      "epoch 183: loss=0.9003176093101501\n",
      "epoch 184: loss=0.8590558171272278\n",
      "epoch 185: loss=0.8929799795150757\n",
      "epoch 186: loss=0.8933314085006714\n",
      "epoch 187: loss=0.8872343301773071\n",
      "epoch 188: loss=0.8600413799285889\n",
      "epoch 189: loss=0.8904969692230225\n",
      "epoch 190: loss=0.9193236827850342\n",
      "epoch 191: loss=0.875895619392395\n",
      "epoch 192: loss=0.9156557321548462\n",
      "epoch 193: loss=0.8855808973312378\n",
      "epoch 194: loss=0.8569633960723877\n",
      "epoch 195: loss=0.8942080140113831\n",
      "epoch 196: loss=0.8726868629455566\n",
      "epoch 197: loss=0.904498279094696\n",
      "epoch 198: loss=0.8904504776000977\n",
      "epoch 199: loss=0.9050824046134949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10388ea1c3494452a0aa6bdb71866a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 7096.0634765625\n",
      "Epoch 10, Loss: 1949.052978515625\n",
      "Epoch 20, Loss: 1498.9818115234375\n",
      "Epoch 30, Loss: 1354.1065673828125\n",
      "Epoch 40, Loss: 1278.39501953125\n",
      "Epoch 50, Loss: 1245.695068359375\n",
      "Epoch 60, Loss: 1227.37646484375\n",
      "Epoch 70, Loss: 1216.846435546875\n",
      "Epoch 80, Loss: 1209.883544921875\n",
      "Epoch 90, Loss: 1204.7830810546875\n",
      "Epoch 100, Loss: 1200.919677734375\n",
      "Epoch 110, Loss: 1197.9598388671875\n",
      "Epoch 120, Loss: 1195.664794921875\n",
      "Epoch 130, Loss: 1193.8634033203125\n",
      "Epoch 140, Loss: 1192.4290771484375\n",
      "Epoch 150, Loss: 1191.2720947265625\n",
      "Epoch 160, Loss: 1190.3243408203125\n",
      "Epoch 170, Loss: 1189.537109375\n",
      "Epoch 180, Loss: 1188.8739013671875\n",
      "Epoch 190, Loss: 1188.3076171875\n",
      "training patch with 2032 edges\n",
      "epoch 0: loss=4.759056091308594\n",
      "epoch 1: loss=4.613770008087158\n",
      "epoch 2: loss=4.252890586853027\n",
      "epoch 3: loss=4.102402210235596\n",
      "epoch 4: loss=3.718076467514038\n",
      "epoch 5: loss=3.507204294204712\n",
      "epoch 6: loss=3.1150505542755127\n",
      "epoch 7: loss=2.9103503227233887\n",
      "epoch 8: loss=2.756819725036621\n",
      "epoch 9: loss=2.4190690517425537\n",
      "epoch 10: loss=2.265568733215332\n",
      "epoch 11: loss=2.066721200942993\n",
      "epoch 12: loss=1.8643168210983276\n",
      "epoch 13: loss=1.7153841257095337\n",
      "epoch 14: loss=1.6200037002563477\n",
      "epoch 15: loss=1.5887221097946167\n",
      "epoch 16: loss=1.5391970872879028\n",
      "epoch 17: loss=1.4723505973815918\n",
      "epoch 18: loss=1.4279747009277344\n",
      "epoch 19: loss=1.4483907222747803\n",
      "epoch 20: loss=1.4264622926712036\n",
      "epoch 21: loss=1.4180670976638794\n",
      "epoch 22: loss=1.4117090702056885\n",
      "epoch 23: loss=1.3871207237243652\n",
      "epoch 24: loss=1.3881793022155762\n",
      "epoch 25: loss=1.3876123428344727\n",
      "epoch 26: loss=1.3729023933410645\n",
      "epoch 27: loss=1.36953604221344\n",
      "epoch 28: loss=1.3548184633255005\n",
      "epoch 29: loss=1.3498936891555786\n",
      "epoch 30: loss=1.3466527462005615\n",
      "epoch 31: loss=1.3249398469924927\n",
      "epoch 32: loss=1.3205243349075317\n",
      "epoch 33: loss=1.3130501508712769\n",
      "epoch 34: loss=1.2992316484451294\n",
      "epoch 35: loss=1.2966792583465576\n",
      "epoch 36: loss=1.2771793603897095\n",
      "epoch 37: loss=1.2695047855377197\n",
      "epoch 38: loss=1.2603262662887573\n",
      "epoch 39: loss=1.2435169219970703\n",
      "epoch 40: loss=1.2415374517440796\n",
      "epoch 41: loss=1.1922494173049927\n",
      "epoch 42: loss=1.1895736455917358\n",
      "epoch 43: loss=1.1632542610168457\n",
      "epoch 44: loss=1.1566283702850342\n",
      "epoch 45: loss=1.1476655006408691\n",
      "epoch 46: loss=1.1391993761062622\n",
      "epoch 47: loss=1.1336519718170166\n",
      "epoch 48: loss=1.1217458248138428\n",
      "epoch 49: loss=1.1103546619415283\n",
      "epoch 50: loss=1.1036919355392456\n",
      "epoch 51: loss=1.108748197555542\n",
      "epoch 52: loss=1.1084645986557007\n",
      "epoch 53: loss=1.0730067491531372\n",
      "epoch 54: loss=1.053102731704712\n",
      "epoch 55: loss=1.0567388534545898\n",
      "epoch 56: loss=1.0654535293579102\n",
      "epoch 57: loss=1.049620270729065\n",
      "epoch 58: loss=1.0499210357666016\n",
      "epoch 59: loss=1.0429588556289673\n",
      "epoch 60: loss=1.0282639265060425\n",
      "epoch 61: loss=1.0105215311050415\n",
      "epoch 62: loss=0.9897096753120422\n",
      "epoch 63: loss=1.0052307844161987\n",
      "epoch 64: loss=1.0060515403747559\n",
      "epoch 65: loss=1.0136984586715698\n",
      "epoch 66: loss=1.0111274719238281\n",
      "epoch 67: loss=1.0110669136047363\n",
      "epoch 68: loss=0.9893107414245605\n",
      "epoch 69: loss=1.005089521408081\n",
      "epoch 70: loss=0.9789389967918396\n",
      "epoch 71: loss=0.9980615377426147\n",
      "epoch 72: loss=0.9818934798240662\n",
      "epoch 73: loss=0.9756158590316772\n",
      "epoch 74: loss=1.0036659240722656\n",
      "epoch 75: loss=0.9676184058189392\n",
      "epoch 76: loss=0.9620601534843445\n",
      "epoch 77: loss=0.9641512036323547\n",
      "epoch 78: loss=0.981600821018219\n",
      "epoch 79: loss=0.9692080616950989\n",
      "epoch 80: loss=0.9767447710037231\n",
      "epoch 81: loss=0.9798749685287476\n",
      "epoch 82: loss=0.9596077799797058\n",
      "epoch 83: loss=0.9667186141014099\n",
      "epoch 84: loss=0.9761740565299988\n",
      "epoch 85: loss=0.9701066613197327\n",
      "epoch 86: loss=0.9676331877708435\n",
      "epoch 87: loss=0.9645370841026306\n",
      "epoch 88: loss=0.960467517375946\n",
      "epoch 89: loss=0.9524060487747192\n",
      "epoch 90: loss=0.9667825698852539\n",
      "epoch 91: loss=0.9629576206207275\n",
      "epoch 92: loss=0.9459250569343567\n",
      "epoch 93: loss=0.9594556093215942\n",
      "epoch 94: loss=0.9640092849731445\n",
      "epoch 95: loss=0.9498429298400879\n",
      "epoch 96: loss=0.9317962527275085\n",
      "epoch 97: loss=0.9470821619033813\n",
      "epoch 98: loss=0.9426550269126892\n",
      "epoch 99: loss=0.9442909359931946\n",
      "epoch 100: loss=0.9633623361587524\n",
      "epoch 101: loss=0.9539168477058411\n",
      "epoch 102: loss=0.9352318644523621\n",
      "epoch 103: loss=0.9351291656494141\n",
      "epoch 104: loss=0.9482976198196411\n",
      "epoch 105: loss=0.9406334161758423\n",
      "epoch 106: loss=0.9468129873275757\n",
      "epoch 107: loss=0.9301524758338928\n",
      "epoch 108: loss=0.9107292294502258\n",
      "epoch 109: loss=0.9498031139373779\n",
      "epoch 110: loss=0.9567115306854248\n",
      "epoch 111: loss=0.9528595805168152\n",
      "epoch 112: loss=0.9349166750907898\n",
      "epoch 113: loss=0.9345534443855286\n",
      "epoch 114: loss=0.9365284442901611\n",
      "epoch 115: loss=0.8995401859283447\n",
      "epoch 116: loss=0.9240740537643433\n",
      "epoch 117: loss=0.9121866822242737\n",
      "epoch 118: loss=0.9206568598747253\n",
      "epoch 119: loss=0.9145535230636597\n",
      "epoch 120: loss=0.9350448846817017\n",
      "epoch 121: loss=0.9189105033874512\n",
      "epoch 122: loss=0.9432159662246704\n",
      "epoch 123: loss=0.9618247151374817\n",
      "epoch 124: loss=0.9578444957733154\n",
      "epoch 125: loss=0.9394940137863159\n",
      "epoch 126: loss=0.929118812084198\n",
      "epoch 127: loss=0.9331076145172119\n",
      "epoch 128: loss=0.9448325634002686\n",
      "epoch 129: loss=0.9284870028495789\n",
      "epoch 130: loss=0.9149889945983887\n",
      "epoch 131: loss=0.9242210388183594\n",
      "epoch 132: loss=0.9345397353172302\n",
      "epoch 133: loss=0.9126706123352051\n",
      "epoch 134: loss=0.9416584372520447\n",
      "epoch 135: loss=0.9217067956924438\n",
      "epoch 136: loss=0.919243335723877\n",
      "epoch 137: loss=0.9142396450042725\n",
      "epoch 138: loss=0.9350968599319458\n",
      "epoch 139: loss=0.8942852020263672\n",
      "epoch 140: loss=0.9279868006706238\n",
      "epoch 141: loss=0.9255124926567078\n",
      "epoch 142: loss=0.935110330581665\n",
      "epoch 143: loss=0.9250467419624329\n",
      "epoch 144: loss=0.9137633442878723\n",
      "epoch 145: loss=0.9393598437309265\n",
      "epoch 146: loss=0.9251244068145752\n",
      "epoch 147: loss=0.9232137799263\n",
      "epoch 148: loss=0.9269609451293945\n",
      "epoch 149: loss=0.9244682788848877\n",
      "epoch 150: loss=0.9242293834686279\n",
      "epoch 151: loss=0.9388622641563416\n",
      "epoch 152: loss=0.940445065498352\n",
      "epoch 153: loss=0.924656331539154\n",
      "epoch 154: loss=0.9326943159103394\n",
      "epoch 155: loss=0.9080268740653992\n",
      "epoch 156: loss=0.9213526248931885\n",
      "epoch 157: loss=0.9175457954406738\n",
      "epoch 158: loss=0.9063565135002136\n",
      "epoch 159: loss=0.8918434381484985\n",
      "epoch 160: loss=0.9144706726074219\n",
      "epoch 161: loss=0.9043393731117249\n",
      "epoch 162: loss=0.9309051036834717\n",
      "epoch 163: loss=0.9163815975189209\n",
      "epoch 164: loss=0.9261128306388855\n",
      "epoch 165: loss=0.9108487367630005\n",
      "epoch 166: loss=0.9210830926895142\n",
      "epoch 167: loss=0.924986720085144\n",
      "epoch 168: loss=0.9139043092727661\n",
      "epoch 169: loss=0.9126314520835876\n",
      "epoch 170: loss=0.914361834526062\n",
      "epoch 171: loss=0.9103497862815857\n",
      "epoch 172: loss=0.9105204939842224\n",
      "epoch 173: loss=0.9036153554916382\n",
      "epoch 174: loss=0.9229809045791626\n",
      "epoch 175: loss=0.9227338433265686\n",
      "epoch 176: loss=0.9349977970123291\n",
      "epoch 177: loss=0.9154501557350159\n",
      "epoch 178: loss=0.9047836661338806\n",
      "epoch 179: loss=0.894616961479187\n",
      "epoch 180: loss=0.9165520071983337\n",
      "epoch 181: loss=0.9212749004364014\n",
      "epoch 182: loss=0.932877779006958\n",
      "epoch 183: loss=0.915086030960083\n",
      "epoch 184: loss=0.9105671048164368\n",
      "epoch 185: loss=0.9069064855575562\n",
      "epoch 186: loss=0.9213840961456299\n",
      "epoch 187: loss=0.9188796281814575\n",
      "epoch 188: loss=0.9075106978416443\n",
      "epoch 189: loss=0.9227673411369324\n",
      "epoch 190: loss=0.8870608806610107\n",
      "epoch 191: loss=0.9109122157096863\n",
      "epoch 192: loss=0.9138476252555847\n",
      "epoch 193: loss=0.8909251689910889\n",
      "epoch 194: loss=0.9084473252296448\n",
      "epoch 195: loss=0.8977315425872803\n",
      "epoch 196: loss=0.9216055274009705\n",
      "epoch 197: loss=0.9181686043739319\n",
      "epoch 198: loss=0.906857430934906\n",
      "epoch 199: loss=0.9171155691146851\n",
      "training patch with 1946 edges\n",
      "epoch 0: loss=5.063405513763428\n",
      "epoch 1: loss=4.583241939544678\n",
      "epoch 2: loss=4.618208885192871\n",
      "epoch 3: loss=4.306044578552246\n",
      "epoch 4: loss=3.954925537109375\n",
      "epoch 5: loss=3.5678322315216064\n",
      "epoch 6: loss=3.487929344177246\n",
      "epoch 7: loss=3.169522762298584\n",
      "epoch 8: loss=3.099078416824341\n",
      "epoch 9: loss=2.7624645233154297\n",
      "epoch 10: loss=2.412397623062134\n",
      "epoch 11: loss=2.180373191833496\n",
      "epoch 12: loss=2.098236560821533\n",
      "epoch 13: loss=1.9137468338012695\n",
      "epoch 14: loss=1.7274731397628784\n",
      "epoch 15: loss=1.6959891319274902\n",
      "epoch 16: loss=1.619864583015442\n",
      "epoch 17: loss=1.5648260116577148\n",
      "epoch 18: loss=1.4908685684204102\n",
      "epoch 19: loss=1.479972243309021\n",
      "epoch 20: loss=1.4517791271209717\n",
      "epoch 21: loss=1.4421343803405762\n",
      "epoch 22: loss=1.4371371269226074\n",
      "epoch 23: loss=1.420257568359375\n",
      "epoch 24: loss=1.3990625143051147\n",
      "epoch 25: loss=1.3886059522628784\n",
      "epoch 26: loss=1.3864176273345947\n",
      "epoch 27: loss=1.3755286931991577\n",
      "epoch 28: loss=1.3656145334243774\n",
      "epoch 29: loss=1.3576786518096924\n",
      "epoch 30: loss=1.3649131059646606\n",
      "epoch 31: loss=1.3389012813568115\n",
      "epoch 32: loss=1.3225291967391968\n",
      "epoch 33: loss=1.3078234195709229\n",
      "epoch 34: loss=1.2926018238067627\n",
      "epoch 35: loss=1.281188726425171\n",
      "epoch 36: loss=1.2615766525268555\n",
      "epoch 37: loss=1.2376048564910889\n",
      "epoch 38: loss=1.2218583822250366\n",
      "epoch 39: loss=1.188003659248352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40: loss=1.1800309419631958\n",
      "epoch 41: loss=1.1635416746139526\n",
      "epoch 42: loss=1.1544309854507446\n",
      "epoch 43: loss=1.1349084377288818\n",
      "epoch 44: loss=1.1225953102111816\n",
      "epoch 45: loss=1.1194401979446411\n",
      "epoch 46: loss=1.0894567966461182\n",
      "epoch 47: loss=1.090209722518921\n",
      "epoch 48: loss=1.0766408443450928\n",
      "epoch 49: loss=1.0585401058197021\n",
      "epoch 50: loss=1.0498727560043335\n",
      "epoch 51: loss=1.0488574504852295\n",
      "epoch 52: loss=1.0786399841308594\n",
      "epoch 53: loss=1.059279203414917\n",
      "epoch 54: loss=1.0366989374160767\n",
      "epoch 55: loss=1.0288653373718262\n",
      "epoch 56: loss=1.0247317552566528\n",
      "epoch 57: loss=1.0078895092010498\n",
      "epoch 58: loss=1.0218119621276855\n",
      "epoch 59: loss=1.0108503103256226\n",
      "epoch 60: loss=1.0067225694656372\n",
      "epoch 61: loss=0.9881677627563477\n",
      "epoch 62: loss=1.0220237970352173\n",
      "epoch 63: loss=0.9796614646911621\n",
      "epoch 64: loss=0.9939139485359192\n",
      "epoch 65: loss=0.9955164790153503\n",
      "epoch 66: loss=0.9963907599449158\n",
      "epoch 67: loss=0.9736525416374207\n",
      "epoch 68: loss=0.9695578813552856\n",
      "epoch 69: loss=0.9673886895179749\n",
      "epoch 70: loss=0.9715214371681213\n",
      "epoch 71: loss=0.9738641381263733\n",
      "epoch 72: loss=0.9630611538887024\n",
      "epoch 73: loss=0.9517581462860107\n",
      "epoch 74: loss=0.9791945219039917\n",
      "epoch 75: loss=0.9537477493286133\n",
      "epoch 76: loss=0.9449340105056763\n",
      "epoch 77: loss=0.9505457878112793\n",
      "epoch 78: loss=0.9491655230522156\n",
      "epoch 79: loss=0.9402399659156799\n",
      "epoch 80: loss=0.9771783351898193\n",
      "epoch 81: loss=0.9610339999198914\n",
      "epoch 82: loss=0.945245623588562\n",
      "epoch 83: loss=0.9448658227920532\n",
      "epoch 84: loss=0.9368668794631958\n",
      "epoch 85: loss=0.9604367613792419\n",
      "epoch 86: loss=0.9723144173622131\n",
      "epoch 87: loss=0.9549852609634399\n",
      "epoch 88: loss=0.9558382034301758\n",
      "epoch 89: loss=0.9402233958244324\n",
      "epoch 90: loss=0.9560229778289795\n",
      "epoch 91: loss=0.9582549333572388\n",
      "epoch 92: loss=0.9483616352081299\n",
      "epoch 93: loss=0.9495826959609985\n",
      "epoch 94: loss=0.9508195519447327\n",
      "epoch 95: loss=0.9484660625457764\n",
      "epoch 96: loss=0.9331744313240051\n",
      "epoch 97: loss=0.9480960965156555\n",
      "epoch 98: loss=0.9427465200424194\n",
      "epoch 99: loss=0.9339499473571777\n",
      "epoch 100: loss=0.9502447843551636\n",
      "epoch 101: loss=0.9383005499839783\n",
      "epoch 102: loss=0.9347532987594604\n",
      "epoch 103: loss=0.9374269843101501\n",
      "epoch 104: loss=0.9400472640991211\n",
      "epoch 105: loss=0.9303523898124695\n",
      "epoch 106: loss=0.9404079914093018\n",
      "epoch 107: loss=0.9382109642028809\n",
      "epoch 108: loss=0.9394392371177673\n",
      "epoch 109: loss=0.9341816306114197\n",
      "epoch 110: loss=0.930136501789093\n",
      "epoch 111: loss=0.9420909881591797\n",
      "epoch 112: loss=0.9500107765197754\n",
      "epoch 113: loss=0.9519449472427368\n",
      "epoch 114: loss=0.9206960797309875\n",
      "epoch 115: loss=0.9530451893806458\n",
      "epoch 116: loss=0.936716616153717\n",
      "epoch 117: loss=0.9279170632362366\n",
      "epoch 118: loss=0.9386826157569885\n",
      "epoch 119: loss=0.919472336769104\n",
      "epoch 120: loss=0.9235118627548218\n",
      "epoch 121: loss=0.9348533749580383\n",
      "epoch 122: loss=0.9083307981491089\n",
      "epoch 123: loss=0.911851704120636\n",
      "epoch 124: loss=0.9278585910797119\n",
      "epoch 125: loss=0.9276174902915955\n",
      "epoch 126: loss=0.9296584725379944\n",
      "epoch 127: loss=0.9256795644760132\n",
      "epoch 128: loss=0.9580751061439514\n",
      "epoch 129: loss=0.93552565574646\n",
      "epoch 130: loss=0.908872127532959\n",
      "epoch 131: loss=0.9145027995109558\n",
      "epoch 132: loss=0.9084445238113403\n",
      "epoch 133: loss=0.9125313758850098\n",
      "epoch 134: loss=0.9166260361671448\n",
      "epoch 135: loss=0.917776882648468\n",
      "epoch 136: loss=0.9276411533355713\n",
      "epoch 137: loss=0.9325099587440491\n",
      "epoch 138: loss=0.9400084018707275\n",
      "epoch 139: loss=0.9264491200447083\n",
      "epoch 140: loss=0.9258714914321899\n",
      "epoch 141: loss=0.9155741930007935\n",
      "epoch 142: loss=0.9251073002815247\n",
      "epoch 143: loss=0.9287066459655762\n",
      "epoch 144: loss=0.9164912700653076\n",
      "epoch 145: loss=0.9346797466278076\n",
      "epoch 146: loss=0.9244686961174011\n",
      "epoch 147: loss=0.9051737785339355\n",
      "epoch 148: loss=0.9457735419273376\n",
      "epoch 149: loss=0.8972135186195374\n",
      "epoch 150: loss=0.8949111104011536\n",
      "epoch 151: loss=0.9206563234329224\n",
      "epoch 152: loss=0.9327051639556885\n",
      "epoch 153: loss=0.9158228039741516\n",
      "epoch 154: loss=0.9405072927474976\n",
      "epoch 155: loss=0.9212899804115295\n",
      "epoch 156: loss=0.9039064645767212\n",
      "epoch 157: loss=0.9407199621200562\n",
      "epoch 158: loss=0.9112008213996887\n",
      "epoch 159: loss=0.9287388920783997\n",
      "epoch 160: loss=0.913336992263794\n",
      "epoch 161: loss=0.9438482522964478\n",
      "epoch 162: loss=0.9280272722244263\n",
      "epoch 163: loss=0.9068072438240051\n",
      "epoch 164: loss=0.9421833157539368\n",
      "epoch 165: loss=0.9192075729370117\n",
      "epoch 166: loss=0.9196743965148926\n",
      "epoch 167: loss=0.9078081250190735\n",
      "epoch 168: loss=0.9200963377952576\n",
      "epoch 169: loss=0.898134708404541\n",
      "epoch 170: loss=0.9064969420433044\n",
      "epoch 171: loss=0.913179337978363\n",
      "epoch 172: loss=0.8993518948554993\n",
      "epoch 173: loss=0.90617436170578\n",
      "epoch 174: loss=0.9162269830703735\n",
      "epoch 175: loss=0.9211939573287964\n",
      "epoch 176: loss=0.9335309267044067\n",
      "epoch 177: loss=0.9145306348800659\n",
      "epoch 178: loss=0.9060744643211365\n",
      "epoch 179: loss=0.944960355758667\n",
      "epoch 180: loss=0.9210054874420166\n",
      "epoch 181: loss=0.9131565093994141\n",
      "epoch 182: loss=0.9085074067115784\n",
      "epoch 183: loss=0.9129794239997864\n",
      "epoch 184: loss=0.9082044363021851\n",
      "epoch 185: loss=0.9105527400970459\n",
      "epoch 186: loss=0.9153479933738708\n",
      "epoch 187: loss=0.937133252620697\n",
      "epoch 188: loss=0.9141108393669128\n",
      "epoch 189: loss=0.9083038568496704\n",
      "epoch 190: loss=0.9152429103851318\n",
      "epoch 191: loss=0.9194599390029907\n",
      "epoch 192: loss=0.9301806092262268\n",
      "epoch 193: loss=0.8933030962944031\n",
      "epoch 194: loss=0.9128997325897217\n",
      "epoch 195: loss=0.9126698970794678\n",
      "epoch 196: loss=0.9290810227394104\n",
      "epoch 197: loss=0.9173051118850708\n",
      "epoch 198: loss=0.9040966033935547\n",
      "epoch 199: loss=0.8772329688072205\n",
      "training patch with 1878 edges\n",
      "epoch 0: loss=4.719152927398682\n",
      "epoch 1: loss=4.512879848480225\n",
      "epoch 2: loss=4.117234230041504\n",
      "epoch 3: loss=4.404742240905762\n",
      "epoch 4: loss=3.979311227798462\n",
      "epoch 5: loss=3.5037307739257812\n",
      "epoch 6: loss=3.5065624713897705\n",
      "epoch 7: loss=2.995009660720825\n",
      "epoch 8: loss=2.861825466156006\n",
      "epoch 9: loss=2.603006362915039\n",
      "epoch 10: loss=2.4431934356689453\n",
      "epoch 11: loss=2.0816311836242676\n",
      "epoch 12: loss=1.975653052330017\n",
      "epoch 13: loss=1.8643513917922974\n",
      "epoch 14: loss=1.66977858543396\n",
      "epoch 15: loss=1.5863639116287231\n",
      "epoch 16: loss=1.5262110233306885\n",
      "epoch 17: loss=1.5144472122192383\n",
      "epoch 18: loss=1.4880703687667847\n",
      "epoch 19: loss=1.4547460079193115\n",
      "epoch 20: loss=1.432074785232544\n",
      "epoch 21: loss=1.4359102249145508\n",
      "epoch 22: loss=1.441239356994629\n",
      "epoch 23: loss=1.4097055196762085\n",
      "epoch 24: loss=1.3867207765579224\n",
      "epoch 25: loss=1.3854470252990723\n",
      "epoch 26: loss=1.3847827911376953\n",
      "epoch 27: loss=1.3603107929229736\n",
      "epoch 28: loss=1.3644944429397583\n",
      "epoch 29: loss=1.3666125535964966\n",
      "epoch 30: loss=1.344744324684143\n",
      "epoch 31: loss=1.3322324752807617\n",
      "epoch 32: loss=1.325299620628357\n",
      "epoch 33: loss=1.3171173334121704\n",
      "epoch 34: loss=1.309206247329712\n",
      "epoch 35: loss=1.2901322841644287\n",
      "epoch 36: loss=1.263912558555603\n",
      "epoch 37: loss=1.2619743347167969\n",
      "epoch 38: loss=1.2303228378295898\n",
      "epoch 39: loss=1.2058193683624268\n",
      "epoch 40: loss=1.1770387887954712\n",
      "epoch 41: loss=1.157975435256958\n",
      "epoch 42: loss=1.1350427865982056\n",
      "epoch 43: loss=1.1144379377365112\n",
      "epoch 44: loss=1.097439169883728\n",
      "epoch 45: loss=1.1095246076583862\n",
      "epoch 46: loss=1.1074573993682861\n",
      "epoch 47: loss=1.0860157012939453\n",
      "epoch 48: loss=1.111297607421875\n",
      "epoch 49: loss=1.095562219619751\n",
      "epoch 50: loss=1.0979294776916504\n",
      "epoch 51: loss=1.0824978351593018\n",
      "epoch 52: loss=1.0418673753738403\n",
      "epoch 53: loss=1.0688769817352295\n",
      "epoch 54: loss=1.0687497854232788\n",
      "epoch 55: loss=1.0478994846343994\n",
      "epoch 56: loss=1.0323857069015503\n",
      "epoch 57: loss=1.024781346321106\n",
      "epoch 58: loss=1.0319414138793945\n",
      "epoch 59: loss=1.01884925365448\n",
      "epoch 60: loss=1.0369877815246582\n",
      "epoch 61: loss=1.0242329835891724\n",
      "epoch 62: loss=1.031246304512024\n",
      "epoch 63: loss=1.023219347000122\n",
      "epoch 64: loss=1.0222111940383911\n",
      "epoch 65: loss=1.023802638053894\n",
      "epoch 66: loss=1.0259637832641602\n",
      "epoch 67: loss=1.0245780944824219\n",
      "epoch 68: loss=0.9976433515548706\n",
      "epoch 69: loss=1.0173461437225342\n",
      "epoch 70: loss=1.0277358293533325\n",
      "epoch 71: loss=1.0051206350326538\n",
      "epoch 72: loss=0.9966005682945251\n",
      "epoch 73: loss=0.980809211730957\n",
      "epoch 74: loss=1.0126926898956299\n",
      "epoch 75: loss=1.0046838521957397\n",
      "epoch 76: loss=0.9928761720657349\n",
      "epoch 77: loss=0.9980723857879639\n",
      "epoch 78: loss=1.0079283714294434\n",
      "epoch 79: loss=1.001046061515808\n",
      "epoch 80: loss=0.9749010801315308\n",
      "epoch 81: loss=0.997736394405365\n",
      "epoch 82: loss=0.9973453283309937\n",
      "epoch 83: loss=0.998162031173706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84: loss=1.0072625875473022\n",
      "epoch 85: loss=0.9885584115982056\n",
      "epoch 86: loss=0.9896461963653564\n",
      "epoch 87: loss=0.987506091594696\n",
      "epoch 88: loss=0.9570573568344116\n",
      "epoch 89: loss=0.9930604100227356\n",
      "epoch 90: loss=0.980913519859314\n",
      "epoch 91: loss=0.9853472709655762\n",
      "epoch 92: loss=0.9797382950782776\n",
      "epoch 93: loss=0.9987504482269287\n",
      "epoch 94: loss=0.9920182228088379\n",
      "epoch 95: loss=1.001626968383789\n",
      "epoch 96: loss=0.9745168685913086\n",
      "epoch 97: loss=0.9866869449615479\n",
      "epoch 98: loss=0.9903402328491211\n",
      "epoch 99: loss=0.9849727153778076\n",
      "epoch 100: loss=0.9604133367538452\n",
      "epoch 101: loss=0.9755289554595947\n",
      "epoch 102: loss=0.978279173374176\n",
      "epoch 103: loss=0.9821091890335083\n",
      "epoch 104: loss=0.9615902304649353\n",
      "epoch 105: loss=0.9965563416481018\n",
      "epoch 106: loss=0.9839971661567688\n",
      "epoch 107: loss=0.9844990372657776\n",
      "epoch 108: loss=0.963493824005127\n",
      "epoch 109: loss=0.9885104894638062\n",
      "epoch 110: loss=0.9777621626853943\n",
      "epoch 111: loss=0.9707575440406799\n",
      "epoch 112: loss=0.9482944011688232\n",
      "epoch 113: loss=0.9721299409866333\n",
      "epoch 114: loss=0.9641175270080566\n",
      "epoch 115: loss=0.9974639415740967\n",
      "epoch 116: loss=0.9874267578125\n",
      "epoch 117: loss=0.9672419428825378\n",
      "epoch 118: loss=0.9566415548324585\n",
      "epoch 119: loss=0.9810780882835388\n",
      "epoch 120: loss=0.9602301120758057\n",
      "epoch 121: loss=0.958099901676178\n",
      "epoch 122: loss=0.9697381854057312\n",
      "epoch 123: loss=0.9722495079040527\n",
      "epoch 124: loss=0.991920530796051\n",
      "epoch 125: loss=0.9622800946235657\n",
      "epoch 126: loss=0.9533386826515198\n",
      "epoch 127: loss=0.974487841129303\n",
      "epoch 128: loss=0.9519283771514893\n",
      "epoch 129: loss=0.9801996946334839\n",
      "epoch 130: loss=0.9736130833625793\n",
      "epoch 131: loss=0.9690094590187073\n",
      "epoch 132: loss=0.9557737112045288\n",
      "epoch 133: loss=0.9343984127044678\n",
      "epoch 134: loss=0.979217529296875\n",
      "epoch 135: loss=0.9775010943412781\n",
      "epoch 136: loss=0.944076657295227\n",
      "epoch 137: loss=0.9572445750236511\n",
      "epoch 138: loss=0.9631341099739075\n",
      "epoch 139: loss=0.9787704348564148\n",
      "epoch 140: loss=0.939985454082489\n",
      "epoch 141: loss=0.9433420896530151\n",
      "epoch 142: loss=0.971137285232544\n",
      "epoch 143: loss=0.9623538255691528\n",
      "epoch 144: loss=0.9404657483100891\n",
      "epoch 145: loss=0.9901450872421265\n",
      "epoch 146: loss=0.9421001672744751\n",
      "epoch 147: loss=0.9474523067474365\n",
      "epoch 148: loss=0.9378275871276855\n",
      "epoch 149: loss=0.9472405910491943\n",
      "epoch 150: loss=0.9344984889030457\n",
      "epoch 151: loss=0.9461482763290405\n",
      "epoch 152: loss=0.9602236747741699\n",
      "epoch 153: loss=0.9425581097602844\n",
      "epoch 154: loss=0.9564699530601501\n",
      "epoch 155: loss=0.9541779160499573\n",
      "epoch 156: loss=0.9344369769096375\n",
      "epoch 157: loss=0.9477841258049011\n",
      "epoch 158: loss=0.9424685835838318\n",
      "epoch 159: loss=0.9450197219848633\n",
      "epoch 160: loss=0.9680010080337524\n",
      "epoch 161: loss=0.9356881976127625\n",
      "epoch 162: loss=0.9523807764053345\n",
      "epoch 163: loss=0.9595637917518616\n",
      "epoch 164: loss=0.9445762038230896\n",
      "epoch 165: loss=0.9375349283218384\n",
      "epoch 166: loss=0.9364548921585083\n",
      "epoch 167: loss=0.9307106733322144\n",
      "epoch 168: loss=0.9528077244758606\n",
      "epoch 169: loss=0.9376854300498962\n",
      "epoch 170: loss=0.9473646879196167\n",
      "epoch 171: loss=0.9301882386207581\n",
      "epoch 172: loss=0.9571520090103149\n",
      "epoch 173: loss=0.9602457284927368\n",
      "epoch 174: loss=0.9554475545883179\n",
      "epoch 175: loss=0.954082727432251\n",
      "epoch 176: loss=0.9561406970024109\n",
      "epoch 177: loss=0.9416788816452026\n",
      "epoch 178: loss=0.9364587664604187\n",
      "epoch 179: loss=0.9460859298706055\n",
      "epoch 180: loss=0.9480957388877869\n",
      "epoch 181: loss=0.9557402729988098\n",
      "epoch 182: loss=0.9448867440223694\n",
      "epoch 183: loss=0.961814820766449\n",
      "epoch 184: loss=0.9392696619033813\n",
      "epoch 185: loss=0.9531420469284058\n",
      "epoch 186: loss=0.9314975738525391\n",
      "epoch 187: loss=0.9454789161682129\n",
      "epoch 188: loss=0.9519199728965759\n",
      "epoch 189: loss=0.9501621127128601\n",
      "epoch 190: loss=0.9436718225479126\n",
      "epoch 191: loss=0.9375693798065186\n",
      "epoch 192: loss=0.9438223242759705\n",
      "epoch 193: loss=0.92035311460495\n",
      "epoch 194: loss=0.9406419396400452\n",
      "epoch 195: loss=0.9422074556350708\n",
      "epoch 196: loss=0.9313357472419739\n",
      "epoch 197: loss=0.9358556866645813\n",
      "epoch 198: loss=0.9218010306358337\n",
      "epoch 199: loss=0.9367378354072571\n",
      "training patch with 2784 edges\n",
      "epoch 0: loss=4.763089656829834\n",
      "epoch 1: loss=4.43105411529541\n",
      "epoch 2: loss=4.255044460296631\n",
      "epoch 3: loss=4.063817977905273\n",
      "epoch 4: loss=3.7816269397735596\n",
      "epoch 5: loss=3.555788040161133\n",
      "epoch 6: loss=3.2233316898345947\n",
      "epoch 7: loss=3.1168508529663086\n",
      "epoch 8: loss=2.7103159427642822\n",
      "epoch 9: loss=2.6015851497650146\n",
      "epoch 10: loss=2.34024977684021\n",
      "epoch 11: loss=2.164247751235962\n",
      "epoch 12: loss=2.0694797039031982\n",
      "epoch 13: loss=1.8442376852035522\n",
      "epoch 14: loss=1.6961119174957275\n",
      "epoch 15: loss=1.624825119972229\n",
      "epoch 16: loss=1.528106451034546\n",
      "epoch 17: loss=1.4873406887054443\n",
      "epoch 18: loss=1.4613665342330933\n",
      "epoch 19: loss=1.4440605640411377\n",
      "epoch 20: loss=1.4260424375534058\n",
      "epoch 21: loss=1.412316083908081\n",
      "epoch 22: loss=1.4062538146972656\n",
      "epoch 23: loss=1.400282859802246\n",
      "epoch 24: loss=1.3762843608856201\n",
      "epoch 25: loss=1.3745321035385132\n",
      "epoch 26: loss=1.3730065822601318\n",
      "epoch 27: loss=1.3665423393249512\n",
      "epoch 28: loss=1.358795166015625\n",
      "epoch 29: loss=1.3539068698883057\n",
      "epoch 30: loss=1.3426889181137085\n",
      "epoch 31: loss=1.3403475284576416\n",
      "epoch 32: loss=1.3324459791183472\n",
      "epoch 33: loss=1.322280764579773\n",
      "epoch 34: loss=1.3218660354614258\n",
      "epoch 35: loss=1.3161178827285767\n",
      "epoch 36: loss=1.2990456819534302\n",
      "epoch 37: loss=1.2925573587417603\n",
      "epoch 38: loss=1.3016570806503296\n",
      "epoch 39: loss=1.2897945642471313\n",
      "epoch 40: loss=1.27018141746521\n",
      "epoch 41: loss=1.2555582523345947\n",
      "epoch 42: loss=1.2428377866744995\n",
      "epoch 43: loss=1.223006010055542\n",
      "epoch 44: loss=1.211951732635498\n",
      "epoch 45: loss=1.1992161273956299\n",
      "epoch 46: loss=1.1747912168502808\n",
      "epoch 47: loss=1.1544816493988037\n",
      "epoch 48: loss=1.1461334228515625\n",
      "epoch 49: loss=1.120916485786438\n",
      "epoch 50: loss=1.1110895872116089\n",
      "epoch 51: loss=1.0869008302688599\n",
      "epoch 52: loss=1.0860787630081177\n",
      "epoch 53: loss=1.0754653215408325\n",
      "epoch 54: loss=1.0909525156021118\n",
      "epoch 55: loss=1.0679293870925903\n",
      "epoch 56: loss=1.0847563743591309\n",
      "epoch 57: loss=1.0729467868804932\n",
      "epoch 58: loss=1.0545281171798706\n",
      "epoch 59: loss=1.05774986743927\n",
      "epoch 60: loss=1.0602307319641113\n",
      "epoch 61: loss=1.0575482845306396\n",
      "epoch 62: loss=1.0351290702819824\n",
      "epoch 63: loss=1.0398132801055908\n",
      "epoch 64: loss=1.0153001546859741\n",
      "epoch 65: loss=1.0288766622543335\n",
      "epoch 66: loss=1.0275131464004517\n",
      "epoch 67: loss=1.020785927772522\n",
      "epoch 68: loss=1.0236526727676392\n",
      "epoch 69: loss=1.0222492218017578\n",
      "epoch 70: loss=1.0046907663345337\n",
      "epoch 71: loss=0.9955499768257141\n",
      "epoch 72: loss=1.0047948360443115\n",
      "epoch 73: loss=0.9831339716911316\n",
      "epoch 74: loss=0.9780577421188354\n",
      "epoch 75: loss=1.0026501417160034\n",
      "epoch 76: loss=0.9970990419387817\n",
      "epoch 77: loss=0.9688224792480469\n",
      "epoch 78: loss=0.9809789657592773\n",
      "epoch 79: loss=0.969884991645813\n",
      "epoch 80: loss=0.9942094087600708\n",
      "epoch 81: loss=1.0000417232513428\n",
      "epoch 82: loss=0.9587323665618896\n",
      "epoch 83: loss=0.9670230746269226\n",
      "epoch 84: loss=0.9827412366867065\n",
      "epoch 85: loss=0.9620440602302551\n",
      "epoch 86: loss=0.9707489013671875\n",
      "epoch 87: loss=0.9814860820770264\n",
      "epoch 88: loss=0.9729863405227661\n",
      "epoch 89: loss=0.9855889678001404\n",
      "epoch 90: loss=0.9594043493270874\n",
      "epoch 91: loss=0.9727191925048828\n",
      "epoch 92: loss=0.9531334638595581\n",
      "epoch 93: loss=0.9622877836227417\n",
      "epoch 94: loss=0.9676814079284668\n",
      "epoch 95: loss=0.9772626757621765\n",
      "epoch 96: loss=0.9558838605880737\n",
      "epoch 97: loss=0.9757081270217896\n",
      "epoch 98: loss=0.970038890838623\n",
      "epoch 99: loss=0.9527547955513\n",
      "epoch 100: loss=0.9542034864425659\n",
      "epoch 101: loss=0.9589666128158569\n",
      "epoch 102: loss=0.9468424320220947\n",
      "epoch 103: loss=0.9563317894935608\n",
      "epoch 104: loss=0.9368640184402466\n",
      "epoch 105: loss=0.9517292976379395\n",
      "epoch 106: loss=0.9478002786636353\n",
      "epoch 107: loss=0.947808027267456\n",
      "epoch 108: loss=0.9302055835723877\n",
      "epoch 109: loss=0.9595397114753723\n",
      "epoch 110: loss=0.9532464146614075\n",
      "epoch 111: loss=0.9559941291809082\n",
      "epoch 112: loss=0.9553341865539551\n",
      "epoch 113: loss=0.950391948223114\n",
      "epoch 114: loss=0.9367085695266724\n",
      "epoch 115: loss=0.9588528871536255\n",
      "epoch 116: loss=0.9510135650634766\n",
      "epoch 117: loss=0.9367278814315796\n",
      "epoch 118: loss=0.9449113607406616\n",
      "epoch 119: loss=0.9546821117401123\n",
      "epoch 120: loss=0.9193509817123413\n",
      "epoch 121: loss=0.948289155960083\n",
      "epoch 122: loss=0.9482060074806213\n",
      "epoch 123: loss=0.9418237209320068\n",
      "epoch 124: loss=0.9397366046905518\n",
      "epoch 125: loss=0.9345537424087524\n",
      "epoch 126: loss=0.9394583702087402\n",
      "epoch 127: loss=0.9197257161140442\n",
      "epoch 128: loss=0.9646040201187134\n",
      "epoch 129: loss=0.9419218301773071\n",
      "epoch 130: loss=0.9256713390350342\n",
      "epoch 131: loss=0.9386164546012878\n",
      "epoch 132: loss=0.9195185899734497\n",
      "epoch 133: loss=0.9379941821098328\n",
      "epoch 134: loss=0.9288250803947449\n",
      "epoch 135: loss=0.9423713684082031\n",
      "epoch 136: loss=0.9298170804977417\n",
      "epoch 137: loss=0.9232050180435181\n",
      "epoch 138: loss=0.957717776298523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 139: loss=0.9257228374481201\n",
      "epoch 140: loss=0.92080157995224\n",
      "epoch 141: loss=0.9246829152107239\n",
      "epoch 142: loss=0.9108940362930298\n",
      "epoch 143: loss=0.9170374870300293\n",
      "epoch 144: loss=0.921373188495636\n",
      "epoch 145: loss=0.9271255731582642\n",
      "epoch 146: loss=0.925122857093811\n",
      "epoch 147: loss=0.9115230441093445\n",
      "epoch 148: loss=0.938994288444519\n",
      "epoch 149: loss=0.9268733263015747\n",
      "epoch 150: loss=0.9301790595054626\n",
      "epoch 151: loss=0.9127997756004333\n",
      "epoch 152: loss=0.9155071973800659\n",
      "epoch 153: loss=0.906125009059906\n",
      "epoch 154: loss=0.9281494617462158\n",
      "epoch 155: loss=0.917358934879303\n",
      "epoch 156: loss=0.9233775734901428\n",
      "epoch 157: loss=0.9220021367073059\n",
      "epoch 158: loss=0.9246546030044556\n",
      "epoch 159: loss=0.9159040451049805\n",
      "epoch 160: loss=0.940230667591095\n",
      "epoch 161: loss=0.8990418910980225\n",
      "epoch 162: loss=0.9272919297218323\n",
      "epoch 163: loss=0.9318501949310303\n",
      "epoch 164: loss=0.9279681444168091\n",
      "epoch 165: loss=0.9251818060874939\n",
      "epoch 166: loss=0.911668062210083\n",
      "epoch 167: loss=0.9274678230285645\n",
      "epoch 168: loss=0.8944474458694458\n",
      "epoch 169: loss=0.9196391105651855\n",
      "epoch 170: loss=0.918576180934906\n",
      "epoch 171: loss=0.9015666842460632\n",
      "epoch 172: loss=0.9160921573638916\n",
      "epoch 173: loss=0.9014596939086914\n",
      "epoch 174: loss=0.9215883612632751\n",
      "epoch 175: loss=0.9225939512252808\n",
      "epoch 176: loss=0.9111620783805847\n",
      "epoch 177: loss=0.9278806447982788\n",
      "epoch 178: loss=0.8894906044006348\n",
      "epoch 179: loss=0.8961484432220459\n",
      "epoch 180: loss=0.8954979181289673\n",
      "epoch 181: loss=0.8994200825691223\n",
      "epoch 182: loss=0.9119889736175537\n",
      "epoch 183: loss=0.9079256057739258\n",
      "epoch 184: loss=0.8969210982322693\n",
      "epoch 185: loss=0.9167698621749878\n",
      "epoch 186: loss=0.892627477645874\n",
      "epoch 187: loss=0.8982495665550232\n",
      "epoch 188: loss=0.9022352695465088\n",
      "epoch 189: loss=0.9016479253768921\n",
      "epoch 190: loss=0.9238495826721191\n",
      "epoch 191: loss=0.9063101410865784\n",
      "epoch 192: loss=0.902999997138977\n",
      "epoch 193: loss=0.9088483452796936\n",
      "epoch 194: loss=0.9180295467376709\n",
      "epoch 195: loss=0.9177074432373047\n",
      "epoch 196: loss=0.9100315570831299\n",
      "epoch 197: loss=0.9168567657470703\n",
      "epoch 198: loss=0.9104173183441162\n",
      "epoch 199: loss=0.9047654867172241\n",
      "training patch with 1652 edges\n",
      "epoch 0: loss=4.759110927581787\n",
      "epoch 1: loss=4.509737968444824\n",
      "epoch 2: loss=4.438603401184082\n",
      "epoch 3: loss=4.1868462562561035\n",
      "epoch 4: loss=3.9445223808288574\n",
      "epoch 5: loss=3.6617953777313232\n",
      "epoch 6: loss=3.6167523860931396\n",
      "epoch 7: loss=3.302874803543091\n",
      "epoch 8: loss=3.277036666870117\n",
      "epoch 9: loss=3.0292248725891113\n",
      "epoch 10: loss=2.6640913486480713\n",
      "epoch 11: loss=2.4275941848754883\n",
      "epoch 12: loss=2.2454395294189453\n",
      "epoch 13: loss=2.0940864086151123\n",
      "epoch 14: loss=1.8905800580978394\n",
      "epoch 15: loss=1.84255051612854\n",
      "epoch 16: loss=1.6527084112167358\n",
      "epoch 17: loss=1.5546678304672241\n",
      "epoch 18: loss=1.5516636371612549\n",
      "epoch 19: loss=1.5046249628067017\n",
      "epoch 20: loss=1.478431224822998\n",
      "epoch 21: loss=1.4376578330993652\n",
      "epoch 22: loss=1.4193038940429688\n",
      "epoch 23: loss=1.4292562007904053\n",
      "epoch 24: loss=1.4172885417938232\n",
      "epoch 25: loss=1.408835768699646\n",
      "epoch 26: loss=1.3914371728897095\n",
      "epoch 27: loss=1.3793681859970093\n",
      "epoch 28: loss=1.3739877939224243\n",
      "epoch 29: loss=1.3636786937713623\n",
      "epoch 30: loss=1.3558727502822876\n",
      "epoch 31: loss=1.33979070186615\n",
      "epoch 32: loss=1.3266202211380005\n",
      "epoch 33: loss=1.3078560829162598\n",
      "epoch 34: loss=1.2949391603469849\n",
      "epoch 35: loss=1.2684993743896484\n",
      "epoch 36: loss=1.247465968132019\n",
      "epoch 37: loss=1.2257150411605835\n",
      "epoch 38: loss=1.197069525718689\n",
      "epoch 39: loss=1.1784653663635254\n",
      "epoch 40: loss=1.1513302326202393\n",
      "epoch 41: loss=1.1447290182113647\n",
      "epoch 42: loss=1.1093484163284302\n",
      "epoch 43: loss=1.0999504327774048\n",
      "epoch 44: loss=1.1093201637268066\n",
      "epoch 45: loss=1.1299957036972046\n",
      "epoch 46: loss=1.100969672203064\n",
      "epoch 47: loss=1.113919734954834\n",
      "epoch 48: loss=1.114461064338684\n",
      "epoch 49: loss=1.0859817266464233\n",
      "epoch 50: loss=1.0842708349227905\n",
      "epoch 51: loss=1.1013462543487549\n",
      "epoch 52: loss=1.1012146472930908\n",
      "epoch 53: loss=1.0409319400787354\n",
      "epoch 54: loss=1.056989312171936\n",
      "epoch 55: loss=1.0385671854019165\n",
      "epoch 56: loss=1.0293527841567993\n",
      "epoch 57: loss=1.0421323776245117\n",
      "epoch 58: loss=1.0374430418014526\n",
      "epoch 59: loss=1.0417375564575195\n",
      "epoch 60: loss=1.0318870544433594\n",
      "epoch 61: loss=1.0221960544586182\n",
      "epoch 62: loss=1.0153613090515137\n",
      "epoch 63: loss=1.0185140371322632\n",
      "epoch 64: loss=1.0113682746887207\n",
      "epoch 65: loss=0.9954322576522827\n",
      "epoch 66: loss=1.0066444873809814\n",
      "epoch 67: loss=1.0017272233963013\n",
      "epoch 68: loss=1.003208875656128\n",
      "epoch 69: loss=1.0051532983779907\n",
      "epoch 70: loss=0.9951459169387817\n",
      "epoch 71: loss=0.9992086887359619\n",
      "epoch 72: loss=0.9878224730491638\n",
      "epoch 73: loss=0.9915070533752441\n",
      "epoch 74: loss=0.9789754152297974\n",
      "epoch 75: loss=0.9592739939689636\n",
      "epoch 76: loss=0.9898263812065125\n",
      "epoch 77: loss=0.9820207357406616\n",
      "epoch 78: loss=0.9936017990112305\n",
      "epoch 79: loss=1.0055720806121826\n",
      "epoch 80: loss=0.9500742554664612\n",
      "epoch 81: loss=0.9774702191352844\n",
      "epoch 82: loss=0.9891022443771362\n",
      "epoch 83: loss=0.9843714237213135\n",
      "epoch 84: loss=0.9399459958076477\n",
      "epoch 85: loss=0.9747253656387329\n",
      "epoch 86: loss=0.9857931137084961\n",
      "epoch 87: loss=0.968150794506073\n",
      "epoch 88: loss=0.972079336643219\n",
      "epoch 89: loss=0.9860421419143677\n",
      "epoch 90: loss=0.9840658903121948\n",
      "epoch 91: loss=0.9775663614273071\n",
      "epoch 92: loss=0.9702649712562561\n",
      "epoch 93: loss=0.9812524318695068\n",
      "epoch 94: loss=0.9938866496086121\n",
      "epoch 95: loss=0.9753822088241577\n",
      "epoch 96: loss=0.9631123542785645\n",
      "epoch 97: loss=0.9769343733787537\n",
      "epoch 98: loss=0.9852659702301025\n",
      "epoch 99: loss=0.9772852063179016\n",
      "epoch 100: loss=0.9710224270820618\n",
      "epoch 101: loss=0.9632686972618103\n",
      "epoch 102: loss=0.9673518538475037\n",
      "epoch 103: loss=0.9557290077209473\n",
      "epoch 104: loss=0.9792362451553345\n",
      "epoch 105: loss=0.9688314199447632\n",
      "epoch 106: loss=0.957677960395813\n",
      "epoch 107: loss=0.9524703621864319\n",
      "epoch 108: loss=0.9567978382110596\n",
      "epoch 109: loss=0.9649538993835449\n",
      "epoch 110: loss=0.9579308032989502\n",
      "epoch 111: loss=0.9782020449638367\n",
      "epoch 112: loss=0.9432459473609924\n",
      "epoch 113: loss=0.9589442610740662\n",
      "epoch 114: loss=0.9684918522834778\n",
      "epoch 115: loss=0.9600428938865662\n",
      "epoch 116: loss=0.950474739074707\n",
      "epoch 117: loss=0.9661891460418701\n",
      "epoch 118: loss=0.962046205997467\n",
      "epoch 119: loss=0.9581786394119263\n",
      "epoch 120: loss=0.9471650719642639\n",
      "epoch 121: loss=0.9703834056854248\n",
      "epoch 122: loss=0.9759964942932129\n",
      "epoch 123: loss=0.9422504901885986\n",
      "epoch 124: loss=0.9863877892494202\n",
      "epoch 125: loss=0.964823305606842\n",
      "epoch 126: loss=0.9682908058166504\n",
      "epoch 127: loss=0.9863123893737793\n",
      "epoch 128: loss=0.9658854007720947\n",
      "epoch 129: loss=0.9375337362289429\n",
      "epoch 130: loss=0.9758947491645813\n",
      "epoch 131: loss=0.9489439129829407\n",
      "epoch 132: loss=0.951744556427002\n",
      "epoch 133: loss=0.9580709338188171\n",
      "epoch 134: loss=0.9526633620262146\n",
      "epoch 135: loss=0.9511884450912476\n",
      "epoch 136: loss=0.9462096095085144\n",
      "epoch 137: loss=0.9659194946289062\n",
      "epoch 138: loss=0.9528114199638367\n",
      "epoch 139: loss=0.950835645198822\n",
      "epoch 140: loss=0.933103621006012\n",
      "epoch 141: loss=0.9423229098320007\n",
      "epoch 142: loss=0.9482234716415405\n",
      "epoch 143: loss=0.9680002927780151\n",
      "epoch 144: loss=0.93797367811203\n",
      "epoch 145: loss=0.9776279926300049\n",
      "epoch 146: loss=0.95588618516922\n",
      "epoch 147: loss=0.9512795805931091\n",
      "epoch 148: loss=0.9696197509765625\n",
      "epoch 149: loss=0.9378208518028259\n",
      "epoch 150: loss=0.9721813797950745\n",
      "epoch 151: loss=0.9152755737304688\n",
      "epoch 152: loss=0.9342057108879089\n",
      "epoch 153: loss=0.9512816667556763\n",
      "epoch 154: loss=0.9420408606529236\n",
      "epoch 155: loss=0.9415236711502075\n",
      "epoch 156: loss=0.9534568190574646\n",
      "epoch 157: loss=0.9415329694747925\n",
      "epoch 158: loss=0.9590165019035339\n",
      "epoch 159: loss=0.9476056098937988\n",
      "epoch 160: loss=0.9608460068702698\n",
      "epoch 161: loss=0.9183833599090576\n",
      "epoch 162: loss=0.9563947916030884\n",
      "epoch 163: loss=0.9354180693626404\n",
      "epoch 164: loss=0.9264428615570068\n",
      "epoch 165: loss=0.9492813944816589\n",
      "epoch 166: loss=0.951697826385498\n",
      "epoch 167: loss=0.9576917290687561\n",
      "epoch 168: loss=0.9351069927215576\n",
      "epoch 169: loss=0.9322302937507629\n",
      "epoch 170: loss=0.9357059001922607\n",
      "epoch 171: loss=0.943135142326355\n",
      "epoch 172: loss=0.9345518350601196\n",
      "epoch 173: loss=0.9519618153572083\n",
      "epoch 174: loss=0.9373686909675598\n",
      "epoch 175: loss=0.9443716406822205\n",
      "epoch 176: loss=0.9260764718055725\n",
      "epoch 177: loss=0.9251206517219543\n",
      "epoch 178: loss=0.9338811039924622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179: loss=0.9363888502120972\n",
      "epoch 180: loss=0.9236276149749756\n",
      "epoch 181: loss=0.9261636734008789\n",
      "epoch 182: loss=0.9357866644859314\n",
      "epoch 183: loss=0.9177855849266052\n",
      "epoch 184: loss=0.931125819683075\n",
      "epoch 185: loss=0.918196439743042\n",
      "epoch 186: loss=0.9308604001998901\n",
      "epoch 187: loss=0.9493473768234253\n",
      "epoch 188: loss=0.926328182220459\n",
      "epoch 189: loss=0.9333856701850891\n",
      "epoch 190: loss=0.9325076341629028\n",
      "epoch 191: loss=0.881605327129364\n",
      "epoch 192: loss=0.9115180373191833\n",
      "epoch 193: loss=0.9303653240203857\n",
      "epoch 194: loss=0.9584967494010925\n",
      "epoch 195: loss=0.9312601089477539\n",
      "epoch 196: loss=0.9182707667350769\n",
      "epoch 197: loss=0.9352793097496033\n",
      "epoch 198: loss=0.9321179986000061\n",
      "epoch 199: loss=0.9209132790565491\n",
      "training patch with 840 edges\n",
      "epoch 0: loss=4.808577537536621\n",
      "epoch 1: loss=4.692917823791504\n",
      "epoch 2: loss=4.429296493530273\n",
      "epoch 3: loss=4.340085506439209\n",
      "epoch 4: loss=4.33628511428833\n",
      "epoch 5: loss=3.6853649616241455\n",
      "epoch 6: loss=3.8052430152893066\n",
      "epoch 7: loss=3.288057804107666\n",
      "epoch 8: loss=3.216383457183838\n",
      "epoch 9: loss=3.0302212238311768\n",
      "epoch 10: loss=2.8226077556610107\n",
      "epoch 11: loss=2.4757015705108643\n",
      "epoch 12: loss=2.3540308475494385\n",
      "epoch 13: loss=2.4210164546966553\n",
      "epoch 14: loss=2.127385139465332\n",
      "epoch 15: loss=1.9840192794799805\n",
      "epoch 16: loss=1.8243257999420166\n",
      "epoch 17: loss=1.7829519510269165\n",
      "epoch 18: loss=1.5692057609558105\n",
      "epoch 19: loss=1.6072633266448975\n",
      "epoch 20: loss=1.5369634628295898\n",
      "epoch 21: loss=1.4921469688415527\n",
      "epoch 22: loss=1.4686558246612549\n",
      "epoch 23: loss=1.4784473180770874\n",
      "epoch 24: loss=1.4623167514801025\n",
      "epoch 25: loss=1.4640713930130005\n",
      "epoch 26: loss=1.46591317653656\n",
      "epoch 27: loss=1.41763436794281\n",
      "epoch 28: loss=1.4201202392578125\n",
      "epoch 29: loss=1.4240624904632568\n",
      "epoch 30: loss=1.425661325454712\n",
      "epoch 31: loss=1.3938957452774048\n",
      "epoch 32: loss=1.3925646543502808\n",
      "epoch 33: loss=1.381256341934204\n",
      "epoch 34: loss=1.3800684213638306\n",
      "epoch 35: loss=1.3677654266357422\n",
      "epoch 36: loss=1.3486289978027344\n",
      "epoch 37: loss=1.3192873001098633\n",
      "epoch 38: loss=1.318572998046875\n",
      "epoch 39: loss=1.3084375858306885\n",
      "epoch 40: loss=1.2966433763504028\n",
      "epoch 41: loss=1.2798551321029663\n",
      "epoch 42: loss=1.253823161125183\n",
      "epoch 43: loss=1.2467284202575684\n",
      "epoch 44: loss=1.1947036981582642\n",
      "epoch 45: loss=1.2118664979934692\n",
      "epoch 46: loss=1.1817138195037842\n",
      "epoch 47: loss=1.176990270614624\n",
      "epoch 48: loss=1.1750646829605103\n",
      "epoch 49: loss=1.1575428247451782\n",
      "epoch 50: loss=1.1517720222473145\n",
      "epoch 51: loss=1.1483979225158691\n",
      "epoch 52: loss=1.1678799390792847\n",
      "epoch 53: loss=1.1736129522323608\n",
      "epoch 54: loss=1.136054515838623\n",
      "epoch 55: loss=1.1256048679351807\n",
      "epoch 56: loss=1.1458046436309814\n",
      "epoch 57: loss=1.1059213876724243\n",
      "epoch 58: loss=1.0956602096557617\n",
      "epoch 59: loss=1.0946435928344727\n",
      "epoch 60: loss=1.1069947481155396\n",
      "epoch 61: loss=1.0890284776687622\n",
      "epoch 62: loss=1.0852382183074951\n",
      "epoch 63: loss=1.0782431364059448\n",
      "epoch 64: loss=1.0643264055252075\n",
      "epoch 65: loss=1.0754655599594116\n",
      "epoch 66: loss=1.0870729684829712\n",
      "epoch 67: loss=1.0692461729049683\n",
      "epoch 68: loss=1.0711956024169922\n",
      "epoch 69: loss=1.064965009689331\n",
      "epoch 70: loss=1.0222053527832031\n",
      "epoch 71: loss=1.0473239421844482\n",
      "epoch 72: loss=1.0344483852386475\n",
      "epoch 73: loss=1.0474191904067993\n",
      "epoch 74: loss=1.0596380233764648\n",
      "epoch 75: loss=1.0545636415481567\n",
      "epoch 76: loss=1.0504814386367798\n",
      "epoch 77: loss=1.0776872634887695\n",
      "epoch 78: loss=1.0375826358795166\n",
      "epoch 79: loss=1.0216878652572632\n",
      "epoch 80: loss=1.063730239868164\n",
      "epoch 81: loss=1.049593448638916\n",
      "epoch 82: loss=1.0453166961669922\n",
      "epoch 83: loss=1.0318387746810913\n",
      "epoch 84: loss=1.0195448398590088\n",
      "epoch 85: loss=1.0494052171707153\n",
      "epoch 86: loss=1.005258321762085\n",
      "epoch 87: loss=1.0412209033966064\n",
      "epoch 88: loss=1.0547189712524414\n",
      "epoch 89: loss=1.0279146432876587\n",
      "epoch 90: loss=1.0464683771133423\n",
      "epoch 91: loss=1.0052387714385986\n",
      "epoch 92: loss=1.0209985971450806\n",
      "epoch 93: loss=1.0197731256484985\n",
      "epoch 94: loss=1.0287693738937378\n",
      "epoch 95: loss=1.0235992670059204\n",
      "epoch 96: loss=1.0306682586669922\n",
      "epoch 97: loss=1.0506701469421387\n",
      "epoch 98: loss=1.0143520832061768\n",
      "epoch 99: loss=1.0372257232666016\n",
      "epoch 100: loss=1.0162708759307861\n",
      "epoch 101: loss=1.023328185081482\n",
      "epoch 102: loss=0.9976233243942261\n",
      "epoch 103: loss=1.0171613693237305\n",
      "epoch 104: loss=1.0051289796829224\n",
      "epoch 105: loss=1.0342234373092651\n",
      "epoch 106: loss=1.0078189373016357\n",
      "epoch 107: loss=1.0505402088165283\n",
      "epoch 108: loss=1.0213487148284912\n",
      "epoch 109: loss=0.981776773929596\n",
      "epoch 110: loss=1.0441206693649292\n",
      "epoch 111: loss=1.0217549800872803\n",
      "epoch 112: loss=1.020868182182312\n",
      "epoch 113: loss=0.9954730272293091\n",
      "epoch 114: loss=1.012332558631897\n",
      "epoch 115: loss=1.0138334035873413\n",
      "epoch 116: loss=1.0156580209732056\n",
      "epoch 117: loss=1.043740153312683\n",
      "epoch 118: loss=1.027177333831787\n",
      "epoch 119: loss=1.0251601934432983\n",
      "epoch 120: loss=1.0220317840576172\n",
      "epoch 121: loss=1.0323779582977295\n",
      "epoch 122: loss=1.0569907426834106\n",
      "epoch 123: loss=1.0249171257019043\n",
      "epoch 124: loss=1.0161668062210083\n",
      "epoch 125: loss=1.0287379026412964\n",
      "epoch 126: loss=0.9840933680534363\n",
      "epoch 127: loss=0.9972079992294312\n",
      "epoch 128: loss=1.0102057456970215\n",
      "epoch 129: loss=0.9860279560089111\n",
      "epoch 130: loss=1.0357757806777954\n",
      "epoch 131: loss=0.9924222826957703\n",
      "epoch 132: loss=1.025405764579773\n",
      "epoch 133: loss=0.999662458896637\n",
      "epoch 134: loss=1.0139771699905396\n",
      "epoch 135: loss=0.987162172794342\n",
      "epoch 136: loss=0.9991825819015503\n",
      "epoch 137: loss=1.0127438306808472\n",
      "epoch 138: loss=0.9899251461029053\n",
      "epoch 139: loss=1.007968544960022\n",
      "epoch 140: loss=1.029891014099121\n",
      "epoch 141: loss=1.0226688385009766\n",
      "epoch 142: loss=1.0341821908950806\n",
      "epoch 143: loss=0.9754469394683838\n",
      "epoch 144: loss=1.02679443359375\n",
      "epoch 145: loss=1.0695409774780273\n",
      "epoch 146: loss=1.0090014934539795\n",
      "epoch 147: loss=1.002195119857788\n",
      "epoch 148: loss=1.0239732265472412\n",
      "epoch 149: loss=1.0053763389587402\n",
      "epoch 150: loss=1.023152470588684\n",
      "epoch 151: loss=0.9961161613464355\n",
      "epoch 152: loss=0.9967136383056641\n",
      "epoch 153: loss=0.9992048740386963\n",
      "epoch 154: loss=1.0142771005630493\n",
      "epoch 155: loss=0.9965609908103943\n",
      "epoch 156: loss=1.0146028995513916\n",
      "epoch 157: loss=0.9892567992210388\n",
      "epoch 158: loss=1.0274724960327148\n",
      "epoch 159: loss=0.9925705194473267\n",
      "epoch 160: loss=0.9979124069213867\n",
      "epoch 161: loss=1.0086278915405273\n",
      "epoch 162: loss=0.9645180106163025\n",
      "epoch 163: loss=1.028102993965149\n",
      "epoch 164: loss=1.0060482025146484\n",
      "epoch 165: loss=1.0083125829696655\n",
      "epoch 166: loss=0.9821720719337463\n",
      "epoch 167: loss=0.9965123534202576\n",
      "epoch 168: loss=0.9891563057899475\n",
      "epoch 169: loss=0.988579273223877\n",
      "epoch 170: loss=1.032617211341858\n",
      "epoch 171: loss=1.0369924306869507\n",
      "epoch 172: loss=1.0268195867538452\n",
      "epoch 173: loss=1.0068647861480713\n",
      "epoch 174: loss=0.9656392335891724\n",
      "epoch 175: loss=1.0222057104110718\n",
      "epoch 176: loss=0.988330066204071\n",
      "epoch 177: loss=0.9866943955421448\n",
      "epoch 178: loss=0.9932975172996521\n",
      "epoch 179: loss=1.0128061771392822\n",
      "epoch 180: loss=1.0029617547988892\n",
      "epoch 181: loss=1.0071468353271484\n",
      "epoch 182: loss=0.980857789516449\n",
      "epoch 183: loss=0.9963129162788391\n",
      "epoch 184: loss=0.9941110014915466\n",
      "epoch 185: loss=0.987819254398346\n",
      "epoch 186: loss=0.9861539602279663\n",
      "epoch 187: loss=1.0101451873779297\n",
      "epoch 188: loss=0.9854841232299805\n",
      "epoch 189: loss=0.986664354801178\n",
      "epoch 190: loss=0.9955780506134033\n",
      "epoch 191: loss=0.9831504821777344\n",
      "epoch 192: loss=0.9695420861244202\n",
      "epoch 193: loss=0.9636663794517517\n",
      "epoch 194: loss=0.9748598337173462\n",
      "epoch 195: loss=0.9849026203155518\n",
      "epoch 196: loss=0.995073676109314\n",
      "epoch 197: loss=0.9986467361450195\n",
      "epoch 198: loss=0.9977837800979614\n",
      "epoch 199: loss=1.0048655271530151\n",
      "training patch with 1460 edges\n",
      "epoch 0: loss=4.566198825836182\n",
      "epoch 1: loss=5.017570972442627\n",
      "epoch 2: loss=4.262852191925049\n",
      "epoch 3: loss=4.194540977478027\n",
      "epoch 4: loss=3.55507755279541\n",
      "epoch 5: loss=3.6169159412384033\n",
      "epoch 6: loss=3.184469699859619\n",
      "epoch 7: loss=2.925482749938965\n",
      "epoch 8: loss=2.6883716583251953\n",
      "epoch 9: loss=2.581881523132324\n",
      "epoch 10: loss=2.3478386402130127\n",
      "epoch 11: loss=2.204606771469116\n",
      "epoch 12: loss=2.0210800170898438\n",
      "epoch 13: loss=1.8099318742752075\n",
      "epoch 14: loss=1.7073396444320679\n",
      "epoch 15: loss=1.581711769104004\n",
      "epoch 16: loss=1.5618287324905396\n",
      "epoch 17: loss=1.5206685066223145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: loss=1.4554823637008667\n",
      "epoch 19: loss=1.4391669034957886\n",
      "epoch 20: loss=1.4545881748199463\n",
      "epoch 21: loss=1.4396156072616577\n",
      "epoch 22: loss=1.4289979934692383\n",
      "epoch 23: loss=1.4080065488815308\n",
      "epoch 24: loss=1.4074862003326416\n",
      "epoch 25: loss=1.3888342380523682\n",
      "epoch 26: loss=1.3832544088363647\n",
      "epoch 27: loss=1.3893678188323975\n",
      "epoch 28: loss=1.381864070892334\n",
      "epoch 29: loss=1.3773725032806396\n",
      "epoch 30: loss=1.3729742765426636\n",
      "epoch 31: loss=1.3672391176223755\n",
      "epoch 32: loss=1.3663219213485718\n",
      "epoch 33: loss=1.3567301034927368\n",
      "epoch 34: loss=1.342426061630249\n",
      "epoch 35: loss=1.3369921445846558\n",
      "epoch 36: loss=1.3166710138320923\n",
      "epoch 37: loss=1.3184505701065063\n",
      "epoch 38: loss=1.299738883972168\n",
      "epoch 39: loss=1.2745144367218018\n",
      "epoch 40: loss=1.2516839504241943\n",
      "epoch 41: loss=1.2419472932815552\n",
      "epoch 42: loss=1.211579442024231\n",
      "epoch 43: loss=1.1985139846801758\n",
      "epoch 44: loss=1.1761853694915771\n",
      "epoch 45: loss=1.1479164361953735\n",
      "epoch 46: loss=1.1212365627288818\n",
      "epoch 47: loss=1.109375\n",
      "epoch 48: loss=1.1414878368377686\n",
      "epoch 49: loss=1.1111644506454468\n",
      "epoch 50: loss=1.1195653676986694\n",
      "epoch 51: loss=1.1246626377105713\n",
      "epoch 52: loss=1.1248347759246826\n",
      "epoch 53: loss=1.1191914081573486\n",
      "epoch 54: loss=1.0988370180130005\n",
      "epoch 55: loss=1.0717304944992065\n",
      "epoch 56: loss=1.0854932069778442\n",
      "epoch 57: loss=1.0641613006591797\n",
      "epoch 58: loss=1.088575005531311\n",
      "epoch 59: loss=1.084673523902893\n",
      "epoch 60: loss=1.060031533241272\n",
      "epoch 61: loss=1.0657721757888794\n",
      "epoch 62: loss=1.0754350423812866\n",
      "epoch 63: loss=1.039299726486206\n",
      "epoch 64: loss=1.0661895275115967\n",
      "epoch 65: loss=1.0403451919555664\n",
      "epoch 66: loss=1.0442324876785278\n",
      "epoch 67: loss=1.050399661064148\n",
      "epoch 68: loss=1.0718786716461182\n",
      "epoch 69: loss=1.0395272970199585\n",
      "epoch 70: loss=1.049807071685791\n",
      "epoch 71: loss=1.0466136932373047\n",
      "epoch 72: loss=1.005608320236206\n",
      "epoch 73: loss=1.0471822023391724\n",
      "epoch 74: loss=1.0074845552444458\n",
      "epoch 75: loss=1.0483059883117676\n",
      "epoch 76: loss=1.0031147003173828\n",
      "epoch 77: loss=1.0033531188964844\n",
      "epoch 78: loss=1.0110636949539185\n",
      "epoch 79: loss=1.0123372077941895\n",
      "epoch 80: loss=0.9845750331878662\n",
      "epoch 81: loss=1.0170706510543823\n",
      "epoch 82: loss=1.000103235244751\n",
      "epoch 83: loss=0.9989298582077026\n",
      "epoch 84: loss=0.9984933733940125\n",
      "epoch 85: loss=1.020604133605957\n",
      "epoch 86: loss=0.9972401857376099\n",
      "epoch 87: loss=1.0016183853149414\n",
      "epoch 88: loss=0.9967312216758728\n",
      "epoch 89: loss=0.9925073981285095\n",
      "epoch 90: loss=0.9932799339294434\n",
      "epoch 91: loss=1.0037829875946045\n",
      "epoch 92: loss=1.0210522413253784\n",
      "epoch 93: loss=0.9945148229598999\n",
      "epoch 94: loss=0.9969193935394287\n",
      "epoch 95: loss=1.0191857814788818\n",
      "epoch 96: loss=0.999633252620697\n",
      "epoch 97: loss=0.9746612310409546\n",
      "epoch 98: loss=0.986847460269928\n",
      "epoch 99: loss=0.9931478500366211\n",
      "epoch 100: loss=0.9963217973709106\n",
      "epoch 101: loss=0.9900686144828796\n",
      "epoch 102: loss=0.9657976031303406\n",
      "epoch 103: loss=0.9911873936653137\n",
      "epoch 104: loss=0.9690919518470764\n",
      "epoch 105: loss=0.9842433333396912\n",
      "epoch 106: loss=0.9929686188697815\n",
      "epoch 107: loss=0.9808975458145142\n",
      "epoch 108: loss=0.974554181098938\n",
      "epoch 109: loss=0.9751182198524475\n",
      "epoch 110: loss=0.979107677936554\n",
      "epoch 111: loss=0.9632996320724487\n",
      "epoch 112: loss=0.9829292297363281\n",
      "epoch 113: loss=0.9732298254966736\n",
      "epoch 114: loss=0.9843022227287292\n",
      "epoch 115: loss=0.9595372080802917\n",
      "epoch 116: loss=0.9666777849197388\n",
      "epoch 117: loss=0.9591078758239746\n",
      "epoch 118: loss=0.9548096060752869\n",
      "epoch 119: loss=0.9756722450256348\n",
      "epoch 120: loss=0.985322892665863\n",
      "epoch 121: loss=0.9891358017921448\n",
      "epoch 122: loss=0.9770857095718384\n",
      "epoch 123: loss=0.9824333190917969\n",
      "epoch 124: loss=0.9484909176826477\n",
      "epoch 125: loss=0.9826462268829346\n",
      "epoch 126: loss=0.9431494474411011\n",
      "epoch 127: loss=0.973073422908783\n",
      "epoch 128: loss=0.9835623502731323\n",
      "epoch 129: loss=0.958276093006134\n",
      "epoch 130: loss=0.9605223536491394\n",
      "epoch 131: loss=0.9542443156242371\n",
      "epoch 132: loss=0.9432366490364075\n",
      "epoch 133: loss=0.9696046113967896\n",
      "epoch 134: loss=0.9495341777801514\n",
      "epoch 135: loss=0.9431082606315613\n",
      "epoch 136: loss=0.9553003907203674\n",
      "epoch 137: loss=0.9579483866691589\n",
      "epoch 138: loss=0.942217230796814\n",
      "epoch 139: loss=0.9557282328605652\n",
      "epoch 140: loss=0.9569762945175171\n",
      "epoch 141: loss=0.9499388933181763\n",
      "epoch 142: loss=0.9556677937507629\n",
      "epoch 143: loss=0.9546488523483276\n",
      "epoch 144: loss=0.9530109763145447\n",
      "epoch 145: loss=0.952528178691864\n",
      "epoch 146: loss=0.9546495676040649\n",
      "epoch 147: loss=0.952552080154419\n",
      "epoch 148: loss=0.9589710831642151\n",
      "epoch 149: loss=0.9459982514381409\n",
      "epoch 150: loss=0.9457480311393738\n",
      "epoch 151: loss=0.9334343671798706\n",
      "epoch 152: loss=0.9527914524078369\n",
      "epoch 153: loss=0.9540576934814453\n",
      "epoch 154: loss=0.9327753186225891\n",
      "epoch 155: loss=0.9702953696250916\n",
      "epoch 156: loss=0.9590858221054077\n",
      "epoch 157: loss=0.9568209052085876\n",
      "epoch 158: loss=0.9577268362045288\n",
      "epoch 159: loss=0.9472647309303284\n",
      "epoch 160: loss=0.9465511441230774\n",
      "epoch 161: loss=0.9433400630950928\n",
      "epoch 162: loss=0.9471002221107483\n",
      "epoch 163: loss=0.9291993379592896\n",
      "epoch 164: loss=0.9350537657737732\n",
      "epoch 165: loss=0.9486214518547058\n",
      "epoch 166: loss=0.9330942630767822\n",
      "epoch 167: loss=0.9432691335678101\n",
      "epoch 168: loss=0.9489371180534363\n",
      "epoch 169: loss=0.9173796772956848\n",
      "epoch 170: loss=0.9658652544021606\n",
      "epoch 171: loss=0.962898313999176\n",
      "epoch 172: loss=0.9721953868865967\n",
      "epoch 173: loss=0.9299896955490112\n",
      "epoch 174: loss=0.9523758292198181\n",
      "epoch 175: loss=0.931466817855835\n",
      "epoch 176: loss=0.9675170183181763\n",
      "epoch 177: loss=0.942789614200592\n",
      "epoch 178: loss=0.9065490961074829\n",
      "epoch 179: loss=0.9469191431999207\n",
      "epoch 180: loss=0.9641923308372498\n",
      "epoch 181: loss=0.9451419711112976\n",
      "epoch 182: loss=0.9333643913269043\n",
      "epoch 183: loss=0.9123990535736084\n",
      "epoch 184: loss=0.9471684098243713\n",
      "epoch 185: loss=0.9528929591178894\n",
      "epoch 186: loss=0.9522424340248108\n",
      "epoch 187: loss=0.9650875329971313\n",
      "epoch 188: loss=0.9620392322540283\n",
      "epoch 189: loss=0.93726646900177\n",
      "epoch 190: loss=0.9201363325119019\n",
      "epoch 191: loss=0.945524275302887\n",
      "epoch 192: loss=0.9138327836990356\n",
      "epoch 193: loss=0.9422942399978638\n",
      "epoch 194: loss=0.9507932662963867\n",
      "epoch 195: loss=0.9392558336257935\n",
      "epoch 196: loss=0.9468460083007812\n",
      "epoch 197: loss=0.9425981640815735\n",
      "epoch 198: loss=0.9446893334388733\n",
      "epoch 199: loss=0.9115532040596008\n",
      "training patch with 764 edges\n",
      "epoch 0: loss=5.022756099700928\n",
      "epoch 1: loss=4.399787902832031\n",
      "epoch 2: loss=4.1356282234191895\n",
      "epoch 3: loss=4.05738639831543\n",
      "epoch 4: loss=3.702909231185913\n",
      "epoch 5: loss=3.7340924739837646\n",
      "epoch 6: loss=3.2811272144317627\n",
      "epoch 7: loss=2.9587814807891846\n",
      "epoch 8: loss=2.9384989738464355\n",
      "epoch 9: loss=2.7267072200775146\n",
      "epoch 10: loss=2.439284324645996\n",
      "epoch 11: loss=2.1780123710632324\n",
      "epoch 12: loss=1.984741449356079\n",
      "epoch 13: loss=1.9610662460327148\n",
      "epoch 14: loss=1.8894603252410889\n",
      "epoch 15: loss=1.7414766550064087\n",
      "epoch 16: loss=1.6492334604263306\n",
      "epoch 17: loss=1.598405361175537\n",
      "epoch 18: loss=1.5553513765335083\n",
      "epoch 19: loss=1.555365800857544\n",
      "epoch 20: loss=1.5337634086608887\n",
      "epoch 21: loss=1.4952611923217773\n",
      "epoch 22: loss=1.51857590675354\n",
      "epoch 23: loss=1.5282695293426514\n",
      "epoch 24: loss=1.5112009048461914\n",
      "epoch 25: loss=1.5248148441314697\n",
      "epoch 26: loss=1.514151930809021\n",
      "epoch 27: loss=1.5048213005065918\n",
      "epoch 28: loss=1.4851537942886353\n",
      "epoch 29: loss=1.4995977878570557\n",
      "epoch 30: loss=1.470141053199768\n",
      "epoch 31: loss=1.4535919427871704\n",
      "epoch 32: loss=1.4464514255523682\n",
      "epoch 33: loss=1.4178862571716309\n",
      "epoch 34: loss=1.4004536867141724\n",
      "epoch 35: loss=1.383501410484314\n",
      "epoch 36: loss=1.3504266738891602\n",
      "epoch 37: loss=1.3190104961395264\n",
      "epoch 38: loss=1.3092683553695679\n",
      "epoch 39: loss=1.2895638942718506\n",
      "epoch 40: loss=1.2902908325195312\n",
      "epoch 41: loss=1.224022626876831\n",
      "epoch 42: loss=1.242394208908081\n",
      "epoch 43: loss=1.2510849237442017\n",
      "epoch 44: loss=1.2278295755386353\n",
      "epoch 45: loss=1.182753086090088\n",
      "epoch 46: loss=1.207872986793518\n",
      "epoch 47: loss=1.2075570821762085\n",
      "epoch 48: loss=1.156348705291748\n",
      "epoch 49: loss=1.2018204927444458\n",
      "epoch 50: loss=1.175201177597046\n",
      "epoch 51: loss=1.1603808403015137\n",
      "epoch 52: loss=1.1344819068908691\n",
      "epoch 53: loss=1.1459041833877563\n",
      "epoch 54: loss=1.1330896615982056\n",
      "epoch 55: loss=1.144046664237976\n",
      "epoch 56: loss=1.1027297973632812\n",
      "epoch 57: loss=1.0789365768432617\n",
      "epoch 58: loss=1.0656226873397827\n",
      "epoch 59: loss=1.112477421760559\n",
      "epoch 60: loss=1.1059476137161255\n",
      "epoch 61: loss=1.1043808460235596\n",
      "epoch 62: loss=1.1610180139541626\n",
      "epoch 63: loss=1.1065735816955566\n",
      "epoch 64: loss=1.1246178150177002\n",
      "epoch 65: loss=1.07613205909729\n",
      "epoch 66: loss=1.0952379703521729\n",
      "epoch 67: loss=1.0825417041778564\n",
      "epoch 68: loss=1.070265293121338\n",
      "epoch 69: loss=1.0725035667419434\n",
      "epoch 70: loss=1.0690525770187378\n",
      "epoch 71: loss=1.0820244550704956\n",
      "epoch 72: loss=1.071642279624939\n",
      "epoch 73: loss=1.0685266256332397\n",
      "epoch 74: loss=1.0855330228805542\n",
      "epoch 75: loss=1.0580145120620728\n",
      "epoch 76: loss=1.0397332906723022\n",
      "epoch 77: loss=1.1299643516540527\n",
      "epoch 78: loss=1.0518683195114136\n",
      "epoch 79: loss=1.0516642332077026\n",
      "epoch 80: loss=1.0946260690689087\n",
      "epoch 81: loss=0.9897385835647583\n",
      "epoch 82: loss=1.0592237710952759\n",
      "epoch 83: loss=1.0550756454467773\n",
      "epoch 84: loss=1.0856094360351562\n",
      "epoch 85: loss=1.0450373888015747\n",
      "epoch 86: loss=1.0858975648880005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87: loss=1.0813089609146118\n",
      "epoch 88: loss=1.0546056032180786\n",
      "epoch 89: loss=1.0705537796020508\n",
      "epoch 90: loss=1.0774681568145752\n",
      "epoch 91: loss=1.1074268817901611\n",
      "epoch 92: loss=1.0472298860549927\n",
      "epoch 93: loss=1.038120985031128\n",
      "epoch 94: loss=1.0579109191894531\n",
      "epoch 95: loss=1.0292456150054932\n",
      "epoch 96: loss=1.0339219570159912\n",
      "epoch 97: loss=1.059461236000061\n",
      "epoch 98: loss=1.0624866485595703\n",
      "epoch 99: loss=1.037335753440857\n",
      "epoch 100: loss=1.0627754926681519\n",
      "epoch 101: loss=1.058619737625122\n",
      "epoch 102: loss=1.0408310890197754\n",
      "epoch 103: loss=1.0497881174087524\n",
      "epoch 104: loss=1.0531225204467773\n",
      "epoch 105: loss=1.043520450592041\n",
      "epoch 106: loss=1.0783567428588867\n",
      "epoch 107: loss=1.060482144355774\n",
      "epoch 108: loss=1.074522614479065\n",
      "epoch 109: loss=1.0459949970245361\n",
      "epoch 110: loss=1.0569936037063599\n",
      "epoch 111: loss=1.0624701976776123\n",
      "epoch 112: loss=1.0310951471328735\n",
      "epoch 113: loss=1.062882423400879\n",
      "epoch 114: loss=1.0733509063720703\n",
      "epoch 115: loss=1.0503196716308594\n",
      "epoch 116: loss=1.1012638807296753\n",
      "epoch 117: loss=1.0490018129348755\n",
      "epoch 118: loss=1.0935927629470825\n",
      "epoch 119: loss=1.0163217782974243\n",
      "epoch 120: loss=1.0543936491012573\n",
      "epoch 121: loss=1.044545292854309\n",
      "epoch 122: loss=1.0341999530792236\n",
      "epoch 123: loss=1.0620931386947632\n",
      "epoch 124: loss=1.081254482269287\n",
      "epoch 125: loss=1.0275288820266724\n",
      "epoch 126: loss=1.0745660066604614\n",
      "epoch 127: loss=1.016535758972168\n",
      "epoch 128: loss=1.0623573064804077\n",
      "epoch 129: loss=1.0834360122680664\n",
      "epoch 130: loss=1.0266458988189697\n",
      "epoch 131: loss=1.0084306001663208\n",
      "epoch 132: loss=1.0648937225341797\n",
      "epoch 133: loss=1.0685970783233643\n",
      "epoch 134: loss=1.04183828830719\n",
      "epoch 135: loss=1.0495622158050537\n",
      "epoch 136: loss=1.0770293474197388\n",
      "epoch 137: loss=1.0427205562591553\n",
      "epoch 138: loss=1.049894094467163\n",
      "epoch 139: loss=1.069011926651001\n",
      "epoch 140: loss=1.0268934965133667\n",
      "epoch 141: loss=1.0432031154632568\n",
      "epoch 142: loss=1.0404891967773438\n",
      "epoch 143: loss=1.0288008451461792\n",
      "epoch 144: loss=1.0401560068130493\n",
      "epoch 145: loss=1.0193736553192139\n",
      "epoch 146: loss=1.0562851428985596\n",
      "epoch 147: loss=1.0536335706710815\n",
      "epoch 148: loss=1.0284314155578613\n",
      "epoch 149: loss=1.0030853748321533\n",
      "epoch 150: loss=1.0507056713104248\n",
      "epoch 151: loss=1.0183579921722412\n",
      "epoch 152: loss=1.0578088760375977\n",
      "epoch 153: loss=1.0392011404037476\n",
      "epoch 154: loss=1.0179957151412964\n",
      "epoch 155: loss=1.031341552734375\n",
      "epoch 156: loss=1.0949418544769287\n",
      "epoch 157: loss=1.006998062133789\n",
      "epoch 158: loss=1.0298995971679688\n",
      "epoch 159: loss=1.0473026037216187\n",
      "epoch 160: loss=1.0631588697433472\n",
      "epoch 161: loss=1.0469236373901367\n",
      "epoch 162: loss=0.9984207153320312\n",
      "epoch 163: loss=1.0357860326766968\n",
      "epoch 164: loss=1.044695258140564\n",
      "epoch 165: loss=1.0053753852844238\n",
      "epoch 166: loss=1.0020610094070435\n",
      "epoch 167: loss=1.0297181606292725\n",
      "epoch 168: loss=1.0325199365615845\n",
      "epoch 169: loss=1.0385487079620361\n",
      "epoch 170: loss=1.058672308921814\n",
      "epoch 171: loss=1.0207010507583618\n",
      "epoch 172: loss=0.9902695417404175\n",
      "epoch 173: loss=1.04154634475708\n",
      "epoch 174: loss=0.9931447505950928\n",
      "epoch 175: loss=1.043478012084961\n",
      "epoch 176: loss=1.0096378326416016\n",
      "epoch 177: loss=1.0151079893112183\n",
      "epoch 178: loss=1.0072073936462402\n",
      "epoch 179: loss=1.0333287715911865\n",
      "epoch 180: loss=1.039223074913025\n",
      "epoch 181: loss=1.0183327198028564\n",
      "epoch 182: loss=1.011295199394226\n",
      "epoch 183: loss=1.0023033618927002\n",
      "epoch 184: loss=1.0061248540878296\n",
      "epoch 185: loss=1.0304020643234253\n",
      "epoch 186: loss=1.0159852504730225\n",
      "epoch 187: loss=0.9917976260185242\n",
      "epoch 188: loss=1.033159613609314\n",
      "epoch 189: loss=1.0073738098144531\n",
      "epoch 190: loss=1.0331772565841675\n",
      "epoch 191: loss=1.0120242834091187\n",
      "epoch 192: loss=0.9963041543960571\n",
      "epoch 193: loss=1.015442967414856\n",
      "epoch 194: loss=1.0450013875961304\n",
      "epoch 195: loss=1.0310765504837036\n",
      "epoch 196: loss=1.0457569360733032\n",
      "epoch 197: loss=1.0057523250579834\n",
      "epoch 198: loss=0.9967139363288879\n",
      "epoch 199: loss=1.0681445598602295\n",
      "training patch with 950 edges\n",
      "epoch 0: loss=4.784521579742432\n",
      "epoch 1: loss=4.635398864746094\n",
      "epoch 2: loss=4.074334144592285\n",
      "epoch 3: loss=4.3263959884643555\n",
      "epoch 4: loss=4.01985502243042\n",
      "epoch 5: loss=3.7090203762054443\n",
      "epoch 6: loss=3.2403564453125\n",
      "epoch 7: loss=3.22636342048645\n",
      "epoch 8: loss=2.9477996826171875\n",
      "epoch 9: loss=2.686821222305298\n",
      "epoch 10: loss=2.662571907043457\n",
      "epoch 11: loss=2.629060983657837\n",
      "epoch 12: loss=2.3711800575256348\n",
      "epoch 13: loss=2.1666808128356934\n",
      "epoch 14: loss=1.9425549507141113\n",
      "epoch 15: loss=1.8941123485565186\n",
      "epoch 16: loss=1.7526516914367676\n",
      "epoch 17: loss=1.6952877044677734\n",
      "epoch 18: loss=1.6555675268173218\n",
      "epoch 19: loss=1.5535345077514648\n",
      "epoch 20: loss=1.5199280977249146\n",
      "epoch 21: loss=1.5011109113693237\n",
      "epoch 22: loss=1.5139847993850708\n",
      "epoch 23: loss=1.4966799020767212\n",
      "epoch 24: loss=1.4741547107696533\n",
      "epoch 25: loss=1.5020884275436401\n",
      "epoch 26: loss=1.4535175561904907\n",
      "epoch 27: loss=1.455627202987671\n",
      "epoch 28: loss=1.4512046575546265\n",
      "epoch 29: loss=1.4634689092636108\n",
      "epoch 30: loss=1.4404765367507935\n",
      "epoch 31: loss=1.4360311031341553\n",
      "epoch 32: loss=1.439645528793335\n",
      "epoch 33: loss=1.4313877820968628\n",
      "epoch 34: loss=1.4410011768341064\n",
      "epoch 35: loss=1.4178369045257568\n",
      "epoch 36: loss=1.40496027469635\n",
      "epoch 37: loss=1.3951867818832397\n",
      "epoch 38: loss=1.3823788166046143\n",
      "epoch 39: loss=1.3760251998901367\n",
      "epoch 40: loss=1.364522933959961\n",
      "epoch 41: loss=1.3396084308624268\n",
      "epoch 42: loss=1.3278162479400635\n",
      "epoch 43: loss=1.3201040029525757\n",
      "epoch 44: loss=1.2879465818405151\n",
      "epoch 45: loss=1.2686092853546143\n",
      "epoch 46: loss=1.2087620496749878\n",
      "epoch 47: loss=1.2136495113372803\n",
      "epoch 48: loss=1.2121158838272095\n",
      "epoch 49: loss=1.1814782619476318\n",
      "epoch 50: loss=1.1674926280975342\n",
      "epoch 51: loss=1.1941601037979126\n",
      "epoch 52: loss=1.1734070777893066\n",
      "epoch 53: loss=1.1683452129364014\n",
      "epoch 54: loss=1.1877669095993042\n",
      "epoch 55: loss=1.1544290781021118\n",
      "epoch 56: loss=1.1508046388626099\n",
      "epoch 57: loss=1.142509937286377\n",
      "epoch 58: loss=1.114637017250061\n",
      "epoch 59: loss=1.087451457977295\n",
      "epoch 60: loss=1.1135765314102173\n",
      "epoch 61: loss=1.0603210926055908\n",
      "epoch 62: loss=1.0975662469863892\n",
      "epoch 63: loss=1.1157021522521973\n",
      "epoch 64: loss=1.0639723539352417\n",
      "epoch 65: loss=1.0824404954910278\n",
      "epoch 66: loss=1.0951015949249268\n",
      "epoch 67: loss=1.051039695739746\n",
      "epoch 68: loss=1.083403468132019\n",
      "epoch 69: loss=1.0573211908340454\n",
      "epoch 70: loss=1.0410408973693848\n",
      "epoch 71: loss=1.0225260257720947\n",
      "epoch 72: loss=1.0754121541976929\n",
      "epoch 73: loss=1.0537265539169312\n",
      "epoch 74: loss=1.0249435901641846\n",
      "epoch 75: loss=1.0892016887664795\n",
      "epoch 76: loss=1.035706877708435\n",
      "epoch 77: loss=1.0374798774719238\n",
      "epoch 78: loss=1.0233782529830933\n",
      "epoch 79: loss=1.0375392436981201\n",
      "epoch 80: loss=1.0594558715820312\n",
      "epoch 81: loss=1.0419061183929443\n",
      "epoch 82: loss=1.0284820795059204\n",
      "epoch 83: loss=1.0450609922409058\n",
      "epoch 84: loss=1.0692859888076782\n",
      "epoch 85: loss=1.0409393310546875\n",
      "epoch 86: loss=1.0608720779418945\n",
      "epoch 87: loss=1.017770767211914\n",
      "epoch 88: loss=1.031367540359497\n",
      "epoch 89: loss=1.041432499885559\n",
      "epoch 90: loss=1.0162930488586426\n",
      "epoch 91: loss=1.0105533599853516\n",
      "epoch 92: loss=1.0050464868545532\n",
      "epoch 93: loss=1.0310472249984741\n",
      "epoch 94: loss=1.0204052925109863\n",
      "epoch 95: loss=1.0402729511260986\n",
      "epoch 96: loss=1.0340023040771484\n",
      "epoch 97: loss=1.0382074117660522\n",
      "epoch 98: loss=1.0530668497085571\n",
      "epoch 99: loss=0.9955011606216431\n",
      "epoch 100: loss=1.0268512964248657\n",
      "epoch 101: loss=1.0493897199630737\n",
      "epoch 102: loss=1.0191116333007812\n",
      "epoch 103: loss=1.0322437286376953\n",
      "epoch 104: loss=1.0618637800216675\n",
      "epoch 105: loss=1.0233359336853027\n",
      "epoch 106: loss=1.0164285898208618\n",
      "epoch 107: loss=1.013716459274292\n",
      "epoch 108: loss=1.0238603353500366\n",
      "epoch 109: loss=1.0206407308578491\n",
      "epoch 110: loss=1.0316965579986572\n",
      "epoch 111: loss=1.0505108833312988\n",
      "epoch 112: loss=0.97530198097229\n",
      "epoch 113: loss=1.0393651723861694\n",
      "epoch 114: loss=1.0086264610290527\n",
      "epoch 115: loss=1.0444493293762207\n",
      "epoch 116: loss=1.0061326026916504\n",
      "epoch 117: loss=0.9989965558052063\n",
      "epoch 118: loss=1.0121580362319946\n",
      "epoch 119: loss=1.0194072723388672\n",
      "epoch 120: loss=1.0187824964523315\n",
      "epoch 121: loss=1.0092816352844238\n",
      "epoch 122: loss=1.0255286693572998\n",
      "epoch 123: loss=1.0131776332855225\n",
      "epoch 124: loss=1.0225516557693481\n",
      "epoch 125: loss=1.0257858037948608\n",
      "epoch 126: loss=1.0329800844192505\n",
      "epoch 127: loss=1.0134891271591187\n",
      "epoch 128: loss=0.9954096674919128\n",
      "epoch 129: loss=1.0266672372817993\n",
      "epoch 130: loss=1.026397466659546\n",
      "epoch 131: loss=1.018250823020935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132: loss=0.9941428303718567\n",
      "epoch 133: loss=1.011146068572998\n",
      "epoch 134: loss=1.0112289190292358\n",
      "epoch 135: loss=1.003009557723999\n",
      "epoch 136: loss=0.993294358253479\n",
      "epoch 137: loss=0.9834318161010742\n",
      "epoch 138: loss=0.9900137782096863\n",
      "epoch 139: loss=0.9817479848861694\n",
      "epoch 140: loss=1.0253795385360718\n",
      "epoch 141: loss=1.0236101150512695\n",
      "epoch 142: loss=1.0000383853912354\n",
      "epoch 143: loss=0.9676843285560608\n",
      "epoch 144: loss=0.9832189083099365\n",
      "epoch 145: loss=1.013695478439331\n",
      "epoch 146: loss=1.0160293579101562\n",
      "epoch 147: loss=0.9981393814086914\n",
      "epoch 148: loss=1.0246714353561401\n",
      "epoch 149: loss=0.9791001081466675\n",
      "epoch 150: loss=0.9902772307395935\n",
      "epoch 151: loss=0.9965965151786804\n",
      "epoch 152: loss=0.9693700075149536\n",
      "epoch 153: loss=0.9908638596534729\n",
      "epoch 154: loss=1.0125222206115723\n",
      "epoch 155: loss=1.0412734746932983\n",
      "epoch 156: loss=0.9800899028778076\n",
      "epoch 157: loss=0.9880803227424622\n",
      "epoch 158: loss=0.9732292890548706\n",
      "epoch 159: loss=0.969261884689331\n",
      "epoch 160: loss=1.0109825134277344\n",
      "epoch 161: loss=0.98658686876297\n",
      "epoch 162: loss=1.0042479038238525\n",
      "epoch 163: loss=1.000494122505188\n",
      "epoch 164: loss=1.0080621242523193\n",
      "epoch 165: loss=1.0196675062179565\n",
      "epoch 166: loss=1.008907675743103\n",
      "epoch 167: loss=0.9788637161254883\n",
      "epoch 168: loss=0.9917857050895691\n",
      "epoch 169: loss=0.9540038108825684\n",
      "epoch 170: loss=0.9797340631484985\n",
      "epoch 171: loss=0.9796736836433411\n",
      "epoch 172: loss=1.022144079208374\n",
      "epoch 173: loss=0.9809479117393494\n",
      "epoch 174: loss=0.9943049550056458\n",
      "epoch 175: loss=0.9798611402511597\n",
      "epoch 176: loss=1.0210399627685547\n",
      "epoch 177: loss=0.9658811092376709\n",
      "epoch 178: loss=0.9685931205749512\n",
      "epoch 179: loss=1.0130547285079956\n",
      "epoch 180: loss=0.9818112254142761\n",
      "epoch 181: loss=1.0216405391693115\n",
      "epoch 182: loss=1.0162461996078491\n",
      "epoch 183: loss=1.0094372034072876\n",
      "epoch 184: loss=0.9863507747650146\n",
      "epoch 185: loss=1.0012972354888916\n",
      "epoch 186: loss=0.9490968585014343\n",
      "epoch 187: loss=0.9980132579803467\n",
      "epoch 188: loss=1.0129762887954712\n",
      "epoch 189: loss=0.9701794981956482\n",
      "epoch 190: loss=0.9847591519355774\n",
      "epoch 191: loss=0.9737734794616699\n",
      "epoch 192: loss=1.0158883333206177\n",
      "epoch 193: loss=0.9902390241622925\n",
      "epoch 194: loss=0.9971281290054321\n",
      "epoch 195: loss=0.9910428524017334\n",
      "epoch 196: loss=0.9817365407943726\n",
      "epoch 197: loss=0.9706819653511047\n",
      "epoch 198: loss=1.0125809907913208\n",
      "epoch 199: loss=1.0075300931930542\n",
      "training patch with 2922 edges\n",
      "epoch 0: loss=4.5374836921691895\n",
      "epoch 1: loss=4.327353477478027\n",
      "epoch 2: loss=4.4572434425354\n",
      "epoch 3: loss=3.9635865688323975\n",
      "epoch 4: loss=3.8280086517333984\n",
      "epoch 5: loss=3.533461093902588\n",
      "epoch 6: loss=3.191312313079834\n",
      "epoch 7: loss=2.9625842571258545\n",
      "epoch 8: loss=2.566263437271118\n",
      "epoch 9: loss=2.3463363647460938\n",
      "epoch 10: loss=2.13529109954834\n",
      "epoch 11: loss=1.9834117889404297\n",
      "epoch 12: loss=1.810294508934021\n",
      "epoch 13: loss=1.7095164060592651\n",
      "epoch 14: loss=1.633118748664856\n",
      "epoch 15: loss=1.555444359779358\n",
      "epoch 16: loss=1.490239143371582\n",
      "epoch 17: loss=1.4829528331756592\n",
      "epoch 18: loss=1.4391549825668335\n",
      "epoch 19: loss=1.4242243766784668\n",
      "epoch 20: loss=1.4166574478149414\n",
      "epoch 21: loss=1.3878740072250366\n",
      "epoch 22: loss=1.3831652402877808\n",
      "epoch 23: loss=1.3841626644134521\n",
      "epoch 24: loss=1.3577868938446045\n",
      "epoch 25: loss=1.365602731704712\n",
      "epoch 26: loss=1.3577253818511963\n",
      "epoch 27: loss=1.3505748510360718\n",
      "epoch 28: loss=1.3447519540786743\n",
      "epoch 29: loss=1.3411741256713867\n",
      "epoch 30: loss=1.3349007368087769\n",
      "epoch 31: loss=1.322268009185791\n",
      "epoch 32: loss=1.324449896812439\n",
      "epoch 33: loss=1.3093715906143188\n",
      "epoch 34: loss=1.306847333908081\n",
      "epoch 35: loss=1.304934024810791\n",
      "epoch 36: loss=1.284571647644043\n",
      "epoch 37: loss=1.2733771800994873\n",
      "epoch 38: loss=1.2654900550842285\n",
      "epoch 39: loss=1.2344467639923096\n",
      "epoch 40: loss=1.2323850393295288\n",
      "epoch 41: loss=1.2054407596588135\n",
      "epoch 42: loss=1.1936190128326416\n",
      "epoch 43: loss=1.1666374206542969\n",
      "epoch 44: loss=1.1528151035308838\n",
      "epoch 45: loss=1.1520370244979858\n",
      "epoch 46: loss=1.1348562240600586\n",
      "epoch 47: loss=1.139632225036621\n",
      "epoch 48: loss=1.138000726699829\n",
      "epoch 49: loss=1.1117281913757324\n",
      "epoch 50: loss=1.0937049388885498\n",
      "epoch 51: loss=1.0888038873672485\n",
      "epoch 52: loss=1.0688937902450562\n",
      "epoch 53: loss=1.0664132833480835\n",
      "epoch 54: loss=1.0713019371032715\n",
      "epoch 55: loss=1.028473138809204\n",
      "epoch 56: loss=1.015644907951355\n",
      "epoch 57: loss=1.00872802734375\n",
      "epoch 58: loss=1.0259678363800049\n",
      "epoch 59: loss=1.007279634475708\n",
      "epoch 60: loss=1.0093801021575928\n",
      "epoch 61: loss=0.9887884259223938\n",
      "epoch 62: loss=0.9977021217346191\n",
      "epoch 63: loss=0.9883542656898499\n",
      "epoch 64: loss=0.9783744215965271\n",
      "epoch 65: loss=1.0009711980819702\n",
      "epoch 66: loss=0.9733427166938782\n",
      "epoch 67: loss=1.0037699937820435\n",
      "epoch 68: loss=0.9845406413078308\n",
      "epoch 69: loss=0.9762683510780334\n",
      "epoch 70: loss=0.9809049367904663\n",
      "epoch 71: loss=0.9801323413848877\n",
      "epoch 72: loss=0.9828300476074219\n",
      "epoch 73: loss=0.9747347235679626\n",
      "epoch 74: loss=0.9442455768585205\n",
      "epoch 75: loss=0.968330979347229\n",
      "epoch 76: loss=0.9399128556251526\n",
      "epoch 77: loss=0.9424753189086914\n",
      "epoch 78: loss=0.962905764579773\n",
      "epoch 79: loss=0.945502519607544\n",
      "epoch 80: loss=0.9528419375419617\n",
      "epoch 81: loss=0.935174822807312\n",
      "epoch 82: loss=0.9481341242790222\n",
      "epoch 83: loss=0.9284509420394897\n",
      "epoch 84: loss=0.9458960294723511\n",
      "epoch 85: loss=0.9589542150497437\n",
      "epoch 86: loss=0.9418999552726746\n",
      "epoch 87: loss=0.9354774951934814\n",
      "epoch 88: loss=0.9303341507911682\n",
      "epoch 89: loss=0.9320123195648193\n",
      "epoch 90: loss=0.9378143548965454\n",
      "epoch 91: loss=0.911312997341156\n",
      "epoch 92: loss=0.9241326451301575\n",
      "epoch 93: loss=0.9327608346939087\n",
      "epoch 94: loss=0.932828426361084\n",
      "epoch 95: loss=0.925609290599823\n",
      "epoch 96: loss=0.916060745716095\n",
      "epoch 97: loss=0.9421762824058533\n",
      "epoch 98: loss=0.9191368818283081\n",
      "epoch 99: loss=0.9148691296577454\n",
      "epoch 100: loss=0.9110912680625916\n",
      "epoch 101: loss=0.9078202843666077\n",
      "epoch 102: loss=0.9220470786094666\n",
      "epoch 103: loss=0.9322118163108826\n",
      "epoch 104: loss=0.909313976764679\n",
      "epoch 105: loss=0.9309114217758179\n",
      "epoch 106: loss=0.919452428817749\n",
      "epoch 107: loss=0.9394955635070801\n",
      "epoch 108: loss=0.9145686626434326\n",
      "epoch 109: loss=0.9089335799217224\n",
      "epoch 110: loss=0.9105396866798401\n",
      "epoch 111: loss=0.9132351279258728\n",
      "epoch 112: loss=0.923560619354248\n",
      "epoch 113: loss=0.925846517086029\n",
      "epoch 114: loss=0.9237834215164185\n",
      "epoch 115: loss=0.9067003726959229\n",
      "epoch 116: loss=0.9079777598381042\n",
      "epoch 117: loss=0.9192276000976562\n",
      "epoch 118: loss=0.9018090963363647\n",
      "epoch 119: loss=0.9018076658248901\n",
      "epoch 120: loss=0.9199934601783752\n",
      "epoch 121: loss=0.9041659832000732\n",
      "epoch 122: loss=0.9130948781967163\n",
      "epoch 123: loss=0.9058761596679688\n",
      "epoch 124: loss=0.895368754863739\n",
      "epoch 125: loss=0.8914135694503784\n",
      "epoch 126: loss=0.9092689752578735\n",
      "epoch 127: loss=0.91847825050354\n",
      "epoch 128: loss=0.9026710391044617\n",
      "epoch 129: loss=0.8994590044021606\n",
      "epoch 130: loss=0.9025248289108276\n",
      "epoch 131: loss=0.9004830121994019\n",
      "epoch 132: loss=0.9119820594787598\n",
      "epoch 133: loss=0.8954418301582336\n",
      "epoch 134: loss=0.8939985036849976\n",
      "epoch 135: loss=0.896433413028717\n",
      "epoch 136: loss=0.8834123611450195\n",
      "epoch 137: loss=0.8919007778167725\n",
      "epoch 138: loss=0.9148111343383789\n",
      "epoch 139: loss=0.9041991233825684\n",
      "epoch 140: loss=0.9055438041687012\n",
      "epoch 141: loss=0.8884069919586182\n",
      "epoch 142: loss=0.8966884016990662\n",
      "epoch 143: loss=0.8899465203285217\n",
      "epoch 144: loss=0.9080812335014343\n",
      "epoch 145: loss=0.8958677053451538\n",
      "epoch 146: loss=0.8997789621353149\n",
      "epoch 147: loss=0.8853903412818909\n",
      "epoch 148: loss=0.8947248458862305\n",
      "epoch 149: loss=0.8964180946350098\n",
      "epoch 150: loss=0.8886696696281433\n",
      "epoch 151: loss=0.8862236142158508\n",
      "epoch 152: loss=0.883274495601654\n",
      "epoch 153: loss=0.8889646530151367\n",
      "epoch 154: loss=0.904823362827301\n",
      "epoch 155: loss=0.8931605815887451\n",
      "epoch 156: loss=0.919106125831604\n",
      "epoch 157: loss=0.8882060647010803\n",
      "epoch 158: loss=0.9004763960838318\n",
      "epoch 159: loss=0.909521222114563\n",
      "epoch 160: loss=0.899854838848114\n",
      "epoch 161: loss=0.9019231796264648\n",
      "epoch 162: loss=0.8983056545257568\n",
      "epoch 163: loss=0.8893707990646362\n",
      "epoch 164: loss=0.8937562704086304\n",
      "epoch 165: loss=0.8915430307388306\n",
      "epoch 166: loss=0.883722186088562\n",
      "epoch 167: loss=0.8892659544944763\n",
      "epoch 168: loss=0.8892625570297241\n",
      "epoch 169: loss=0.8987760543823242\n",
      "epoch 170: loss=0.8853507041931152\n",
      "epoch 171: loss=0.8901693820953369\n",
      "epoch 172: loss=0.8771127462387085\n",
      "epoch 173: loss=0.8958240151405334\n",
      "epoch 174: loss=0.8870927095413208\n",
      "epoch 175: loss=0.8863071203231812\n",
      "epoch 176: loss=0.8898665904998779\n",
      "epoch 177: loss=0.8888576626777649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178: loss=0.8816537857055664\n",
      "epoch 179: loss=0.8908329010009766\n",
      "epoch 180: loss=0.8870757818222046\n",
      "epoch 181: loss=0.8612002730369568\n",
      "epoch 182: loss=0.878415584564209\n",
      "epoch 183: loss=0.8851631283760071\n",
      "epoch 184: loss=0.8829987645149231\n",
      "epoch 185: loss=0.885945200920105\n",
      "epoch 186: loss=0.8780505657196045\n",
      "epoch 187: loss=0.8853228092193604\n",
      "epoch 188: loss=0.8900936841964722\n",
      "epoch 189: loss=0.8844433426856995\n",
      "epoch 190: loss=0.8789582252502441\n",
      "epoch 191: loss=0.8640150427818298\n",
      "epoch 192: loss=0.8875018358230591\n",
      "epoch 193: loss=0.8742205500602722\n",
      "epoch 194: loss=0.8840014934539795\n",
      "epoch 195: loss=0.874291181564331\n",
      "epoch 196: loss=0.8731591105461121\n",
      "epoch 197: loss=0.8942465782165527\n",
      "epoch 198: loss=0.8952763080596924\n",
      "epoch 199: loss=0.8844396471977234\n",
      "training patch with 1698 edges\n",
      "epoch 0: loss=4.76274299621582\n",
      "epoch 1: loss=4.680187702178955\n",
      "epoch 2: loss=4.293592929840088\n",
      "epoch 3: loss=4.180954933166504\n",
      "epoch 4: loss=3.9214887619018555\n",
      "epoch 5: loss=3.7556533813476562\n",
      "epoch 6: loss=3.5426228046417236\n",
      "epoch 7: loss=3.2151453495025635\n",
      "epoch 8: loss=2.910447597503662\n",
      "epoch 9: loss=2.59169340133667\n",
      "epoch 10: loss=2.522679567337036\n",
      "epoch 11: loss=2.320918321609497\n",
      "epoch 12: loss=2.1056153774261475\n",
      "epoch 13: loss=1.915692687034607\n",
      "epoch 14: loss=1.75942063331604\n",
      "epoch 15: loss=1.64994215965271\n",
      "epoch 16: loss=1.5814000368118286\n",
      "epoch 17: loss=1.521480679512024\n",
      "epoch 18: loss=1.4962992668151855\n",
      "epoch 19: loss=1.4556454420089722\n",
      "epoch 20: loss=1.453647255897522\n",
      "epoch 21: loss=1.4616085290908813\n",
      "epoch 22: loss=1.4335274696350098\n",
      "epoch 23: loss=1.4311950206756592\n",
      "epoch 24: loss=1.429636836051941\n",
      "epoch 25: loss=1.4190129041671753\n",
      "epoch 26: loss=1.414177417755127\n",
      "epoch 27: loss=1.3959851264953613\n",
      "epoch 28: loss=1.399125337600708\n",
      "epoch 29: loss=1.3824440240859985\n",
      "epoch 30: loss=1.376511812210083\n",
      "epoch 31: loss=1.3552526235580444\n",
      "epoch 32: loss=1.34464430809021\n",
      "epoch 33: loss=1.339954137802124\n",
      "epoch 34: loss=1.3171826601028442\n",
      "epoch 35: loss=1.3002244234085083\n",
      "epoch 36: loss=1.2816855907440186\n",
      "epoch 37: loss=1.2643866539001465\n",
      "epoch 38: loss=1.2392082214355469\n",
      "epoch 39: loss=1.2033803462982178\n",
      "epoch 40: loss=1.1970187425613403\n",
      "epoch 41: loss=1.1691571474075317\n",
      "epoch 42: loss=1.1559196710586548\n",
      "epoch 43: loss=1.1474380493164062\n",
      "epoch 44: loss=1.106136441230774\n",
      "epoch 45: loss=1.1041069030761719\n",
      "epoch 46: loss=1.0865286588668823\n",
      "epoch 47: loss=1.1020628213882446\n",
      "epoch 48: loss=1.0980724096298218\n",
      "epoch 49: loss=1.0900956392288208\n",
      "epoch 50: loss=1.0994343757629395\n",
      "epoch 51: loss=1.0635032653808594\n",
      "epoch 52: loss=1.091920256614685\n",
      "epoch 53: loss=1.031247615814209\n",
      "epoch 54: loss=1.022483229637146\n",
      "epoch 55: loss=1.0345938205718994\n",
      "epoch 56: loss=1.0622587203979492\n",
      "epoch 57: loss=1.025064468383789\n",
      "epoch 58: loss=1.030144214630127\n",
      "epoch 59: loss=0.9940109848976135\n",
      "epoch 60: loss=0.9907718300819397\n",
      "epoch 61: loss=1.0061041116714478\n",
      "epoch 62: loss=1.0240309238433838\n",
      "epoch 63: loss=1.016347885131836\n",
      "epoch 64: loss=0.9898696541786194\n",
      "epoch 65: loss=0.9871577024459839\n",
      "epoch 66: loss=1.0214260816574097\n",
      "epoch 67: loss=1.0044113397598267\n",
      "epoch 68: loss=0.9744625687599182\n",
      "epoch 69: loss=0.9954833388328552\n",
      "epoch 70: loss=0.9797572493553162\n",
      "epoch 71: loss=0.9754310250282288\n",
      "epoch 72: loss=0.9954975843429565\n",
      "epoch 73: loss=0.9948338866233826\n",
      "epoch 74: loss=0.9710032343864441\n",
      "epoch 75: loss=0.9545583724975586\n",
      "epoch 76: loss=0.9626860022544861\n",
      "epoch 77: loss=0.9846446514129639\n",
      "epoch 78: loss=0.9976133704185486\n",
      "epoch 79: loss=0.9875117540359497\n",
      "epoch 80: loss=0.9616278409957886\n",
      "epoch 81: loss=0.965336263179779\n",
      "epoch 82: loss=0.9813461303710938\n",
      "epoch 83: loss=0.9763711094856262\n",
      "epoch 84: loss=0.9699932336807251\n",
      "epoch 85: loss=0.9729369878768921\n",
      "epoch 86: loss=0.9707097411155701\n",
      "epoch 87: loss=0.9419512748718262\n",
      "epoch 88: loss=0.9554057717323303\n",
      "epoch 89: loss=0.9430091977119446\n",
      "epoch 90: loss=0.9576265811920166\n",
      "epoch 91: loss=0.9622863531112671\n",
      "epoch 92: loss=0.952894926071167\n",
      "epoch 93: loss=0.9762729406356812\n",
      "epoch 94: loss=0.9608712792396545\n",
      "epoch 95: loss=0.9612676501274109\n",
      "epoch 96: loss=0.9438743591308594\n",
      "epoch 97: loss=0.9546331763267517\n",
      "epoch 98: loss=0.9480742812156677\n",
      "epoch 99: loss=0.9730944633483887\n",
      "epoch 100: loss=0.9303932189941406\n",
      "epoch 101: loss=0.9478670358657837\n",
      "epoch 102: loss=0.9512248635292053\n",
      "epoch 103: loss=0.9797110557556152\n",
      "epoch 104: loss=0.958960235118866\n",
      "epoch 105: loss=0.9641971588134766\n",
      "epoch 106: loss=0.955137312412262\n",
      "epoch 107: loss=0.9601787328720093\n",
      "epoch 108: loss=0.9555529356002808\n",
      "epoch 109: loss=0.9412408471107483\n",
      "epoch 110: loss=0.932300329208374\n",
      "epoch 111: loss=0.9652160406112671\n",
      "epoch 112: loss=0.9550319910049438\n",
      "epoch 113: loss=0.9321320652961731\n",
      "epoch 114: loss=0.9455345273017883\n",
      "epoch 115: loss=0.9370176196098328\n",
      "epoch 116: loss=0.9474488496780396\n",
      "epoch 117: loss=0.9453163743019104\n",
      "epoch 118: loss=0.9515900611877441\n",
      "epoch 119: loss=0.9338681697845459\n",
      "epoch 120: loss=0.9245452284812927\n",
      "epoch 121: loss=0.9461219906806946\n",
      "epoch 122: loss=0.9702335596084595\n",
      "epoch 123: loss=0.9398941397666931\n",
      "epoch 124: loss=0.9441161155700684\n",
      "epoch 125: loss=0.960911214351654\n",
      "epoch 126: loss=0.9176334142684937\n",
      "epoch 127: loss=0.9424254894256592\n",
      "epoch 128: loss=0.924820065498352\n",
      "epoch 129: loss=0.9291489124298096\n",
      "epoch 130: loss=0.9543665647506714\n",
      "epoch 131: loss=0.9594362378120422\n",
      "epoch 132: loss=0.9647567272186279\n",
      "epoch 133: loss=0.927983820438385\n",
      "epoch 134: loss=0.9455040693283081\n",
      "epoch 135: loss=0.9203206300735474\n",
      "epoch 136: loss=0.9338459968566895\n",
      "epoch 137: loss=0.9084646105766296\n",
      "epoch 138: loss=0.9237341284751892\n",
      "epoch 139: loss=0.9501707553863525\n",
      "epoch 140: loss=0.9368463158607483\n",
      "epoch 141: loss=0.9451357126235962\n",
      "epoch 142: loss=0.9364303350448608\n",
      "epoch 143: loss=0.9055911302566528\n",
      "epoch 144: loss=0.9272154569625854\n",
      "epoch 145: loss=0.9416440725326538\n",
      "epoch 146: loss=0.9500921964645386\n",
      "epoch 147: loss=0.9439436197280884\n",
      "epoch 148: loss=0.9193004965782166\n",
      "epoch 149: loss=0.9034464955329895\n",
      "epoch 150: loss=0.9589810967445374\n",
      "epoch 151: loss=0.9461602568626404\n",
      "epoch 152: loss=0.932788610458374\n",
      "epoch 153: loss=0.9309457540512085\n",
      "epoch 154: loss=0.9325507879257202\n",
      "epoch 155: loss=0.9365959167480469\n",
      "epoch 156: loss=0.9317466020584106\n",
      "epoch 157: loss=0.9075599908828735\n",
      "epoch 158: loss=0.9526109099388123\n",
      "epoch 159: loss=0.9418874382972717\n",
      "epoch 160: loss=0.9369418025016785\n",
      "epoch 161: loss=0.9311587810516357\n",
      "epoch 162: loss=0.9284310936927795\n",
      "epoch 163: loss=0.9401751160621643\n",
      "epoch 164: loss=0.9096943736076355\n",
      "epoch 165: loss=0.9441584944725037\n",
      "epoch 166: loss=0.9377469420433044\n",
      "epoch 167: loss=0.9212919473648071\n",
      "epoch 168: loss=0.9477883577346802\n",
      "epoch 169: loss=0.9219348430633545\n",
      "epoch 170: loss=0.9471449255943298\n",
      "epoch 171: loss=0.9322407841682434\n",
      "epoch 172: loss=0.9557030200958252\n",
      "epoch 173: loss=0.9245869517326355\n",
      "epoch 174: loss=0.9370601773262024\n",
      "epoch 175: loss=0.9163655042648315\n",
      "epoch 176: loss=0.9240199327468872\n",
      "epoch 177: loss=0.9173976182937622\n",
      "epoch 178: loss=0.9303085803985596\n",
      "epoch 179: loss=0.9207460880279541\n",
      "epoch 180: loss=0.9259675741195679\n",
      "epoch 181: loss=0.9204227328300476\n",
      "epoch 182: loss=0.9212340116500854\n",
      "epoch 183: loss=0.9241779446601868\n",
      "epoch 184: loss=0.9165787696838379\n",
      "epoch 185: loss=0.9240459203720093\n",
      "epoch 186: loss=0.9333733320236206\n",
      "epoch 187: loss=0.9266149997711182\n",
      "epoch 188: loss=0.9371771812438965\n",
      "epoch 189: loss=0.9231238961219788\n",
      "epoch 190: loss=0.9037755131721497\n",
      "epoch 191: loss=0.9091936349868774\n",
      "epoch 192: loss=0.9409834742546082\n",
      "epoch 193: loss=0.9254442453384399\n",
      "epoch 194: loss=0.9078419208526611\n",
      "epoch 195: loss=0.9205446839332581\n",
      "epoch 196: loss=0.9386398792266846\n",
      "epoch 197: loss=0.9292985796928406\n",
      "epoch 198: loss=0.8912127614021301\n",
      "epoch 199: loss=0.9297906756401062\n",
      "training patch with 670 edges\n",
      "epoch 0: loss=4.575788497924805\n",
      "epoch 1: loss=4.430027484893799\n",
      "epoch 2: loss=4.075164318084717\n",
      "epoch 3: loss=4.106596946716309\n",
      "epoch 4: loss=4.123163223266602\n",
      "epoch 5: loss=3.6491127014160156\n",
      "epoch 6: loss=3.4547641277313232\n",
      "epoch 7: loss=3.241859197616577\n",
      "epoch 8: loss=2.9595048427581787\n",
      "epoch 9: loss=2.7174978256225586\n",
      "epoch 10: loss=2.435333251953125\n",
      "epoch 11: loss=2.3264222145080566\n",
      "epoch 12: loss=2.130974054336548\n",
      "epoch 13: loss=2.0239875316619873\n",
      "epoch 14: loss=1.8218703269958496\n",
      "epoch 15: loss=1.769005537033081\n",
      "epoch 16: loss=1.6378341913223267\n",
      "epoch 17: loss=1.549720287322998\n",
      "epoch 18: loss=1.5564992427825928\n",
      "epoch 19: loss=1.5462920665740967\n",
      "epoch 20: loss=1.5186465978622437\n",
      "epoch 21: loss=1.564604640007019\n",
      "epoch 22: loss=1.5122661590576172\n",
      "epoch 23: loss=1.5317295789718628\n",
      "epoch 24: loss=1.5289123058319092\n",
      "epoch 25: loss=1.5220308303833008\n",
      "epoch 26: loss=1.5385675430297852\n",
      "epoch 27: loss=1.523763656616211\n",
      "epoch 28: loss=1.5301945209503174\n",
      "epoch 29: loss=1.5285428762435913\n",
      "epoch 30: loss=1.510553240776062\n",
      "epoch 31: loss=1.4938057661056519\n",
      "epoch 32: loss=1.4909210205078125\n",
      "epoch 33: loss=1.4837288856506348\n",
      "epoch 34: loss=1.4686371088027954\n",
      "epoch 35: loss=1.4536840915679932\n",
      "epoch 36: loss=1.4291067123413086\n",
      "epoch 37: loss=1.441666603088379\n",
      "epoch 38: loss=1.4131664037704468\n",
      "epoch 39: loss=1.3872315883636475\n",
      "epoch 40: loss=1.3539321422576904\n",
      "epoch 41: loss=1.3325706720352173\n",
      "epoch 42: loss=1.3058193922042847\n",
      "epoch 43: loss=1.2780816555023193\n",
      "epoch 44: loss=1.2677162885665894\n",
      "epoch 45: loss=1.2074416875839233\n",
      "epoch 46: loss=1.171553134918213\n",
      "epoch 47: loss=1.2538270950317383\n",
      "epoch 48: loss=1.2233119010925293\n",
      "epoch 49: loss=1.2413746118545532\n",
      "epoch 50: loss=1.1652461290359497\n",
      "epoch 51: loss=1.1874563694000244\n",
      "epoch 52: loss=1.201359748840332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53: loss=1.1945774555206299\n",
      "epoch 54: loss=1.2274596691131592\n",
      "epoch 55: loss=1.1999634504318237\n",
      "epoch 56: loss=1.1916322708129883\n",
      "epoch 57: loss=1.0964924097061157\n",
      "epoch 58: loss=1.18020761013031\n",
      "epoch 59: loss=1.1499032974243164\n",
      "epoch 60: loss=1.110244631767273\n",
      "epoch 61: loss=1.0970438718795776\n",
      "epoch 62: loss=1.1221708059310913\n",
      "epoch 63: loss=1.1290936470031738\n",
      "epoch 64: loss=1.1362221240997314\n",
      "epoch 65: loss=1.1267907619476318\n",
      "epoch 66: loss=1.1660306453704834\n",
      "epoch 67: loss=1.119943618774414\n",
      "epoch 68: loss=1.139685869216919\n",
      "epoch 69: loss=1.127371907234192\n",
      "epoch 70: loss=1.0877267122268677\n",
      "epoch 71: loss=1.0844762325286865\n",
      "epoch 72: loss=1.0790698528289795\n",
      "epoch 73: loss=1.067293405532837\n",
      "epoch 74: loss=1.0742167234420776\n",
      "epoch 75: loss=1.0714330673217773\n",
      "epoch 76: loss=1.122895359992981\n",
      "epoch 77: loss=1.0854110717773438\n",
      "epoch 78: loss=1.097333550453186\n",
      "epoch 79: loss=1.1029459238052368\n",
      "epoch 80: loss=1.1313384771347046\n",
      "epoch 81: loss=1.1094361543655396\n",
      "epoch 82: loss=1.0849552154541016\n",
      "epoch 83: loss=1.0871787071228027\n",
      "epoch 84: loss=1.074126958847046\n",
      "epoch 85: loss=1.0750062465667725\n",
      "epoch 86: loss=1.1020894050598145\n",
      "epoch 87: loss=1.0513157844543457\n",
      "epoch 88: loss=1.0826507806777954\n",
      "epoch 89: loss=1.035352349281311\n",
      "epoch 90: loss=1.0394734144210815\n",
      "epoch 91: loss=1.0771702527999878\n",
      "epoch 92: loss=1.0827463865280151\n",
      "epoch 93: loss=1.010538101196289\n",
      "epoch 94: loss=1.0144987106323242\n",
      "epoch 95: loss=1.0598037242889404\n",
      "epoch 96: loss=1.0732187032699585\n",
      "epoch 97: loss=1.0875835418701172\n",
      "epoch 98: loss=1.066586971282959\n",
      "epoch 99: loss=1.010180115699768\n",
      "epoch 100: loss=1.0415525436401367\n",
      "epoch 101: loss=1.0407836437225342\n",
      "epoch 102: loss=1.0697730779647827\n",
      "epoch 103: loss=1.0274900197982788\n",
      "epoch 104: loss=1.0880732536315918\n",
      "epoch 105: loss=1.0727968215942383\n",
      "epoch 106: loss=1.0606523752212524\n",
      "epoch 107: loss=1.0614145994186401\n",
      "epoch 108: loss=1.0938409566879272\n",
      "epoch 109: loss=1.0209258794784546\n",
      "epoch 110: loss=1.0865901708602905\n",
      "epoch 111: loss=1.0501692295074463\n",
      "epoch 112: loss=1.0559192895889282\n",
      "epoch 113: loss=1.0740389823913574\n",
      "epoch 114: loss=1.1020795106887817\n",
      "epoch 115: loss=1.0603625774383545\n",
      "epoch 116: loss=1.0351102352142334\n",
      "epoch 117: loss=1.062574028968811\n",
      "epoch 118: loss=1.0562183856964111\n",
      "epoch 119: loss=1.0450260639190674\n",
      "epoch 120: loss=1.0744606256484985\n",
      "epoch 121: loss=1.0749897956848145\n",
      "epoch 122: loss=1.003293752670288\n",
      "epoch 123: loss=1.0546700954437256\n",
      "epoch 124: loss=1.04166579246521\n",
      "epoch 125: loss=1.0481196641921997\n",
      "epoch 126: loss=1.0579984188079834\n",
      "epoch 127: loss=1.0622049570083618\n",
      "epoch 128: loss=1.0420945882797241\n",
      "epoch 129: loss=1.0840117931365967\n",
      "epoch 130: loss=1.082678198814392\n",
      "epoch 131: loss=1.011780858039856\n",
      "epoch 132: loss=1.0652995109558105\n",
      "epoch 133: loss=1.0413894653320312\n",
      "epoch 134: loss=1.032603144645691\n",
      "epoch 135: loss=0.9961450695991516\n",
      "epoch 136: loss=1.021568775177002\n",
      "epoch 137: loss=1.0219589471817017\n",
      "epoch 138: loss=1.0326085090637207\n",
      "epoch 139: loss=1.0475512742996216\n",
      "epoch 140: loss=1.003253698348999\n",
      "epoch 141: loss=1.0417282581329346\n",
      "epoch 142: loss=1.0788885354995728\n",
      "epoch 143: loss=1.0322216749191284\n",
      "epoch 144: loss=1.0560972690582275\n",
      "epoch 145: loss=1.0298442840576172\n",
      "epoch 146: loss=1.0112988948822021\n",
      "epoch 147: loss=1.0567777156829834\n",
      "epoch 148: loss=1.0501708984375\n",
      "epoch 149: loss=1.015417456626892\n",
      "epoch 150: loss=1.0577375888824463\n",
      "epoch 151: loss=1.039246916770935\n",
      "epoch 152: loss=1.0551573038101196\n",
      "epoch 153: loss=1.0102756023406982\n",
      "epoch 154: loss=1.0105020999908447\n",
      "epoch 155: loss=1.0391883850097656\n",
      "epoch 156: loss=1.0069416761398315\n",
      "epoch 157: loss=1.0164469480514526\n",
      "epoch 158: loss=1.0413048267364502\n",
      "epoch 159: loss=1.049881935119629\n",
      "epoch 160: loss=1.0482351779937744\n",
      "epoch 161: loss=1.0169156789779663\n",
      "epoch 162: loss=1.0024323463439941\n",
      "epoch 163: loss=1.0368669033050537\n",
      "epoch 164: loss=1.0033836364746094\n",
      "epoch 165: loss=1.0249817371368408\n",
      "epoch 166: loss=1.0289791822433472\n",
      "epoch 167: loss=1.0286041498184204\n",
      "epoch 168: loss=1.0456515550613403\n",
      "epoch 169: loss=1.0410008430480957\n",
      "epoch 170: loss=1.0234436988830566\n",
      "epoch 171: loss=1.0280803442001343\n",
      "epoch 172: loss=1.0216830968856812\n",
      "epoch 173: loss=1.0410902500152588\n",
      "epoch 174: loss=1.0171496868133545\n",
      "epoch 175: loss=1.0316904783248901\n",
      "epoch 176: loss=0.995383620262146\n",
      "epoch 177: loss=0.9796412587165833\n",
      "epoch 178: loss=1.053791880607605\n",
      "epoch 179: loss=1.0382953882217407\n",
      "epoch 180: loss=1.0812206268310547\n",
      "epoch 181: loss=1.04380202293396\n",
      "epoch 182: loss=1.019610047340393\n",
      "epoch 183: loss=1.0522907972335815\n",
      "epoch 184: loss=1.0605310201644897\n",
      "epoch 185: loss=1.0221099853515625\n",
      "epoch 186: loss=1.0167251825332642\n",
      "epoch 187: loss=1.0642790794372559\n",
      "epoch 188: loss=0.9818931818008423\n",
      "epoch 189: loss=1.0450148582458496\n",
      "epoch 190: loss=1.0219093561172485\n",
      "epoch 191: loss=1.0479141473770142\n",
      "epoch 192: loss=1.0755503177642822\n",
      "epoch 193: loss=1.0146175622940063\n",
      "epoch 194: loss=1.0161255598068237\n",
      "epoch 195: loss=0.988152265548706\n",
      "epoch 196: loss=1.0045020580291748\n",
      "epoch 197: loss=1.0089823007583618\n",
      "epoch 198: loss=1.0093368291854858\n",
      "epoch 199: loss=1.0474780797958374\n",
      "training patch with 1602 edges\n",
      "epoch 0: loss=4.6419758796691895\n",
      "epoch 1: loss=4.578364849090576\n",
      "epoch 2: loss=4.363830089569092\n",
      "epoch 3: loss=4.006088733673096\n",
      "epoch 4: loss=3.846102237701416\n",
      "epoch 5: loss=3.6015918254852295\n",
      "epoch 6: loss=3.3667244911193848\n",
      "epoch 7: loss=3.033634901046753\n",
      "epoch 8: loss=2.8554530143737793\n",
      "epoch 9: loss=2.629549264907837\n",
      "epoch 10: loss=2.420234441757202\n",
      "epoch 11: loss=2.2001631259918213\n",
      "epoch 12: loss=2.1008620262145996\n",
      "epoch 13: loss=1.8800166845321655\n",
      "epoch 14: loss=1.8185254335403442\n",
      "epoch 15: loss=1.6824769973754883\n",
      "epoch 16: loss=1.581027865409851\n",
      "epoch 17: loss=1.5457124710083008\n",
      "epoch 18: loss=1.5018482208251953\n",
      "epoch 19: loss=1.4482970237731934\n",
      "epoch 20: loss=1.4285486936569214\n",
      "epoch 21: loss=1.442513108253479\n",
      "epoch 22: loss=1.4268460273742676\n",
      "epoch 23: loss=1.4276610612869263\n",
      "epoch 24: loss=1.4110846519470215\n",
      "epoch 25: loss=1.4036788940429688\n",
      "epoch 26: loss=1.4033502340316772\n",
      "epoch 27: loss=1.3957334756851196\n",
      "epoch 28: loss=1.3899751901626587\n",
      "epoch 29: loss=1.3831453323364258\n",
      "epoch 30: loss=1.369663119316101\n",
      "epoch 31: loss=1.3673406839370728\n",
      "epoch 32: loss=1.3535665273666382\n",
      "epoch 33: loss=1.3332456350326538\n",
      "epoch 34: loss=1.319258689880371\n",
      "epoch 35: loss=1.3127470016479492\n",
      "epoch 36: loss=1.2949769496917725\n",
      "epoch 37: loss=1.2738817930221558\n",
      "epoch 38: loss=1.251654863357544\n",
      "epoch 39: loss=1.214869499206543\n",
      "epoch 40: loss=1.193871021270752\n",
      "epoch 41: loss=1.1757484674453735\n",
      "epoch 42: loss=1.1551179885864258\n",
      "epoch 43: loss=1.1337332725524902\n",
      "epoch 44: loss=1.1196870803833008\n",
      "epoch 45: loss=1.100516676902771\n",
      "epoch 46: loss=1.0910675525665283\n",
      "epoch 47: loss=1.0828964710235596\n",
      "epoch 48: loss=1.1246013641357422\n",
      "epoch 49: loss=1.0885263681411743\n",
      "epoch 50: loss=1.0779236555099487\n",
      "epoch 51: loss=1.0664258003234863\n",
      "epoch 52: loss=1.056560754776001\n",
      "epoch 53: loss=1.0286904573440552\n",
      "epoch 54: loss=1.0628399848937988\n",
      "epoch 55: loss=1.0560498237609863\n",
      "epoch 56: loss=1.0466363430023193\n",
      "epoch 57: loss=1.0175179243087769\n",
      "epoch 58: loss=1.0163116455078125\n",
      "epoch 59: loss=1.0397658348083496\n",
      "epoch 60: loss=1.0113167762756348\n",
      "epoch 61: loss=1.0186110734939575\n",
      "epoch 62: loss=0.9707087278366089\n",
      "epoch 63: loss=0.9896218776702881\n",
      "epoch 64: loss=0.9840959310531616\n",
      "epoch 65: loss=0.96900874376297\n",
      "epoch 66: loss=0.9857037663459778\n",
      "epoch 67: loss=0.9894728064537048\n",
      "epoch 68: loss=0.9791812896728516\n",
      "epoch 69: loss=0.9687587022781372\n",
      "epoch 70: loss=0.9801149368286133\n",
      "epoch 71: loss=0.9815982580184937\n",
      "epoch 72: loss=0.9733843803405762\n",
      "epoch 73: loss=0.9906187057495117\n",
      "epoch 74: loss=0.9888851046562195\n",
      "epoch 75: loss=0.9666863679885864\n",
      "epoch 76: loss=0.975663959980011\n",
      "epoch 77: loss=0.977681040763855\n",
      "epoch 78: loss=0.9602628946304321\n",
      "epoch 79: loss=0.987509548664093\n",
      "epoch 80: loss=0.9638050198554993\n",
      "epoch 81: loss=0.9758820533752441\n",
      "epoch 82: loss=0.964527428150177\n",
      "epoch 83: loss=0.9603232741355896\n",
      "epoch 84: loss=0.9541500806808472\n",
      "epoch 85: loss=0.9672811031341553\n",
      "epoch 86: loss=0.9535704851150513\n",
      "epoch 87: loss=0.9480894207954407\n",
      "epoch 88: loss=0.9545246362686157\n",
      "epoch 89: loss=0.9612260460853577\n",
      "epoch 90: loss=0.9423713088035583\n",
      "epoch 91: loss=0.9780473709106445\n",
      "epoch 92: loss=0.9382429122924805\n",
      "epoch 93: loss=0.9449594616889954\n",
      "epoch 94: loss=0.9369513988494873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95: loss=0.9470832943916321\n",
      "epoch 96: loss=0.9703119993209839\n",
      "epoch 97: loss=0.9314358234405518\n",
      "epoch 98: loss=0.9551458358764648\n",
      "epoch 99: loss=0.936421275138855\n",
      "epoch 100: loss=0.9537475109100342\n",
      "epoch 101: loss=0.9436256289482117\n",
      "epoch 102: loss=0.9480897784233093\n",
      "epoch 103: loss=0.9424835443496704\n",
      "epoch 104: loss=0.9490006566047668\n",
      "epoch 105: loss=0.9486067295074463\n",
      "epoch 106: loss=0.9483808875083923\n",
      "epoch 107: loss=0.9213935732841492\n",
      "epoch 108: loss=0.9379076957702637\n",
      "epoch 109: loss=0.938117265701294\n",
      "epoch 110: loss=0.9467324614524841\n",
      "epoch 111: loss=0.9467586874961853\n",
      "epoch 112: loss=0.9419493079185486\n",
      "epoch 113: loss=0.9347904920578003\n",
      "epoch 114: loss=0.9526792168617249\n",
      "epoch 115: loss=0.9265837669372559\n",
      "epoch 116: loss=0.9741926193237305\n",
      "epoch 117: loss=0.9699603915214539\n",
      "epoch 118: loss=0.9281555414199829\n",
      "epoch 119: loss=0.9399968385696411\n",
      "epoch 120: loss=0.9610525965690613\n",
      "epoch 121: loss=0.9406198859214783\n",
      "epoch 122: loss=0.9404520392417908\n",
      "epoch 123: loss=0.9402762055397034\n",
      "epoch 124: loss=0.9355430603027344\n",
      "epoch 125: loss=0.9379744529724121\n",
      "epoch 126: loss=0.9449967741966248\n",
      "epoch 127: loss=0.9311223030090332\n",
      "epoch 128: loss=0.9497334957122803\n",
      "epoch 129: loss=0.936673641204834\n",
      "epoch 130: loss=0.9230102300643921\n",
      "epoch 131: loss=0.9481372833251953\n",
      "epoch 132: loss=0.9293668270111084\n",
      "epoch 133: loss=0.9410471320152283\n",
      "epoch 134: loss=0.9189578294754028\n",
      "epoch 135: loss=0.9568377137184143\n",
      "epoch 136: loss=0.9451940655708313\n",
      "epoch 137: loss=0.9336745142936707\n",
      "epoch 138: loss=0.9426231980323792\n",
      "epoch 139: loss=0.9500292539596558\n",
      "epoch 140: loss=0.9453490376472473\n",
      "epoch 141: loss=0.9485586285591125\n",
      "epoch 142: loss=0.9370623230934143\n",
      "epoch 143: loss=0.9370502829551697\n",
      "epoch 144: loss=0.9383499026298523\n",
      "epoch 145: loss=0.9176862239837646\n",
      "epoch 146: loss=0.9539605379104614\n",
      "epoch 147: loss=0.9283429384231567\n",
      "epoch 148: loss=0.9381588697433472\n",
      "epoch 149: loss=0.9329410195350647\n",
      "epoch 150: loss=0.9228194355964661\n",
      "epoch 151: loss=0.9256381392478943\n",
      "epoch 152: loss=0.9200640320777893\n",
      "epoch 153: loss=0.9490153789520264\n",
      "epoch 154: loss=0.9568814039230347\n",
      "epoch 155: loss=0.9253681302070618\n",
      "epoch 156: loss=0.927713930606842\n",
      "epoch 157: loss=0.9260737895965576\n",
      "epoch 158: loss=0.9651288986206055\n",
      "epoch 159: loss=0.9268848896026611\n",
      "epoch 160: loss=0.9338915944099426\n",
      "epoch 161: loss=0.9171178340911865\n",
      "epoch 162: loss=0.9347600936889648\n",
      "epoch 163: loss=0.9130472540855408\n",
      "epoch 164: loss=0.9210353493690491\n",
      "epoch 165: loss=0.918655514717102\n",
      "epoch 166: loss=0.9147682189941406\n",
      "epoch 167: loss=0.9175346493721008\n",
      "epoch 168: loss=0.9146537780761719\n",
      "epoch 169: loss=0.9364142417907715\n",
      "epoch 170: loss=0.9287570714950562\n",
      "epoch 171: loss=0.9190958142280579\n",
      "epoch 172: loss=0.9012655019760132\n",
      "epoch 173: loss=0.9136559963226318\n",
      "epoch 174: loss=0.9354705214500427\n",
      "epoch 175: loss=0.9208076596260071\n",
      "epoch 176: loss=0.911615788936615\n",
      "epoch 177: loss=0.9178679585456848\n",
      "epoch 178: loss=0.9548969864845276\n",
      "epoch 179: loss=0.8947640061378479\n",
      "epoch 180: loss=0.9265468716621399\n",
      "epoch 181: loss=0.9222398996353149\n",
      "epoch 182: loss=0.9108985662460327\n",
      "epoch 183: loss=0.9451988935470581\n",
      "epoch 184: loss=0.9098225831985474\n",
      "epoch 185: loss=0.9482840299606323\n",
      "epoch 186: loss=0.9221419095993042\n",
      "epoch 187: loss=0.9327895641326904\n",
      "epoch 188: loss=0.9287235140800476\n",
      "epoch 189: loss=0.9256871938705444\n",
      "epoch 190: loss=0.9431412220001221\n",
      "epoch 191: loss=0.9237650632858276\n",
      "epoch 192: loss=0.8897668123245239\n",
      "epoch 193: loss=0.9173911213874817\n",
      "epoch 194: loss=0.9255375862121582\n",
      "epoch 195: loss=0.9123234748840332\n",
      "epoch 196: loss=0.8979843258857727\n",
      "epoch 197: loss=0.9253584742546082\n",
      "epoch 198: loss=0.9173532724380493\n",
      "epoch 199: loss=0.9303727149963379\n",
      "training patch with 1800 edges\n",
      "epoch 0: loss=4.663582801818848\n",
      "epoch 1: loss=4.445477485656738\n",
      "epoch 2: loss=4.777449607849121\n",
      "epoch 3: loss=4.009675025939941\n",
      "epoch 4: loss=4.002717018127441\n",
      "epoch 5: loss=3.8671467304229736\n",
      "epoch 6: loss=3.6086978912353516\n",
      "epoch 7: loss=3.2603983879089355\n",
      "epoch 8: loss=3.072317123413086\n",
      "epoch 9: loss=2.744166135787964\n",
      "epoch 10: loss=2.626164436340332\n",
      "epoch 11: loss=2.394321918487549\n",
      "epoch 12: loss=2.2669715881347656\n",
      "epoch 13: loss=2.0608673095703125\n",
      "epoch 14: loss=1.8847953081130981\n",
      "epoch 15: loss=1.7096800804138184\n",
      "epoch 16: loss=1.6511150598526\n",
      "epoch 17: loss=1.5892990827560425\n",
      "epoch 18: loss=1.53529953956604\n",
      "epoch 19: loss=1.4803032875061035\n",
      "epoch 20: loss=1.4458250999450684\n",
      "epoch 21: loss=1.503993034362793\n",
      "epoch 22: loss=1.4496005773544312\n",
      "epoch 23: loss=1.423751950263977\n",
      "epoch 24: loss=1.4123550653457642\n",
      "epoch 25: loss=1.4137426614761353\n",
      "epoch 26: loss=1.3976490497589111\n",
      "epoch 27: loss=1.385172724723816\n",
      "epoch 28: loss=1.3751200437545776\n",
      "epoch 29: loss=1.3641194105148315\n",
      "epoch 30: loss=1.3460966348648071\n",
      "epoch 31: loss=1.3287017345428467\n",
      "epoch 32: loss=1.3213129043579102\n",
      "epoch 33: loss=1.291680932044983\n",
      "epoch 34: loss=1.268506646156311\n",
      "epoch 35: loss=1.2567344903945923\n",
      "epoch 36: loss=1.2642087936401367\n",
      "epoch 37: loss=1.2448283433914185\n",
      "epoch 38: loss=1.2329550981521606\n",
      "epoch 39: loss=1.2244998216629028\n",
      "epoch 40: loss=1.237446904182434\n",
      "epoch 41: loss=1.2142621278762817\n",
      "epoch 42: loss=1.2125630378723145\n",
      "epoch 43: loss=1.195573329925537\n",
      "epoch 44: loss=1.183223843574524\n",
      "epoch 45: loss=1.196800708770752\n",
      "epoch 46: loss=1.1982178688049316\n",
      "epoch 47: loss=1.1503452062606812\n",
      "epoch 48: loss=1.1827547550201416\n",
      "epoch 49: loss=1.1410449743270874\n",
      "epoch 50: loss=1.119288682937622\n",
      "epoch 51: loss=1.1039409637451172\n",
      "epoch 52: loss=1.123352289199829\n",
      "epoch 53: loss=1.110660195350647\n",
      "epoch 54: loss=1.096555233001709\n",
      "epoch 55: loss=1.0901868343353271\n",
      "epoch 56: loss=1.071726679801941\n",
      "epoch 57: loss=1.0874528884887695\n",
      "epoch 58: loss=1.0750765800476074\n",
      "epoch 59: loss=1.0778889656066895\n",
      "epoch 60: loss=1.0567095279693604\n",
      "epoch 61: loss=1.0647410154342651\n",
      "epoch 62: loss=1.0474791526794434\n",
      "epoch 63: loss=1.0310442447662354\n",
      "epoch 64: loss=1.0292699337005615\n",
      "epoch 65: loss=1.0374141931533813\n",
      "epoch 66: loss=1.0436631441116333\n",
      "epoch 67: loss=1.0173698663711548\n",
      "epoch 68: loss=1.0271536111831665\n",
      "epoch 69: loss=1.014899492263794\n",
      "epoch 70: loss=1.0268871784210205\n",
      "epoch 71: loss=1.0307412147521973\n",
      "epoch 72: loss=1.0277965068817139\n",
      "epoch 73: loss=0.9979579448699951\n",
      "epoch 74: loss=1.0283079147338867\n",
      "epoch 75: loss=1.0168205499649048\n",
      "epoch 76: loss=1.00791597366333\n",
      "epoch 77: loss=1.0211409330368042\n",
      "epoch 78: loss=1.0299046039581299\n",
      "epoch 79: loss=1.0152792930603027\n",
      "epoch 80: loss=1.018093228340149\n",
      "epoch 81: loss=1.0219953060150146\n",
      "epoch 82: loss=1.0272269248962402\n",
      "epoch 83: loss=1.0043680667877197\n",
      "epoch 84: loss=0.9991942048072815\n",
      "epoch 85: loss=1.0012872219085693\n",
      "epoch 86: loss=1.030784249305725\n",
      "epoch 87: loss=1.000131607055664\n",
      "epoch 88: loss=1.0167711973190308\n",
      "epoch 89: loss=0.9899867177009583\n",
      "epoch 90: loss=0.9808838963508606\n",
      "epoch 91: loss=1.0012305974960327\n",
      "epoch 92: loss=1.0002901554107666\n",
      "epoch 93: loss=1.0005987882614136\n",
      "epoch 94: loss=0.9927466511726379\n",
      "epoch 95: loss=1.0365467071533203\n",
      "epoch 96: loss=1.0021615028381348\n",
      "epoch 97: loss=0.9985815286636353\n",
      "epoch 98: loss=0.9814448952674866\n",
      "epoch 99: loss=0.9841667413711548\n",
      "epoch 100: loss=0.9828467965126038\n",
      "epoch 101: loss=0.984717071056366\n",
      "epoch 102: loss=0.9797215461730957\n",
      "epoch 103: loss=0.9994457364082336\n",
      "epoch 104: loss=0.9838865995407104\n",
      "epoch 105: loss=0.9754958152770996\n",
      "epoch 106: loss=0.9678581953048706\n",
      "epoch 107: loss=0.9692829847335815\n",
      "epoch 108: loss=0.9563871622085571\n",
      "epoch 109: loss=0.9734176397323608\n",
      "epoch 110: loss=0.9758707284927368\n",
      "epoch 111: loss=0.9648904800415039\n",
      "epoch 112: loss=0.9887934923171997\n",
      "epoch 113: loss=0.9742414355278015\n",
      "epoch 114: loss=0.9913771152496338\n",
      "epoch 115: loss=0.9716799259185791\n",
      "epoch 116: loss=0.9574834108352661\n",
      "epoch 117: loss=1.0006986856460571\n",
      "epoch 118: loss=0.9680300951004028\n",
      "epoch 119: loss=0.9953926205635071\n",
      "epoch 120: loss=0.9879552125930786\n",
      "epoch 121: loss=0.960602879524231\n",
      "epoch 122: loss=0.9797244071960449\n",
      "epoch 123: loss=0.9501733779907227\n",
      "epoch 124: loss=1.0051825046539307\n",
      "epoch 125: loss=0.9818099141120911\n",
      "epoch 126: loss=0.9818357825279236\n",
      "epoch 127: loss=0.979565441608429\n",
      "epoch 128: loss=0.9690462350845337\n",
      "epoch 129: loss=0.9668068885803223\n",
      "epoch 130: loss=0.9762237668037415\n",
      "epoch 131: loss=0.9358306527137756\n",
      "epoch 132: loss=0.9607368111610413\n",
      "epoch 133: loss=0.9616954326629639\n",
      "epoch 134: loss=0.9636446833610535\n",
      "epoch 135: loss=0.9830254912376404\n",
      "epoch 136: loss=0.9436182379722595\n",
      "epoch 137: loss=0.9720966219902039\n",
      "epoch 138: loss=0.9578426480293274\n",
      "epoch 139: loss=0.9641098380088806\n",
      "epoch 140: loss=0.9675352573394775\n",
      "epoch 141: loss=0.9571208953857422\n",
      "epoch 142: loss=0.9709700345993042\n",
      "epoch 143: loss=0.9512442350387573\n",
      "epoch 144: loss=0.9454985857009888\n",
      "epoch 145: loss=0.9621278643608093\n",
      "epoch 146: loss=0.9459503293037415\n",
      "epoch 147: loss=0.9515634775161743\n",
      "epoch 148: loss=0.9787123203277588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149: loss=0.9647775888442993\n",
      "epoch 150: loss=0.957587480545044\n",
      "epoch 151: loss=0.9607871174812317\n",
      "epoch 152: loss=0.9893607497215271\n",
      "epoch 153: loss=0.9526538848876953\n",
      "epoch 154: loss=0.9527350664138794\n",
      "epoch 155: loss=0.9701844453811646\n",
      "epoch 156: loss=0.960349440574646\n",
      "epoch 157: loss=0.9475865364074707\n",
      "epoch 158: loss=0.9514642953872681\n",
      "epoch 159: loss=0.9504614472389221\n",
      "epoch 160: loss=0.9617577791213989\n",
      "epoch 161: loss=0.9498549699783325\n",
      "epoch 162: loss=0.9507278203964233\n",
      "epoch 163: loss=0.9541702270507812\n",
      "epoch 164: loss=0.9528781175613403\n",
      "epoch 165: loss=0.9456906318664551\n",
      "epoch 166: loss=0.9681656360626221\n",
      "epoch 167: loss=0.956066906452179\n",
      "epoch 168: loss=0.9688145518302917\n",
      "epoch 169: loss=0.9296897649765015\n",
      "epoch 170: loss=0.9530874490737915\n",
      "epoch 171: loss=0.942926824092865\n",
      "epoch 172: loss=0.9424040913581848\n",
      "epoch 173: loss=0.954269528388977\n",
      "epoch 174: loss=0.9434757232666016\n",
      "epoch 175: loss=0.9364224076271057\n",
      "epoch 176: loss=0.9491742849349976\n",
      "epoch 177: loss=0.9571250081062317\n",
      "epoch 178: loss=0.9455201029777527\n",
      "epoch 179: loss=0.9328762292861938\n",
      "epoch 180: loss=0.9622980952262878\n",
      "epoch 181: loss=0.9510256052017212\n",
      "epoch 182: loss=0.9380427598953247\n",
      "epoch 183: loss=0.9494701027870178\n",
      "epoch 184: loss=0.9348318576812744\n",
      "epoch 185: loss=0.9557115435600281\n",
      "epoch 186: loss=0.9239580035209656\n",
      "epoch 187: loss=0.9402132034301758\n",
      "epoch 188: loss=0.9506507515907288\n",
      "epoch 189: loss=0.9355452060699463\n",
      "epoch 190: loss=0.9412550926208496\n",
      "epoch 191: loss=0.9355102777481079\n",
      "epoch 192: loss=0.9305627942085266\n",
      "epoch 193: loss=0.9524151086807251\n",
      "epoch 194: loss=0.9531293511390686\n",
      "epoch 195: loss=0.9263874888420105\n",
      "epoch 196: loss=0.9579460620880127\n",
      "epoch 197: loss=0.9421395063400269\n",
      "epoch 198: loss=0.9389017224311829\n",
      "epoch 199: loss=0.9337158203125\n",
      "training patch with 1844 edges\n",
      "epoch 0: loss=4.55216646194458\n",
      "epoch 1: loss=4.749902248382568\n",
      "epoch 2: loss=4.491666793823242\n",
      "epoch 3: loss=4.142573356628418\n",
      "epoch 4: loss=3.6894805431365967\n",
      "epoch 5: loss=3.5856246948242188\n",
      "epoch 6: loss=3.571866035461426\n",
      "epoch 7: loss=3.391167640686035\n",
      "epoch 8: loss=3.0130350589752197\n",
      "epoch 9: loss=2.729126214981079\n",
      "epoch 10: loss=2.464653491973877\n",
      "epoch 11: loss=2.4754912853240967\n",
      "epoch 12: loss=2.2644600868225098\n",
      "epoch 13: loss=2.078322410583496\n",
      "epoch 14: loss=1.9169775247573853\n",
      "epoch 15: loss=1.789113998413086\n",
      "epoch 16: loss=1.6470105648040771\n",
      "epoch 17: loss=1.576599359512329\n",
      "epoch 18: loss=1.5139950513839722\n",
      "epoch 19: loss=1.496307611465454\n",
      "epoch 20: loss=1.4607185125350952\n",
      "epoch 21: loss=1.4275803565979004\n",
      "epoch 22: loss=1.4335206747055054\n",
      "epoch 23: loss=1.4262614250183105\n",
      "epoch 24: loss=1.425909399986267\n",
      "epoch 25: loss=1.3906580209732056\n",
      "epoch 26: loss=1.4013904333114624\n",
      "epoch 27: loss=1.3733546733856201\n",
      "epoch 28: loss=1.3849326372146606\n",
      "epoch 29: loss=1.3693596124649048\n",
      "epoch 30: loss=1.379704475402832\n",
      "epoch 31: loss=1.3393527269363403\n",
      "epoch 32: loss=1.3354945182800293\n",
      "epoch 33: loss=1.3291901350021362\n",
      "epoch 34: loss=1.2874869108200073\n",
      "epoch 35: loss=1.2706605195999146\n",
      "epoch 36: loss=1.2402781248092651\n",
      "epoch 37: loss=1.226629614830017\n",
      "epoch 38: loss=1.19454026222229\n",
      "epoch 39: loss=1.1768214702606201\n",
      "epoch 40: loss=1.1668449640274048\n",
      "epoch 41: loss=1.1572833061218262\n",
      "epoch 42: loss=1.1339833736419678\n",
      "epoch 43: loss=1.1412696838378906\n",
      "epoch 44: loss=1.1409181356430054\n",
      "epoch 45: loss=1.118128776550293\n",
      "epoch 46: loss=1.1361756324768066\n",
      "epoch 47: loss=1.0907227993011475\n",
      "epoch 48: loss=1.123105525970459\n",
      "epoch 49: loss=1.07291579246521\n",
      "epoch 50: loss=1.0922126770019531\n",
      "epoch 51: loss=1.0636721849441528\n",
      "epoch 52: loss=1.0800303220748901\n",
      "epoch 53: loss=1.0718721151351929\n",
      "epoch 54: loss=1.0509756803512573\n",
      "epoch 55: loss=1.0407131910324097\n",
      "epoch 56: loss=1.0505561828613281\n",
      "epoch 57: loss=1.0428706407546997\n",
      "epoch 58: loss=1.0551338195800781\n",
      "epoch 59: loss=1.0287423133850098\n",
      "epoch 60: loss=1.0168746709823608\n",
      "epoch 61: loss=1.0206375122070312\n",
      "epoch 62: loss=1.0121005773544312\n",
      "epoch 63: loss=1.0138684511184692\n",
      "epoch 64: loss=1.0333706140518188\n",
      "epoch 65: loss=0.9935209155082703\n",
      "epoch 66: loss=0.9988925457000732\n",
      "epoch 67: loss=1.0013600587844849\n",
      "epoch 68: loss=0.9981313347816467\n",
      "epoch 69: loss=0.9991146922111511\n",
      "epoch 70: loss=1.0025570392608643\n",
      "epoch 71: loss=0.9975247383117676\n",
      "epoch 72: loss=0.9952552318572998\n",
      "epoch 73: loss=1.0109838247299194\n",
      "epoch 74: loss=0.9808188080787659\n",
      "epoch 75: loss=0.9718383550643921\n",
      "epoch 76: loss=1.0077600479125977\n",
      "epoch 77: loss=0.9888701438903809\n",
      "epoch 78: loss=0.9641385674476624\n",
      "epoch 79: loss=0.9786484241485596\n",
      "epoch 80: loss=0.975541353225708\n",
      "epoch 81: loss=0.9888623952865601\n",
      "epoch 82: loss=0.985294759273529\n",
      "epoch 83: loss=0.984908938407898\n",
      "epoch 84: loss=0.959812581539154\n",
      "epoch 85: loss=0.9736729860305786\n",
      "epoch 86: loss=1.00763738155365\n",
      "epoch 87: loss=0.9463779926300049\n",
      "epoch 88: loss=0.974745512008667\n",
      "epoch 89: loss=0.9824245572090149\n",
      "epoch 90: loss=0.9462162256240845\n",
      "epoch 91: loss=0.9642922282218933\n",
      "epoch 92: loss=0.9543138146400452\n",
      "epoch 93: loss=0.9683361649513245\n",
      "epoch 94: loss=0.9617631435394287\n",
      "epoch 95: loss=0.954643726348877\n",
      "epoch 96: loss=0.9771392941474915\n",
      "epoch 97: loss=0.948741614818573\n",
      "epoch 98: loss=0.9454179406166077\n",
      "epoch 99: loss=0.9861152172088623\n",
      "epoch 100: loss=0.9628767967224121\n",
      "epoch 101: loss=0.9597346782684326\n",
      "epoch 102: loss=0.9873378276824951\n",
      "epoch 103: loss=0.9552657604217529\n",
      "epoch 104: loss=0.96646648645401\n",
      "epoch 105: loss=0.967252790927887\n",
      "epoch 106: loss=0.9253219962120056\n",
      "epoch 107: loss=0.9733365178108215\n",
      "epoch 108: loss=0.9581847786903381\n",
      "epoch 109: loss=0.9473605155944824\n",
      "epoch 110: loss=0.9713137149810791\n",
      "epoch 111: loss=0.9314093589782715\n",
      "epoch 112: loss=0.9330245852470398\n",
      "epoch 113: loss=0.9425245523452759\n",
      "epoch 114: loss=0.9590756893157959\n",
      "epoch 115: loss=0.9579635858535767\n",
      "epoch 116: loss=0.9406102299690247\n",
      "epoch 117: loss=0.9174696207046509\n",
      "epoch 118: loss=0.9448536038398743\n",
      "epoch 119: loss=0.9490336179733276\n",
      "epoch 120: loss=0.9625222086906433\n",
      "epoch 121: loss=0.9374430179595947\n",
      "epoch 122: loss=0.9324957132339478\n",
      "epoch 123: loss=0.9564478993415833\n",
      "epoch 124: loss=0.9341812133789062\n",
      "epoch 125: loss=0.9482542276382446\n",
      "epoch 126: loss=0.9237849116325378\n",
      "epoch 127: loss=0.9355254769325256\n",
      "epoch 128: loss=0.95494544506073\n",
      "epoch 129: loss=0.9454843997955322\n",
      "epoch 130: loss=0.939642071723938\n",
      "epoch 131: loss=0.9558843374252319\n",
      "epoch 132: loss=0.9465746283531189\n",
      "epoch 133: loss=0.934410035610199\n",
      "epoch 134: loss=0.9215408563613892\n",
      "epoch 135: loss=0.9511404633522034\n",
      "epoch 136: loss=0.9181174635887146\n",
      "epoch 137: loss=0.9269895553588867\n",
      "epoch 138: loss=0.9535164833068848\n",
      "epoch 139: loss=0.9444239139556885\n",
      "epoch 140: loss=0.9273911118507385\n",
      "epoch 141: loss=0.9295045137405396\n",
      "epoch 142: loss=0.9188488721847534\n",
      "epoch 143: loss=0.9441341757774353\n",
      "epoch 144: loss=0.9349250197410583\n",
      "epoch 145: loss=0.9300397634506226\n",
      "epoch 146: loss=0.9222060441970825\n",
      "epoch 147: loss=0.9253584146499634\n",
      "epoch 148: loss=0.9393283128738403\n",
      "epoch 149: loss=0.9370856881141663\n",
      "epoch 150: loss=0.9267421364784241\n",
      "epoch 151: loss=0.9298229217529297\n",
      "epoch 152: loss=0.9279647469520569\n",
      "epoch 153: loss=0.9148836731910706\n",
      "epoch 154: loss=0.9211231470108032\n",
      "epoch 155: loss=0.9487873315811157\n",
      "epoch 156: loss=0.9269635081291199\n",
      "epoch 157: loss=0.9398503303527832\n",
      "epoch 158: loss=0.9161347150802612\n",
      "epoch 159: loss=0.9255406260490417\n",
      "epoch 160: loss=0.9348238110542297\n",
      "epoch 161: loss=0.9200570583343506\n",
      "epoch 162: loss=0.9349528551101685\n",
      "epoch 163: loss=0.9278304576873779\n",
      "epoch 164: loss=0.9003623723983765\n",
      "epoch 165: loss=0.9321873784065247\n",
      "epoch 166: loss=0.9267067909240723\n",
      "epoch 167: loss=0.9639356136322021\n",
      "epoch 168: loss=0.9206923246383667\n",
      "epoch 169: loss=0.8921242952346802\n",
      "epoch 170: loss=0.9236521124839783\n",
      "epoch 171: loss=0.9104562997817993\n",
      "epoch 172: loss=0.9239667057991028\n",
      "epoch 173: loss=0.9263359904289246\n",
      "epoch 174: loss=0.9074628353118896\n",
      "epoch 175: loss=0.9310452342033386\n",
      "epoch 176: loss=0.9341055750846863\n",
      "epoch 177: loss=0.9190685749053955\n",
      "epoch 178: loss=0.9259178638458252\n",
      "epoch 179: loss=0.9144457578659058\n",
      "epoch 180: loss=0.9284380078315735\n",
      "epoch 181: loss=0.9269894361495972\n",
      "epoch 182: loss=0.9219093918800354\n",
      "epoch 183: loss=0.9044375419616699\n",
      "epoch 184: loss=0.9304616451263428\n",
      "epoch 185: loss=0.9003216624259949\n",
      "epoch 186: loss=0.9284732937812805\n",
      "epoch 187: loss=0.9027042388916016\n",
      "epoch 188: loss=0.9091945886611938\n",
      "epoch 189: loss=0.9006534814834595\n",
      "epoch 190: loss=0.9002876877784729\n",
      "epoch 191: loss=0.9162600636482239\n",
      "epoch 192: loss=0.928615927696228\n",
      "epoch 193: loss=0.9422255754470825\n",
      "epoch 194: loss=0.9045241475105286\n",
      "epoch 195: loss=0.912917971611023\n",
      "epoch 196: loss=0.9409903883934021\n",
      "epoch 197: loss=0.8943026661872864\n",
      "epoch 198: loss=0.9196698665618896\n",
      "epoch 199: loss=0.898147702217102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bae24ddad2a45c1880904523989db23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 7306.62451171875\n",
      "Epoch 10, Loss: 1775.634033203125\n",
      "Epoch 20, Loss: 1347.51611328125\n",
      "Epoch 30, Loss: 1191.383544921875\n",
      "Epoch 40, Loss: 1130.4990234375\n",
      "Epoch 50, Loss: 1103.169921875\n",
      "Epoch 60, Loss: 1090.2603759765625\n",
      "Epoch 70, Loss: 1082.931396484375\n",
      "Epoch 80, Loss: 1078.40380859375\n",
      "Epoch 90, Loss: 1075.32763671875\n",
      "Epoch 100, Loss: 1073.1097412109375\n",
      "Epoch 110, Loss: 1071.420166015625\n",
      "Epoch 120, Loss: 1070.088134765625\n",
      "Epoch 130, Loss: 1069.004150390625\n",
      "Epoch 140, Loss: 1068.1015625\n",
      "Epoch 150, Loss: 1067.3380126953125\n",
      "Epoch 160, Loss: 1066.684326171875\n",
      "Epoch 170, Loss: 1066.1185302734375\n",
      "Epoch 180, Loss: 1065.62548828125\n",
      "Epoch 190, Loss: 1065.1920166015625\n",
      "training patch with 2032 edges\n",
      "epoch 0: loss=6.896004676818848\n",
      "epoch 1: loss=6.4881062507629395\n",
      "epoch 2: loss=6.259882926940918\n",
      "epoch 3: loss=5.870259761810303\n",
      "epoch 4: loss=5.358037948608398\n",
      "epoch 5: loss=5.162400722503662\n",
      "epoch 6: loss=4.751814365386963\n",
      "epoch 7: loss=4.22744607925415\n",
      "epoch 8: loss=3.929048538208008\n",
      "epoch 9: loss=3.5372557640075684\n",
      "epoch 10: loss=3.194361686706543\n",
      "epoch 11: loss=3.0786290168762207\n",
      "epoch 12: loss=2.665073871612549\n",
      "epoch 13: loss=2.406803846359253\n",
      "epoch 14: loss=2.0871663093566895\n",
      "epoch 15: loss=1.9253339767456055\n",
      "epoch 16: loss=1.7832860946655273\n",
      "epoch 17: loss=1.6600810289382935\n",
      "epoch 18: loss=1.6231063604354858\n",
      "epoch 19: loss=1.5910626649856567\n",
      "epoch 20: loss=1.5867754220962524\n",
      "epoch 21: loss=1.5461184978485107\n",
      "epoch 22: loss=1.5114909410476685\n",
      "epoch 23: loss=1.484458088874817\n",
      "epoch 24: loss=1.4750956296920776\n",
      "epoch 25: loss=1.4785428047180176\n",
      "epoch 26: loss=1.4934144020080566\n",
      "epoch 27: loss=1.4937013387680054\n",
      "epoch 28: loss=1.4584953784942627\n",
      "epoch 29: loss=1.4393489360809326\n",
      "epoch 30: loss=1.4333678483963013\n",
      "epoch 31: loss=1.4205846786499023\n",
      "epoch 32: loss=1.4201653003692627\n",
      "epoch 33: loss=1.4314141273498535\n",
      "epoch 34: loss=1.4112088680267334\n",
      "epoch 35: loss=1.3974835872650146\n",
      "epoch 36: loss=1.3736628293991089\n",
      "epoch 37: loss=1.3737139701843262\n",
      "epoch 38: loss=1.3680164813995361\n",
      "epoch 39: loss=1.3523736000061035\n",
      "epoch 40: loss=1.3301262855529785\n",
      "epoch 41: loss=1.3151192665100098\n",
      "epoch 42: loss=1.292395830154419\n",
      "epoch 43: loss=1.2652578353881836\n",
      "epoch 44: loss=1.252581000328064\n",
      "epoch 45: loss=1.2084128856658936\n",
      "epoch 46: loss=1.2077447175979614\n",
      "epoch 47: loss=1.201322317123413\n",
      "epoch 48: loss=1.2031967639923096\n",
      "epoch 49: loss=1.2110084295272827\n",
      "epoch 50: loss=1.1797852516174316\n",
      "epoch 51: loss=1.157886266708374\n",
      "epoch 52: loss=1.162812352180481\n",
      "epoch 53: loss=1.1612608432769775\n",
      "epoch 54: loss=1.1415654420852661\n",
      "epoch 55: loss=1.1358890533447266\n",
      "epoch 56: loss=1.1311405897140503\n",
      "epoch 57: loss=1.1321289539337158\n",
      "epoch 58: loss=1.1077574491500854\n",
      "epoch 59: loss=1.0847809314727783\n",
      "epoch 60: loss=1.1186273097991943\n",
      "epoch 61: loss=1.0994631052017212\n",
      "epoch 62: loss=1.0773063898086548\n",
      "epoch 63: loss=1.1114085912704468\n",
      "epoch 64: loss=1.0822709798812866\n",
      "epoch 65: loss=1.0747122764587402\n",
      "epoch 66: loss=1.0715200901031494\n",
      "epoch 67: loss=1.0492780208587646\n",
      "epoch 68: loss=1.0672029256820679\n",
      "epoch 69: loss=1.0636177062988281\n",
      "epoch 70: loss=1.069472074508667\n",
      "epoch 71: loss=1.0466278791427612\n",
      "epoch 72: loss=1.0739367008209229\n",
      "epoch 73: loss=1.0423227548599243\n",
      "epoch 74: loss=1.0620969533920288\n",
      "epoch 75: loss=1.0539906024932861\n",
      "epoch 76: loss=1.0559871196746826\n",
      "epoch 77: loss=1.0414369106292725\n",
      "epoch 78: loss=1.051099181175232\n",
      "epoch 79: loss=1.0423012971878052\n",
      "epoch 80: loss=1.0436056852340698\n",
      "epoch 81: loss=1.0462194681167603\n",
      "epoch 82: loss=1.0356853008270264\n",
      "epoch 83: loss=1.0335279703140259\n",
      "epoch 84: loss=1.0122324228286743\n",
      "epoch 85: loss=1.0515159368515015\n",
      "epoch 86: loss=1.0296827554702759\n",
      "epoch 87: loss=1.0105600357055664\n",
      "epoch 88: loss=1.0233174562454224\n",
      "epoch 89: loss=1.0539661645889282\n",
      "epoch 90: loss=1.0257679224014282\n",
      "epoch 91: loss=1.020186185836792\n",
      "epoch 92: loss=1.028390645980835\n",
      "epoch 93: loss=1.0324808359146118\n",
      "epoch 94: loss=0.9955242276191711\n",
      "epoch 95: loss=1.0251504182815552\n",
      "epoch 96: loss=1.0250712633132935\n",
      "epoch 97: loss=1.0251811742782593\n",
      "epoch 98: loss=1.0196714401245117\n",
      "epoch 99: loss=1.0165040493011475\n",
      "epoch 100: loss=1.0043535232543945\n",
      "epoch 101: loss=1.0293817520141602\n",
      "epoch 102: loss=1.036560297012329\n",
      "epoch 103: loss=1.0283739566802979\n",
      "epoch 104: loss=1.0139384269714355\n",
      "epoch 105: loss=1.0321779251098633\n",
      "epoch 106: loss=1.0512406826019287\n",
      "epoch 107: loss=1.0157679319381714\n",
      "epoch 108: loss=1.0031157732009888\n",
      "epoch 109: loss=0.9939330816268921\n",
      "epoch 110: loss=1.0136239528656006\n",
      "epoch 111: loss=1.0330123901367188\n",
      "epoch 112: loss=0.975446879863739\n",
      "epoch 113: loss=1.0038304328918457\n",
      "epoch 114: loss=1.0160642862319946\n",
      "epoch 115: loss=1.0317611694335938\n",
      "epoch 116: loss=1.0282676219940186\n",
      "epoch 117: loss=1.049232840538025\n",
      "epoch 118: loss=0.9863815307617188\n",
      "epoch 119: loss=1.0014445781707764\n",
      "epoch 120: loss=0.9882083535194397\n",
      "epoch 121: loss=0.9640652537345886\n",
      "epoch 122: loss=1.0369733572006226\n",
      "epoch 123: loss=1.029374122619629\n",
      "epoch 124: loss=1.0105398893356323\n",
      "epoch 125: loss=0.9947894215583801\n",
      "epoch 126: loss=1.0051472187042236\n",
      "epoch 127: loss=1.0077617168426514\n",
      "epoch 128: loss=0.9971036314964294\n",
      "epoch 129: loss=0.9797719120979309\n",
      "epoch 130: loss=0.9977571964263916\n",
      "epoch 131: loss=1.0260311365127563\n",
      "epoch 132: loss=1.01095449924469\n",
      "epoch 133: loss=0.9864875674247742\n",
      "epoch 134: loss=0.9941109418869019\n",
      "epoch 135: loss=1.0090117454528809\n",
      "epoch 136: loss=1.0063406229019165\n",
      "epoch 137: loss=0.9977052211761475\n",
      "epoch 138: loss=1.0016756057739258\n",
      "epoch 139: loss=1.0268728733062744\n",
      "epoch 140: loss=1.0119078159332275\n",
      "epoch 141: loss=1.001380443572998\n",
      "epoch 142: loss=1.0086852312088013\n",
      "epoch 143: loss=0.9939079284667969\n",
      "epoch 144: loss=0.9862744212150574\n",
      "epoch 145: loss=1.0172593593597412\n",
      "epoch 146: loss=1.005435585975647\n",
      "epoch 147: loss=0.9899349212646484\n",
      "epoch 148: loss=1.0056802034378052\n",
      "epoch 149: loss=0.9876714944839478\n",
      "epoch 150: loss=0.9969938397407532\n",
      "epoch 151: loss=0.9834434986114502\n",
      "epoch 152: loss=0.9831434488296509\n",
      "epoch 153: loss=0.9931244254112244\n",
      "epoch 154: loss=1.0019502639770508\n",
      "epoch 155: loss=1.0145525932312012\n",
      "epoch 156: loss=0.9728404879570007\n",
      "epoch 157: loss=0.9943777322769165\n",
      "epoch 158: loss=0.9904338121414185\n",
      "epoch 159: loss=0.965485155582428\n",
      "epoch 160: loss=1.002821922302246\n",
      "epoch 161: loss=0.9941684007644653\n",
      "epoch 162: loss=0.984964907169342\n",
      "epoch 163: loss=0.9953246712684631\n",
      "epoch 164: loss=0.9976948499679565\n",
      "epoch 165: loss=0.9917743802070618\n",
      "epoch 166: loss=0.9924296140670776\n",
      "epoch 167: loss=0.9985513091087341\n",
      "epoch 168: loss=0.9858437776565552\n",
      "epoch 169: loss=0.9880734086036682\n",
      "epoch 170: loss=0.9938232898712158\n",
      "epoch 171: loss=1.0020917654037476\n",
      "epoch 172: loss=0.9862524271011353\n",
      "epoch 173: loss=1.0090935230255127\n",
      "epoch 174: loss=0.9917184114456177\n",
      "epoch 175: loss=1.0135971307754517\n",
      "epoch 176: loss=0.9770053625106812\n",
      "epoch 177: loss=0.9968677163124084\n",
      "epoch 178: loss=0.9773722290992737\n",
      "epoch 179: loss=0.9826412200927734\n",
      "epoch 180: loss=0.9812108278274536\n",
      "epoch 181: loss=1.001731276512146\n",
      "epoch 182: loss=0.9687747359275818\n",
      "epoch 183: loss=0.9816195368766785\n",
      "epoch 184: loss=1.009194016456604\n",
      "epoch 185: loss=0.9876870512962341\n",
      "epoch 186: loss=0.995148241519928\n",
      "epoch 187: loss=0.9825942516326904\n",
      "epoch 188: loss=0.9872477054595947\n",
      "epoch 189: loss=0.993485689163208\n",
      "epoch 190: loss=0.9742664098739624\n",
      "epoch 191: loss=1.0051288604736328\n",
      "epoch 192: loss=0.97845059633255\n",
      "epoch 193: loss=0.9859402179718018\n",
      "epoch 194: loss=1.0017547607421875\n",
      "epoch 195: loss=0.974276065826416\n",
      "epoch 196: loss=0.9658628702163696\n",
      "epoch 197: loss=1.0034157037734985\n",
      "epoch 198: loss=0.9652141332626343\n",
      "epoch 199: loss=0.9920204281806946\n",
      "training patch with 1946 edges\n",
      "epoch 0: loss=6.628381729125977\n",
      "epoch 1: loss=6.5699663162231445\n",
      "epoch 2: loss=5.8325395584106445\n",
      "epoch 3: loss=6.022768974304199\n",
      "epoch 4: loss=5.34930944442749\n",
      "epoch 5: loss=5.0211381912231445\n",
      "epoch 6: loss=4.585139274597168\n",
      "epoch 7: loss=4.1418914794921875\n",
      "epoch 8: loss=3.9970948696136475\n",
      "epoch 9: loss=3.6814539432525635\n",
      "epoch 10: loss=3.2176308631896973\n",
      "epoch 11: loss=2.949388265609741\n",
      "epoch 12: loss=2.6444056034088135\n",
      "epoch 13: loss=2.3539602756500244\n",
      "epoch 14: loss=2.039412498474121\n",
      "epoch 15: loss=1.8397377729415894\n",
      "epoch 16: loss=1.727052092552185\n",
      "epoch 17: loss=1.6708673238754272\n",
      "epoch 18: loss=1.6875046491622925\n",
      "epoch 19: loss=1.6158918142318726\n",
      "epoch 20: loss=1.5730841159820557\n",
      "epoch 21: loss=1.5366759300231934\n",
      "epoch 22: loss=1.546075463294983\n",
      "epoch 23: loss=1.5029852390289307\n",
      "epoch 24: loss=1.4946439266204834\n",
      "epoch 25: loss=1.5145020484924316\n",
      "epoch 26: loss=1.4960284233093262\n",
      "epoch 27: loss=1.486294150352478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28: loss=1.4873689413070679\n",
      "epoch 29: loss=1.4746954441070557\n",
      "epoch 30: loss=1.4518296718597412\n",
      "epoch 31: loss=1.4533511400222778\n",
      "epoch 32: loss=1.4480878114700317\n",
      "epoch 33: loss=1.4377175569534302\n",
      "epoch 34: loss=1.4333221912384033\n",
      "epoch 35: loss=1.419609546661377\n",
      "epoch 36: loss=1.4005399942398071\n",
      "epoch 37: loss=1.3788588047027588\n",
      "epoch 38: loss=1.3625036478042603\n",
      "epoch 39: loss=1.3487225770950317\n",
      "epoch 40: loss=1.317636489868164\n",
      "epoch 41: loss=1.306405782699585\n",
      "epoch 42: loss=1.2770886421203613\n",
      "epoch 43: loss=1.250104308128357\n",
      "epoch 44: loss=1.2360217571258545\n",
      "epoch 45: loss=1.2124354839324951\n",
      "epoch 46: loss=1.193184733390808\n",
      "epoch 47: loss=1.1755298376083374\n",
      "epoch 48: loss=1.1618129014968872\n",
      "epoch 49: loss=1.1588952541351318\n",
      "epoch 50: loss=1.152428388595581\n",
      "epoch 51: loss=1.1240808963775635\n",
      "epoch 52: loss=1.1280481815338135\n",
      "epoch 53: loss=1.1147328615188599\n",
      "epoch 54: loss=1.1286242008209229\n",
      "epoch 55: loss=1.122435450553894\n",
      "epoch 56: loss=1.1033413410186768\n",
      "epoch 57: loss=1.1136956214904785\n",
      "epoch 58: loss=1.0724611282348633\n",
      "epoch 59: loss=1.1153217554092407\n",
      "epoch 60: loss=1.061610221862793\n",
      "epoch 61: loss=1.0811597108840942\n",
      "epoch 62: loss=1.0736432075500488\n",
      "epoch 63: loss=1.0669931173324585\n",
      "epoch 64: loss=1.0543758869171143\n",
      "epoch 65: loss=1.0426366329193115\n",
      "epoch 66: loss=1.0564996004104614\n",
      "epoch 67: loss=1.0495593547821045\n",
      "epoch 68: loss=1.0491913557052612\n",
      "epoch 69: loss=1.0340558290481567\n",
      "epoch 70: loss=1.031713843345642\n",
      "epoch 71: loss=1.0411049127578735\n",
      "epoch 72: loss=1.0296005010604858\n",
      "epoch 73: loss=1.038530945777893\n",
      "epoch 74: loss=1.0266417264938354\n",
      "epoch 75: loss=1.0746574401855469\n",
      "epoch 76: loss=1.0198779106140137\n",
      "epoch 77: loss=1.042386531829834\n",
      "epoch 78: loss=1.0301867723464966\n",
      "epoch 79: loss=1.0285210609436035\n",
      "epoch 80: loss=1.0399014949798584\n",
      "epoch 81: loss=1.0145900249481201\n",
      "epoch 82: loss=1.0221842527389526\n",
      "epoch 83: loss=1.027646780014038\n",
      "epoch 84: loss=1.0442047119140625\n",
      "epoch 85: loss=1.0476691722869873\n",
      "epoch 86: loss=1.0181379318237305\n",
      "epoch 87: loss=0.9977335929870605\n",
      "epoch 88: loss=1.0226991176605225\n",
      "epoch 89: loss=1.0347259044647217\n",
      "epoch 90: loss=1.01716947555542\n",
      "epoch 91: loss=1.0074012279510498\n",
      "epoch 92: loss=1.0196670293807983\n",
      "epoch 93: loss=1.0180803537368774\n",
      "epoch 94: loss=1.0136260986328125\n",
      "epoch 95: loss=1.0258623361587524\n",
      "epoch 96: loss=1.0182580947875977\n",
      "epoch 97: loss=0.9915571808815002\n",
      "epoch 98: loss=1.019533395767212\n",
      "epoch 99: loss=1.0012516975402832\n",
      "epoch 100: loss=1.0329241752624512\n",
      "epoch 101: loss=1.016484022140503\n",
      "epoch 102: loss=1.0135293006896973\n",
      "epoch 103: loss=1.0018826723098755\n",
      "epoch 104: loss=1.0110257863998413\n",
      "epoch 105: loss=1.0160777568817139\n",
      "epoch 106: loss=1.0182714462280273\n",
      "epoch 107: loss=1.009358286857605\n",
      "epoch 108: loss=1.0094174146652222\n",
      "epoch 109: loss=1.0086711645126343\n",
      "epoch 110: loss=1.0145657062530518\n",
      "epoch 111: loss=1.0233097076416016\n",
      "epoch 112: loss=0.9829269647598267\n",
      "epoch 113: loss=0.9925175905227661\n",
      "epoch 114: loss=0.9973932504653931\n",
      "epoch 115: loss=1.0194579362869263\n",
      "epoch 116: loss=0.9964970350265503\n",
      "epoch 117: loss=0.9985530376434326\n",
      "epoch 118: loss=1.0253986120224\n",
      "epoch 119: loss=0.9884775876998901\n",
      "epoch 120: loss=0.991823673248291\n",
      "epoch 121: loss=0.9941733479499817\n",
      "epoch 122: loss=0.9955511689186096\n",
      "epoch 123: loss=0.9986213445663452\n",
      "epoch 124: loss=0.9935130476951599\n",
      "epoch 125: loss=0.9974927306175232\n",
      "epoch 126: loss=1.0109833478927612\n",
      "epoch 127: loss=0.9962743520736694\n",
      "epoch 128: loss=0.9815647006034851\n",
      "epoch 129: loss=0.9999148845672607\n",
      "epoch 130: loss=1.0099844932556152\n",
      "epoch 131: loss=1.0172579288482666\n",
      "epoch 132: loss=1.0077149868011475\n",
      "epoch 133: loss=0.998680591583252\n",
      "epoch 134: loss=1.002697467803955\n",
      "epoch 135: loss=0.977802038192749\n",
      "epoch 136: loss=0.9896214008331299\n",
      "epoch 137: loss=0.9980332851409912\n",
      "epoch 138: loss=1.0075477361679077\n",
      "epoch 139: loss=1.006910800933838\n",
      "epoch 140: loss=1.013380765914917\n",
      "epoch 141: loss=1.014134168624878\n",
      "epoch 142: loss=1.017212152481079\n",
      "epoch 143: loss=1.0061516761779785\n",
      "epoch 144: loss=0.9796842336654663\n",
      "epoch 145: loss=1.0006381273269653\n",
      "epoch 146: loss=1.0110468864440918\n",
      "epoch 147: loss=1.013592004776001\n",
      "epoch 148: loss=0.9937281608581543\n",
      "epoch 149: loss=1.0041710138320923\n",
      "epoch 150: loss=1.0014867782592773\n",
      "epoch 151: loss=0.9845085144042969\n",
      "epoch 152: loss=0.9803457260131836\n",
      "epoch 153: loss=0.9985974431037903\n",
      "epoch 154: loss=1.0010936260223389\n",
      "epoch 155: loss=1.004651427268982\n",
      "epoch 156: loss=0.9689767360687256\n",
      "epoch 157: loss=0.9738976359367371\n",
      "epoch 158: loss=0.9945744276046753\n",
      "epoch 159: loss=0.9822824597358704\n",
      "epoch 160: loss=0.9869022369384766\n",
      "epoch 161: loss=0.9710412621498108\n",
      "epoch 162: loss=0.9558352828025818\n",
      "epoch 163: loss=0.9859224557876587\n",
      "epoch 164: loss=1.02859365940094\n",
      "epoch 165: loss=0.9807811379432678\n",
      "epoch 166: loss=1.0010164976119995\n",
      "epoch 167: loss=0.9884293079376221\n",
      "epoch 168: loss=0.991677463054657\n",
      "epoch 169: loss=0.9819796085357666\n",
      "epoch 170: loss=0.9716829657554626\n",
      "epoch 171: loss=1.0102999210357666\n",
      "epoch 172: loss=0.9838570356369019\n",
      "epoch 173: loss=0.9933754205703735\n",
      "epoch 174: loss=0.979397177696228\n",
      "epoch 175: loss=0.980567455291748\n",
      "epoch 176: loss=0.9711408019065857\n",
      "epoch 177: loss=0.9909368753433228\n",
      "epoch 178: loss=0.9801647067070007\n",
      "epoch 179: loss=0.9687138199806213\n",
      "epoch 180: loss=0.9872444868087769\n",
      "epoch 181: loss=0.9846261143684387\n",
      "epoch 182: loss=0.9958059787750244\n",
      "epoch 183: loss=0.9998799562454224\n",
      "epoch 184: loss=0.98441082239151\n",
      "epoch 185: loss=0.9938332438468933\n",
      "epoch 186: loss=0.9796733260154724\n",
      "epoch 187: loss=0.9906908273696899\n",
      "epoch 188: loss=1.0024468898773193\n",
      "epoch 189: loss=0.9870495796203613\n",
      "epoch 190: loss=0.9923834800720215\n",
      "epoch 191: loss=0.9948645234107971\n",
      "epoch 192: loss=0.9833941459655762\n",
      "epoch 193: loss=1.0080186128616333\n",
      "epoch 194: loss=0.9760663509368896\n",
      "epoch 195: loss=0.9640606045722961\n",
      "epoch 196: loss=0.9863278865814209\n",
      "epoch 197: loss=0.9900734424591064\n",
      "epoch 198: loss=0.9950879812240601\n",
      "epoch 199: loss=0.9973517656326294\n",
      "training patch with 1878 edges\n",
      "epoch 0: loss=6.661046028137207\n",
      "epoch 1: loss=6.536859035491943\n",
      "epoch 2: loss=6.385151386260986\n",
      "epoch 3: loss=5.997189044952393\n",
      "epoch 4: loss=5.619143962860107\n",
      "epoch 5: loss=5.339794158935547\n",
      "epoch 6: loss=5.100432872772217\n",
      "epoch 7: loss=4.169401168823242\n",
      "epoch 8: loss=4.153723239898682\n",
      "epoch 9: loss=3.99155592918396\n",
      "epoch 10: loss=3.6198108196258545\n",
      "epoch 11: loss=3.2370026111602783\n",
      "epoch 12: loss=2.9766862392425537\n",
      "epoch 13: loss=2.6500818729400635\n",
      "epoch 14: loss=2.34279203414917\n",
      "epoch 15: loss=2.0641086101531982\n",
      "epoch 16: loss=1.8699352741241455\n",
      "epoch 17: loss=1.7831209897994995\n",
      "epoch 18: loss=1.6966980695724487\n",
      "epoch 19: loss=1.6311912536621094\n",
      "epoch 20: loss=1.6218634843826294\n",
      "epoch 21: loss=1.6016417741775513\n",
      "epoch 22: loss=1.6104248762130737\n",
      "epoch 23: loss=1.5828583240509033\n",
      "epoch 24: loss=1.5299711227416992\n",
      "epoch 25: loss=1.5156177282333374\n",
      "epoch 26: loss=1.5052460432052612\n",
      "epoch 27: loss=1.5094541311264038\n",
      "epoch 28: loss=1.4947128295898438\n",
      "epoch 29: loss=1.5049108266830444\n",
      "epoch 30: loss=1.5027902126312256\n",
      "epoch 31: loss=1.4922062158584595\n",
      "epoch 32: loss=1.4803804159164429\n",
      "epoch 33: loss=1.4728738069534302\n",
      "epoch 34: loss=1.473283052444458\n",
      "epoch 35: loss=1.4595999717712402\n",
      "epoch 36: loss=1.4563915729522705\n",
      "epoch 37: loss=1.4356451034545898\n",
      "epoch 38: loss=1.4199416637420654\n",
      "epoch 39: loss=1.4199062585830688\n",
      "epoch 40: loss=1.3982083797454834\n",
      "epoch 41: loss=1.3785240650177002\n",
      "epoch 42: loss=1.367959976196289\n",
      "epoch 43: loss=1.3412425518035889\n",
      "epoch 44: loss=1.3225502967834473\n",
      "epoch 45: loss=1.3056914806365967\n",
      "epoch 46: loss=1.2767542600631714\n",
      "epoch 47: loss=1.25064218044281\n",
      "epoch 48: loss=1.2349375486373901\n",
      "epoch 49: loss=1.210391879081726\n",
      "epoch 50: loss=1.2028532028198242\n",
      "epoch 51: loss=1.1867917776107788\n",
      "epoch 52: loss=1.1890616416931152\n",
      "epoch 53: loss=1.1991846561431885\n",
      "epoch 54: loss=1.1665371656417847\n",
      "epoch 55: loss=1.1542778015136719\n",
      "epoch 56: loss=1.178966999053955\n",
      "epoch 57: loss=1.167481780052185\n",
      "epoch 58: loss=1.139261245727539\n",
      "epoch 59: loss=1.1838256120681763\n",
      "epoch 60: loss=1.1473543643951416\n",
      "epoch 61: loss=1.1434540748596191\n",
      "epoch 62: loss=1.1151878833770752\n",
      "epoch 63: loss=1.1294053792953491\n",
      "epoch 64: loss=1.1195048093795776\n",
      "epoch 65: loss=1.0999115705490112\n",
      "epoch 66: loss=1.107741355895996\n",
      "epoch 67: loss=1.072055459022522\n",
      "epoch 68: loss=1.110281229019165\n",
      "epoch 69: loss=1.0918633937835693\n",
      "epoch 70: loss=1.1120213270187378\n",
      "epoch 71: loss=1.1053918600082397\n",
      "epoch 72: loss=1.1179955005645752\n",
      "epoch 73: loss=1.1108627319335938\n",
      "epoch 74: loss=1.1074587106704712\n",
      "epoch 75: loss=1.1018813848495483\n",
      "epoch 76: loss=1.089453101158142\n",
      "epoch 77: loss=1.1166201829910278\n",
      "epoch 78: loss=1.1295326948165894\n",
      "epoch 79: loss=1.1066900491714478\n",
      "epoch 80: loss=1.1130857467651367\n",
      "epoch 81: loss=1.1034501791000366\n",
      "epoch 82: loss=1.1018025875091553\n",
      "epoch 83: loss=1.0688024759292603\n",
      "epoch 84: loss=1.109567403793335\n",
      "epoch 85: loss=1.070809006690979\n",
      "epoch 86: loss=1.0786696672439575\n",
      "epoch 87: loss=1.0754600763320923\n",
      "epoch 88: loss=1.086126446723938\n",
      "epoch 89: loss=1.0771664381027222\n",
      "epoch 90: loss=1.0790115594863892\n",
      "epoch 91: loss=1.0564228296279907\n",
      "epoch 92: loss=1.0647342205047607\n",
      "epoch 93: loss=1.0639458894729614\n",
      "epoch 94: loss=1.063899040222168\n",
      "epoch 95: loss=1.0864405632019043\n",
      "epoch 96: loss=1.0477616786956787\n",
      "epoch 97: loss=1.0529087781906128\n",
      "epoch 98: loss=1.066513180732727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99: loss=1.0817774534225464\n",
      "epoch 100: loss=1.0501618385314941\n",
      "epoch 101: loss=1.080947756767273\n",
      "epoch 102: loss=1.0685460567474365\n",
      "epoch 103: loss=1.0692758560180664\n",
      "epoch 104: loss=1.0680227279663086\n",
      "epoch 105: loss=1.0693525075912476\n",
      "epoch 106: loss=1.0578930377960205\n",
      "epoch 107: loss=1.0560688972473145\n",
      "epoch 108: loss=1.0419141054153442\n",
      "epoch 109: loss=1.0690878629684448\n",
      "epoch 110: loss=1.0512586832046509\n",
      "epoch 111: loss=1.0436640977859497\n",
      "epoch 112: loss=1.0522559881210327\n",
      "epoch 113: loss=1.058711290359497\n",
      "epoch 114: loss=1.0705770254135132\n",
      "epoch 115: loss=1.052522897720337\n",
      "epoch 116: loss=1.058781385421753\n",
      "epoch 117: loss=1.070457935333252\n",
      "epoch 118: loss=1.0597995519638062\n",
      "epoch 119: loss=1.0750283002853394\n",
      "epoch 120: loss=1.0429767370224\n",
      "epoch 121: loss=1.0323907136917114\n",
      "epoch 122: loss=1.0571467876434326\n",
      "epoch 123: loss=1.0600124597549438\n",
      "epoch 124: loss=1.0700817108154297\n",
      "epoch 125: loss=1.0619831085205078\n",
      "epoch 126: loss=1.0637792348861694\n",
      "epoch 127: loss=1.0677268505096436\n",
      "epoch 128: loss=1.0481481552124023\n",
      "epoch 129: loss=1.065482497215271\n",
      "epoch 130: loss=1.0878392457962036\n",
      "epoch 131: loss=1.0418630838394165\n",
      "epoch 132: loss=1.0644571781158447\n",
      "epoch 133: loss=1.0442911386489868\n",
      "epoch 134: loss=1.0333353281021118\n",
      "epoch 135: loss=1.0708303451538086\n",
      "epoch 136: loss=1.0311695337295532\n",
      "epoch 137: loss=1.0427805185317993\n",
      "epoch 138: loss=1.044790267944336\n",
      "epoch 139: loss=1.0538854598999023\n",
      "epoch 140: loss=1.0343043804168701\n",
      "epoch 141: loss=1.0261589288711548\n",
      "epoch 142: loss=1.038034200668335\n",
      "epoch 143: loss=1.043074607849121\n",
      "epoch 144: loss=1.0470194816589355\n",
      "epoch 145: loss=1.0331075191497803\n",
      "epoch 146: loss=1.0361212491989136\n",
      "epoch 147: loss=1.0470671653747559\n",
      "epoch 148: loss=1.071347951889038\n",
      "epoch 149: loss=1.0444303750991821\n",
      "epoch 150: loss=1.0265966653823853\n",
      "epoch 151: loss=1.05158269405365\n",
      "epoch 152: loss=1.0358392000198364\n",
      "epoch 153: loss=1.0392955541610718\n",
      "epoch 154: loss=1.038490891456604\n",
      "epoch 155: loss=1.0487602949142456\n",
      "epoch 156: loss=1.0362156629562378\n",
      "epoch 157: loss=1.0239996910095215\n",
      "epoch 158: loss=1.0118482112884521\n",
      "epoch 159: loss=1.0143647193908691\n",
      "epoch 160: loss=1.0304545164108276\n",
      "epoch 161: loss=1.006931185722351\n",
      "epoch 162: loss=1.0545322895050049\n",
      "epoch 163: loss=1.0214325189590454\n",
      "epoch 164: loss=1.0468628406524658\n",
      "epoch 165: loss=1.0223746299743652\n",
      "epoch 166: loss=1.042822241783142\n",
      "epoch 167: loss=1.0028841495513916\n",
      "epoch 168: loss=1.0353776216506958\n",
      "epoch 169: loss=1.036679983139038\n",
      "epoch 170: loss=1.0197683572769165\n",
      "epoch 171: loss=1.026219129562378\n",
      "epoch 172: loss=1.0363868474960327\n",
      "epoch 173: loss=1.0196895599365234\n",
      "epoch 174: loss=1.0579274892807007\n",
      "epoch 175: loss=1.0452615022659302\n",
      "epoch 176: loss=1.0413827896118164\n",
      "epoch 177: loss=1.0285472869873047\n",
      "epoch 178: loss=0.9985520243644714\n",
      "epoch 179: loss=1.0385558605194092\n",
      "epoch 180: loss=1.0330500602722168\n",
      "epoch 181: loss=1.0358903408050537\n",
      "epoch 182: loss=1.0319405794143677\n",
      "epoch 183: loss=1.0049936771392822\n",
      "epoch 184: loss=0.9972895383834839\n",
      "epoch 185: loss=1.0349675416946411\n",
      "epoch 186: loss=1.0172797441482544\n",
      "epoch 187: loss=1.0148744583129883\n",
      "epoch 188: loss=1.0223389863967896\n",
      "epoch 189: loss=1.039257287979126\n",
      "epoch 190: loss=1.0089271068572998\n",
      "epoch 191: loss=1.0258954763412476\n",
      "epoch 192: loss=1.016255497932434\n",
      "epoch 193: loss=1.0488154888153076\n",
      "epoch 194: loss=1.0403566360473633\n",
      "epoch 195: loss=1.027010440826416\n",
      "epoch 196: loss=1.036711573600769\n",
      "epoch 197: loss=1.025130033493042\n",
      "epoch 198: loss=1.0120915174484253\n",
      "epoch 199: loss=1.0118082761764526\n",
      "training patch with 2784 edges\n",
      "epoch 0: loss=6.6076812744140625\n",
      "epoch 1: loss=6.38102388381958\n",
      "epoch 2: loss=6.159411430358887\n",
      "epoch 3: loss=5.881701469421387\n",
      "epoch 4: loss=5.299317359924316\n",
      "epoch 5: loss=4.739419937133789\n",
      "epoch 6: loss=4.396737098693848\n",
      "epoch 7: loss=4.000051021575928\n",
      "epoch 8: loss=3.8836352825164795\n",
      "epoch 9: loss=3.34799861907959\n",
      "epoch 10: loss=3.169482707977295\n",
      "epoch 11: loss=2.74198579788208\n",
      "epoch 12: loss=2.391430377960205\n",
      "epoch 13: loss=2.063324213027954\n",
      "epoch 14: loss=1.8970131874084473\n",
      "epoch 15: loss=1.7603766918182373\n",
      "epoch 16: loss=1.6742860078811646\n",
      "epoch 17: loss=1.640737533569336\n",
      "epoch 18: loss=1.6039469242095947\n",
      "epoch 19: loss=1.5690730810165405\n",
      "epoch 20: loss=1.5264641046524048\n",
      "epoch 21: loss=1.4953209161758423\n",
      "epoch 22: loss=1.457972764968872\n",
      "epoch 23: loss=1.4603158235549927\n",
      "epoch 24: loss=1.4604395627975464\n",
      "epoch 25: loss=1.4628037214279175\n",
      "epoch 26: loss=1.4498050212860107\n",
      "epoch 27: loss=1.431569218635559\n",
      "epoch 28: loss=1.4289844036102295\n",
      "epoch 29: loss=1.4194426536560059\n",
      "epoch 30: loss=1.4074325561523438\n",
      "epoch 31: loss=1.41636061668396\n",
      "epoch 32: loss=1.4068832397460938\n",
      "epoch 33: loss=1.4002901315689087\n",
      "epoch 34: loss=1.401452660560608\n",
      "epoch 35: loss=1.3893331289291382\n",
      "epoch 36: loss=1.3799811601638794\n",
      "epoch 37: loss=1.3764665126800537\n",
      "epoch 38: loss=1.3767569065093994\n",
      "epoch 39: loss=1.366225242614746\n",
      "epoch 40: loss=1.3561114072799683\n",
      "epoch 41: loss=1.3495627641677856\n",
      "epoch 42: loss=1.3187545537948608\n",
      "epoch 43: loss=1.310366153717041\n",
      "epoch 44: loss=1.2827415466308594\n",
      "epoch 45: loss=1.2602951526641846\n",
      "epoch 46: loss=1.2389203310012817\n",
      "epoch 47: loss=1.2194510698318481\n",
      "epoch 48: loss=1.2024060487747192\n",
      "epoch 49: loss=1.1919231414794922\n",
      "epoch 50: loss=1.1647976636886597\n",
      "epoch 51: loss=1.1494849920272827\n",
      "epoch 52: loss=1.1558799743652344\n",
      "epoch 53: loss=1.1348049640655518\n",
      "epoch 54: loss=1.1490628719329834\n",
      "epoch 55: loss=1.132470726966858\n",
      "epoch 56: loss=1.1274967193603516\n",
      "epoch 57: loss=1.109850525856018\n",
      "epoch 58: loss=1.1040786504745483\n",
      "epoch 59: loss=1.114717960357666\n",
      "epoch 60: loss=1.107143521308899\n",
      "epoch 61: loss=1.0907844305038452\n",
      "epoch 62: loss=1.0860650539398193\n",
      "epoch 63: loss=1.0674165487289429\n",
      "epoch 64: loss=1.0710524320602417\n",
      "epoch 65: loss=1.0576587915420532\n",
      "epoch 66: loss=1.075240135192871\n",
      "epoch 67: loss=1.0827198028564453\n",
      "epoch 68: loss=1.0775880813598633\n",
      "epoch 69: loss=1.0600460767745972\n",
      "epoch 70: loss=1.0611228942871094\n",
      "epoch 71: loss=1.0679693222045898\n",
      "epoch 72: loss=1.0476903915405273\n",
      "epoch 73: loss=1.044216513633728\n",
      "epoch 74: loss=1.0549193620681763\n",
      "epoch 75: loss=1.0501574277877808\n",
      "epoch 76: loss=1.0413868427276611\n",
      "epoch 77: loss=1.028067946434021\n",
      "epoch 78: loss=1.0462744235992432\n",
      "epoch 79: loss=1.0316438674926758\n",
      "epoch 80: loss=1.0230069160461426\n",
      "epoch 81: loss=1.0171128511428833\n",
      "epoch 82: loss=1.0289310216903687\n",
      "epoch 83: loss=1.0134433507919312\n",
      "epoch 84: loss=1.024863839149475\n",
      "epoch 85: loss=1.0220059156417847\n",
      "epoch 86: loss=1.0208299160003662\n",
      "epoch 87: loss=1.0089406967163086\n",
      "epoch 88: loss=1.0157511234283447\n",
      "epoch 89: loss=1.021222710609436\n",
      "epoch 90: loss=1.009995460510254\n",
      "epoch 91: loss=1.0133284330368042\n",
      "epoch 92: loss=1.0235921144485474\n",
      "epoch 93: loss=1.0150158405303955\n",
      "epoch 94: loss=1.0200804471969604\n",
      "epoch 95: loss=1.0155391693115234\n",
      "epoch 96: loss=1.0082093477249146\n",
      "epoch 97: loss=1.0228357315063477\n",
      "epoch 98: loss=1.0039784908294678\n",
      "epoch 99: loss=0.9923747777938843\n",
      "epoch 100: loss=1.0095572471618652\n",
      "epoch 101: loss=0.9925875663757324\n",
      "epoch 102: loss=1.010605812072754\n",
      "epoch 103: loss=1.0031288862228394\n",
      "epoch 104: loss=0.985665500164032\n",
      "epoch 105: loss=0.988829493522644\n",
      "epoch 106: loss=0.9914288520812988\n",
      "epoch 107: loss=1.00559401512146\n",
      "epoch 108: loss=1.0100876092910767\n",
      "epoch 109: loss=0.9882237911224365\n",
      "epoch 110: loss=0.9900747537612915\n",
      "epoch 111: loss=1.012007713317871\n",
      "epoch 112: loss=1.0102459192276\n",
      "epoch 113: loss=1.0075212717056274\n",
      "epoch 114: loss=0.9992058277130127\n",
      "epoch 115: loss=1.016560435295105\n",
      "epoch 116: loss=0.9967398643493652\n",
      "epoch 117: loss=0.9941631555557251\n",
      "epoch 118: loss=1.0022778511047363\n",
      "epoch 119: loss=0.9825934767723083\n",
      "epoch 120: loss=0.9864722490310669\n",
      "epoch 121: loss=0.9871337413787842\n",
      "epoch 122: loss=0.9839063286781311\n",
      "epoch 123: loss=1.0094317197799683\n",
      "epoch 124: loss=0.9809086322784424\n",
      "epoch 125: loss=0.9912683367729187\n",
      "epoch 126: loss=0.9848477840423584\n",
      "epoch 127: loss=0.980127215385437\n",
      "epoch 128: loss=0.9831132888793945\n",
      "epoch 129: loss=0.9866967797279358\n",
      "epoch 130: loss=0.9780824184417725\n",
      "epoch 131: loss=0.9927002191543579\n",
      "epoch 132: loss=0.9761716723442078\n",
      "epoch 133: loss=0.9860246181488037\n",
      "epoch 134: loss=0.9758067727088928\n",
      "epoch 135: loss=0.9750669002532959\n",
      "epoch 136: loss=0.9691562652587891\n",
      "epoch 137: loss=0.9816420078277588\n",
      "epoch 138: loss=0.9951832890510559\n",
      "epoch 139: loss=0.9894956946372986\n",
      "epoch 140: loss=1.0024824142456055\n",
      "epoch 141: loss=0.9801301956176758\n",
      "epoch 142: loss=0.9787198305130005\n",
      "epoch 143: loss=0.9741271734237671\n",
      "epoch 144: loss=0.9735928773880005\n",
      "epoch 145: loss=0.9651445746421814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146: loss=0.986823558807373\n",
      "epoch 147: loss=0.9685982465744019\n",
      "epoch 148: loss=0.9611096978187561\n",
      "epoch 149: loss=0.9789570569992065\n",
      "epoch 150: loss=0.9873935580253601\n",
      "epoch 151: loss=0.9688456058502197\n",
      "epoch 152: loss=0.9616225957870483\n",
      "epoch 153: loss=0.9728036522865295\n",
      "epoch 154: loss=0.999002993106842\n",
      "epoch 155: loss=0.966492772102356\n",
      "epoch 156: loss=0.9858420491218567\n",
      "epoch 157: loss=0.9767774343490601\n",
      "epoch 158: loss=0.9716967940330505\n",
      "epoch 159: loss=0.9748858213424683\n",
      "epoch 160: loss=0.9906063675880432\n",
      "epoch 161: loss=0.9714327454566956\n",
      "epoch 162: loss=0.9617555141448975\n",
      "epoch 163: loss=0.9632830619812012\n",
      "epoch 164: loss=0.9744547009468079\n",
      "epoch 165: loss=0.9697990417480469\n",
      "epoch 166: loss=0.9753814935684204\n",
      "epoch 167: loss=0.9755856990814209\n",
      "epoch 168: loss=0.9647364616394043\n",
      "epoch 169: loss=0.9678775668144226\n",
      "epoch 170: loss=0.9798716902732849\n",
      "epoch 171: loss=0.9777105450630188\n",
      "epoch 172: loss=0.9622653126716614\n",
      "epoch 173: loss=0.9579648971557617\n",
      "epoch 174: loss=0.9556581974029541\n",
      "epoch 175: loss=0.9722859859466553\n",
      "epoch 176: loss=0.9698550701141357\n",
      "epoch 177: loss=0.9621003866195679\n",
      "epoch 178: loss=0.954261064529419\n",
      "epoch 179: loss=0.9822088479995728\n",
      "epoch 180: loss=0.9630791544914246\n",
      "epoch 181: loss=0.9754980802536011\n",
      "epoch 182: loss=0.955102264881134\n",
      "epoch 183: loss=0.9684587121009827\n",
      "epoch 184: loss=0.9708253741264343\n",
      "epoch 185: loss=0.9636144042015076\n",
      "epoch 186: loss=0.9561388492584229\n",
      "epoch 187: loss=0.9812471866607666\n",
      "epoch 188: loss=0.9794749021530151\n",
      "epoch 189: loss=0.9809234738349915\n",
      "epoch 190: loss=0.957790195941925\n",
      "epoch 191: loss=0.9588162899017334\n",
      "epoch 192: loss=0.9773383736610413\n",
      "epoch 193: loss=0.9735126495361328\n",
      "epoch 194: loss=0.9705212116241455\n",
      "epoch 195: loss=0.9811089038848877\n",
      "epoch 196: loss=0.9629006385803223\n",
      "epoch 197: loss=0.9871110320091248\n",
      "epoch 198: loss=0.9535989165306091\n",
      "epoch 199: loss=0.9640931487083435\n",
      "training patch with 1652 edges\n",
      "epoch 0: loss=6.757911682128906\n",
      "epoch 1: loss=6.546629905700684\n",
      "epoch 2: loss=6.402936935424805\n",
      "epoch 3: loss=6.203738212585449\n",
      "epoch 4: loss=5.613818168640137\n",
      "epoch 5: loss=5.411327362060547\n",
      "epoch 6: loss=4.697854518890381\n",
      "epoch 7: loss=4.25577449798584\n",
      "epoch 8: loss=4.102414131164551\n",
      "epoch 9: loss=3.8451173305511475\n",
      "epoch 10: loss=3.4268627166748047\n",
      "epoch 11: loss=3.148967742919922\n",
      "epoch 12: loss=2.7352612018585205\n",
      "epoch 13: loss=2.5879147052764893\n",
      "epoch 14: loss=2.336578845977783\n",
      "epoch 15: loss=2.0272340774536133\n",
      "epoch 16: loss=1.839691162109375\n",
      "epoch 17: loss=1.775248408317566\n",
      "epoch 18: loss=1.7000689506530762\n",
      "epoch 19: loss=1.6085104942321777\n",
      "epoch 20: loss=1.6049185991287231\n",
      "epoch 21: loss=1.6034795045852661\n",
      "epoch 22: loss=1.5590633153915405\n",
      "epoch 23: loss=1.5458810329437256\n",
      "epoch 24: loss=1.5417354106903076\n",
      "epoch 25: loss=1.5419821739196777\n",
      "epoch 26: loss=1.54050612449646\n",
      "epoch 27: loss=1.5346872806549072\n",
      "epoch 28: loss=1.523901343345642\n",
      "epoch 29: loss=1.5170079469680786\n",
      "epoch 30: loss=1.5106866359710693\n",
      "epoch 31: loss=1.495988368988037\n",
      "epoch 32: loss=1.4842685461044312\n",
      "epoch 33: loss=1.4851775169372559\n",
      "epoch 34: loss=1.4865930080413818\n",
      "epoch 35: loss=1.4685981273651123\n",
      "epoch 36: loss=1.463496208190918\n",
      "epoch 37: loss=1.443256139755249\n",
      "epoch 38: loss=1.4350074529647827\n",
      "epoch 39: loss=1.4266724586486816\n",
      "epoch 40: loss=1.417154312133789\n",
      "epoch 41: loss=1.3967843055725098\n",
      "epoch 42: loss=1.371886968612671\n",
      "epoch 43: loss=1.3491241931915283\n",
      "epoch 44: loss=1.3381394147872925\n",
      "epoch 45: loss=1.2910435199737549\n",
      "epoch 46: loss=1.2567641735076904\n",
      "epoch 47: loss=1.256940245628357\n",
      "epoch 48: loss=1.2089309692382812\n",
      "epoch 49: loss=1.212761640548706\n",
      "epoch 50: loss=1.1934491395950317\n",
      "epoch 51: loss=1.1608504056930542\n",
      "epoch 52: loss=1.21054208278656\n",
      "epoch 53: loss=1.18448805809021\n",
      "epoch 54: loss=1.16605544090271\n",
      "epoch 55: loss=1.13533353805542\n",
      "epoch 56: loss=1.179720163345337\n",
      "epoch 57: loss=1.145725131034851\n",
      "epoch 58: loss=1.1427124738693237\n",
      "epoch 59: loss=1.1264617443084717\n",
      "epoch 60: loss=1.17146635055542\n",
      "epoch 61: loss=1.123810887336731\n",
      "epoch 62: loss=1.0931997299194336\n",
      "epoch 63: loss=1.1315858364105225\n",
      "epoch 64: loss=1.102918267250061\n",
      "epoch 65: loss=1.116788625717163\n",
      "epoch 66: loss=1.0966988801956177\n",
      "epoch 67: loss=1.1083686351776123\n",
      "epoch 68: loss=1.118587851524353\n",
      "epoch 69: loss=1.1062076091766357\n",
      "epoch 70: loss=1.0970362424850464\n",
      "epoch 71: loss=1.0917422771453857\n",
      "epoch 72: loss=1.0911928415298462\n",
      "epoch 73: loss=1.0714207887649536\n",
      "epoch 74: loss=1.107399582862854\n",
      "epoch 75: loss=1.1094090938568115\n",
      "epoch 76: loss=1.0987467765808105\n",
      "epoch 77: loss=1.0598130226135254\n",
      "epoch 78: loss=1.0640686750411987\n",
      "epoch 79: loss=1.1069796085357666\n",
      "epoch 80: loss=1.0705825090408325\n",
      "epoch 81: loss=1.052677035331726\n",
      "epoch 82: loss=1.0830217599868774\n",
      "epoch 83: loss=1.0567033290863037\n",
      "epoch 84: loss=1.0570778846740723\n",
      "epoch 85: loss=1.0531480312347412\n",
      "epoch 86: loss=1.0721638202667236\n",
      "epoch 87: loss=1.034644365310669\n",
      "epoch 88: loss=1.0621322393417358\n",
      "epoch 89: loss=1.0303311347961426\n",
      "epoch 90: loss=1.0554696321487427\n",
      "epoch 91: loss=1.0436530113220215\n",
      "epoch 92: loss=1.035575270652771\n",
      "epoch 93: loss=1.0546857118606567\n",
      "epoch 94: loss=1.0473582744598389\n",
      "epoch 95: loss=1.0670380592346191\n",
      "epoch 96: loss=1.0549218654632568\n",
      "epoch 97: loss=1.0472021102905273\n",
      "epoch 98: loss=1.057586908340454\n",
      "epoch 99: loss=1.067291021347046\n",
      "epoch 100: loss=1.046390175819397\n",
      "epoch 101: loss=1.0470101833343506\n",
      "epoch 102: loss=1.040107250213623\n",
      "epoch 103: loss=1.029780387878418\n",
      "epoch 104: loss=1.0416890382766724\n",
      "epoch 105: loss=1.0654739141464233\n",
      "epoch 106: loss=1.049668550491333\n",
      "epoch 107: loss=1.0274624824523926\n",
      "epoch 108: loss=1.030460000038147\n",
      "epoch 109: loss=1.0252766609191895\n",
      "epoch 110: loss=1.031949520111084\n",
      "epoch 111: loss=1.026258945465088\n",
      "epoch 112: loss=1.0364139080047607\n",
      "epoch 113: loss=1.061301827430725\n",
      "epoch 114: loss=1.068340539932251\n",
      "epoch 115: loss=1.0263348817825317\n",
      "epoch 116: loss=1.031661033630371\n",
      "epoch 117: loss=1.0473977327346802\n",
      "epoch 118: loss=1.0466793775558472\n",
      "epoch 119: loss=1.0906426906585693\n",
      "epoch 120: loss=1.0155670642852783\n",
      "epoch 121: loss=1.0311408042907715\n",
      "epoch 122: loss=1.0316894054412842\n",
      "epoch 123: loss=1.0334346294403076\n",
      "epoch 124: loss=1.0361976623535156\n",
      "epoch 125: loss=1.0134302377700806\n",
      "epoch 126: loss=1.0115611553192139\n",
      "epoch 127: loss=1.0170435905456543\n",
      "epoch 128: loss=1.0433098077774048\n",
      "epoch 129: loss=1.022638201713562\n",
      "epoch 130: loss=1.0314295291900635\n",
      "epoch 131: loss=1.0215109586715698\n",
      "epoch 132: loss=1.0268255472183228\n",
      "epoch 133: loss=1.029361605644226\n",
      "epoch 134: loss=1.0286349058151245\n",
      "epoch 135: loss=1.0464071035385132\n",
      "epoch 136: loss=1.0257391929626465\n",
      "epoch 137: loss=1.014925479888916\n",
      "epoch 138: loss=1.0428892374038696\n",
      "epoch 139: loss=1.0193408727645874\n",
      "epoch 140: loss=1.0255895853042603\n",
      "epoch 141: loss=1.0418208837509155\n",
      "epoch 142: loss=1.0436229705810547\n",
      "epoch 143: loss=1.038093090057373\n",
      "epoch 144: loss=1.015892505645752\n",
      "epoch 145: loss=1.0130966901779175\n",
      "epoch 146: loss=1.0154130458831787\n",
      "epoch 147: loss=1.057863712310791\n",
      "epoch 148: loss=1.0292668342590332\n",
      "epoch 149: loss=1.000914216041565\n",
      "epoch 150: loss=1.0039162635803223\n",
      "epoch 151: loss=1.0256239175796509\n",
      "epoch 152: loss=1.0399466753005981\n",
      "epoch 153: loss=1.0035319328308105\n",
      "epoch 154: loss=0.9992979764938354\n",
      "epoch 155: loss=1.0435668230056763\n",
      "epoch 156: loss=1.0301141738891602\n",
      "epoch 157: loss=1.0098559856414795\n",
      "epoch 158: loss=1.025819182395935\n",
      "epoch 159: loss=1.0307711362838745\n",
      "epoch 160: loss=1.0213651657104492\n",
      "epoch 161: loss=1.0166691541671753\n",
      "epoch 162: loss=1.0119293928146362\n",
      "epoch 163: loss=0.9946508407592773\n",
      "epoch 164: loss=1.0126376152038574\n",
      "epoch 165: loss=1.0216026306152344\n",
      "epoch 166: loss=1.0109002590179443\n",
      "epoch 167: loss=1.0316925048828125\n",
      "epoch 168: loss=1.030570387840271\n",
      "epoch 169: loss=1.02721107006073\n",
      "epoch 170: loss=1.0181150436401367\n",
      "epoch 171: loss=1.0173475742340088\n",
      "epoch 172: loss=1.016315221786499\n",
      "epoch 173: loss=1.0451699495315552\n",
      "epoch 174: loss=1.0083858966827393\n",
      "epoch 175: loss=1.006984829902649\n",
      "epoch 176: loss=1.0357050895690918\n",
      "epoch 177: loss=1.023450493812561\n",
      "epoch 178: loss=0.9979093074798584\n",
      "epoch 179: loss=1.0130743980407715\n",
      "epoch 180: loss=1.0304076671600342\n",
      "epoch 181: loss=1.0235795974731445\n",
      "epoch 182: loss=1.0271413326263428\n",
      "epoch 183: loss=1.028017282485962\n",
      "epoch 184: loss=1.0326200723648071\n",
      "epoch 185: loss=1.0212312936782837\n",
      "epoch 186: loss=1.0053519010543823\n",
      "epoch 187: loss=1.0332237482070923\n",
      "epoch 188: loss=1.0139617919921875\n",
      "epoch 189: loss=1.0262858867645264\n",
      "epoch 190: loss=0.9959515929222107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191: loss=1.0200291872024536\n",
      "epoch 192: loss=1.0396900177001953\n",
      "epoch 193: loss=1.0185332298278809\n",
      "epoch 194: loss=1.0042667388916016\n",
      "epoch 195: loss=1.0009617805480957\n",
      "epoch 196: loss=0.9850413203239441\n",
      "epoch 197: loss=1.0184617042541504\n",
      "epoch 198: loss=1.023080587387085\n",
      "epoch 199: loss=1.0150892734527588\n",
      "training patch with 840 edges\n",
      "epoch 0: loss=6.502488136291504\n",
      "epoch 1: loss=6.226147174835205\n",
      "epoch 2: loss=6.1758856773376465\n",
      "epoch 3: loss=5.764733791351318\n",
      "epoch 4: loss=5.649180889129639\n",
      "epoch 5: loss=5.157655239105225\n",
      "epoch 6: loss=4.52720308303833\n",
      "epoch 7: loss=4.339728355407715\n",
      "epoch 8: loss=3.89579439163208\n",
      "epoch 9: loss=3.5361149311065674\n",
      "epoch 10: loss=3.2470719814300537\n",
      "epoch 11: loss=3.1738767623901367\n",
      "epoch 12: loss=2.6105122566223145\n",
      "epoch 13: loss=2.4981558322906494\n",
      "epoch 14: loss=2.169940710067749\n",
      "epoch 15: loss=2.049501895904541\n",
      "epoch 16: loss=1.8638132810592651\n",
      "epoch 17: loss=1.8248780965805054\n",
      "epoch 18: loss=1.691100835800171\n",
      "epoch 19: loss=1.6356885433197021\n",
      "epoch 20: loss=1.6603538990020752\n",
      "epoch 21: loss=1.7211557626724243\n",
      "epoch 22: loss=1.6606712341308594\n",
      "epoch 23: loss=1.6195383071899414\n",
      "epoch 24: loss=1.5820763111114502\n",
      "epoch 25: loss=1.577684760093689\n",
      "epoch 26: loss=1.5726020336151123\n",
      "epoch 27: loss=1.5756405591964722\n",
      "epoch 28: loss=1.5819119215011597\n",
      "epoch 29: loss=1.5709272623062134\n",
      "epoch 30: loss=1.554225206375122\n",
      "epoch 31: loss=1.5333064794540405\n",
      "epoch 32: loss=1.5248067378997803\n",
      "epoch 33: loss=1.508437156677246\n",
      "epoch 34: loss=1.5253143310546875\n",
      "epoch 35: loss=1.4952243566513062\n",
      "epoch 36: loss=1.4878060817718506\n",
      "epoch 37: loss=1.4576302766799927\n",
      "epoch 38: loss=1.4331574440002441\n",
      "epoch 39: loss=1.387904167175293\n",
      "epoch 40: loss=1.3976819515228271\n",
      "epoch 41: loss=1.3728257417678833\n",
      "epoch 42: loss=1.3816444873809814\n",
      "epoch 43: loss=1.4019577503204346\n",
      "epoch 44: loss=1.400674819946289\n",
      "epoch 45: loss=1.3382221460342407\n",
      "epoch 46: loss=1.3211734294891357\n",
      "epoch 47: loss=1.2849688529968262\n",
      "epoch 48: loss=1.277573823928833\n",
      "epoch 49: loss=1.273343801498413\n",
      "epoch 50: loss=1.2998173236846924\n",
      "epoch 51: loss=1.2644764184951782\n",
      "epoch 52: loss=1.2609138488769531\n",
      "epoch 53: loss=1.3048065900802612\n",
      "epoch 54: loss=1.269268274307251\n",
      "epoch 55: loss=1.2512872219085693\n",
      "epoch 56: loss=1.2497384548187256\n",
      "epoch 57: loss=1.2200894355773926\n",
      "epoch 58: loss=1.2026506662368774\n",
      "epoch 59: loss=1.2070848941802979\n",
      "epoch 60: loss=1.1939283609390259\n",
      "epoch 61: loss=1.2032060623168945\n",
      "epoch 62: loss=1.1976560354232788\n",
      "epoch 63: loss=1.2326171398162842\n",
      "epoch 64: loss=1.1794663667678833\n",
      "epoch 65: loss=1.2197113037109375\n",
      "epoch 66: loss=1.1904213428497314\n",
      "epoch 67: loss=1.1672812700271606\n",
      "epoch 68: loss=1.1900142431259155\n",
      "epoch 69: loss=1.1876869201660156\n",
      "epoch 70: loss=1.1605628728866577\n",
      "epoch 71: loss=1.1718729734420776\n",
      "epoch 72: loss=1.1695797443389893\n",
      "epoch 73: loss=1.2160706520080566\n",
      "epoch 74: loss=1.155050277709961\n",
      "epoch 75: loss=1.2227230072021484\n",
      "epoch 76: loss=1.1793557405471802\n",
      "epoch 77: loss=1.1857953071594238\n",
      "epoch 78: loss=1.1866554021835327\n",
      "epoch 79: loss=1.1709325313568115\n",
      "epoch 80: loss=1.1325666904449463\n",
      "epoch 81: loss=1.128717064857483\n",
      "epoch 82: loss=1.1304535865783691\n",
      "epoch 83: loss=1.178135871887207\n",
      "epoch 84: loss=1.1946418285369873\n",
      "epoch 85: loss=1.1403616666793823\n",
      "epoch 86: loss=1.1317365169525146\n",
      "epoch 87: loss=1.1889313459396362\n",
      "epoch 88: loss=1.116995930671692\n",
      "epoch 89: loss=1.0950069427490234\n",
      "epoch 90: loss=1.1599491834640503\n",
      "epoch 91: loss=1.178908348083496\n",
      "epoch 92: loss=1.1646414995193481\n",
      "epoch 93: loss=1.176566243171692\n",
      "epoch 94: loss=1.159106969833374\n",
      "epoch 95: loss=1.1509621143341064\n",
      "epoch 96: loss=1.161803960800171\n",
      "epoch 97: loss=1.113000512123108\n",
      "epoch 98: loss=1.1483922004699707\n",
      "epoch 99: loss=1.1443498134613037\n",
      "epoch 100: loss=1.1500499248504639\n",
      "epoch 101: loss=1.1560840606689453\n",
      "epoch 102: loss=1.1667611598968506\n",
      "epoch 103: loss=1.1650238037109375\n",
      "epoch 104: loss=1.1343016624450684\n",
      "epoch 105: loss=1.1495275497436523\n",
      "epoch 106: loss=1.1358113288879395\n",
      "epoch 107: loss=1.112159013748169\n",
      "epoch 108: loss=1.1516053676605225\n",
      "epoch 109: loss=1.098708152770996\n",
      "epoch 110: loss=1.1128957271575928\n",
      "epoch 111: loss=1.1451992988586426\n",
      "epoch 112: loss=1.089110255241394\n",
      "epoch 113: loss=1.128847360610962\n",
      "epoch 114: loss=1.1354159116744995\n",
      "epoch 115: loss=1.0966870784759521\n",
      "epoch 116: loss=1.1390478610992432\n",
      "epoch 117: loss=1.1028881072998047\n",
      "epoch 118: loss=1.1811504364013672\n",
      "epoch 119: loss=1.159008502960205\n",
      "epoch 120: loss=1.1600537300109863\n",
      "epoch 121: loss=1.1647601127624512\n",
      "epoch 122: loss=1.1262470483779907\n",
      "epoch 123: loss=1.1553977727890015\n",
      "epoch 124: loss=1.1015145778656006\n",
      "epoch 125: loss=1.1578091382980347\n",
      "epoch 126: loss=1.1164844036102295\n",
      "epoch 127: loss=1.1113743782043457\n",
      "epoch 128: loss=1.165055274963379\n",
      "epoch 129: loss=1.148099660873413\n",
      "epoch 130: loss=1.139583945274353\n",
      "epoch 131: loss=1.151763677597046\n",
      "epoch 132: loss=1.1271642446517944\n",
      "epoch 133: loss=1.1048495769500732\n",
      "epoch 134: loss=1.1639578342437744\n",
      "epoch 135: loss=1.1754226684570312\n",
      "epoch 136: loss=1.1319935321807861\n",
      "epoch 137: loss=1.1247913837432861\n",
      "epoch 138: loss=1.1423654556274414\n",
      "epoch 139: loss=1.129485845565796\n",
      "epoch 140: loss=1.0918530225753784\n",
      "epoch 141: loss=1.1206812858581543\n",
      "epoch 142: loss=1.1131312847137451\n",
      "epoch 143: loss=1.1188751459121704\n",
      "epoch 144: loss=1.1490882635116577\n",
      "epoch 145: loss=1.1384403705596924\n",
      "epoch 146: loss=1.1133781671524048\n",
      "epoch 147: loss=1.1086196899414062\n",
      "epoch 148: loss=1.1445112228393555\n",
      "epoch 149: loss=1.1230013370513916\n",
      "epoch 150: loss=1.1159800291061401\n",
      "epoch 151: loss=1.1631261110305786\n",
      "epoch 152: loss=1.1206883192062378\n",
      "epoch 153: loss=1.0988552570343018\n",
      "epoch 154: loss=1.1192810535430908\n",
      "epoch 155: loss=1.146287202835083\n",
      "epoch 156: loss=1.178655743598938\n",
      "epoch 157: loss=1.1257431507110596\n",
      "epoch 158: loss=1.0909473896026611\n",
      "epoch 159: loss=1.1169013977050781\n",
      "epoch 160: loss=1.1328620910644531\n",
      "epoch 161: loss=1.1110656261444092\n",
      "epoch 162: loss=1.123783826828003\n",
      "epoch 163: loss=1.1183024644851685\n",
      "epoch 164: loss=1.1073311567306519\n",
      "epoch 165: loss=1.104818344116211\n",
      "epoch 166: loss=1.1228841543197632\n",
      "epoch 167: loss=1.121593952178955\n",
      "epoch 168: loss=1.107951283454895\n",
      "epoch 169: loss=1.1198155879974365\n",
      "epoch 170: loss=1.1566451787948608\n",
      "epoch 171: loss=1.1350772380828857\n",
      "epoch 172: loss=1.140751838684082\n",
      "epoch 173: loss=1.1181838512420654\n",
      "epoch 174: loss=1.12539803981781\n",
      "epoch 175: loss=1.1207103729248047\n",
      "epoch 176: loss=1.1378448009490967\n",
      "epoch 177: loss=1.1305606365203857\n",
      "epoch 178: loss=1.1477055549621582\n",
      "epoch 179: loss=1.111680507659912\n",
      "epoch 180: loss=1.1480934619903564\n",
      "epoch 181: loss=1.0912928581237793\n",
      "epoch 182: loss=1.1355462074279785\n",
      "epoch 183: loss=1.1211391687393188\n",
      "epoch 184: loss=1.1175954341888428\n",
      "epoch 185: loss=1.1107268333435059\n",
      "epoch 186: loss=1.135573387145996\n",
      "epoch 187: loss=1.1304312944412231\n",
      "epoch 188: loss=1.1161550283432007\n",
      "epoch 189: loss=1.1375023126602173\n",
      "epoch 190: loss=1.093853235244751\n",
      "epoch 191: loss=1.0949751138687134\n",
      "epoch 192: loss=1.1104663610458374\n",
      "epoch 193: loss=1.1690094470977783\n",
      "epoch 194: loss=1.0847256183624268\n",
      "epoch 195: loss=1.1333765983581543\n",
      "epoch 196: loss=1.1570892333984375\n",
      "epoch 197: loss=1.1422975063323975\n",
      "epoch 198: loss=1.1052342653274536\n",
      "epoch 199: loss=1.082642912864685\n",
      "training patch with 1460 edges\n",
      "epoch 0: loss=7.421989440917969\n",
      "epoch 1: loss=6.624995708465576\n",
      "epoch 2: loss=6.0376434326171875\n",
      "epoch 3: loss=5.5617852210998535\n",
      "epoch 4: loss=5.253617286682129\n",
      "epoch 5: loss=5.056657791137695\n",
      "epoch 6: loss=4.677395343780518\n",
      "epoch 7: loss=4.519965171813965\n",
      "epoch 8: loss=3.9339983463287354\n",
      "epoch 9: loss=3.6390256881713867\n",
      "epoch 10: loss=3.2735235691070557\n",
      "epoch 11: loss=3.189967393875122\n",
      "epoch 12: loss=2.830564022064209\n",
      "epoch 13: loss=2.5393171310424805\n",
      "epoch 14: loss=2.3695080280303955\n",
      "epoch 15: loss=2.130875825881958\n",
      "epoch 16: loss=1.9388407468795776\n",
      "epoch 17: loss=1.7708557844161987\n",
      "epoch 18: loss=1.7170363664627075\n",
      "epoch 19: loss=1.6718204021453857\n",
      "epoch 20: loss=1.680783748626709\n",
      "epoch 21: loss=1.6228418350219727\n",
      "epoch 22: loss=1.5799039602279663\n",
      "epoch 23: loss=1.5563186407089233\n",
      "epoch 24: loss=1.511066198348999\n",
      "epoch 25: loss=1.532871961593628\n",
      "epoch 26: loss=1.5483404397964478\n",
      "epoch 27: loss=1.5317028760910034\n",
      "epoch 28: loss=1.5441380739212036\n",
      "epoch 29: loss=1.544590950012207\n",
      "epoch 30: loss=1.5272120237350464\n",
      "epoch 31: loss=1.507057785987854\n",
      "epoch 32: loss=1.5055378675460815\n",
      "epoch 33: loss=1.4919028282165527\n",
      "epoch 34: loss=1.4778026342391968\n",
      "epoch 35: loss=1.4691946506500244\n",
      "epoch 36: loss=1.4764864444732666\n",
      "epoch 37: loss=1.4703179597854614\n",
      "epoch 38: loss=1.4582313299179077\n",
      "epoch 39: loss=1.4358689785003662\n",
      "epoch 40: loss=1.4299579858779907\n",
      "epoch 41: loss=1.4179613590240479\n",
      "epoch 42: loss=1.405889868736267\n",
      "epoch 43: loss=1.3810815811157227\n",
      "epoch 44: loss=1.3757554292678833\n",
      "epoch 45: loss=1.3541643619537354\n",
      "epoch 46: loss=1.3340482711791992\n",
      "epoch 47: loss=1.3147703409194946\n",
      "epoch 48: loss=1.303580403327942\n",
      "epoch 49: loss=1.3057218790054321\n",
      "epoch 50: loss=1.2720156908035278\n",
      "epoch 51: loss=1.2569398880004883\n",
      "epoch 52: loss=1.2658207416534424\n",
      "epoch 53: loss=1.2439994812011719\n",
      "epoch 54: loss=1.2396184206008911\n",
      "epoch 55: loss=1.2427653074264526\n",
      "epoch 56: loss=1.219831109046936\n",
      "epoch 57: loss=1.2316067218780518\n",
      "epoch 58: loss=1.2044496536254883\n",
      "epoch 59: loss=1.1900975704193115\n",
      "epoch 60: loss=1.1967625617980957\n",
      "epoch 61: loss=1.171918511390686\n",
      "epoch 62: loss=1.1631592512130737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63: loss=1.1820130348205566\n",
      "epoch 64: loss=1.1692333221435547\n",
      "epoch 65: loss=1.1621975898742676\n",
      "epoch 66: loss=1.156503677368164\n",
      "epoch 67: loss=1.14967942237854\n",
      "epoch 68: loss=1.1349989175796509\n",
      "epoch 69: loss=1.1720327138900757\n",
      "epoch 70: loss=1.1785264015197754\n",
      "epoch 71: loss=1.1537423133850098\n",
      "epoch 72: loss=1.1474668979644775\n",
      "epoch 73: loss=1.1259620189666748\n",
      "epoch 74: loss=1.1159533262252808\n",
      "epoch 75: loss=1.0998423099517822\n",
      "epoch 76: loss=1.130456805229187\n",
      "epoch 77: loss=1.1283364295959473\n",
      "epoch 78: loss=1.1260626316070557\n",
      "epoch 79: loss=1.1210792064666748\n",
      "epoch 80: loss=1.128817081451416\n",
      "epoch 81: loss=1.1239025592803955\n",
      "epoch 82: loss=1.1104726791381836\n",
      "epoch 83: loss=1.1169958114624023\n",
      "epoch 84: loss=1.1231461763381958\n",
      "epoch 85: loss=1.0955384969711304\n",
      "epoch 86: loss=1.0926979780197144\n",
      "epoch 87: loss=1.1218876838684082\n",
      "epoch 88: loss=1.0914723873138428\n",
      "epoch 89: loss=1.0781936645507812\n",
      "epoch 90: loss=1.082216501235962\n",
      "epoch 91: loss=1.1089001893997192\n",
      "epoch 92: loss=1.0814019441604614\n",
      "epoch 93: loss=1.0849213600158691\n",
      "epoch 94: loss=1.1013418436050415\n",
      "epoch 95: loss=1.0865997076034546\n",
      "epoch 96: loss=1.0835312604904175\n",
      "epoch 97: loss=1.0886462926864624\n",
      "epoch 98: loss=1.1012892723083496\n",
      "epoch 99: loss=1.0781270265579224\n",
      "epoch 100: loss=1.0613656044006348\n",
      "epoch 101: loss=1.06171452999115\n",
      "epoch 102: loss=1.083914875984192\n",
      "epoch 103: loss=1.0991953611373901\n",
      "epoch 104: loss=1.1054949760437012\n",
      "epoch 105: loss=1.0767513513565063\n",
      "epoch 106: loss=1.0682854652404785\n",
      "epoch 107: loss=1.0546472072601318\n",
      "epoch 108: loss=1.0699337720870972\n",
      "epoch 109: loss=1.0452370643615723\n",
      "epoch 110: loss=1.0599699020385742\n",
      "epoch 111: loss=1.0650608539581299\n",
      "epoch 112: loss=1.0783534049987793\n",
      "epoch 113: loss=1.0791889429092407\n",
      "epoch 114: loss=1.098907470703125\n",
      "epoch 115: loss=1.0569164752960205\n",
      "epoch 116: loss=1.080024242401123\n",
      "epoch 117: loss=1.0802533626556396\n",
      "epoch 118: loss=1.062903881072998\n",
      "epoch 119: loss=1.0580532550811768\n",
      "epoch 120: loss=1.0553089380264282\n",
      "epoch 121: loss=1.0640108585357666\n",
      "epoch 122: loss=1.0678526163101196\n",
      "epoch 123: loss=1.0726152658462524\n",
      "epoch 124: loss=1.0652498006820679\n",
      "epoch 125: loss=1.0843136310577393\n",
      "epoch 126: loss=1.0517542362213135\n",
      "epoch 127: loss=1.0499069690704346\n",
      "epoch 128: loss=1.0804582834243774\n",
      "epoch 129: loss=1.0671510696411133\n",
      "epoch 130: loss=1.0271704196929932\n",
      "epoch 131: loss=1.0528753995895386\n",
      "epoch 132: loss=1.064028024673462\n",
      "epoch 133: loss=1.0477219820022583\n",
      "epoch 134: loss=1.0475523471832275\n",
      "epoch 135: loss=1.0573889017105103\n",
      "epoch 136: loss=1.0092657804489136\n",
      "epoch 137: loss=1.0633544921875\n",
      "epoch 138: loss=1.0757379531860352\n",
      "epoch 139: loss=1.0672999620437622\n",
      "epoch 140: loss=1.0479538440704346\n",
      "epoch 141: loss=1.0310404300689697\n",
      "epoch 142: loss=1.070541262626648\n",
      "epoch 143: loss=1.0268757343292236\n",
      "epoch 144: loss=1.0313395261764526\n",
      "epoch 145: loss=1.0258806943893433\n",
      "epoch 146: loss=1.0334560871124268\n",
      "epoch 147: loss=1.051615595817566\n",
      "epoch 148: loss=1.065833330154419\n",
      "epoch 149: loss=1.0695159435272217\n",
      "epoch 150: loss=1.0503442287445068\n",
      "epoch 151: loss=1.0389739274978638\n",
      "epoch 152: loss=1.070833444595337\n",
      "epoch 153: loss=1.047904133796692\n",
      "epoch 154: loss=1.049497365951538\n",
      "epoch 155: loss=1.059421181678772\n",
      "epoch 156: loss=1.0526444911956787\n",
      "epoch 157: loss=1.0370904207229614\n",
      "epoch 158: loss=1.0540329217910767\n",
      "epoch 159: loss=1.0604350566864014\n",
      "epoch 160: loss=1.0272794961929321\n",
      "epoch 161: loss=1.0558350086212158\n",
      "epoch 162: loss=1.0491869449615479\n",
      "epoch 163: loss=1.0518138408660889\n",
      "epoch 164: loss=1.071425199508667\n",
      "epoch 165: loss=1.0506072044372559\n",
      "epoch 166: loss=1.0318363904953003\n",
      "epoch 167: loss=1.0217803716659546\n",
      "epoch 168: loss=1.0095252990722656\n",
      "epoch 169: loss=1.060158610343933\n",
      "epoch 170: loss=1.046430230140686\n",
      "epoch 171: loss=1.0458669662475586\n",
      "epoch 172: loss=1.051147222518921\n",
      "epoch 173: loss=1.0433037281036377\n",
      "epoch 174: loss=1.0576683282852173\n",
      "epoch 175: loss=1.0375710725784302\n",
      "epoch 176: loss=1.063673734664917\n",
      "epoch 177: loss=1.0453333854675293\n",
      "epoch 178: loss=1.015578269958496\n",
      "epoch 179: loss=1.0509984493255615\n",
      "epoch 180: loss=1.0516607761383057\n",
      "epoch 181: loss=1.0516773462295532\n",
      "epoch 182: loss=1.0531885623931885\n",
      "epoch 183: loss=1.0404138565063477\n",
      "epoch 184: loss=1.0013892650604248\n",
      "epoch 185: loss=1.051328182220459\n",
      "epoch 186: loss=1.0261375904083252\n",
      "epoch 187: loss=1.0204100608825684\n",
      "epoch 188: loss=1.0590463876724243\n",
      "epoch 189: loss=1.0378273725509644\n",
      "epoch 190: loss=1.0202409029006958\n",
      "epoch 191: loss=1.0454591512680054\n",
      "epoch 192: loss=1.0635075569152832\n",
      "epoch 193: loss=1.018792986869812\n",
      "epoch 194: loss=1.0412838459014893\n",
      "epoch 195: loss=1.055920958518982\n",
      "epoch 196: loss=1.0364824533462524\n",
      "epoch 197: loss=1.02047860622406\n",
      "epoch 198: loss=1.0340662002563477\n",
      "epoch 199: loss=1.0474804639816284\n",
      "training patch with 764 edges\n",
      "epoch 0: loss=6.94945764541626\n",
      "epoch 1: loss=6.796901226043701\n",
      "epoch 2: loss=6.528519630432129\n",
      "epoch 3: loss=6.628703594207764\n",
      "epoch 4: loss=5.8761820793151855\n",
      "epoch 5: loss=5.4138922691345215\n",
      "epoch 6: loss=4.959935188293457\n",
      "epoch 7: loss=4.967121601104736\n",
      "epoch 8: loss=4.280948162078857\n",
      "epoch 9: loss=4.142829895019531\n",
      "epoch 10: loss=3.5783374309539795\n",
      "epoch 11: loss=3.484884023666382\n",
      "epoch 12: loss=3.1947641372680664\n",
      "epoch 13: loss=2.6036529541015625\n",
      "epoch 14: loss=2.38100266456604\n",
      "epoch 15: loss=2.182896852493286\n",
      "epoch 16: loss=2.022014856338501\n",
      "epoch 17: loss=1.8874541521072388\n",
      "epoch 18: loss=1.8301887512207031\n",
      "epoch 19: loss=1.7395036220550537\n",
      "epoch 20: loss=1.6781060695648193\n",
      "epoch 21: loss=1.7030742168426514\n",
      "epoch 22: loss=1.725977897644043\n",
      "epoch 23: loss=1.701730728149414\n",
      "epoch 24: loss=1.7046360969543457\n",
      "epoch 25: loss=1.6348416805267334\n",
      "epoch 26: loss=1.6629360914230347\n",
      "epoch 27: loss=1.6337438821792603\n",
      "epoch 28: loss=1.6196284294128418\n",
      "epoch 29: loss=1.6494264602661133\n",
      "epoch 30: loss=1.6413302421569824\n",
      "epoch 31: loss=1.6090799570083618\n",
      "epoch 32: loss=1.5691320896148682\n",
      "epoch 33: loss=1.5657663345336914\n",
      "epoch 34: loss=1.547322154045105\n",
      "epoch 35: loss=1.5080533027648926\n",
      "epoch 36: loss=1.508439064025879\n",
      "epoch 37: loss=1.4783862829208374\n",
      "epoch 38: loss=1.4716401100158691\n",
      "epoch 39: loss=1.4465887546539307\n",
      "epoch 40: loss=1.418562412261963\n",
      "epoch 41: loss=1.3681131601333618\n",
      "epoch 42: loss=1.3898106813430786\n",
      "epoch 43: loss=1.4116299152374268\n",
      "epoch 44: loss=1.386950969696045\n",
      "epoch 45: loss=1.3350874185562134\n",
      "epoch 46: loss=1.3628908395767212\n",
      "epoch 47: loss=1.3302196264266968\n",
      "epoch 48: loss=1.3271000385284424\n",
      "epoch 49: loss=1.3017454147338867\n",
      "epoch 50: loss=1.333557367324829\n",
      "epoch 51: loss=1.3094836473464966\n",
      "epoch 52: loss=1.334862232208252\n",
      "epoch 53: loss=1.2368271350860596\n",
      "epoch 54: loss=1.249478816986084\n",
      "epoch 55: loss=1.2918753623962402\n",
      "epoch 56: loss=1.3055434226989746\n",
      "epoch 57: loss=1.2680591344833374\n",
      "epoch 58: loss=1.2758785486221313\n",
      "epoch 59: loss=1.2254799604415894\n",
      "epoch 60: loss=1.235244870185852\n",
      "epoch 61: loss=1.2241545915603638\n",
      "epoch 62: loss=1.2369208335876465\n",
      "epoch 63: loss=1.245678186416626\n",
      "epoch 64: loss=1.237976312637329\n",
      "epoch 65: loss=1.2338461875915527\n",
      "epoch 66: loss=1.2810943126678467\n",
      "epoch 67: loss=1.231230616569519\n",
      "epoch 68: loss=1.26541268825531\n",
      "epoch 69: loss=1.261748194694519\n",
      "epoch 70: loss=1.2520802021026611\n",
      "epoch 71: loss=1.2291311025619507\n",
      "epoch 72: loss=1.2207231521606445\n",
      "epoch 73: loss=1.2447147369384766\n",
      "epoch 74: loss=1.21763014793396\n",
      "epoch 75: loss=1.2465450763702393\n",
      "epoch 76: loss=1.2412352561950684\n",
      "epoch 77: loss=1.2214282751083374\n",
      "epoch 78: loss=1.2075806856155396\n",
      "epoch 79: loss=1.2368911504745483\n",
      "epoch 80: loss=1.1865146160125732\n",
      "epoch 81: loss=1.1757826805114746\n",
      "epoch 82: loss=1.2117908000946045\n",
      "epoch 83: loss=1.2369414567947388\n",
      "epoch 84: loss=1.237404704093933\n",
      "epoch 85: loss=1.2077412605285645\n",
      "epoch 86: loss=1.2331151962280273\n",
      "epoch 87: loss=1.207646369934082\n",
      "epoch 88: loss=1.183807134628296\n",
      "epoch 89: loss=1.2073767185211182\n",
      "epoch 90: loss=1.233817458152771\n",
      "epoch 91: loss=1.1756333112716675\n",
      "epoch 92: loss=1.2114084959030151\n",
      "epoch 93: loss=1.2227989435195923\n",
      "epoch 94: loss=1.2173593044281006\n",
      "epoch 95: loss=1.2187217473983765\n",
      "epoch 96: loss=1.1998014450073242\n",
      "epoch 97: loss=1.1810564994812012\n",
      "epoch 98: loss=1.246962308883667\n",
      "epoch 99: loss=1.1986346244812012\n",
      "epoch 100: loss=1.2175824642181396\n",
      "epoch 101: loss=1.2073932886123657\n",
      "epoch 102: loss=1.2185554504394531\n",
      "epoch 103: loss=1.2099230289459229\n",
      "epoch 104: loss=1.2298667430877686\n",
      "epoch 105: loss=1.1865668296813965\n",
      "epoch 106: loss=1.206368088722229\n",
      "epoch 107: loss=1.2246090173721313\n",
      "epoch 108: loss=1.1937575340270996\n",
      "epoch 109: loss=1.1966923475265503\n",
      "epoch 110: loss=1.2066130638122559\n",
      "epoch 111: loss=1.1828142404556274\n",
      "epoch 112: loss=1.2133240699768066\n",
      "epoch 113: loss=1.209582805633545\n",
      "epoch 114: loss=1.1830213069915771\n",
      "epoch 115: loss=1.1674716472625732\n",
      "epoch 116: loss=1.2230451107025146\n",
      "epoch 117: loss=1.2239269018173218\n",
      "epoch 118: loss=1.1862483024597168\n",
      "epoch 119: loss=1.2122000455856323\n",
      "epoch 120: loss=1.198197603225708\n",
      "epoch 121: loss=1.1331387758255005\n",
      "epoch 122: loss=1.146120309829712\n",
      "epoch 123: loss=1.2278499603271484\n",
      "epoch 124: loss=1.1699814796447754\n",
      "epoch 125: loss=1.1603132486343384\n",
      "epoch 126: loss=1.1991498470306396\n",
      "epoch 127: loss=1.180749535560608\n",
      "epoch 128: loss=1.2054316997528076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129: loss=1.1551356315612793\n",
      "epoch 130: loss=1.195228099822998\n",
      "epoch 131: loss=1.1719448566436768\n",
      "epoch 132: loss=1.1919625997543335\n",
      "epoch 133: loss=1.1825445890426636\n",
      "epoch 134: loss=1.2052967548370361\n",
      "epoch 135: loss=1.2228937149047852\n",
      "epoch 136: loss=1.1871389150619507\n",
      "epoch 137: loss=1.1567552089691162\n",
      "epoch 138: loss=1.209915280342102\n",
      "epoch 139: loss=1.2099332809448242\n",
      "epoch 140: loss=1.1610735654830933\n",
      "epoch 141: loss=1.1439716815948486\n",
      "epoch 142: loss=1.2266325950622559\n",
      "epoch 143: loss=1.1521832942962646\n",
      "epoch 144: loss=1.2140578031539917\n",
      "epoch 145: loss=1.2179102897644043\n",
      "epoch 146: loss=1.2237991094589233\n",
      "epoch 147: loss=1.2365046739578247\n",
      "epoch 148: loss=1.2144205570220947\n",
      "epoch 149: loss=1.1870355606079102\n",
      "epoch 150: loss=1.180922031402588\n",
      "epoch 151: loss=1.16762113571167\n",
      "epoch 152: loss=1.180173635482788\n",
      "epoch 153: loss=1.1685794591903687\n",
      "epoch 154: loss=1.2609155178070068\n",
      "epoch 155: loss=1.169528603553772\n",
      "epoch 156: loss=1.2252048254013062\n",
      "epoch 157: loss=1.2339742183685303\n",
      "epoch 158: loss=1.1479078531265259\n",
      "epoch 159: loss=1.2144310474395752\n",
      "epoch 160: loss=1.1411621570587158\n",
      "epoch 161: loss=1.1587451696395874\n",
      "epoch 162: loss=1.1938546895980835\n",
      "epoch 163: loss=1.2024070024490356\n",
      "epoch 164: loss=1.1670080423355103\n",
      "epoch 165: loss=1.169677972793579\n",
      "epoch 166: loss=1.1974265575408936\n",
      "epoch 167: loss=1.1722486019134521\n",
      "epoch 168: loss=1.1545734405517578\n",
      "epoch 169: loss=1.1639481782913208\n",
      "epoch 170: loss=1.2136061191558838\n",
      "epoch 171: loss=1.1530230045318604\n",
      "epoch 172: loss=1.165395975112915\n",
      "epoch 173: loss=1.1492993831634521\n",
      "epoch 174: loss=1.1286970376968384\n",
      "epoch 175: loss=1.1751004457473755\n",
      "epoch 176: loss=1.1982656717300415\n",
      "epoch 177: loss=1.1971626281738281\n",
      "epoch 178: loss=1.1613291501998901\n",
      "epoch 179: loss=1.0951440334320068\n",
      "epoch 180: loss=1.217236042022705\n",
      "epoch 181: loss=1.1670633554458618\n",
      "epoch 182: loss=1.1391422748565674\n",
      "epoch 183: loss=1.1810212135314941\n",
      "epoch 184: loss=1.1588196754455566\n",
      "epoch 185: loss=1.1542489528656006\n",
      "epoch 186: loss=1.1430169343948364\n",
      "epoch 187: loss=1.1645667552947998\n",
      "epoch 188: loss=1.2026797533035278\n",
      "epoch 189: loss=1.1447138786315918\n",
      "epoch 190: loss=1.202658772468567\n",
      "epoch 191: loss=1.2041122913360596\n",
      "epoch 192: loss=1.1739895343780518\n",
      "epoch 193: loss=1.1371738910675049\n",
      "epoch 194: loss=1.1841397285461426\n",
      "epoch 195: loss=1.192770004272461\n",
      "epoch 196: loss=1.1667661666870117\n",
      "epoch 197: loss=1.1789627075195312\n",
      "epoch 198: loss=1.1948586702346802\n",
      "epoch 199: loss=1.1445949077606201\n",
      "training patch with 950 edges\n",
      "epoch 0: loss=6.580936908721924\n",
      "epoch 1: loss=6.981348037719727\n",
      "epoch 2: loss=6.278087139129639\n",
      "epoch 3: loss=6.128215789794922\n",
      "epoch 4: loss=5.58303689956665\n",
      "epoch 5: loss=5.335814476013184\n",
      "epoch 6: loss=5.198687553405762\n",
      "epoch 7: loss=4.625101089477539\n",
      "epoch 8: loss=3.9773030281066895\n",
      "epoch 9: loss=3.9059340953826904\n",
      "epoch 10: loss=3.515338897705078\n",
      "epoch 11: loss=3.5032289028167725\n",
      "epoch 12: loss=3.3755199909210205\n",
      "epoch 13: loss=2.7893168926239014\n",
      "epoch 14: loss=2.577847480773926\n",
      "epoch 15: loss=2.308598041534424\n",
      "epoch 16: loss=2.1975772380828857\n",
      "epoch 17: loss=1.8624850511550903\n",
      "epoch 18: loss=1.8825678825378418\n",
      "epoch 19: loss=1.7338242530822754\n",
      "epoch 20: loss=1.647403359413147\n",
      "epoch 21: loss=1.6674139499664307\n",
      "epoch 22: loss=1.6352814435958862\n",
      "epoch 23: loss=1.6411967277526855\n",
      "epoch 24: loss=1.6195505857467651\n",
      "epoch 25: loss=1.5622657537460327\n",
      "epoch 26: loss=1.5720514059066772\n",
      "epoch 27: loss=1.592092514038086\n",
      "epoch 28: loss=1.5538444519042969\n",
      "epoch 29: loss=1.5703657865524292\n",
      "epoch 30: loss=1.567869782447815\n",
      "epoch 31: loss=1.5629907846450806\n",
      "epoch 32: loss=1.5370022058486938\n",
      "epoch 33: loss=1.5237559080123901\n",
      "epoch 34: loss=1.4990267753601074\n",
      "epoch 35: loss=1.5014568567276\n",
      "epoch 36: loss=1.4726845026016235\n",
      "epoch 37: loss=1.4275128841400146\n",
      "epoch 38: loss=1.3893249034881592\n",
      "epoch 39: loss=1.3617501258850098\n",
      "epoch 40: loss=1.3653061389923096\n",
      "epoch 41: loss=1.3366320133209229\n",
      "epoch 42: loss=1.3289391994476318\n",
      "epoch 43: loss=1.343451738357544\n",
      "epoch 44: loss=1.2953866720199585\n",
      "epoch 45: loss=1.301877737045288\n",
      "epoch 46: loss=1.2734938859939575\n",
      "epoch 47: loss=1.3346000909805298\n",
      "epoch 48: loss=1.290808916091919\n",
      "epoch 49: loss=1.2547025680541992\n",
      "epoch 50: loss=1.2487270832061768\n",
      "epoch 51: loss=1.2711195945739746\n",
      "epoch 52: loss=1.2179696559906006\n",
      "epoch 53: loss=1.2119728326797485\n",
      "epoch 54: loss=1.2501356601715088\n",
      "epoch 55: loss=1.2574434280395508\n",
      "epoch 56: loss=1.2202415466308594\n",
      "epoch 57: loss=1.2173943519592285\n",
      "epoch 58: loss=1.2400238513946533\n",
      "epoch 59: loss=1.2273365259170532\n",
      "epoch 60: loss=1.2072868347167969\n",
      "epoch 61: loss=1.1871715784072876\n",
      "epoch 62: loss=1.2272148132324219\n",
      "epoch 63: loss=1.166810154914856\n",
      "epoch 64: loss=1.2080237865447998\n",
      "epoch 65: loss=1.2019331455230713\n",
      "epoch 66: loss=1.1886186599731445\n",
      "epoch 67: loss=1.201466679573059\n",
      "epoch 68: loss=1.1827518939971924\n",
      "epoch 69: loss=1.2372742891311646\n",
      "epoch 70: loss=1.1630727052688599\n",
      "epoch 71: loss=1.199110984802246\n",
      "epoch 72: loss=1.1953377723693848\n",
      "epoch 73: loss=1.1588666439056396\n",
      "epoch 74: loss=1.1512917280197144\n",
      "epoch 75: loss=1.2055031061172485\n",
      "epoch 76: loss=1.1916496753692627\n",
      "epoch 77: loss=1.183112382888794\n",
      "epoch 78: loss=1.165592074394226\n",
      "epoch 79: loss=1.1536462306976318\n",
      "epoch 80: loss=1.1496143341064453\n",
      "epoch 81: loss=1.1508221626281738\n",
      "epoch 82: loss=1.1363444328308105\n",
      "epoch 83: loss=1.18387770652771\n",
      "epoch 84: loss=1.1649911403656006\n",
      "epoch 85: loss=1.1686015129089355\n",
      "epoch 86: loss=1.1723896265029907\n",
      "epoch 87: loss=1.1547794342041016\n",
      "epoch 88: loss=1.1719019412994385\n",
      "epoch 89: loss=1.118603229522705\n",
      "epoch 90: loss=1.134823203086853\n",
      "epoch 91: loss=1.1524031162261963\n",
      "epoch 92: loss=1.1609143018722534\n",
      "epoch 93: loss=1.1577273607254028\n",
      "epoch 94: loss=1.168384075164795\n",
      "epoch 95: loss=1.1386491060256958\n",
      "epoch 96: loss=1.1243170499801636\n",
      "epoch 97: loss=1.1681571006774902\n",
      "epoch 98: loss=1.16145658493042\n",
      "epoch 99: loss=1.1550792455673218\n",
      "epoch 100: loss=1.1442694664001465\n",
      "epoch 101: loss=1.1602792739868164\n",
      "epoch 102: loss=1.1047018766403198\n",
      "epoch 103: loss=1.137575626373291\n",
      "epoch 104: loss=1.123148798942566\n",
      "epoch 105: loss=1.1453860998153687\n",
      "epoch 106: loss=1.1582016944885254\n",
      "epoch 107: loss=1.1436643600463867\n",
      "epoch 108: loss=1.1342695951461792\n",
      "epoch 109: loss=1.104219913482666\n",
      "epoch 110: loss=1.127232551574707\n",
      "epoch 111: loss=1.117733120918274\n",
      "epoch 112: loss=1.1149431467056274\n",
      "epoch 113: loss=1.1387548446655273\n",
      "epoch 114: loss=1.1535440683364868\n",
      "epoch 115: loss=1.1538113355636597\n",
      "epoch 116: loss=1.0955865383148193\n",
      "epoch 117: loss=1.1543694734573364\n",
      "epoch 118: loss=1.1770625114440918\n",
      "epoch 119: loss=1.109694242477417\n",
      "epoch 120: loss=1.1461151838302612\n",
      "epoch 121: loss=1.1562209129333496\n",
      "epoch 122: loss=1.1470608711242676\n",
      "epoch 123: loss=1.124856948852539\n",
      "epoch 124: loss=1.0933758020401\n",
      "epoch 125: loss=1.120018720626831\n",
      "epoch 126: loss=1.095252513885498\n",
      "epoch 127: loss=1.1302745342254639\n",
      "epoch 128: loss=1.161231279373169\n",
      "epoch 129: loss=1.0929691791534424\n",
      "epoch 130: loss=1.0877567529678345\n",
      "epoch 131: loss=1.1267688274383545\n",
      "epoch 132: loss=1.148866891860962\n",
      "epoch 133: loss=1.1364467144012451\n",
      "epoch 134: loss=1.1084895133972168\n",
      "epoch 135: loss=1.0765150785446167\n",
      "epoch 136: loss=1.1498808860778809\n",
      "epoch 137: loss=1.1252731084823608\n",
      "epoch 138: loss=1.1249321699142456\n",
      "epoch 139: loss=1.1543210744857788\n",
      "epoch 140: loss=1.140160322189331\n",
      "epoch 141: loss=1.1410030126571655\n",
      "epoch 142: loss=1.100502610206604\n",
      "epoch 143: loss=1.1397995948791504\n",
      "epoch 144: loss=1.107861042022705\n",
      "epoch 145: loss=1.1140121221542358\n",
      "epoch 146: loss=1.0861766338348389\n",
      "epoch 147: loss=1.0919767618179321\n",
      "epoch 148: loss=1.1287809610366821\n",
      "epoch 149: loss=1.1279231309890747\n",
      "epoch 150: loss=1.1553385257720947\n",
      "epoch 151: loss=1.0750494003295898\n",
      "epoch 152: loss=1.1183679103851318\n",
      "epoch 153: loss=1.1154818534851074\n",
      "epoch 154: loss=1.1089022159576416\n",
      "epoch 155: loss=1.1197011470794678\n",
      "epoch 156: loss=1.1276377439498901\n",
      "epoch 157: loss=1.1403017044067383\n",
      "epoch 158: loss=1.124860405921936\n",
      "epoch 159: loss=1.0942606925964355\n",
      "epoch 160: loss=1.1649956703186035\n",
      "epoch 161: loss=1.1379984617233276\n",
      "epoch 162: loss=1.1130034923553467\n",
      "epoch 163: loss=1.154259204864502\n",
      "epoch 164: loss=1.0957965850830078\n",
      "epoch 165: loss=1.1173348426818848\n",
      "epoch 166: loss=1.1392426490783691\n",
      "epoch 167: loss=1.1087507009506226\n",
      "epoch 168: loss=1.087500810623169\n",
      "epoch 169: loss=1.0908234119415283\n",
      "epoch 170: loss=1.1207998991012573\n",
      "epoch 171: loss=1.107546091079712\n",
      "epoch 172: loss=1.1311922073364258\n",
      "epoch 173: loss=1.1799309253692627\n",
      "epoch 174: loss=1.1353996992111206\n",
      "epoch 175: loss=1.1347839832305908\n",
      "epoch 176: loss=1.1158711910247803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177: loss=1.1165302991867065\n",
      "epoch 178: loss=1.109877347946167\n",
      "epoch 179: loss=1.109308123588562\n",
      "epoch 180: loss=1.1179633140563965\n",
      "epoch 181: loss=1.1344687938690186\n",
      "epoch 182: loss=1.0897938013076782\n",
      "epoch 183: loss=1.098679780960083\n",
      "epoch 184: loss=1.110715389251709\n",
      "epoch 185: loss=1.1026684045791626\n",
      "epoch 186: loss=1.1176291704177856\n",
      "epoch 187: loss=1.1119345426559448\n",
      "epoch 188: loss=1.1007858514785767\n",
      "epoch 189: loss=1.113182544708252\n",
      "epoch 190: loss=1.0918045043945312\n",
      "epoch 191: loss=1.1008247137069702\n",
      "epoch 192: loss=1.104010820388794\n",
      "epoch 193: loss=1.130750060081482\n",
      "epoch 194: loss=1.1037577390670776\n",
      "epoch 195: loss=1.1179769039154053\n",
      "epoch 196: loss=1.098341703414917\n",
      "epoch 197: loss=1.1287176609039307\n",
      "epoch 198: loss=1.1243544816970825\n",
      "epoch 199: loss=1.1295995712280273\n",
      "training patch with 2922 edges\n",
      "epoch 0: loss=6.823473930358887\n",
      "epoch 1: loss=6.760735034942627\n",
      "epoch 2: loss=6.238694667816162\n",
      "epoch 3: loss=6.0727458000183105\n",
      "epoch 4: loss=5.8995585441589355\n",
      "epoch 5: loss=5.758203983306885\n",
      "epoch 6: loss=5.052059173583984\n",
      "epoch 7: loss=4.678208351135254\n",
      "epoch 8: loss=4.363996505737305\n",
      "epoch 9: loss=3.94561767578125\n",
      "epoch 10: loss=3.649073362350464\n",
      "epoch 11: loss=3.4664409160614014\n",
      "epoch 12: loss=3.214765787124634\n",
      "epoch 13: loss=2.849925994873047\n",
      "epoch 14: loss=2.4610769748687744\n",
      "epoch 15: loss=2.233640432357788\n",
      "epoch 16: loss=1.931535243988037\n",
      "epoch 17: loss=1.880998134613037\n",
      "epoch 18: loss=1.7041324377059937\n",
      "epoch 19: loss=1.6608389616012573\n",
      "epoch 20: loss=1.5605934858322144\n",
      "epoch 21: loss=1.5700929164886475\n",
      "epoch 22: loss=1.5039507150650024\n",
      "epoch 23: loss=1.4848480224609375\n",
      "epoch 24: loss=1.4684374332427979\n",
      "epoch 25: loss=1.439279317855835\n",
      "epoch 26: loss=1.426396131515503\n",
      "epoch 27: loss=1.4125057458877563\n",
      "epoch 28: loss=1.4104634523391724\n",
      "epoch 29: loss=1.3959612846374512\n",
      "epoch 30: loss=1.3868075609207153\n",
      "epoch 31: loss=1.3788262605667114\n",
      "epoch 32: loss=1.3598021268844604\n",
      "epoch 33: loss=1.339653491973877\n",
      "epoch 34: loss=1.3309338092803955\n",
      "epoch 35: loss=1.317690134048462\n",
      "epoch 36: loss=1.3029993772506714\n",
      "epoch 37: loss=1.2833362817764282\n",
      "epoch 38: loss=1.258191704750061\n",
      "epoch 39: loss=1.2382960319519043\n",
      "epoch 40: loss=1.2192933559417725\n",
      "epoch 41: loss=1.1984974145889282\n",
      "epoch 42: loss=1.1791119575500488\n",
      "epoch 43: loss=1.1758852005004883\n",
      "epoch 44: loss=1.163538932800293\n",
      "epoch 45: loss=1.124373435974121\n",
      "epoch 46: loss=1.154163122177124\n",
      "epoch 47: loss=1.1420974731445312\n",
      "epoch 48: loss=1.131371021270752\n",
      "epoch 49: loss=1.1324504613876343\n",
      "epoch 50: loss=1.0969467163085938\n",
      "epoch 51: loss=1.0942639112472534\n",
      "epoch 52: loss=1.1039823293685913\n",
      "epoch 53: loss=1.086452603340149\n",
      "epoch 54: loss=1.0632222890853882\n",
      "epoch 55: loss=1.0543146133422852\n",
      "epoch 56: loss=1.0682082176208496\n",
      "epoch 57: loss=1.0553038120269775\n",
      "epoch 58: loss=1.0498888492584229\n",
      "epoch 59: loss=1.0623571872711182\n",
      "epoch 60: loss=1.0570118427276611\n",
      "epoch 61: loss=1.0425605773925781\n",
      "epoch 62: loss=1.0469939708709717\n",
      "epoch 63: loss=1.0290805101394653\n",
      "epoch 64: loss=1.0405426025390625\n",
      "epoch 65: loss=1.0492602586746216\n",
      "epoch 66: loss=1.0365451574325562\n",
      "epoch 67: loss=1.0262584686279297\n",
      "epoch 68: loss=1.007369041442871\n",
      "epoch 69: loss=1.0008642673492432\n",
      "epoch 70: loss=1.0150177478790283\n",
      "epoch 71: loss=1.0067940950393677\n",
      "epoch 72: loss=0.9993504881858826\n",
      "epoch 73: loss=1.0228955745697021\n",
      "epoch 74: loss=1.0105825662612915\n",
      "epoch 75: loss=1.0026781558990479\n",
      "epoch 76: loss=0.9971460700035095\n",
      "epoch 77: loss=0.9891517162322998\n",
      "epoch 78: loss=1.0005574226379395\n",
      "epoch 79: loss=1.0112686157226562\n",
      "epoch 80: loss=1.0118916034698486\n",
      "epoch 81: loss=0.9899581670761108\n",
      "epoch 82: loss=0.9832608699798584\n",
      "epoch 83: loss=0.9866501688957214\n",
      "epoch 84: loss=0.9872241616249084\n",
      "epoch 85: loss=0.9920573830604553\n",
      "epoch 86: loss=0.9895468950271606\n",
      "epoch 87: loss=0.9853246808052063\n",
      "epoch 88: loss=0.9879769086837769\n",
      "epoch 89: loss=0.9836102724075317\n",
      "epoch 90: loss=0.9963692426681519\n",
      "epoch 91: loss=0.9685261249542236\n",
      "epoch 92: loss=0.9870216846466064\n",
      "epoch 93: loss=0.9866625666618347\n",
      "epoch 94: loss=0.9912295341491699\n",
      "epoch 95: loss=0.9752637147903442\n",
      "epoch 96: loss=0.9758355021476746\n",
      "epoch 97: loss=0.989945650100708\n",
      "epoch 98: loss=0.9894633889198303\n",
      "epoch 99: loss=0.9603744149208069\n",
      "epoch 100: loss=0.9839627742767334\n",
      "epoch 101: loss=0.971858024597168\n",
      "epoch 102: loss=0.9620150327682495\n",
      "epoch 103: loss=1.0019949674606323\n",
      "epoch 104: loss=0.9806102514266968\n",
      "epoch 105: loss=0.9845818877220154\n",
      "epoch 106: loss=0.9867261648178101\n",
      "epoch 107: loss=0.9768846035003662\n",
      "epoch 108: loss=0.9755483865737915\n",
      "epoch 109: loss=0.9723824262619019\n",
      "epoch 110: loss=0.9588199853897095\n",
      "epoch 111: loss=0.9803816676139832\n",
      "epoch 112: loss=0.9792272448539734\n",
      "epoch 113: loss=0.986052393913269\n",
      "epoch 114: loss=0.9584811329841614\n",
      "epoch 115: loss=0.9636372923851013\n",
      "epoch 116: loss=0.9731789827346802\n",
      "epoch 117: loss=0.97091144323349\n",
      "epoch 118: loss=0.9644641876220703\n",
      "epoch 119: loss=0.9705794453620911\n",
      "epoch 120: loss=0.9761193990707397\n",
      "epoch 121: loss=0.9578713774681091\n",
      "epoch 122: loss=0.974373459815979\n",
      "epoch 123: loss=0.9694942831993103\n",
      "epoch 124: loss=0.9661409258842468\n",
      "epoch 125: loss=0.9599031805992126\n",
      "epoch 126: loss=0.9833797216415405\n",
      "epoch 127: loss=0.9582639336585999\n",
      "epoch 128: loss=0.9633791446685791\n",
      "epoch 129: loss=0.9604463577270508\n",
      "epoch 130: loss=0.9419392347335815\n",
      "epoch 131: loss=0.9582381844520569\n",
      "epoch 132: loss=0.9571640491485596\n",
      "epoch 133: loss=0.9579702615737915\n",
      "epoch 134: loss=0.9695919156074524\n",
      "epoch 135: loss=0.9697733521461487\n",
      "epoch 136: loss=0.9560692310333252\n",
      "epoch 137: loss=0.9567052125930786\n",
      "epoch 138: loss=0.9300063848495483\n",
      "epoch 139: loss=0.9536809325218201\n",
      "epoch 140: loss=0.95885169506073\n",
      "epoch 141: loss=0.9647567272186279\n",
      "epoch 142: loss=0.9430327415466309\n",
      "epoch 143: loss=0.9533657431602478\n",
      "epoch 144: loss=0.9497522711753845\n",
      "epoch 145: loss=0.9737345576286316\n",
      "epoch 146: loss=0.9619478583335876\n",
      "epoch 147: loss=0.9551692008972168\n",
      "epoch 148: loss=0.9499887228012085\n",
      "epoch 149: loss=0.9622796773910522\n",
      "epoch 150: loss=0.9588515758514404\n",
      "epoch 151: loss=0.9452852606773376\n",
      "epoch 152: loss=0.955962598323822\n",
      "epoch 153: loss=0.9681829810142517\n",
      "epoch 154: loss=0.940829873085022\n",
      "epoch 155: loss=0.939898669719696\n",
      "epoch 156: loss=0.9383288621902466\n",
      "epoch 157: loss=0.9561710953712463\n",
      "epoch 158: loss=0.9450133442878723\n",
      "epoch 159: loss=0.9651873707771301\n",
      "epoch 160: loss=0.958787202835083\n",
      "epoch 161: loss=0.9368842244148254\n",
      "epoch 162: loss=0.956147313117981\n",
      "epoch 163: loss=0.9516519904136658\n",
      "epoch 164: loss=0.9313348531723022\n",
      "epoch 165: loss=0.9508948922157288\n",
      "epoch 166: loss=0.9638844132423401\n",
      "epoch 167: loss=0.9659060835838318\n",
      "epoch 168: loss=0.9419375658035278\n",
      "epoch 169: loss=0.9382742047309875\n",
      "epoch 170: loss=0.9425210952758789\n",
      "epoch 171: loss=0.9510146379470825\n",
      "epoch 172: loss=0.957115888595581\n",
      "epoch 173: loss=0.9353736042976379\n",
      "epoch 174: loss=0.9556432366371155\n",
      "epoch 175: loss=0.9543455839157104\n",
      "epoch 176: loss=0.9564576745033264\n",
      "epoch 177: loss=0.9497790336608887\n",
      "epoch 178: loss=0.9440873861312866\n",
      "epoch 179: loss=0.9357312917709351\n",
      "epoch 180: loss=0.9352319240570068\n",
      "epoch 181: loss=0.9442439079284668\n",
      "epoch 182: loss=0.9485992789268494\n",
      "epoch 183: loss=0.9422211647033691\n",
      "epoch 184: loss=0.9356143474578857\n",
      "epoch 185: loss=0.9375937581062317\n",
      "epoch 186: loss=0.9357913136482239\n",
      "epoch 187: loss=0.9409334659576416\n",
      "epoch 188: loss=0.9474495649337769\n",
      "epoch 189: loss=0.9371929168701172\n",
      "epoch 190: loss=0.9469805955886841\n",
      "epoch 191: loss=0.9464585781097412\n",
      "epoch 192: loss=0.9302263259887695\n",
      "epoch 193: loss=0.9442554712295532\n",
      "epoch 194: loss=0.9223842620849609\n",
      "epoch 195: loss=0.9304372072219849\n",
      "epoch 196: loss=0.951344907283783\n",
      "epoch 197: loss=0.9643762707710266\n",
      "epoch 198: loss=0.9587310552597046\n",
      "epoch 199: loss=0.9392123222351074\n",
      "training patch with 1698 edges\n",
      "epoch 0: loss=6.7017741203308105\n",
      "epoch 1: loss=6.799108982086182\n",
      "epoch 2: loss=6.307352542877197\n",
      "epoch 3: loss=5.626965522766113\n",
      "epoch 4: loss=5.436591625213623\n",
      "epoch 5: loss=5.111266613006592\n",
      "epoch 6: loss=4.80719518661499\n",
      "epoch 7: loss=4.366796016693115\n",
      "epoch 8: loss=4.102992534637451\n",
      "epoch 9: loss=3.717928886413574\n",
      "epoch 10: loss=3.2915139198303223\n",
      "epoch 11: loss=2.858384132385254\n",
      "epoch 12: loss=2.6334927082061768\n",
      "epoch 13: loss=2.1624298095703125\n",
      "epoch 14: loss=2.0355753898620605\n",
      "epoch 15: loss=1.828777551651001\n",
      "epoch 16: loss=1.7401231527328491\n",
      "epoch 17: loss=1.6821894645690918\n",
      "epoch 18: loss=1.6272162199020386\n",
      "epoch 19: loss=1.6138191223144531\n",
      "epoch 20: loss=1.5779176950454712\n",
      "epoch 21: loss=1.5441501140594482\n",
      "epoch 22: loss=1.534947395324707\n",
      "epoch 23: loss=1.55960214138031\n",
      "epoch 24: loss=1.5254944562911987\n",
      "epoch 25: loss=1.5224277973175049\n",
      "epoch 26: loss=1.527022361755371\n",
      "epoch 27: loss=1.5140111446380615\n",
      "epoch 28: loss=1.5138508081436157\n",
      "epoch 29: loss=1.5125349760055542\n",
      "epoch 30: loss=1.4791529178619385\n",
      "epoch 31: loss=1.4771924018859863\n",
      "epoch 32: loss=1.4608922004699707\n",
      "epoch 33: loss=1.4517886638641357\n",
      "epoch 34: loss=1.432131052017212\n",
      "epoch 35: loss=1.4208208322525024\n",
      "epoch 36: loss=1.3947325944900513\n",
      "epoch 37: loss=1.3667618036270142\n",
      "epoch 38: loss=1.3376426696777344\n",
      "epoch 39: loss=1.315568208694458\n",
      "epoch 40: loss=1.2946568727493286\n",
      "epoch 41: loss=1.281530499458313\n",
      "epoch 42: loss=1.2948217391967773\n",
      "epoch 43: loss=1.2683751583099365\n",
      "epoch 44: loss=1.257081151008606\n",
      "epoch 45: loss=1.2307955026626587\n",
      "epoch 46: loss=1.2623380422592163\n",
      "epoch 47: loss=1.228811264038086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48: loss=1.21869695186615\n",
      "epoch 49: loss=1.2047913074493408\n",
      "epoch 50: loss=1.1707744598388672\n",
      "epoch 51: loss=1.167733073234558\n",
      "epoch 52: loss=1.1632018089294434\n",
      "epoch 53: loss=1.1546157598495483\n",
      "epoch 54: loss=1.1408493518829346\n",
      "epoch 55: loss=1.1701198816299438\n",
      "epoch 56: loss=1.1449499130249023\n",
      "epoch 57: loss=1.1493334770202637\n",
      "epoch 58: loss=1.1350032091140747\n",
      "epoch 59: loss=1.1399586200714111\n",
      "epoch 60: loss=1.1452066898345947\n",
      "epoch 61: loss=1.1362872123718262\n",
      "epoch 62: loss=1.1049777269363403\n",
      "epoch 63: loss=1.138599157333374\n",
      "epoch 64: loss=1.0931882858276367\n",
      "epoch 65: loss=1.1003856658935547\n",
      "epoch 66: loss=1.1006190776824951\n",
      "epoch 67: loss=1.1058968305587769\n",
      "epoch 68: loss=1.0914130210876465\n",
      "epoch 69: loss=1.0806572437286377\n",
      "epoch 70: loss=1.0896657705307007\n",
      "epoch 71: loss=1.0942270755767822\n",
      "epoch 72: loss=1.045286774635315\n",
      "epoch 73: loss=1.0839908123016357\n",
      "epoch 74: loss=1.0768260955810547\n",
      "epoch 75: loss=1.0642024278640747\n",
      "epoch 76: loss=1.068041205406189\n",
      "epoch 77: loss=1.0739504098892212\n",
      "epoch 78: loss=1.0759398937225342\n",
      "epoch 79: loss=1.0743560791015625\n",
      "epoch 80: loss=1.0912007093429565\n",
      "epoch 81: loss=1.0613130331039429\n",
      "epoch 82: loss=1.0545779466629028\n",
      "epoch 83: loss=1.086051106452942\n",
      "epoch 84: loss=1.0759341716766357\n",
      "epoch 85: loss=1.0484168529510498\n",
      "epoch 86: loss=1.0834242105484009\n",
      "epoch 87: loss=1.0481661558151245\n",
      "epoch 88: loss=1.0691627264022827\n",
      "epoch 89: loss=1.0587923526763916\n",
      "epoch 90: loss=1.091991662979126\n",
      "epoch 91: loss=1.0805813074111938\n",
      "epoch 92: loss=1.0531954765319824\n",
      "epoch 93: loss=1.052156686782837\n",
      "epoch 94: loss=1.0394294261932373\n",
      "epoch 95: loss=1.0439125299453735\n",
      "epoch 96: loss=1.0707578659057617\n",
      "epoch 97: loss=1.0648353099822998\n",
      "epoch 98: loss=1.056384563446045\n",
      "epoch 99: loss=1.056839942932129\n",
      "epoch 100: loss=1.0795438289642334\n",
      "epoch 101: loss=1.0602234601974487\n",
      "epoch 102: loss=1.096449851989746\n",
      "epoch 103: loss=1.0721796751022339\n",
      "epoch 104: loss=1.0344667434692383\n",
      "epoch 105: loss=1.0510122776031494\n",
      "epoch 106: loss=1.049299716949463\n",
      "epoch 107: loss=1.0480523109436035\n",
      "epoch 108: loss=1.081488847732544\n",
      "epoch 109: loss=1.0274237394332886\n",
      "epoch 110: loss=1.067460060119629\n",
      "epoch 111: loss=1.04273521900177\n",
      "epoch 112: loss=1.0520298480987549\n",
      "epoch 113: loss=1.026078462600708\n",
      "epoch 114: loss=1.0402722358703613\n",
      "epoch 115: loss=1.0475504398345947\n",
      "epoch 116: loss=1.037474274635315\n",
      "epoch 117: loss=1.0183017253875732\n",
      "epoch 118: loss=1.0796890258789062\n",
      "epoch 119: loss=1.0350470542907715\n",
      "epoch 120: loss=1.0069416761398315\n",
      "epoch 121: loss=1.0486259460449219\n",
      "epoch 122: loss=1.044396162033081\n",
      "epoch 123: loss=1.0567256212234497\n",
      "epoch 124: loss=1.0393414497375488\n",
      "epoch 125: loss=1.06389582157135\n",
      "epoch 126: loss=1.0325102806091309\n",
      "epoch 127: loss=1.0268518924713135\n",
      "epoch 128: loss=1.02057945728302\n",
      "epoch 129: loss=1.025740385055542\n",
      "epoch 130: loss=1.0286909341812134\n",
      "epoch 131: loss=1.013134241104126\n",
      "epoch 132: loss=1.0113400220870972\n",
      "epoch 133: loss=1.0418140888214111\n",
      "epoch 134: loss=1.050644874572754\n",
      "epoch 135: loss=1.005780816078186\n",
      "epoch 136: loss=1.022440791130066\n",
      "epoch 137: loss=1.0321049690246582\n",
      "epoch 138: loss=1.0387176275253296\n",
      "epoch 139: loss=1.0114468336105347\n",
      "epoch 140: loss=1.047266960144043\n",
      "epoch 141: loss=1.0340912342071533\n",
      "epoch 142: loss=1.000239610671997\n",
      "epoch 143: loss=1.0470094680786133\n",
      "epoch 144: loss=1.0386745929718018\n",
      "epoch 145: loss=1.0190361738204956\n",
      "epoch 146: loss=1.0368562936782837\n",
      "epoch 147: loss=1.0325886011123657\n",
      "epoch 148: loss=1.0553094148635864\n",
      "epoch 149: loss=1.0446631908416748\n",
      "epoch 150: loss=1.0349702835083008\n",
      "epoch 151: loss=1.0092957019805908\n",
      "epoch 152: loss=1.0503475666046143\n",
      "epoch 153: loss=1.011138916015625\n",
      "epoch 154: loss=1.0076181888580322\n",
      "epoch 155: loss=1.0030186176300049\n",
      "epoch 156: loss=1.0343513488769531\n",
      "epoch 157: loss=1.0111604928970337\n",
      "epoch 158: loss=1.0110185146331787\n",
      "epoch 159: loss=1.0184965133666992\n",
      "epoch 160: loss=1.0177481174468994\n",
      "epoch 161: loss=1.0558205842971802\n",
      "epoch 162: loss=1.0144541263580322\n",
      "epoch 163: loss=1.030003547668457\n",
      "epoch 164: loss=1.000321626663208\n",
      "epoch 165: loss=1.0004301071166992\n",
      "epoch 166: loss=1.0169391632080078\n",
      "epoch 167: loss=1.0031635761260986\n",
      "epoch 168: loss=1.0160396099090576\n",
      "epoch 169: loss=1.0203386545181274\n",
      "epoch 170: loss=1.039595603942871\n",
      "epoch 171: loss=1.0329959392547607\n",
      "epoch 172: loss=1.0130259990692139\n",
      "epoch 173: loss=1.0160859823226929\n",
      "epoch 174: loss=1.0030757188796997\n",
      "epoch 175: loss=0.9927015900611877\n",
      "epoch 176: loss=1.0050973892211914\n",
      "epoch 177: loss=1.043563723564148\n",
      "epoch 178: loss=1.0130724906921387\n",
      "epoch 179: loss=1.0069793462753296\n",
      "epoch 180: loss=1.0550310611724854\n",
      "epoch 181: loss=1.0213263034820557\n",
      "epoch 182: loss=1.0162502527236938\n",
      "epoch 183: loss=1.0295817852020264\n",
      "epoch 184: loss=1.0040433406829834\n",
      "epoch 185: loss=0.9982080459594727\n",
      "epoch 186: loss=0.9938089847564697\n",
      "epoch 187: loss=0.9976279735565186\n",
      "epoch 188: loss=1.0012049674987793\n",
      "epoch 189: loss=1.0125561952590942\n",
      "epoch 190: loss=1.0285629034042358\n",
      "epoch 191: loss=1.011754035949707\n",
      "epoch 192: loss=1.0235693454742432\n",
      "epoch 193: loss=1.000222086906433\n",
      "epoch 194: loss=0.9941863417625427\n",
      "epoch 195: loss=1.0083026885986328\n",
      "epoch 196: loss=1.0139963626861572\n",
      "epoch 197: loss=0.9946928024291992\n",
      "epoch 198: loss=1.003052830696106\n",
      "epoch 199: loss=1.0130054950714111\n",
      "training patch with 670 edges\n",
      "epoch 0: loss=6.772058010101318\n",
      "epoch 1: loss=5.950711250305176\n",
      "epoch 2: loss=6.215697765350342\n",
      "epoch 3: loss=6.438940048217773\n",
      "epoch 4: loss=5.399720191955566\n",
      "epoch 5: loss=6.053067207336426\n",
      "epoch 6: loss=5.068432331085205\n",
      "epoch 7: loss=4.350454807281494\n",
      "epoch 8: loss=4.192984104156494\n",
      "epoch 9: loss=3.7958967685699463\n",
      "epoch 10: loss=3.6932296752929688\n",
      "epoch 11: loss=2.995676279067993\n",
      "epoch 12: loss=2.8931870460510254\n",
      "epoch 13: loss=2.5111067295074463\n",
      "epoch 14: loss=2.2792856693267822\n",
      "epoch 15: loss=2.043674945831299\n",
      "epoch 16: loss=1.88765549659729\n",
      "epoch 17: loss=1.8031772375106812\n",
      "epoch 18: loss=1.690688133239746\n",
      "epoch 19: loss=1.6920502185821533\n",
      "epoch 20: loss=1.7266937494277954\n",
      "epoch 21: loss=1.7403231859207153\n",
      "epoch 22: loss=1.7573752403259277\n",
      "epoch 23: loss=1.6980030536651611\n",
      "epoch 24: loss=1.6733729839324951\n",
      "epoch 25: loss=1.692939281463623\n",
      "epoch 26: loss=1.6954388618469238\n",
      "epoch 27: loss=1.6859283447265625\n",
      "epoch 28: loss=1.7022875547409058\n",
      "epoch 29: loss=1.6829755306243896\n",
      "epoch 30: loss=1.680083155632019\n",
      "epoch 31: loss=1.6589058637619019\n",
      "epoch 32: loss=1.6479369401931763\n",
      "epoch 33: loss=1.6238527297973633\n",
      "epoch 34: loss=1.6274842023849487\n",
      "epoch 35: loss=1.6249271631240845\n",
      "epoch 36: loss=1.5879037380218506\n",
      "epoch 37: loss=1.549332618713379\n",
      "epoch 38: loss=1.5085102319717407\n",
      "epoch 39: loss=1.48272705078125\n",
      "epoch 40: loss=1.494347333908081\n",
      "epoch 41: loss=1.509725570678711\n",
      "epoch 42: loss=1.4578726291656494\n",
      "epoch 43: loss=1.400612473487854\n",
      "epoch 44: loss=1.3803194761276245\n",
      "epoch 45: loss=1.4049568176269531\n",
      "epoch 46: loss=1.3946778774261475\n",
      "epoch 47: loss=1.3753893375396729\n",
      "epoch 48: loss=1.3599426746368408\n",
      "epoch 49: loss=1.3952988386154175\n",
      "epoch 50: loss=1.3945417404174805\n",
      "epoch 51: loss=1.3604286909103394\n",
      "epoch 52: loss=1.343738079071045\n",
      "epoch 53: loss=1.3282514810562134\n",
      "epoch 54: loss=1.3065204620361328\n",
      "epoch 55: loss=1.2407225370407104\n",
      "epoch 56: loss=1.2776339054107666\n",
      "epoch 57: loss=1.283029317855835\n",
      "epoch 58: loss=1.3587968349456787\n",
      "epoch 59: loss=1.298027515411377\n",
      "epoch 60: loss=1.3041421175003052\n",
      "epoch 61: loss=1.2803528308868408\n",
      "epoch 62: loss=1.2411915063858032\n",
      "epoch 63: loss=1.248496413230896\n",
      "epoch 64: loss=1.3111155033111572\n",
      "epoch 65: loss=1.2724360227584839\n",
      "epoch 66: loss=1.3113532066345215\n",
      "epoch 67: loss=1.2966320514678955\n",
      "epoch 68: loss=1.2687034606933594\n",
      "epoch 69: loss=1.2230781316757202\n",
      "epoch 70: loss=1.2724782228469849\n",
      "epoch 71: loss=1.2493125200271606\n",
      "epoch 72: loss=1.3591831922531128\n",
      "epoch 73: loss=1.3139731884002686\n",
      "epoch 74: loss=1.2565324306488037\n",
      "epoch 75: loss=1.2864419221878052\n",
      "epoch 76: loss=1.290893793106079\n",
      "epoch 77: loss=1.2629703283309937\n",
      "epoch 78: loss=1.2921756505966187\n",
      "epoch 79: loss=1.2993030548095703\n",
      "epoch 80: loss=1.2695680856704712\n",
      "epoch 81: loss=1.3545033931732178\n",
      "epoch 82: loss=1.266086459159851\n",
      "epoch 83: loss=1.2943284511566162\n",
      "epoch 84: loss=1.264941692352295\n",
      "epoch 85: loss=1.255662441253662\n",
      "epoch 86: loss=1.3068809509277344\n",
      "epoch 87: loss=1.2785111665725708\n",
      "epoch 88: loss=1.2483900785446167\n",
      "epoch 89: loss=1.2874261140823364\n",
      "epoch 90: loss=1.2332041263580322\n",
      "epoch 91: loss=1.2284390926361084\n",
      "epoch 92: loss=1.2783653736114502\n",
      "epoch 93: loss=1.2680152654647827\n",
      "epoch 94: loss=1.2181265354156494\n",
      "epoch 95: loss=1.2338881492614746\n",
      "epoch 96: loss=1.2198771238327026\n",
      "epoch 97: loss=1.230824589729309\n",
      "epoch 98: loss=1.1654961109161377\n",
      "epoch 99: loss=1.2320144176483154\n",
      "epoch 100: loss=1.1929806470870972\n",
      "epoch 101: loss=1.223399043083191\n",
      "epoch 102: loss=1.1731364727020264\n",
      "epoch 103: loss=1.2226195335388184\n",
      "epoch 104: loss=1.1889901161193848\n",
      "epoch 105: loss=1.1950931549072266\n",
      "epoch 106: loss=1.2935669422149658\n",
      "epoch 107: loss=1.2753294706344604\n",
      "epoch 108: loss=1.2118536233901978\n",
      "epoch 109: loss=1.2191669940948486\n",
      "epoch 110: loss=1.211575984954834\n",
      "epoch 111: loss=1.2170854806900024\n",
      "epoch 112: loss=1.2351936101913452\n",
      "epoch 113: loss=1.2466260194778442\n",
      "epoch 114: loss=1.2875341176986694\n",
      "epoch 115: loss=1.294418454170227\n",
      "epoch 116: loss=1.2093751430511475\n",
      "epoch 117: loss=1.1919218301773071\n",
      "epoch 118: loss=1.2551567554473877\n",
      "epoch 119: loss=1.1980926990509033\n",
      "epoch 120: loss=1.2250947952270508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 121: loss=1.2342092990875244\n",
      "epoch 122: loss=1.189674973487854\n",
      "epoch 123: loss=1.2250723838806152\n",
      "epoch 124: loss=1.1955580711364746\n",
      "epoch 125: loss=1.2441906929016113\n",
      "epoch 126: loss=1.2141213417053223\n",
      "epoch 127: loss=1.2534321546554565\n",
      "epoch 128: loss=1.1915837526321411\n",
      "epoch 129: loss=1.2339792251586914\n",
      "epoch 130: loss=1.1794514656066895\n",
      "epoch 131: loss=1.2072807550430298\n",
      "epoch 132: loss=1.2209501266479492\n",
      "epoch 133: loss=1.197981834411621\n",
      "epoch 134: loss=1.1917954683303833\n",
      "epoch 135: loss=1.1874618530273438\n",
      "epoch 136: loss=1.2153669595718384\n",
      "epoch 137: loss=1.2464771270751953\n",
      "epoch 138: loss=1.186665415763855\n",
      "epoch 139: loss=1.1684730052947998\n",
      "epoch 140: loss=1.2080515623092651\n",
      "epoch 141: loss=1.2251094579696655\n",
      "epoch 142: loss=1.1985770463943481\n",
      "epoch 143: loss=1.1765403747558594\n",
      "epoch 144: loss=1.194018840789795\n",
      "epoch 145: loss=1.183855414390564\n",
      "epoch 146: loss=1.2453804016113281\n",
      "epoch 147: loss=1.2283762693405151\n",
      "epoch 148: loss=1.1963034868240356\n",
      "epoch 149: loss=1.1746797561645508\n",
      "epoch 150: loss=1.2284830808639526\n",
      "epoch 151: loss=1.1957796812057495\n",
      "epoch 152: loss=1.1811882257461548\n",
      "epoch 153: loss=1.2448712587356567\n",
      "epoch 154: loss=1.1932358741760254\n",
      "epoch 155: loss=1.1861357688903809\n",
      "epoch 156: loss=1.1774406433105469\n",
      "epoch 157: loss=1.2094783782958984\n",
      "epoch 158: loss=1.1858575344085693\n",
      "epoch 159: loss=1.2070167064666748\n",
      "epoch 160: loss=1.1985210180282593\n",
      "epoch 161: loss=1.245308756828308\n",
      "epoch 162: loss=1.189316987991333\n",
      "epoch 163: loss=1.176934003829956\n",
      "epoch 164: loss=1.1691489219665527\n",
      "epoch 165: loss=1.2158746719360352\n",
      "epoch 166: loss=1.2365593910217285\n",
      "epoch 167: loss=1.2678511142730713\n",
      "epoch 168: loss=1.2058892250061035\n",
      "epoch 169: loss=1.2008713483810425\n",
      "epoch 170: loss=1.1972057819366455\n",
      "epoch 171: loss=1.192861795425415\n",
      "epoch 172: loss=1.2018402814865112\n",
      "epoch 173: loss=1.1897822618484497\n",
      "epoch 174: loss=1.2049198150634766\n",
      "epoch 175: loss=1.1489282846450806\n",
      "epoch 176: loss=1.1298201084136963\n",
      "epoch 177: loss=1.1816139221191406\n",
      "epoch 178: loss=1.1676057577133179\n",
      "epoch 179: loss=1.161476492881775\n",
      "epoch 180: loss=1.1925320625305176\n",
      "epoch 181: loss=1.210158348083496\n",
      "epoch 182: loss=1.1607975959777832\n",
      "epoch 183: loss=1.2069368362426758\n",
      "epoch 184: loss=1.1876198053359985\n",
      "epoch 185: loss=1.1930656433105469\n",
      "epoch 186: loss=1.1445636749267578\n",
      "epoch 187: loss=1.1814838647842407\n",
      "epoch 188: loss=1.1514723300933838\n",
      "epoch 189: loss=1.2371909618377686\n",
      "epoch 190: loss=1.1869432926177979\n",
      "epoch 191: loss=1.1594932079315186\n",
      "epoch 192: loss=1.221347689628601\n",
      "epoch 193: loss=1.157138466835022\n",
      "epoch 194: loss=1.1552871465682983\n",
      "epoch 195: loss=1.1881568431854248\n",
      "epoch 196: loss=1.169779658317566\n",
      "epoch 197: loss=1.173262357711792\n",
      "epoch 198: loss=1.222291350364685\n",
      "epoch 199: loss=1.2131626605987549\n",
      "training patch with 1602 edges\n",
      "epoch 0: loss=6.78585147857666\n",
      "epoch 1: loss=6.619243144989014\n",
      "epoch 2: loss=6.29556131362915\n",
      "epoch 3: loss=6.231899261474609\n",
      "epoch 4: loss=5.421162128448486\n",
      "epoch 5: loss=4.966087341308594\n",
      "epoch 6: loss=4.718679904937744\n",
      "epoch 7: loss=4.2744855880737305\n",
      "epoch 8: loss=3.9297127723693848\n",
      "epoch 9: loss=3.658165693283081\n",
      "epoch 10: loss=3.2200441360473633\n",
      "epoch 11: loss=2.760892152786255\n",
      "epoch 12: loss=2.5692498683929443\n",
      "epoch 13: loss=2.2484893798828125\n",
      "epoch 14: loss=2.013392925262451\n",
      "epoch 15: loss=1.8541693687438965\n",
      "epoch 16: loss=1.656467080116272\n",
      "epoch 17: loss=1.657560110092163\n",
      "epoch 18: loss=1.6287879943847656\n",
      "epoch 19: loss=1.5507967472076416\n",
      "epoch 20: loss=1.591788649559021\n",
      "epoch 21: loss=1.5296224355697632\n",
      "epoch 22: loss=1.5161020755767822\n",
      "epoch 23: loss=1.5278929471969604\n",
      "epoch 24: loss=1.519861102104187\n",
      "epoch 25: loss=1.5034239292144775\n",
      "epoch 26: loss=1.5340864658355713\n",
      "epoch 27: loss=1.509709119796753\n",
      "epoch 28: loss=1.501882553100586\n",
      "epoch 29: loss=1.4869132041931152\n",
      "epoch 30: loss=1.4805141687393188\n",
      "epoch 31: loss=1.4681222438812256\n",
      "epoch 32: loss=1.4576454162597656\n",
      "epoch 33: loss=1.4483723640441895\n",
      "epoch 34: loss=1.446418285369873\n",
      "epoch 35: loss=1.425306797027588\n",
      "epoch 36: loss=1.3945451974868774\n",
      "epoch 37: loss=1.3716212511062622\n",
      "epoch 38: loss=1.3518754243850708\n",
      "epoch 39: loss=1.3430507183074951\n",
      "epoch 40: loss=1.2986559867858887\n",
      "epoch 41: loss=1.2735096216201782\n",
      "epoch 42: loss=1.2427842617034912\n",
      "epoch 43: loss=1.233005404472351\n",
      "epoch 44: loss=1.225269079208374\n",
      "epoch 45: loss=1.1995677947998047\n",
      "epoch 46: loss=1.1821799278259277\n",
      "epoch 47: loss=1.1914817094802856\n",
      "epoch 48: loss=1.187330961227417\n",
      "epoch 49: loss=1.171550989151001\n",
      "epoch 50: loss=1.1495448350906372\n",
      "epoch 51: loss=1.175640344619751\n",
      "epoch 52: loss=1.1310782432556152\n",
      "epoch 53: loss=1.1595866680145264\n",
      "epoch 54: loss=1.134130597114563\n",
      "epoch 55: loss=1.1374726295471191\n",
      "epoch 56: loss=1.1247546672821045\n",
      "epoch 57: loss=1.1027753353118896\n",
      "epoch 58: loss=1.1182063817977905\n",
      "epoch 59: loss=1.1085023880004883\n",
      "epoch 60: loss=1.1021991968154907\n",
      "epoch 61: loss=1.1019814014434814\n",
      "epoch 62: loss=1.0801535844802856\n",
      "epoch 63: loss=1.0934686660766602\n",
      "epoch 64: loss=1.0934629440307617\n",
      "epoch 65: loss=1.063989281654358\n",
      "epoch 66: loss=1.077439785003662\n",
      "epoch 67: loss=1.075840950012207\n",
      "epoch 68: loss=1.0721405744552612\n",
      "epoch 69: loss=1.0810929536819458\n",
      "epoch 70: loss=1.0756257772445679\n",
      "epoch 71: loss=1.0854239463806152\n",
      "epoch 72: loss=1.0536489486694336\n",
      "epoch 73: loss=1.0647958517074585\n",
      "epoch 74: loss=1.0700613260269165\n",
      "epoch 75: loss=1.0476295948028564\n",
      "epoch 76: loss=1.0645228624343872\n",
      "epoch 77: loss=1.0701210498809814\n",
      "epoch 78: loss=1.0680549144744873\n",
      "epoch 79: loss=1.0596731901168823\n",
      "epoch 80: loss=1.055551290512085\n",
      "epoch 81: loss=1.0445082187652588\n",
      "epoch 82: loss=1.0521340370178223\n",
      "epoch 83: loss=1.057266354560852\n",
      "epoch 84: loss=1.068158507347107\n",
      "epoch 85: loss=1.0647423267364502\n",
      "epoch 86: loss=1.036064624786377\n",
      "epoch 87: loss=1.0325771570205688\n",
      "epoch 88: loss=1.047603726387024\n",
      "epoch 89: loss=1.0316053628921509\n",
      "epoch 90: loss=1.039474368095398\n",
      "epoch 91: loss=1.0205111503601074\n",
      "epoch 92: loss=1.0181204080581665\n",
      "epoch 93: loss=1.0339391231536865\n",
      "epoch 94: loss=1.045027256011963\n",
      "epoch 95: loss=1.0355947017669678\n",
      "epoch 96: loss=1.0307735204696655\n",
      "epoch 97: loss=1.0377297401428223\n",
      "epoch 98: loss=1.0357550382614136\n",
      "epoch 99: loss=1.0224822759628296\n",
      "epoch 100: loss=1.0188058614730835\n",
      "epoch 101: loss=1.0200209617614746\n",
      "epoch 102: loss=1.0566082000732422\n",
      "epoch 103: loss=1.0358858108520508\n",
      "epoch 104: loss=1.0711946487426758\n",
      "epoch 105: loss=1.0298559665679932\n",
      "epoch 106: loss=1.0494304895401\n",
      "epoch 107: loss=1.0296858549118042\n",
      "epoch 108: loss=1.0399463176727295\n",
      "epoch 109: loss=1.0310267210006714\n",
      "epoch 110: loss=1.0369995832443237\n",
      "epoch 111: loss=1.0465898513793945\n",
      "epoch 112: loss=1.0395636558532715\n",
      "epoch 113: loss=1.0544183254241943\n",
      "epoch 114: loss=1.0289041996002197\n",
      "epoch 115: loss=1.0066938400268555\n",
      "epoch 116: loss=1.0291239023208618\n",
      "epoch 117: loss=1.0447450876235962\n",
      "epoch 118: loss=1.0151317119598389\n",
      "epoch 119: loss=1.0055668354034424\n",
      "epoch 120: loss=1.0134460926055908\n",
      "epoch 121: loss=1.0318983793258667\n",
      "epoch 122: loss=1.0156855583190918\n",
      "epoch 123: loss=1.0211446285247803\n",
      "epoch 124: loss=1.0208946466445923\n",
      "epoch 125: loss=1.025286316871643\n",
      "epoch 126: loss=1.025997281074524\n",
      "epoch 127: loss=1.0543478727340698\n",
      "epoch 128: loss=1.0163168907165527\n",
      "epoch 129: loss=1.0161155462265015\n",
      "epoch 130: loss=1.015712857246399\n",
      "epoch 131: loss=1.0465830564498901\n",
      "epoch 132: loss=1.0256125926971436\n",
      "epoch 133: loss=1.0228098630905151\n",
      "epoch 134: loss=1.0491667985916138\n",
      "epoch 135: loss=1.0193699598312378\n",
      "epoch 136: loss=1.0113651752471924\n",
      "epoch 137: loss=0.9995630979537964\n",
      "epoch 138: loss=1.0315335988998413\n",
      "epoch 139: loss=1.032120943069458\n",
      "epoch 140: loss=1.0493990182876587\n",
      "epoch 141: loss=1.0346717834472656\n",
      "epoch 142: loss=1.0701125860214233\n",
      "epoch 143: loss=1.0223435163497925\n",
      "epoch 144: loss=1.0054627656936646\n",
      "epoch 145: loss=1.0073587894439697\n",
      "epoch 146: loss=1.0282680988311768\n",
      "epoch 147: loss=0.9892816543579102\n",
      "epoch 148: loss=0.9917269945144653\n",
      "epoch 149: loss=1.0215739011764526\n",
      "epoch 150: loss=1.0372107028961182\n",
      "epoch 151: loss=1.0122214555740356\n",
      "epoch 152: loss=1.0254521369934082\n",
      "epoch 153: loss=1.0260493755340576\n",
      "epoch 154: loss=1.0119996070861816\n",
      "epoch 155: loss=1.0184342861175537\n",
      "epoch 156: loss=1.0292909145355225\n",
      "epoch 157: loss=1.012264609336853\n",
      "epoch 158: loss=1.0420632362365723\n",
      "epoch 159: loss=1.024191975593567\n",
      "epoch 160: loss=1.0297558307647705\n",
      "epoch 161: loss=1.0183368921279907\n",
      "epoch 162: loss=1.0013349056243896\n",
      "epoch 163: loss=0.9779562950134277\n",
      "epoch 164: loss=1.0024458169937134\n",
      "epoch 165: loss=0.9909254908561707\n",
      "epoch 166: loss=0.9774909019470215\n",
      "epoch 167: loss=1.0037143230438232\n",
      "epoch 168: loss=1.0010249614715576\n",
      "epoch 169: loss=1.0106124877929688\n",
      "epoch 170: loss=0.9910200834274292\n",
      "epoch 171: loss=1.0031461715698242\n",
      "epoch 172: loss=1.000797152519226\n",
      "epoch 173: loss=1.0043495893478394\n",
      "epoch 174: loss=1.0140140056610107\n",
      "epoch 175: loss=0.9891937971115112\n",
      "epoch 176: loss=1.0387603044509888\n",
      "epoch 177: loss=1.0023949146270752\n",
      "epoch 178: loss=0.9939253330230713\n",
      "epoch 179: loss=0.9966778755187988\n",
      "epoch 180: loss=1.0056958198547363\n",
      "epoch 181: loss=1.0098308324813843\n",
      "epoch 182: loss=1.0074036121368408\n",
      "epoch 183: loss=1.0242846012115479\n",
      "epoch 184: loss=0.9941668510437012\n",
      "epoch 185: loss=1.0066379308700562\n",
      "epoch 186: loss=1.0063501596450806\n",
      "epoch 187: loss=1.0030320882797241\n",
      "epoch 188: loss=1.0312265157699585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189: loss=0.9838104248046875\n",
      "epoch 190: loss=1.0044057369232178\n",
      "epoch 191: loss=1.006929874420166\n",
      "epoch 192: loss=1.0233159065246582\n",
      "epoch 193: loss=1.017153263092041\n",
      "epoch 194: loss=0.9939295053482056\n",
      "epoch 195: loss=1.0151994228363037\n",
      "epoch 196: loss=0.9835689663887024\n",
      "epoch 197: loss=1.0041615962982178\n",
      "epoch 198: loss=1.0026915073394775\n",
      "epoch 199: loss=0.997859001159668\n",
      "training patch with 1800 edges\n",
      "epoch 0: loss=6.888447284698486\n",
      "epoch 1: loss=6.700713157653809\n",
      "epoch 2: loss=6.462304592132568\n",
      "epoch 3: loss=5.906325817108154\n",
      "epoch 4: loss=5.463725566864014\n",
      "epoch 5: loss=5.2576494216918945\n",
      "epoch 6: loss=4.847644805908203\n",
      "epoch 7: loss=4.627277374267578\n",
      "epoch 8: loss=3.978670597076416\n",
      "epoch 9: loss=3.5190494060516357\n",
      "epoch 10: loss=3.385509490966797\n",
      "epoch 11: loss=2.884932279586792\n",
      "epoch 12: loss=2.6462674140930176\n",
      "epoch 13: loss=2.3730273246765137\n",
      "epoch 14: loss=2.099102020263672\n",
      "epoch 15: loss=1.9242634773254395\n",
      "epoch 16: loss=1.7726892232894897\n",
      "epoch 17: loss=1.6619168519973755\n",
      "epoch 18: loss=1.6440399885177612\n",
      "epoch 19: loss=1.6134635210037231\n",
      "epoch 20: loss=1.5988125801086426\n",
      "epoch 21: loss=1.5555264949798584\n",
      "epoch 22: loss=1.5561809539794922\n",
      "epoch 23: loss=1.5152177810668945\n",
      "epoch 24: loss=1.5109260082244873\n",
      "epoch 25: loss=1.5111875534057617\n",
      "epoch 26: loss=1.5025728940963745\n",
      "epoch 27: loss=1.503393292427063\n",
      "epoch 28: loss=1.4957275390625\n",
      "epoch 29: loss=1.4751571416854858\n",
      "epoch 30: loss=1.4669831991195679\n",
      "epoch 31: loss=1.461179256439209\n",
      "epoch 32: loss=1.458590030670166\n",
      "epoch 33: loss=1.4450407028198242\n",
      "epoch 34: loss=1.4274417161941528\n",
      "epoch 35: loss=1.4128835201263428\n",
      "epoch 36: loss=1.3868670463562012\n",
      "epoch 37: loss=1.3699671030044556\n",
      "epoch 38: loss=1.3512526750564575\n",
      "epoch 39: loss=1.3472472429275513\n",
      "epoch 40: loss=1.333190679550171\n",
      "epoch 41: loss=1.320216417312622\n",
      "epoch 42: loss=1.304783821105957\n",
      "epoch 43: loss=1.3139705657958984\n",
      "epoch 44: loss=1.3010765314102173\n",
      "epoch 45: loss=1.2710040807724\n",
      "epoch 46: loss=1.2436892986297607\n",
      "epoch 47: loss=1.2428345680236816\n",
      "epoch 48: loss=1.2693958282470703\n",
      "epoch 49: loss=1.2318699359893799\n",
      "epoch 50: loss=1.249487042427063\n",
      "epoch 51: loss=1.2114824056625366\n",
      "epoch 52: loss=1.219877004623413\n",
      "epoch 53: loss=1.205536961555481\n",
      "epoch 54: loss=1.1994894742965698\n",
      "epoch 55: loss=1.2004462480545044\n",
      "epoch 56: loss=1.1591254472732544\n",
      "epoch 57: loss=1.1805357933044434\n",
      "epoch 58: loss=1.17503023147583\n",
      "epoch 59: loss=1.1483817100524902\n",
      "epoch 60: loss=1.1428226232528687\n",
      "epoch 61: loss=1.1706688404083252\n",
      "epoch 62: loss=1.1379423141479492\n",
      "epoch 63: loss=1.152139663696289\n",
      "epoch 64: loss=1.1268908977508545\n",
      "epoch 65: loss=1.1185122728347778\n",
      "epoch 66: loss=1.1321005821228027\n",
      "epoch 67: loss=1.1318062543869019\n",
      "epoch 68: loss=1.1210322380065918\n",
      "epoch 69: loss=1.103010654449463\n",
      "epoch 70: loss=1.1143605709075928\n",
      "epoch 71: loss=1.1190159320831299\n",
      "epoch 72: loss=1.1504125595092773\n",
      "epoch 73: loss=1.1025025844573975\n",
      "epoch 74: loss=1.1310261487960815\n",
      "epoch 75: loss=1.096564769744873\n",
      "epoch 76: loss=1.102948784828186\n",
      "epoch 77: loss=1.1072975397109985\n",
      "epoch 78: loss=1.0769919157028198\n",
      "epoch 79: loss=1.0708403587341309\n",
      "epoch 80: loss=1.0845777988433838\n",
      "epoch 81: loss=1.1176923513412476\n",
      "epoch 82: loss=1.0695555210113525\n",
      "epoch 83: loss=1.0981941223144531\n",
      "epoch 84: loss=1.0765432119369507\n",
      "epoch 85: loss=1.071897029876709\n",
      "epoch 86: loss=1.0780085325241089\n",
      "epoch 87: loss=1.0842219591140747\n",
      "epoch 88: loss=1.0742634534835815\n",
      "epoch 89: loss=1.0875691175460815\n",
      "epoch 90: loss=1.0954785346984863\n",
      "epoch 91: loss=1.058037281036377\n",
      "epoch 92: loss=1.0674159526824951\n",
      "epoch 93: loss=1.0646127462387085\n",
      "epoch 94: loss=1.0450036525726318\n",
      "epoch 95: loss=1.062815546989441\n",
      "epoch 96: loss=1.0645010471343994\n",
      "epoch 97: loss=1.0755239725112915\n",
      "epoch 98: loss=1.0836127996444702\n",
      "epoch 99: loss=1.074181318283081\n",
      "epoch 100: loss=1.0588676929473877\n",
      "epoch 101: loss=1.069465160369873\n",
      "epoch 102: loss=1.0454926490783691\n",
      "epoch 103: loss=1.067678689956665\n",
      "epoch 104: loss=1.0308387279510498\n",
      "epoch 105: loss=1.062615156173706\n",
      "epoch 106: loss=1.0538175106048584\n",
      "epoch 107: loss=1.060872197151184\n",
      "epoch 108: loss=1.0573885440826416\n",
      "epoch 109: loss=1.0425082445144653\n",
      "epoch 110: loss=1.032089352607727\n",
      "epoch 111: loss=1.052663803100586\n",
      "epoch 112: loss=1.0622930526733398\n",
      "epoch 113: loss=1.0575814247131348\n",
      "epoch 114: loss=1.0543484687805176\n",
      "epoch 115: loss=1.05837881565094\n",
      "epoch 116: loss=1.078055739402771\n",
      "epoch 117: loss=1.0380717515945435\n",
      "epoch 118: loss=1.0347152948379517\n",
      "epoch 119: loss=1.0593464374542236\n",
      "epoch 120: loss=1.062290906906128\n",
      "epoch 121: loss=1.0303521156311035\n",
      "epoch 122: loss=1.040486216545105\n",
      "epoch 123: loss=1.0288006067276\n",
      "epoch 124: loss=1.072851300239563\n",
      "epoch 125: loss=1.0329434871673584\n",
      "epoch 126: loss=1.0484437942504883\n",
      "epoch 127: loss=1.0492088794708252\n",
      "epoch 128: loss=1.0615382194519043\n",
      "epoch 129: loss=1.0470975637435913\n",
      "epoch 130: loss=1.044350028038025\n",
      "epoch 131: loss=1.0531598329544067\n",
      "epoch 132: loss=1.0400972366333008\n",
      "epoch 133: loss=1.030982255935669\n",
      "epoch 134: loss=1.0343432426452637\n",
      "epoch 135: loss=1.0482478141784668\n",
      "epoch 136: loss=1.0649644136428833\n",
      "epoch 137: loss=1.0448120832443237\n",
      "epoch 138: loss=1.0480741262435913\n",
      "epoch 139: loss=1.0526316165924072\n",
      "epoch 140: loss=1.03811514377594\n",
      "epoch 141: loss=1.044363260269165\n",
      "epoch 142: loss=1.0351061820983887\n",
      "epoch 143: loss=1.0440913438796997\n",
      "epoch 144: loss=1.0328878164291382\n",
      "epoch 145: loss=1.0312732458114624\n",
      "epoch 146: loss=1.028380274772644\n",
      "epoch 147: loss=1.0425821542739868\n",
      "epoch 148: loss=1.0463587045669556\n",
      "epoch 149: loss=1.048458218574524\n",
      "epoch 150: loss=1.05641770362854\n",
      "epoch 151: loss=1.0369096994400024\n",
      "epoch 152: loss=1.0144941806793213\n",
      "epoch 153: loss=1.066450595855713\n",
      "epoch 154: loss=1.0557489395141602\n",
      "epoch 155: loss=1.0458073616027832\n",
      "epoch 156: loss=1.0408029556274414\n",
      "epoch 157: loss=1.0556272268295288\n",
      "epoch 158: loss=1.0488263368606567\n",
      "epoch 159: loss=1.0454142093658447\n",
      "epoch 160: loss=1.0467451810836792\n",
      "epoch 161: loss=1.056618332862854\n",
      "epoch 162: loss=1.0455485582351685\n",
      "epoch 163: loss=1.0282702445983887\n",
      "epoch 164: loss=1.052659273147583\n",
      "epoch 165: loss=1.04209303855896\n",
      "epoch 166: loss=1.0190584659576416\n",
      "epoch 167: loss=1.026850938796997\n",
      "epoch 168: loss=1.034435749053955\n",
      "epoch 169: loss=1.0220215320587158\n",
      "epoch 170: loss=1.0271129608154297\n",
      "epoch 171: loss=1.0134155750274658\n",
      "epoch 172: loss=1.0279674530029297\n",
      "epoch 173: loss=1.0304598808288574\n",
      "epoch 174: loss=1.0498857498168945\n",
      "epoch 175: loss=1.0363606214523315\n",
      "epoch 176: loss=1.0228312015533447\n",
      "epoch 177: loss=1.0253089666366577\n",
      "epoch 178: loss=1.046455979347229\n",
      "epoch 179: loss=1.060813546180725\n",
      "epoch 180: loss=1.028709053993225\n",
      "epoch 181: loss=1.0457779169082642\n",
      "epoch 182: loss=1.0217485427856445\n",
      "epoch 183: loss=1.0459575653076172\n",
      "epoch 184: loss=1.0533818006515503\n",
      "epoch 185: loss=1.0114643573760986\n",
      "epoch 186: loss=1.039462685585022\n",
      "epoch 187: loss=1.0112874507904053\n",
      "epoch 188: loss=1.0423343181610107\n",
      "epoch 189: loss=1.0226689577102661\n",
      "epoch 190: loss=1.0676066875457764\n",
      "epoch 191: loss=1.0447075366973877\n",
      "epoch 192: loss=1.0426008701324463\n",
      "epoch 193: loss=1.0260854959487915\n",
      "epoch 194: loss=1.0206680297851562\n",
      "epoch 195: loss=1.0501859188079834\n",
      "epoch 196: loss=1.034514307975769\n",
      "epoch 197: loss=1.0045087337493896\n",
      "epoch 198: loss=1.0453641414642334\n",
      "epoch 199: loss=1.045364499092102\n",
      "training patch with 1844 edges\n",
      "epoch 0: loss=7.028485298156738\n",
      "epoch 1: loss=6.325381278991699\n",
      "epoch 2: loss=6.424560546875\n",
      "epoch 3: loss=6.143165588378906\n",
      "epoch 4: loss=5.612557888031006\n",
      "epoch 5: loss=5.003644943237305\n",
      "epoch 6: loss=4.770003318786621\n",
      "epoch 7: loss=4.669283390045166\n",
      "epoch 8: loss=4.153915882110596\n",
      "epoch 9: loss=3.7984180450439453\n",
      "epoch 10: loss=3.5613725185394287\n",
      "epoch 11: loss=3.245270013809204\n",
      "epoch 12: loss=2.910909414291382\n",
      "epoch 13: loss=2.450038194656372\n",
      "epoch 14: loss=2.2973554134368896\n",
      "epoch 15: loss=2.0868589878082275\n",
      "epoch 16: loss=1.8209824562072754\n",
      "epoch 17: loss=1.722682237625122\n",
      "epoch 18: loss=1.623313069343567\n",
      "epoch 19: loss=1.6119065284729004\n",
      "epoch 20: loss=1.553923487663269\n",
      "epoch 21: loss=1.5451587438583374\n",
      "epoch 22: loss=1.5265439748764038\n",
      "epoch 23: loss=1.5118355751037598\n",
      "epoch 24: loss=1.4876136779785156\n",
      "epoch 25: loss=1.5044339895248413\n",
      "epoch 26: loss=1.4990020990371704\n",
      "epoch 27: loss=1.4772343635559082\n",
      "epoch 28: loss=1.471858263015747\n",
      "epoch 29: loss=1.4585227966308594\n",
      "epoch 30: loss=1.4408607482910156\n",
      "epoch 31: loss=1.430741786956787\n",
      "epoch 32: loss=1.435282826423645\n",
      "epoch 33: loss=1.4124937057495117\n",
      "epoch 34: loss=1.4021210670471191\n",
      "epoch 35: loss=1.388179898262024\n",
      "epoch 36: loss=1.3612340688705444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37: loss=1.3501014709472656\n",
      "epoch 38: loss=1.3326990604400635\n",
      "epoch 39: loss=1.3172686100006104\n",
      "epoch 40: loss=1.292809247970581\n",
      "epoch 41: loss=1.267116904258728\n",
      "epoch 42: loss=1.2316876649856567\n",
      "epoch 43: loss=1.2172212600708008\n",
      "epoch 44: loss=1.189345359802246\n",
      "epoch 45: loss=1.177861213684082\n",
      "epoch 46: loss=1.1589030027389526\n",
      "epoch 47: loss=1.1680196523666382\n",
      "epoch 48: loss=1.143049716949463\n",
      "epoch 49: loss=1.1703540086746216\n",
      "epoch 50: loss=1.1440149545669556\n",
      "epoch 51: loss=1.1660106182098389\n",
      "epoch 52: loss=1.138547420501709\n",
      "epoch 53: loss=1.122524380683899\n",
      "epoch 54: loss=1.1164108514785767\n",
      "epoch 55: loss=1.1251424551010132\n",
      "epoch 56: loss=1.1028519868850708\n",
      "epoch 57: loss=1.1126525402069092\n",
      "epoch 58: loss=1.0959250926971436\n",
      "epoch 59: loss=1.1015596389770508\n",
      "epoch 60: loss=1.0853149890899658\n",
      "epoch 61: loss=1.0659254789352417\n",
      "epoch 62: loss=1.0744576454162598\n",
      "epoch 63: loss=1.0690829753875732\n",
      "epoch 64: loss=1.0731885433197021\n",
      "epoch 65: loss=1.0594562292099\n",
      "epoch 66: loss=1.0638689994812012\n",
      "epoch 67: loss=1.0622817277908325\n",
      "epoch 68: loss=1.0675619840621948\n",
      "epoch 69: loss=1.0493428707122803\n",
      "epoch 70: loss=1.0504077672958374\n",
      "epoch 71: loss=1.0539565086364746\n",
      "epoch 72: loss=1.0617773532867432\n",
      "epoch 73: loss=1.0729236602783203\n",
      "epoch 74: loss=1.0459622144699097\n",
      "epoch 75: loss=1.0455442667007446\n",
      "epoch 76: loss=1.0554863214492798\n",
      "epoch 77: loss=1.0375922918319702\n",
      "epoch 78: loss=1.0196970701217651\n",
      "epoch 79: loss=1.0425184965133667\n",
      "epoch 80: loss=1.0658748149871826\n",
      "epoch 81: loss=1.040204405784607\n",
      "epoch 82: loss=1.0614323616027832\n",
      "epoch 83: loss=1.0637680292129517\n",
      "epoch 84: loss=1.0593881607055664\n",
      "epoch 85: loss=1.0392063856124878\n",
      "epoch 86: loss=1.036604642868042\n",
      "epoch 87: loss=1.0350878238677979\n",
      "epoch 88: loss=1.0522395372390747\n",
      "epoch 89: loss=1.050808310508728\n",
      "epoch 90: loss=1.013686180114746\n",
      "epoch 91: loss=1.0292161703109741\n",
      "epoch 92: loss=1.033481478691101\n",
      "epoch 93: loss=1.0285561084747314\n",
      "epoch 94: loss=1.0247248411178589\n",
      "epoch 95: loss=1.0060477256774902\n",
      "epoch 96: loss=1.0296630859375\n",
      "epoch 97: loss=1.0373027324676514\n",
      "epoch 98: loss=1.0545883178710938\n",
      "epoch 99: loss=1.0255296230316162\n",
      "epoch 100: loss=1.024519920349121\n",
      "epoch 101: loss=1.0387375354766846\n",
      "epoch 102: loss=1.0332074165344238\n",
      "epoch 103: loss=1.0211049318313599\n",
      "epoch 104: loss=1.031458854675293\n",
      "epoch 105: loss=1.014543890953064\n",
      "epoch 106: loss=1.0265284776687622\n",
      "epoch 107: loss=1.0119775533676147\n",
      "epoch 108: loss=1.0213326215744019\n",
      "epoch 109: loss=1.021679401397705\n",
      "epoch 110: loss=1.0012223720550537\n",
      "epoch 111: loss=1.012228012084961\n",
      "epoch 112: loss=1.0173486471176147\n",
      "epoch 113: loss=1.0142643451690674\n",
      "epoch 114: loss=0.9994403719902039\n",
      "epoch 115: loss=1.0536481142044067\n",
      "epoch 116: loss=1.0360136032104492\n",
      "epoch 117: loss=1.01750648021698\n",
      "epoch 118: loss=1.0283666849136353\n",
      "epoch 119: loss=1.0105408430099487\n",
      "epoch 120: loss=0.9966325163841248\n",
      "epoch 121: loss=1.0130432844161987\n",
      "epoch 122: loss=1.0085128545761108\n",
      "epoch 123: loss=0.9966137409210205\n",
      "epoch 124: loss=1.0485985279083252\n",
      "epoch 125: loss=1.0236387252807617\n",
      "epoch 126: loss=0.9921112060546875\n",
      "epoch 127: loss=1.0099812746047974\n",
      "epoch 128: loss=1.0248430967330933\n",
      "epoch 129: loss=1.0154204368591309\n",
      "epoch 130: loss=1.0151604413986206\n",
      "epoch 131: loss=1.0277700424194336\n",
      "epoch 132: loss=1.0543307065963745\n",
      "epoch 133: loss=1.0104963779449463\n",
      "epoch 134: loss=1.0120563507080078\n",
      "epoch 135: loss=1.0361545085906982\n",
      "epoch 136: loss=1.0024607181549072\n",
      "epoch 137: loss=1.0200244188308716\n",
      "epoch 138: loss=1.005589485168457\n",
      "epoch 139: loss=1.0174994468688965\n",
      "epoch 140: loss=1.0156490802764893\n",
      "epoch 141: loss=0.9912054538726807\n",
      "epoch 142: loss=1.0116699934005737\n",
      "epoch 143: loss=1.0121721029281616\n",
      "epoch 144: loss=1.0114778280258179\n",
      "epoch 145: loss=1.0040801763534546\n",
      "epoch 146: loss=1.0351539850234985\n",
      "epoch 147: loss=1.0286507606506348\n",
      "epoch 148: loss=1.017285943031311\n",
      "epoch 149: loss=1.005510926246643\n",
      "epoch 150: loss=1.019888162612915\n",
      "epoch 151: loss=1.005650520324707\n",
      "epoch 152: loss=1.0189721584320068\n",
      "epoch 153: loss=1.0085872411727905\n",
      "epoch 154: loss=1.0201754570007324\n",
      "epoch 155: loss=1.0149383544921875\n",
      "epoch 156: loss=1.0064101219177246\n",
      "epoch 157: loss=0.9828793406486511\n",
      "epoch 158: loss=0.9924126863479614\n",
      "epoch 159: loss=1.0179816484451294\n",
      "epoch 160: loss=1.0043892860412598\n",
      "epoch 161: loss=0.9909716844558716\n",
      "epoch 162: loss=0.9999734163284302\n",
      "epoch 163: loss=1.0068137645721436\n",
      "epoch 164: loss=0.9884814023971558\n",
      "epoch 165: loss=1.0166829824447632\n",
      "epoch 166: loss=1.0110983848571777\n",
      "epoch 167: loss=1.0016793012619019\n",
      "epoch 168: loss=1.017165184020996\n",
      "epoch 169: loss=1.0118621587753296\n",
      "epoch 170: loss=0.9949263334274292\n",
      "epoch 171: loss=1.003576397895813\n",
      "epoch 172: loss=1.0179189443588257\n",
      "epoch 173: loss=1.0228632688522339\n",
      "epoch 174: loss=1.0137747526168823\n",
      "epoch 175: loss=1.0166279077529907\n",
      "epoch 176: loss=1.0002048015594482\n",
      "epoch 177: loss=0.9906859993934631\n",
      "epoch 178: loss=1.0064635276794434\n",
      "epoch 179: loss=1.0156850814819336\n",
      "epoch 180: loss=1.0493812561035156\n",
      "epoch 181: loss=1.013616681098938\n",
      "epoch 182: loss=0.998839259147644\n",
      "epoch 183: loss=1.002954363822937\n",
      "epoch 184: loss=1.0054224729537964\n",
      "epoch 185: loss=0.9658627510070801\n",
      "epoch 186: loss=1.005354404449463\n",
      "epoch 187: loss=0.9951871633529663\n",
      "epoch 188: loss=0.9987237453460693\n",
      "epoch 189: loss=1.0015270709991455\n",
      "epoch 190: loss=0.9917656779289246\n",
      "epoch 191: loss=0.98436039686203\n",
      "epoch 192: loss=1.0007636547088623\n",
      "epoch 193: loss=0.9999637007713318\n",
      "epoch 194: loss=1.0058828592300415\n",
      "epoch 195: loss=0.9968370795249939\n",
      "epoch 196: loss=0.9856128692626953\n",
      "epoch 197: loss=0.9997879266738892\n",
      "epoch 198: loss=0.9916753768920898\n",
      "epoch 199: loss=0.973741352558136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94776d13771c42a097651131827cd8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 7731.3994140625\n",
      "Epoch 10, Loss: 1805.26171875\n",
      "Epoch 20, Loss: 1294.81396484375\n",
      "Epoch 30, Loss: 1125.568359375\n",
      "Epoch 40, Loss: 1059.741455078125\n",
      "Epoch 50, Loss: 1032.333984375\n",
      "Epoch 60, Loss: 1020.0194091796875\n",
      "Epoch 70, Loss: 1013.797119140625\n",
      "Epoch 80, Loss: 1010.1845092773438\n",
      "Epoch 90, Loss: 1007.8825073242188\n",
      "Epoch 100, Loss: 1006.2428588867188\n",
      "Epoch 110, Loss: 1004.9977416992188\n",
      "Epoch 120, Loss: 1004.0095825195312\n",
      "Epoch 130, Loss: 1003.2020263671875\n",
      "Epoch 140, Loss: 1002.5259399414062\n",
      "Epoch 150, Loss: 1001.9506225585938\n",
      "Epoch 160, Loss: 1001.454833984375\n",
      "Epoch 170, Loss: 1001.0231323242188\n",
      "Epoch 180, Loss: 1000.6437377929688\n",
      "Epoch 190, Loss: 1000.3096923828125\n",
      "training patch with 2032 edges\n",
      "epoch 0: loss=10.035090446472168\n",
      "epoch 1: loss=9.534984588623047\n",
      "epoch 2: loss=9.165922164916992\n",
      "epoch 3: loss=9.4194974899292\n",
      "epoch 4: loss=8.96267318725586\n",
      "epoch 5: loss=8.049686431884766\n",
      "epoch 6: loss=7.267372131347656\n",
      "epoch 7: loss=6.181058406829834\n",
      "epoch 8: loss=6.104068756103516\n",
      "epoch 9: loss=5.767523288726807\n",
      "epoch 10: loss=4.838925838470459\n",
      "epoch 11: loss=4.490942001342773\n",
      "epoch 12: loss=4.164677143096924\n",
      "epoch 13: loss=3.42984938621521\n",
      "epoch 14: loss=2.9111034870147705\n",
      "epoch 15: loss=2.583087205886841\n",
      "epoch 16: loss=2.322169780731201\n",
      "epoch 17: loss=2.173403739929199\n",
      "epoch 18: loss=2.0006744861602783\n",
      "epoch 19: loss=1.9321095943450928\n",
      "epoch 20: loss=1.8695385456085205\n",
      "epoch 21: loss=1.794831395149231\n",
      "epoch 22: loss=1.7045457363128662\n",
      "epoch 23: loss=1.678290843963623\n",
      "epoch 24: loss=1.6477093696594238\n",
      "epoch 25: loss=1.6983330249786377\n",
      "epoch 26: loss=1.6656835079193115\n",
      "epoch 27: loss=1.6509792804718018\n",
      "epoch 28: loss=1.6345081329345703\n",
      "epoch 29: loss=1.6425269842147827\n",
      "epoch 30: loss=1.6261271238327026\n",
      "epoch 31: loss=1.6187211275100708\n",
      "epoch 32: loss=1.611983299255371\n",
      "epoch 33: loss=1.6062899827957153\n",
      "epoch 34: loss=1.5917503833770752\n",
      "epoch 35: loss=1.5881799459457397\n",
      "epoch 36: loss=1.5921366214752197\n",
      "epoch 37: loss=1.5808888673782349\n",
      "epoch 38: loss=1.5697641372680664\n",
      "epoch 39: loss=1.5657145977020264\n",
      "epoch 40: loss=1.5417084693908691\n",
      "epoch 41: loss=1.5328874588012695\n",
      "epoch 42: loss=1.5279371738433838\n",
      "epoch 43: loss=1.5041996240615845\n",
      "epoch 44: loss=1.4823352098464966\n",
      "epoch 45: loss=1.4571094512939453\n",
      "epoch 46: loss=1.4529858827590942\n",
      "epoch 47: loss=1.4348669052124023\n",
      "epoch 48: loss=1.4027063846588135\n",
      "epoch 49: loss=1.3906487226486206\n",
      "epoch 50: loss=1.3873616456985474\n",
      "epoch 51: loss=1.3623368740081787\n",
      "epoch 52: loss=1.3568012714385986\n",
      "epoch 53: loss=1.3581619262695312\n",
      "epoch 54: loss=1.336296796798706\n",
      "epoch 55: loss=1.3403502702713013\n",
      "epoch 56: loss=1.3170881271362305\n",
      "epoch 57: loss=1.3047304153442383\n",
      "epoch 58: loss=1.2724432945251465\n",
      "epoch 59: loss=1.2686903476715088\n",
      "epoch 60: loss=1.2876684665679932\n",
      "epoch 61: loss=1.2721750736236572\n",
      "epoch 62: loss=1.2624609470367432\n",
      "epoch 63: loss=1.2630946636199951\n",
      "epoch 64: loss=1.257439136505127\n",
      "epoch 65: loss=1.2376070022583008\n",
      "epoch 66: loss=1.2295879125595093\n",
      "epoch 67: loss=1.2444441318511963\n",
      "epoch 68: loss=1.2449440956115723\n",
      "epoch 69: loss=1.229508638381958\n",
      "epoch 70: loss=1.2383745908737183\n",
      "epoch 71: loss=1.2238776683807373\n",
      "epoch 72: loss=1.223517894744873\n",
      "epoch 73: loss=1.2401045560836792\n",
      "epoch 74: loss=1.2214019298553467\n",
      "epoch 75: loss=1.2097548246383667\n",
      "epoch 76: loss=1.2135494947433472\n",
      "epoch 77: loss=1.2017476558685303\n",
      "epoch 78: loss=1.1930299997329712\n",
      "epoch 79: loss=1.2210537195205688\n",
      "epoch 80: loss=1.1908528804779053\n",
      "epoch 81: loss=1.1943033933639526\n",
      "epoch 82: loss=1.2089436054229736\n",
      "epoch 83: loss=1.2083017826080322\n",
      "epoch 84: loss=1.1946250200271606\n",
      "epoch 85: loss=1.2046349048614502\n",
      "epoch 86: loss=1.187764048576355\n",
      "epoch 87: loss=1.1984593868255615\n",
      "epoch 88: loss=1.1820290088653564\n",
      "epoch 89: loss=1.1694364547729492\n",
      "epoch 90: loss=1.175410270690918\n",
      "epoch 91: loss=1.1671271324157715\n",
      "epoch 92: loss=1.1578528881072998\n",
      "epoch 93: loss=1.2004650831222534\n",
      "epoch 94: loss=1.1642179489135742\n",
      "epoch 95: loss=1.2029236555099487\n",
      "epoch 96: loss=1.1586809158325195\n",
      "epoch 97: loss=1.1835801601409912\n",
      "epoch 98: loss=1.1379777193069458\n",
      "epoch 99: loss=1.1893975734710693\n",
      "epoch 100: loss=1.1661362648010254\n",
      "epoch 101: loss=1.164376974105835\n",
      "epoch 102: loss=1.1481062173843384\n",
      "epoch 103: loss=1.1731922626495361\n",
      "epoch 104: loss=1.1871912479400635\n",
      "epoch 105: loss=1.1770938634872437\n",
      "epoch 106: loss=1.1781110763549805\n",
      "epoch 107: loss=1.1858537197113037\n",
      "epoch 108: loss=1.175180435180664\n",
      "epoch 109: loss=1.1685675382614136\n",
      "epoch 110: loss=1.1789534091949463\n",
      "epoch 111: loss=1.1627376079559326\n",
      "epoch 112: loss=1.1526466608047485\n",
      "epoch 113: loss=1.1567167043685913\n",
      "epoch 114: loss=1.1703068017959595\n",
      "epoch 115: loss=1.1978564262390137\n",
      "epoch 116: loss=1.1687132120132446\n",
      "epoch 117: loss=1.1663342714309692\n",
      "epoch 118: loss=1.1631596088409424\n",
      "epoch 119: loss=1.1835830211639404\n",
      "epoch 120: loss=1.1402256488800049\n",
      "epoch 121: loss=1.1465442180633545\n",
      "epoch 122: loss=1.167618751525879\n",
      "epoch 123: loss=1.1355570554733276\n",
      "epoch 124: loss=1.1802575588226318\n",
      "epoch 125: loss=1.1718778610229492\n",
      "epoch 126: loss=1.161340594291687\n",
      "epoch 127: loss=1.1519464254379272\n",
      "epoch 128: loss=1.1505569219589233\n",
      "epoch 129: loss=1.158508062362671\n",
      "epoch 130: loss=1.1429630517959595\n",
      "epoch 131: loss=1.15214204788208\n",
      "epoch 132: loss=1.1376545429229736\n",
      "epoch 133: loss=1.1482782363891602\n",
      "epoch 134: loss=1.167686939239502\n",
      "epoch 135: loss=1.1519103050231934\n",
      "epoch 136: loss=1.1638619899749756\n",
      "epoch 137: loss=1.1516411304473877\n",
      "epoch 138: loss=1.1183812618255615\n",
      "epoch 139: loss=1.1857523918151855\n",
      "epoch 140: loss=1.144572138786316\n",
      "epoch 141: loss=1.1612786054611206\n",
      "epoch 142: loss=1.153296947479248\n",
      "epoch 143: loss=1.1356987953186035\n",
      "epoch 144: loss=1.1389398574829102\n",
      "epoch 145: loss=1.1586427688598633\n",
      "epoch 146: loss=1.141089916229248\n",
      "epoch 147: loss=1.148754596710205\n",
      "epoch 148: loss=1.1136395931243896\n",
      "epoch 149: loss=1.1557254791259766\n",
      "epoch 150: loss=1.1533746719360352\n",
      "epoch 151: loss=1.1479196548461914\n",
      "epoch 152: loss=1.151195764541626\n",
      "epoch 153: loss=1.1644763946533203\n",
      "epoch 154: loss=1.1551666259765625\n",
      "epoch 155: loss=1.1527411937713623\n",
      "epoch 156: loss=1.1720882654190063\n",
      "epoch 157: loss=1.1189066171646118\n",
      "epoch 158: loss=1.1436976194381714\n",
      "epoch 159: loss=1.1285351514816284\n",
      "epoch 160: loss=1.1225439310073853\n",
      "epoch 161: loss=1.1471912860870361\n",
      "epoch 162: loss=1.1333597898483276\n",
      "epoch 163: loss=1.133245587348938\n",
      "epoch 164: loss=1.155222773551941\n",
      "epoch 165: loss=1.1549019813537598\n",
      "epoch 166: loss=1.1367309093475342\n",
      "epoch 167: loss=1.1767441034317017\n",
      "epoch 168: loss=1.1448006629943848\n",
      "epoch 169: loss=1.141920566558838\n",
      "epoch 170: loss=1.1391258239746094\n",
      "epoch 171: loss=1.1267997026443481\n",
      "epoch 172: loss=1.151961088180542\n",
      "epoch 173: loss=1.1416637897491455\n",
      "epoch 174: loss=1.1281957626342773\n",
      "epoch 175: loss=1.1492825746536255\n",
      "epoch 176: loss=1.1418136358261108\n",
      "epoch 177: loss=1.121636986732483\n",
      "epoch 178: loss=1.1381268501281738\n",
      "epoch 179: loss=1.1352009773254395\n",
      "epoch 180: loss=1.140944004058838\n",
      "epoch 181: loss=1.150405764579773\n",
      "epoch 182: loss=1.113571286201477\n",
      "epoch 183: loss=1.1464874744415283\n",
      "epoch 184: loss=1.1385571956634521\n",
      "epoch 185: loss=1.139299988746643\n",
      "epoch 186: loss=1.13227117061615\n",
      "epoch 187: loss=1.1317282915115356\n",
      "epoch 188: loss=1.1312204599380493\n",
      "epoch 189: loss=1.1375751495361328\n",
      "epoch 190: loss=1.1382980346679688\n",
      "epoch 191: loss=1.1348956823349\n",
      "epoch 192: loss=1.1489500999450684\n",
      "epoch 193: loss=1.1388444900512695\n",
      "epoch 194: loss=1.1421833038330078\n",
      "epoch 195: loss=1.1601263284683228\n",
      "epoch 196: loss=1.1411150693893433\n",
      "epoch 197: loss=1.1221188306808472\n",
      "epoch 198: loss=1.1653366088867188\n",
      "epoch 199: loss=1.1384973526000977\n",
      "training patch with 1946 edges\n",
      "epoch 0: loss=10.055113792419434\n",
      "epoch 1: loss=10.260274887084961\n",
      "epoch 2: loss=9.35940170288086\n",
      "epoch 3: loss=9.234118461608887\n",
      "epoch 4: loss=8.639534950256348\n",
      "epoch 5: loss=7.936190605163574\n",
      "epoch 6: loss=7.402175426483154\n",
      "epoch 7: loss=6.804693698883057\n",
      "epoch 8: loss=6.082799911499023\n",
      "epoch 9: loss=5.541090488433838\n",
      "epoch 10: loss=5.089450359344482\n",
      "epoch 11: loss=4.936180114746094\n",
      "epoch 12: loss=4.134978771209717\n",
      "epoch 13: loss=3.5627079010009766\n",
      "epoch 14: loss=3.080481767654419\n",
      "epoch 15: loss=2.5585122108459473\n",
      "epoch 16: loss=2.330556869506836\n",
      "epoch 17: loss=2.204305410385132\n",
      "epoch 18: loss=2.0452001094818115\n",
      "epoch 19: loss=1.9462993144989014\n",
      "epoch 20: loss=1.8502296209335327\n",
      "epoch 21: loss=1.8231842517852783\n",
      "epoch 22: loss=1.757753610610962\n",
      "epoch 23: loss=1.6913429498672485\n",
      "epoch 24: loss=1.6833086013793945\n",
      "epoch 25: loss=1.7358384132385254\n",
      "epoch 26: loss=1.6840580701828003\n",
      "epoch 27: loss=1.6753785610198975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28: loss=1.6495020389556885\n",
      "epoch 29: loss=1.6292572021484375\n",
      "epoch 30: loss=1.6176676750183105\n",
      "epoch 31: loss=1.5952999591827393\n",
      "epoch 32: loss=1.6073992252349854\n",
      "epoch 33: loss=1.5871070623397827\n",
      "epoch 34: loss=1.5863566398620605\n",
      "epoch 35: loss=1.5776917934417725\n",
      "epoch 36: loss=1.5487957000732422\n",
      "epoch 37: loss=1.5340638160705566\n",
      "epoch 38: loss=1.5391992330551147\n",
      "epoch 39: loss=1.5124156475067139\n",
      "epoch 40: loss=1.492364525794983\n",
      "epoch 41: loss=1.4765406847000122\n",
      "epoch 42: loss=1.4468574523925781\n",
      "epoch 43: loss=1.4251911640167236\n",
      "epoch 44: loss=1.3903286457061768\n",
      "epoch 45: loss=1.3773880004882812\n",
      "epoch 46: loss=1.3756234645843506\n",
      "epoch 47: loss=1.3680989742279053\n",
      "epoch 48: loss=1.3372458219528198\n",
      "epoch 49: loss=1.305076003074646\n",
      "epoch 50: loss=1.3440970182418823\n",
      "epoch 51: loss=1.3086309432983398\n",
      "epoch 52: loss=1.280043125152588\n",
      "epoch 53: loss=1.3182557821273804\n",
      "epoch 54: loss=1.2883729934692383\n",
      "epoch 55: loss=1.2824963331222534\n",
      "epoch 56: loss=1.2616288661956787\n",
      "epoch 57: loss=1.2418689727783203\n",
      "epoch 58: loss=1.2433875799179077\n",
      "epoch 59: loss=1.2678344249725342\n",
      "epoch 60: loss=1.260232925415039\n",
      "epoch 61: loss=1.253749132156372\n",
      "epoch 62: loss=1.2375249862670898\n",
      "epoch 63: loss=1.2143830060958862\n",
      "epoch 64: loss=1.2339246273040771\n",
      "epoch 65: loss=1.224158763885498\n",
      "epoch 66: loss=1.1968083381652832\n",
      "epoch 67: loss=1.2290184497833252\n",
      "epoch 68: loss=1.1995089054107666\n",
      "epoch 69: loss=1.2076256275177002\n",
      "epoch 70: loss=1.249866008758545\n",
      "epoch 71: loss=1.216616153717041\n",
      "epoch 72: loss=1.2143104076385498\n",
      "epoch 73: loss=1.204121708869934\n",
      "epoch 74: loss=1.2246944904327393\n",
      "epoch 75: loss=1.215223789215088\n",
      "epoch 76: loss=1.2277926206588745\n",
      "epoch 77: loss=1.2038732767105103\n",
      "epoch 78: loss=1.195613980293274\n",
      "epoch 79: loss=1.1883609294891357\n",
      "epoch 80: loss=1.2070224285125732\n",
      "epoch 81: loss=1.1830768585205078\n",
      "epoch 82: loss=1.2017323970794678\n",
      "epoch 83: loss=1.1558395624160767\n",
      "epoch 84: loss=1.1870471239089966\n",
      "epoch 85: loss=1.201426386833191\n",
      "epoch 86: loss=1.2062513828277588\n",
      "epoch 87: loss=1.207541823387146\n",
      "epoch 88: loss=1.1990385055541992\n",
      "epoch 89: loss=1.1781312227249146\n",
      "epoch 90: loss=1.1826505661010742\n",
      "epoch 91: loss=1.15733003616333\n",
      "epoch 92: loss=1.1928461790084839\n",
      "epoch 93: loss=1.1774020195007324\n",
      "epoch 94: loss=1.1952831745147705\n",
      "epoch 95: loss=1.1900290250778198\n",
      "epoch 96: loss=1.1562550067901611\n",
      "epoch 97: loss=1.1712640523910522\n",
      "epoch 98: loss=1.1801559925079346\n",
      "epoch 99: loss=1.1904559135437012\n",
      "epoch 100: loss=1.1776214838027954\n",
      "epoch 101: loss=1.1872247457504272\n",
      "epoch 102: loss=1.1540228128433228\n",
      "epoch 103: loss=1.1616230010986328\n",
      "epoch 104: loss=1.1689949035644531\n",
      "epoch 105: loss=1.1928901672363281\n",
      "epoch 106: loss=1.1559247970581055\n",
      "epoch 107: loss=1.1788709163665771\n",
      "epoch 108: loss=1.17478346824646\n",
      "epoch 109: loss=1.1671268939971924\n",
      "epoch 110: loss=1.151942253112793\n",
      "epoch 111: loss=1.1784504652023315\n",
      "epoch 112: loss=1.1733388900756836\n",
      "epoch 113: loss=1.158450961112976\n",
      "epoch 114: loss=1.1672269105911255\n",
      "epoch 115: loss=1.1800600290298462\n",
      "epoch 116: loss=1.166954755783081\n",
      "epoch 117: loss=1.1350446939468384\n",
      "epoch 118: loss=1.181174635887146\n",
      "epoch 119: loss=1.1316039562225342\n",
      "epoch 120: loss=1.1454235315322876\n",
      "epoch 121: loss=1.1463162899017334\n",
      "epoch 122: loss=1.110093116760254\n",
      "epoch 123: loss=1.1476101875305176\n",
      "epoch 124: loss=1.151255488395691\n",
      "epoch 125: loss=1.1812320947647095\n",
      "epoch 126: loss=1.164124608039856\n",
      "epoch 127: loss=1.1839721202850342\n",
      "epoch 128: loss=1.1336008310317993\n",
      "epoch 129: loss=1.1656843423843384\n",
      "epoch 130: loss=1.1444931030273438\n",
      "epoch 131: loss=1.162132740020752\n",
      "epoch 132: loss=1.1349129676818848\n",
      "epoch 133: loss=1.1501595973968506\n",
      "epoch 134: loss=1.1608175039291382\n",
      "epoch 135: loss=1.1492143869400024\n",
      "epoch 136: loss=1.1356356143951416\n",
      "epoch 137: loss=1.1477395296096802\n",
      "epoch 138: loss=1.1748337745666504\n",
      "epoch 139: loss=1.149032711982727\n",
      "epoch 140: loss=1.1345468759536743\n",
      "epoch 141: loss=1.1570038795471191\n",
      "epoch 142: loss=1.1713922023773193\n",
      "epoch 143: loss=1.1495190858840942\n",
      "epoch 144: loss=1.1326278448104858\n",
      "epoch 145: loss=1.1349718570709229\n",
      "epoch 146: loss=1.1307404041290283\n",
      "epoch 147: loss=1.1430456638336182\n",
      "epoch 148: loss=1.1775668859481812\n",
      "epoch 149: loss=1.1468855142593384\n",
      "epoch 150: loss=1.1912145614624023\n",
      "epoch 151: loss=1.1345725059509277\n",
      "epoch 152: loss=1.1727347373962402\n",
      "epoch 153: loss=1.1526641845703125\n",
      "epoch 154: loss=1.1209959983825684\n",
      "epoch 155: loss=1.1500048637390137\n",
      "epoch 156: loss=1.1625018119812012\n",
      "epoch 157: loss=1.1394844055175781\n",
      "epoch 158: loss=1.1141964197158813\n",
      "epoch 159: loss=1.1468796730041504\n",
      "epoch 160: loss=1.1647435426712036\n",
      "epoch 161: loss=1.151451587677002\n",
      "epoch 162: loss=1.142182469367981\n",
      "epoch 163: loss=1.1327711343765259\n",
      "epoch 164: loss=1.1545557975769043\n",
      "epoch 165: loss=1.1696728467941284\n",
      "epoch 166: loss=1.1643590927124023\n",
      "epoch 167: loss=1.124019980430603\n",
      "epoch 168: loss=1.1510226726531982\n",
      "epoch 169: loss=1.1324570178985596\n",
      "epoch 170: loss=1.1469740867614746\n",
      "epoch 171: loss=1.1557282209396362\n",
      "epoch 172: loss=1.1441987752914429\n",
      "epoch 173: loss=1.1321998834609985\n",
      "epoch 174: loss=1.156435251235962\n",
      "epoch 175: loss=1.1308482885360718\n",
      "epoch 176: loss=1.1326279640197754\n",
      "epoch 177: loss=1.1342109441757202\n",
      "epoch 178: loss=1.160781979560852\n",
      "epoch 179: loss=1.1325678825378418\n",
      "epoch 180: loss=1.1346449851989746\n",
      "epoch 181: loss=1.1445016860961914\n",
      "epoch 182: loss=1.1259026527404785\n",
      "epoch 183: loss=1.1557608842849731\n",
      "epoch 184: loss=1.157553791999817\n",
      "epoch 185: loss=1.132392168045044\n",
      "epoch 186: loss=1.12870454788208\n",
      "epoch 187: loss=1.1564220190048218\n",
      "epoch 188: loss=1.1217048168182373\n",
      "epoch 189: loss=1.121267318725586\n",
      "epoch 190: loss=1.1226844787597656\n",
      "epoch 191: loss=1.1592967510223389\n",
      "epoch 192: loss=1.137546420097351\n",
      "epoch 193: loss=1.1419596672058105\n",
      "epoch 194: loss=1.141031265258789\n",
      "epoch 195: loss=1.134466290473938\n",
      "epoch 196: loss=1.1358137130737305\n",
      "epoch 197: loss=1.124007225036621\n",
      "epoch 198: loss=1.1433557271957397\n",
      "epoch 199: loss=1.153512954711914\n",
      "training patch with 1878 edges\n",
      "epoch 0: loss=10.026883125305176\n",
      "epoch 1: loss=9.8231840133667\n",
      "epoch 2: loss=9.31166934967041\n",
      "epoch 3: loss=9.236406326293945\n",
      "epoch 4: loss=8.611725807189941\n",
      "epoch 5: loss=8.113373756408691\n",
      "epoch 6: loss=6.847168922424316\n",
      "epoch 7: loss=6.374039649963379\n",
      "epoch 8: loss=5.7030348777771\n",
      "epoch 9: loss=5.432170391082764\n",
      "epoch 10: loss=4.510163307189941\n",
      "epoch 11: loss=4.219616413116455\n",
      "epoch 12: loss=3.5580310821533203\n",
      "epoch 13: loss=3.1284000873565674\n",
      "epoch 14: loss=2.615377902984619\n",
      "epoch 15: loss=2.325756549835205\n",
      "epoch 16: loss=2.194777011871338\n",
      "epoch 17: loss=1.955173373222351\n",
      "epoch 18: loss=1.9061366319656372\n",
      "epoch 19: loss=1.9432244300842285\n",
      "epoch 20: loss=1.8656693696975708\n",
      "epoch 21: loss=1.793070912361145\n",
      "epoch 22: loss=1.7449374198913574\n",
      "epoch 23: loss=1.725956678390503\n",
      "epoch 24: loss=1.728139877319336\n",
      "epoch 25: loss=1.733902931213379\n",
      "epoch 26: loss=1.7225637435913086\n",
      "epoch 27: loss=1.722206950187683\n",
      "epoch 28: loss=1.681185245513916\n",
      "epoch 29: loss=1.7051100730895996\n",
      "epoch 30: loss=1.6850707530975342\n",
      "epoch 31: loss=1.6737555265426636\n",
      "epoch 32: loss=1.6988816261291504\n",
      "epoch 33: loss=1.6782996654510498\n",
      "epoch 34: loss=1.6783339977264404\n",
      "epoch 35: loss=1.6660103797912598\n",
      "epoch 36: loss=1.6520037651062012\n",
      "epoch 37: loss=1.6386460065841675\n",
      "epoch 38: loss=1.6481388807296753\n",
      "epoch 39: loss=1.6284775733947754\n",
      "epoch 40: loss=1.6168241500854492\n",
      "epoch 41: loss=1.6034735441207886\n",
      "epoch 42: loss=1.5940525531768799\n",
      "epoch 43: loss=1.5642650127410889\n",
      "epoch 44: loss=1.5611238479614258\n",
      "epoch 45: loss=1.5248383283615112\n",
      "epoch 46: loss=1.5037420988082886\n",
      "epoch 47: loss=1.4873777627944946\n",
      "epoch 48: loss=1.4716593027114868\n",
      "epoch 49: loss=1.4183685779571533\n",
      "epoch 50: loss=1.4097868204116821\n",
      "epoch 51: loss=1.3991799354553223\n",
      "epoch 52: loss=1.38151216506958\n",
      "epoch 53: loss=1.3711594343185425\n",
      "epoch 54: loss=1.3608723878860474\n",
      "epoch 55: loss=1.352820873260498\n",
      "epoch 56: loss=1.3560280799865723\n",
      "epoch 57: loss=1.397128701210022\n",
      "epoch 58: loss=1.358489990234375\n",
      "epoch 59: loss=1.316656231880188\n",
      "epoch 60: loss=1.3285105228424072\n",
      "epoch 61: loss=1.3247119188308716\n",
      "epoch 62: loss=1.3182268142700195\n",
      "epoch 63: loss=1.292004942893982\n",
      "epoch 64: loss=1.3128222227096558\n",
      "epoch 65: loss=1.3167929649353027\n",
      "epoch 66: loss=1.333418846130371\n",
      "epoch 67: loss=1.2978122234344482\n",
      "epoch 68: loss=1.3081755638122559\n",
      "epoch 69: loss=1.2920310497283936\n",
      "epoch 70: loss=1.3175195455551147\n",
      "epoch 71: loss=1.2838575839996338\n",
      "epoch 72: loss=1.3094255924224854\n",
      "epoch 73: loss=1.2902635335922241\n",
      "epoch 74: loss=1.285308837890625\n",
      "epoch 75: loss=1.2761855125427246\n",
      "epoch 76: loss=1.2603322267532349\n",
      "epoch 77: loss=1.2600460052490234\n",
      "epoch 78: loss=1.2688645124435425\n",
      "epoch 79: loss=1.2648422718048096\n",
      "epoch 80: loss=1.272807240486145\n",
      "epoch 81: loss=1.2984379529953003\n",
      "epoch 82: loss=1.2646855115890503\n",
      "epoch 83: loss=1.227057695388794\n",
      "epoch 84: loss=1.265713095664978\n",
      "epoch 85: loss=1.2619917392730713\n",
      "epoch 86: loss=1.240654706954956\n",
      "epoch 87: loss=1.2411749362945557\n",
      "epoch 88: loss=1.246419072151184\n",
      "epoch 89: loss=1.2328405380249023\n",
      "epoch 90: loss=1.2623993158340454\n",
      "epoch 91: loss=1.273116111755371\n",
      "epoch 92: loss=1.247612476348877\n",
      "epoch 93: loss=1.253580927848816\n",
      "epoch 94: loss=1.2719504833221436\n",
      "epoch 95: loss=1.2744340896606445\n",
      "epoch 96: loss=1.2462382316589355\n",
      "epoch 97: loss=1.2129552364349365\n",
      "epoch 98: loss=1.2557432651519775\n",
      "epoch 99: loss=1.2509397268295288\n",
      "epoch 100: loss=1.2764277458190918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101: loss=1.2062374353408813\n",
      "epoch 102: loss=1.2609244585037231\n",
      "epoch 103: loss=1.2375235557556152\n",
      "epoch 104: loss=1.2202785015106201\n",
      "epoch 105: loss=1.2203497886657715\n",
      "epoch 106: loss=1.207509994506836\n",
      "epoch 107: loss=1.2403351068496704\n",
      "epoch 108: loss=1.2399752140045166\n",
      "epoch 109: loss=1.2281166315078735\n",
      "epoch 110: loss=1.2283037900924683\n",
      "epoch 111: loss=1.2550326585769653\n",
      "epoch 112: loss=1.222825050354004\n",
      "epoch 113: loss=1.22316312789917\n",
      "epoch 114: loss=1.2197070121765137\n",
      "epoch 115: loss=1.2524127960205078\n",
      "epoch 116: loss=1.2496142387390137\n",
      "epoch 117: loss=1.2129836082458496\n",
      "epoch 118: loss=1.2617870569229126\n",
      "epoch 119: loss=1.2171664237976074\n",
      "epoch 120: loss=1.2462767362594604\n",
      "epoch 121: loss=1.2358849048614502\n",
      "epoch 122: loss=1.2256929874420166\n",
      "epoch 123: loss=1.2083619832992554\n",
      "epoch 124: loss=1.22250235080719\n",
      "epoch 125: loss=1.2003976106643677\n",
      "epoch 126: loss=1.2029054164886475\n",
      "epoch 127: loss=1.22471284866333\n",
      "epoch 128: loss=1.2084249258041382\n",
      "epoch 129: loss=1.2266887426376343\n",
      "epoch 130: loss=1.2195377349853516\n",
      "epoch 131: loss=1.2341125011444092\n",
      "epoch 132: loss=1.233426570892334\n",
      "epoch 133: loss=1.2021843194961548\n",
      "epoch 134: loss=1.2057058811187744\n",
      "epoch 135: loss=1.2371784448623657\n",
      "epoch 136: loss=1.2071356773376465\n",
      "epoch 137: loss=1.2109839916229248\n",
      "epoch 138: loss=1.217841625213623\n",
      "epoch 139: loss=1.2230628728866577\n",
      "epoch 140: loss=1.2432451248168945\n",
      "epoch 141: loss=1.238154411315918\n",
      "epoch 142: loss=1.20094633102417\n",
      "epoch 143: loss=1.2406654357910156\n",
      "epoch 144: loss=1.2391504049301147\n",
      "epoch 145: loss=1.2461497783660889\n",
      "epoch 146: loss=1.2254858016967773\n",
      "epoch 147: loss=1.209230899810791\n",
      "epoch 148: loss=1.245805025100708\n",
      "epoch 149: loss=1.2004839181900024\n",
      "epoch 150: loss=1.2334986925125122\n",
      "epoch 151: loss=1.2026183605194092\n",
      "epoch 152: loss=1.2131643295288086\n",
      "epoch 153: loss=1.2355095148086548\n",
      "epoch 154: loss=1.2177542448043823\n",
      "epoch 155: loss=1.189621925354004\n",
      "epoch 156: loss=1.2387290000915527\n",
      "epoch 157: loss=1.2046984434127808\n",
      "epoch 158: loss=1.232425332069397\n",
      "epoch 159: loss=1.1809419393539429\n",
      "epoch 160: loss=1.2282675504684448\n",
      "epoch 161: loss=1.2082908153533936\n",
      "epoch 162: loss=1.2019726037979126\n",
      "epoch 163: loss=1.2241290807724\n",
      "epoch 164: loss=1.214367389678955\n",
      "epoch 165: loss=1.1704726219177246\n",
      "epoch 166: loss=1.1994752883911133\n",
      "epoch 167: loss=1.194580078125\n",
      "epoch 168: loss=1.205653190612793\n",
      "epoch 169: loss=1.2140096426010132\n",
      "epoch 170: loss=1.2090883255004883\n",
      "epoch 171: loss=1.2024219036102295\n",
      "epoch 172: loss=1.1944029331207275\n",
      "epoch 173: loss=1.2041692733764648\n",
      "epoch 174: loss=1.1991372108459473\n",
      "epoch 175: loss=1.2164881229400635\n",
      "epoch 176: loss=1.2299211025238037\n",
      "epoch 177: loss=1.2122373580932617\n",
      "epoch 178: loss=1.2230650186538696\n",
      "epoch 179: loss=1.1906676292419434\n",
      "epoch 180: loss=1.1897497177124023\n",
      "epoch 181: loss=1.1864550113677979\n",
      "epoch 182: loss=1.1866164207458496\n",
      "epoch 183: loss=1.199476957321167\n",
      "epoch 184: loss=1.1875792741775513\n",
      "epoch 185: loss=1.194096565246582\n",
      "epoch 186: loss=1.1996450424194336\n",
      "epoch 187: loss=1.2052770853042603\n",
      "epoch 188: loss=1.221859097480774\n",
      "epoch 189: loss=1.1946557760238647\n",
      "epoch 190: loss=1.2035609483718872\n",
      "epoch 191: loss=1.2090847492218018\n",
      "epoch 192: loss=1.189063549041748\n",
      "epoch 193: loss=1.2162171602249146\n",
      "epoch 194: loss=1.2163336277008057\n",
      "epoch 195: loss=1.1903610229492188\n",
      "epoch 196: loss=1.2239725589752197\n",
      "epoch 197: loss=1.200225830078125\n",
      "epoch 198: loss=1.2278891801834106\n",
      "epoch 199: loss=1.2121670246124268\n",
      "training patch with 2784 edges\n",
      "epoch 0: loss=10.16836166381836\n",
      "epoch 1: loss=9.67145824432373\n",
      "epoch 2: loss=9.794694900512695\n",
      "epoch 3: loss=9.077247619628906\n",
      "epoch 4: loss=8.583383560180664\n",
      "epoch 5: loss=7.536599159240723\n",
      "epoch 6: loss=6.857658863067627\n",
      "epoch 7: loss=6.384227752685547\n",
      "epoch 8: loss=5.914773941040039\n",
      "epoch 9: loss=5.2060322761535645\n",
      "epoch 10: loss=4.929008960723877\n",
      "epoch 11: loss=4.224371910095215\n",
      "epoch 12: loss=3.725578784942627\n",
      "epoch 13: loss=3.234800338745117\n",
      "epoch 14: loss=2.7317116260528564\n",
      "epoch 15: loss=2.4484283924102783\n",
      "epoch 16: loss=2.189426898956299\n",
      "epoch 17: loss=2.0418365001678467\n",
      "epoch 18: loss=1.9485597610473633\n",
      "epoch 19: loss=1.897871971130371\n",
      "epoch 20: loss=1.7562758922576904\n",
      "epoch 21: loss=1.6917213201522827\n",
      "epoch 22: loss=1.664961338043213\n",
      "epoch 23: loss=1.6170189380645752\n",
      "epoch 24: loss=1.6325232982635498\n",
      "epoch 25: loss=1.6326878070831299\n",
      "epoch 26: loss=1.6035656929016113\n",
      "epoch 27: loss=1.5914474725723267\n",
      "epoch 28: loss=1.5722355842590332\n",
      "epoch 29: loss=1.5565099716186523\n",
      "epoch 30: loss=1.5603777170181274\n",
      "epoch 31: loss=1.5457994937896729\n",
      "epoch 32: loss=1.5627555847167969\n",
      "epoch 33: loss=1.554102897644043\n",
      "epoch 34: loss=1.5437963008880615\n",
      "epoch 35: loss=1.5537304878234863\n",
      "epoch 36: loss=1.5374690294265747\n",
      "epoch 37: loss=1.5468493700027466\n",
      "epoch 38: loss=1.5364868640899658\n",
      "epoch 39: loss=1.5299805402755737\n",
      "epoch 40: loss=1.5164129734039307\n",
      "epoch 41: loss=1.5205483436584473\n",
      "epoch 42: loss=1.4977936744689941\n",
      "epoch 43: loss=1.475672721862793\n",
      "epoch 44: loss=1.482997179031372\n",
      "epoch 45: loss=1.4552338123321533\n",
      "epoch 46: loss=1.4319838285446167\n",
      "epoch 47: loss=1.4200730323791504\n",
      "epoch 48: loss=1.40018630027771\n",
      "epoch 49: loss=1.385671615600586\n",
      "epoch 50: loss=1.3732995986938477\n",
      "epoch 51: loss=1.343159794807434\n",
      "epoch 52: loss=1.3218293190002441\n",
      "epoch 53: loss=1.3138554096221924\n",
      "epoch 54: loss=1.2991527318954468\n",
      "epoch 55: loss=1.276582956314087\n",
      "epoch 56: loss=1.2547709941864014\n",
      "epoch 57: loss=1.2448832988739014\n",
      "epoch 58: loss=1.2403839826583862\n",
      "epoch 59: loss=1.2438404560089111\n",
      "epoch 60: loss=1.224716305732727\n",
      "epoch 61: loss=1.2494946718215942\n",
      "epoch 62: loss=1.2382657527923584\n",
      "epoch 63: loss=1.2300292253494263\n",
      "epoch 64: loss=1.208117127418518\n",
      "epoch 65: loss=1.217413067817688\n",
      "epoch 66: loss=1.183568000793457\n",
      "epoch 67: loss=1.20322585105896\n",
      "epoch 68: loss=1.1637858152389526\n",
      "epoch 69: loss=1.1951231956481934\n",
      "epoch 70: loss=1.1772340536117554\n",
      "epoch 71: loss=1.1680442094802856\n",
      "epoch 72: loss=1.1632927656173706\n",
      "epoch 73: loss=1.1644924879074097\n",
      "epoch 74: loss=1.1541082859039307\n",
      "epoch 75: loss=1.160880208015442\n",
      "epoch 76: loss=1.1644052267074585\n",
      "epoch 77: loss=1.1668933629989624\n",
      "epoch 78: loss=1.1474754810333252\n",
      "epoch 79: loss=1.1539764404296875\n",
      "epoch 80: loss=1.1383253335952759\n",
      "epoch 81: loss=1.1612942218780518\n",
      "epoch 82: loss=1.1391493082046509\n",
      "epoch 83: loss=1.1437458992004395\n",
      "epoch 84: loss=1.1392229795455933\n",
      "epoch 85: loss=1.1357731819152832\n",
      "epoch 86: loss=1.1398574113845825\n",
      "epoch 87: loss=1.1488165855407715\n",
      "epoch 88: loss=1.146192193031311\n",
      "epoch 89: loss=1.1358613967895508\n",
      "epoch 90: loss=1.1441248655319214\n",
      "epoch 91: loss=1.1253104209899902\n",
      "epoch 92: loss=1.128947138786316\n",
      "epoch 93: loss=1.120316982269287\n",
      "epoch 94: loss=1.1140540838241577\n",
      "epoch 95: loss=1.129370093345642\n",
      "epoch 96: loss=1.1326004266738892\n",
      "epoch 97: loss=1.133773922920227\n",
      "epoch 98: loss=1.132375955581665\n",
      "epoch 99: loss=1.145765781402588\n",
      "epoch 100: loss=1.1140252351760864\n",
      "epoch 101: loss=1.1232104301452637\n",
      "epoch 102: loss=1.0975693464279175\n",
      "epoch 103: loss=1.111578106880188\n",
      "epoch 104: loss=1.0998890399932861\n",
      "epoch 105: loss=1.1304776668548584\n",
      "epoch 106: loss=1.1290206909179688\n",
      "epoch 107: loss=1.103822946548462\n",
      "epoch 108: loss=1.1243700981140137\n",
      "epoch 109: loss=1.1140391826629639\n",
      "epoch 110: loss=1.1074438095092773\n",
      "epoch 111: loss=1.1267222166061401\n",
      "epoch 112: loss=1.1185197830200195\n",
      "epoch 113: loss=1.1290805339813232\n",
      "epoch 114: loss=1.1157467365264893\n",
      "epoch 115: loss=1.1068602800369263\n",
      "epoch 116: loss=1.119157314300537\n",
      "epoch 117: loss=1.1056327819824219\n",
      "epoch 118: loss=1.131516456604004\n",
      "epoch 119: loss=1.110289454460144\n",
      "epoch 120: loss=1.1191024780273438\n",
      "epoch 121: loss=1.1046324968338013\n",
      "epoch 122: loss=1.101818561553955\n",
      "epoch 123: loss=1.1073437929153442\n",
      "epoch 124: loss=1.0871152877807617\n",
      "epoch 125: loss=1.1141518354415894\n",
      "epoch 126: loss=1.0881614685058594\n",
      "epoch 127: loss=1.1074063777923584\n",
      "epoch 128: loss=1.1163249015808105\n",
      "epoch 129: loss=1.084040641784668\n",
      "epoch 130: loss=1.123459815979004\n",
      "epoch 131: loss=1.1200084686279297\n",
      "epoch 132: loss=1.109017252922058\n",
      "epoch 133: loss=1.09811532497406\n",
      "epoch 134: loss=1.1217740774154663\n",
      "epoch 135: loss=1.11186683177948\n",
      "epoch 136: loss=1.1087088584899902\n",
      "epoch 137: loss=1.1132391691207886\n",
      "epoch 138: loss=1.0984165668487549\n",
      "epoch 139: loss=1.0967657566070557\n",
      "epoch 140: loss=1.1093978881835938\n",
      "epoch 141: loss=1.118546962738037\n",
      "epoch 142: loss=1.105350375175476\n",
      "epoch 143: loss=1.1064833402633667\n",
      "epoch 144: loss=1.1057698726654053\n",
      "epoch 145: loss=1.0888960361480713\n",
      "epoch 146: loss=1.1140000820159912\n",
      "epoch 147: loss=1.0941928625106812\n",
      "epoch 148: loss=1.0960102081298828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149: loss=1.0990424156188965\n",
      "epoch 150: loss=1.0894814729690552\n",
      "epoch 151: loss=1.0968657732009888\n",
      "epoch 152: loss=1.119612693786621\n",
      "epoch 153: loss=1.0807838439941406\n",
      "epoch 154: loss=1.0986043214797974\n",
      "epoch 155: loss=1.0780518054962158\n",
      "epoch 156: loss=1.1114001274108887\n",
      "epoch 157: loss=1.1009589433670044\n",
      "epoch 158: loss=1.1017189025878906\n",
      "epoch 159: loss=1.1089584827423096\n",
      "epoch 160: loss=1.0914983749389648\n",
      "epoch 161: loss=1.0939745903015137\n",
      "epoch 162: loss=1.1035852432250977\n",
      "epoch 163: loss=1.0823359489440918\n",
      "epoch 164: loss=1.1026723384857178\n",
      "epoch 165: loss=1.0811973810195923\n",
      "epoch 166: loss=1.086662769317627\n",
      "epoch 167: loss=1.0892139673233032\n",
      "epoch 168: loss=1.0887277126312256\n",
      "epoch 169: loss=1.0970845222473145\n",
      "epoch 170: loss=1.0871891975402832\n",
      "epoch 171: loss=1.099916934967041\n",
      "epoch 172: loss=1.0911363363265991\n",
      "epoch 173: loss=1.0942914485931396\n",
      "epoch 174: loss=1.1008938550949097\n",
      "epoch 175: loss=1.0618126392364502\n",
      "epoch 176: loss=1.0896421670913696\n",
      "epoch 177: loss=1.0939446687698364\n",
      "epoch 178: loss=1.083197832107544\n",
      "epoch 179: loss=1.075817346572876\n",
      "epoch 180: loss=1.0973734855651855\n",
      "epoch 181: loss=1.1084598302841187\n",
      "epoch 182: loss=1.0718544721603394\n",
      "epoch 183: loss=1.0839543342590332\n",
      "epoch 184: loss=1.087849736213684\n",
      "epoch 185: loss=1.0968759059906006\n",
      "epoch 186: loss=1.068177342414856\n",
      "epoch 187: loss=1.082531452178955\n",
      "epoch 188: loss=1.0843678712844849\n",
      "epoch 189: loss=1.0911180973052979\n",
      "epoch 190: loss=1.1002229452133179\n",
      "epoch 191: loss=1.0682563781738281\n",
      "epoch 192: loss=1.1018997430801392\n",
      "epoch 193: loss=1.0945322513580322\n",
      "epoch 194: loss=1.099043607711792\n",
      "epoch 195: loss=1.0942602157592773\n",
      "epoch 196: loss=1.0837985277175903\n",
      "epoch 197: loss=1.0838886499404907\n",
      "epoch 198: loss=1.0693823099136353\n",
      "epoch 199: loss=1.089519739151001\n",
      "training patch with 1652 edges\n",
      "epoch 0: loss=10.22365951538086\n",
      "epoch 1: loss=9.738659858703613\n",
      "epoch 2: loss=9.1256742477417\n",
      "epoch 3: loss=8.637625694274902\n",
      "epoch 4: loss=8.849593162536621\n",
      "epoch 5: loss=8.311017036437988\n",
      "epoch 6: loss=7.358439922332764\n",
      "epoch 7: loss=6.6026611328125\n",
      "epoch 8: loss=6.264927864074707\n",
      "epoch 9: loss=5.661109447479248\n",
      "epoch 10: loss=5.112014293670654\n",
      "epoch 11: loss=4.159262657165527\n",
      "epoch 12: loss=3.791036605834961\n",
      "epoch 13: loss=3.3935441970825195\n",
      "epoch 14: loss=2.629990339279175\n",
      "epoch 15: loss=2.504120111465454\n",
      "epoch 16: loss=2.1922647953033447\n",
      "epoch 17: loss=1.9821836948394775\n",
      "epoch 18: loss=1.9189012050628662\n",
      "epoch 19: loss=1.9827364683151245\n",
      "epoch 20: loss=1.9102067947387695\n",
      "epoch 21: loss=1.8097310066223145\n",
      "epoch 22: loss=1.7553036212921143\n",
      "epoch 23: loss=1.7274277210235596\n",
      "epoch 24: loss=1.7255170345306396\n",
      "epoch 25: loss=1.7168645858764648\n",
      "epoch 26: loss=1.7359074354171753\n",
      "epoch 27: loss=1.7189668416976929\n",
      "epoch 28: loss=1.7059460878372192\n",
      "epoch 29: loss=1.6895345449447632\n",
      "epoch 30: loss=1.6955125331878662\n",
      "epoch 31: loss=1.6889899969100952\n",
      "epoch 32: loss=1.6713149547576904\n",
      "epoch 33: loss=1.6518852710723877\n",
      "epoch 34: loss=1.6432002782821655\n",
      "epoch 35: loss=1.6359056234359741\n",
      "epoch 36: loss=1.6356903314590454\n",
      "epoch 37: loss=1.612337589263916\n",
      "epoch 38: loss=1.600149154663086\n",
      "epoch 39: loss=1.5947624444961548\n",
      "epoch 40: loss=1.5781855583190918\n",
      "epoch 41: loss=1.5503489971160889\n",
      "epoch 42: loss=1.522584080696106\n",
      "epoch 43: loss=1.5267983675003052\n",
      "epoch 44: loss=1.4940530061721802\n",
      "epoch 45: loss=1.4752461910247803\n",
      "epoch 46: loss=1.4567091464996338\n",
      "epoch 47: loss=1.4195587635040283\n",
      "epoch 48: loss=1.4498035907745361\n",
      "epoch 49: loss=1.399983286857605\n",
      "epoch 50: loss=1.418470025062561\n",
      "epoch 51: loss=1.4210922718048096\n",
      "epoch 52: loss=1.3660005331039429\n",
      "epoch 53: loss=1.34621262550354\n",
      "epoch 54: loss=1.344302773475647\n",
      "epoch 55: loss=1.3690791130065918\n",
      "epoch 56: loss=1.347926378250122\n",
      "epoch 57: loss=1.3301417827606201\n",
      "epoch 58: loss=1.3383746147155762\n",
      "epoch 59: loss=1.3308556079864502\n",
      "epoch 60: loss=1.3350900411605835\n",
      "epoch 61: loss=1.330873966217041\n",
      "epoch 62: loss=1.2831964492797852\n",
      "epoch 63: loss=1.295638084411621\n",
      "epoch 64: loss=1.2766387462615967\n",
      "epoch 65: loss=1.300404667854309\n",
      "epoch 66: loss=1.3156884908676147\n",
      "epoch 67: loss=1.2934821844100952\n",
      "epoch 68: loss=1.2647920846939087\n",
      "epoch 69: loss=1.275063395500183\n",
      "epoch 70: loss=1.287736415863037\n",
      "epoch 71: loss=1.2639816999435425\n",
      "epoch 72: loss=1.2689090967178345\n",
      "epoch 73: loss=1.2746357917785645\n",
      "epoch 74: loss=1.2680531740188599\n",
      "epoch 75: loss=1.2572962045669556\n",
      "epoch 76: loss=1.2405496835708618\n",
      "epoch 77: loss=1.2357943058013916\n",
      "epoch 78: loss=1.2682642936706543\n",
      "epoch 79: loss=1.2310880422592163\n",
      "epoch 80: loss=1.237626314163208\n",
      "epoch 81: loss=1.274611234664917\n",
      "epoch 82: loss=1.2821598052978516\n",
      "epoch 83: loss=1.2610282897949219\n",
      "epoch 84: loss=1.248582363128662\n",
      "epoch 85: loss=1.2518292665481567\n",
      "epoch 86: loss=1.2244709730148315\n",
      "epoch 87: loss=1.245043396949768\n",
      "epoch 88: loss=1.258378028869629\n",
      "epoch 89: loss=1.2633345127105713\n",
      "epoch 90: loss=1.237655758857727\n",
      "epoch 91: loss=1.2173371315002441\n",
      "epoch 92: loss=1.2242918014526367\n",
      "epoch 93: loss=1.2423393726348877\n",
      "epoch 94: loss=1.232410192489624\n",
      "epoch 95: loss=1.233681082725525\n",
      "epoch 96: loss=1.2458243370056152\n",
      "epoch 97: loss=1.222084879875183\n",
      "epoch 98: loss=1.2052128314971924\n",
      "epoch 99: loss=1.2237094640731812\n",
      "epoch 100: loss=1.2091048955917358\n",
      "epoch 101: loss=1.2323157787322998\n",
      "epoch 102: loss=1.2470879554748535\n",
      "epoch 103: loss=1.2432475090026855\n",
      "epoch 104: loss=1.198265790939331\n",
      "epoch 105: loss=1.2155513763427734\n",
      "epoch 106: loss=1.226142406463623\n",
      "epoch 107: loss=1.2339394092559814\n",
      "epoch 108: loss=1.2330347299575806\n",
      "epoch 109: loss=1.2277809381484985\n",
      "epoch 110: loss=1.2136116027832031\n",
      "epoch 111: loss=1.2322319746017456\n",
      "epoch 112: loss=1.2403331995010376\n",
      "epoch 113: loss=1.20915949344635\n",
      "epoch 114: loss=1.197616457939148\n",
      "epoch 115: loss=1.2076104879379272\n",
      "epoch 116: loss=1.238079309463501\n",
      "epoch 117: loss=1.2078914642333984\n",
      "epoch 118: loss=1.2081935405731201\n",
      "epoch 119: loss=1.2004505395889282\n",
      "epoch 120: loss=1.2355612516403198\n",
      "epoch 121: loss=1.215964436531067\n",
      "epoch 122: loss=1.2299199104309082\n",
      "epoch 123: loss=1.2417948246002197\n",
      "epoch 124: loss=1.1960618495941162\n",
      "epoch 125: loss=1.20186185836792\n",
      "epoch 126: loss=1.2338074445724487\n",
      "epoch 127: loss=1.211200475692749\n",
      "epoch 128: loss=1.2242398262023926\n",
      "epoch 129: loss=1.2217869758605957\n",
      "epoch 130: loss=1.2279598712921143\n",
      "epoch 131: loss=1.1995097398757935\n",
      "epoch 132: loss=1.20955228805542\n",
      "epoch 133: loss=1.1735975742340088\n",
      "epoch 134: loss=1.20380699634552\n",
      "epoch 135: loss=1.180500864982605\n",
      "epoch 136: loss=1.2235684394836426\n",
      "epoch 137: loss=1.2381863594055176\n",
      "epoch 138: loss=1.2005317211151123\n",
      "epoch 139: loss=1.234493613243103\n",
      "epoch 140: loss=1.1835100650787354\n",
      "epoch 141: loss=1.1780879497528076\n",
      "epoch 142: loss=1.2130844593048096\n",
      "epoch 143: loss=1.1778866052627563\n",
      "epoch 144: loss=1.1994473934173584\n",
      "epoch 145: loss=1.2119956016540527\n",
      "epoch 146: loss=1.1957508325576782\n",
      "epoch 147: loss=1.1977975368499756\n",
      "epoch 148: loss=1.197091817855835\n",
      "epoch 149: loss=1.203977346420288\n",
      "epoch 150: loss=1.1955573558807373\n",
      "epoch 151: loss=1.2046993970870972\n",
      "epoch 152: loss=1.1852543354034424\n",
      "epoch 153: loss=1.1967614889144897\n",
      "epoch 154: loss=1.1796561479568481\n",
      "epoch 155: loss=1.2033319473266602\n",
      "epoch 156: loss=1.2204864025115967\n",
      "epoch 157: loss=1.2018687725067139\n",
      "epoch 158: loss=1.207788348197937\n",
      "epoch 159: loss=1.1800669431686401\n",
      "epoch 160: loss=1.2081857919692993\n",
      "epoch 161: loss=1.2127320766448975\n",
      "epoch 162: loss=1.1755092144012451\n",
      "epoch 163: loss=1.16425359249115\n",
      "epoch 164: loss=1.217742681503296\n",
      "epoch 165: loss=1.207186222076416\n",
      "epoch 166: loss=1.1837046146392822\n",
      "epoch 167: loss=1.1784522533416748\n",
      "epoch 168: loss=1.2008094787597656\n",
      "epoch 169: loss=1.1892105340957642\n",
      "epoch 170: loss=1.2158013582229614\n",
      "epoch 171: loss=1.2184627056121826\n",
      "epoch 172: loss=1.2300684452056885\n",
      "epoch 173: loss=1.2010786533355713\n",
      "epoch 174: loss=1.2121484279632568\n",
      "epoch 175: loss=1.2124874591827393\n",
      "epoch 176: loss=1.2185062170028687\n",
      "epoch 177: loss=1.2127540111541748\n",
      "epoch 178: loss=1.1784820556640625\n",
      "epoch 179: loss=1.1916894912719727\n",
      "epoch 180: loss=1.174418568611145\n",
      "epoch 181: loss=1.2156516313552856\n",
      "epoch 182: loss=1.1924588680267334\n",
      "epoch 183: loss=1.1848398447036743\n",
      "epoch 184: loss=1.209059715270996\n",
      "epoch 185: loss=1.1952314376831055\n",
      "epoch 186: loss=1.1900556087493896\n",
      "epoch 187: loss=1.2179542779922485\n",
      "epoch 188: loss=1.1798999309539795\n",
      "epoch 189: loss=1.2105238437652588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190: loss=1.1627099514007568\n",
      "epoch 191: loss=1.2030998468399048\n",
      "epoch 192: loss=1.176172137260437\n",
      "epoch 193: loss=1.1956608295440674\n",
      "epoch 194: loss=1.187885046005249\n",
      "epoch 195: loss=1.1593931913375854\n",
      "epoch 196: loss=1.175851821899414\n",
      "epoch 197: loss=1.1849838495254517\n",
      "epoch 198: loss=1.1979944705963135\n",
      "epoch 199: loss=1.1969934701919556\n",
      "training patch with 840 edges\n",
      "epoch 0: loss=9.985466957092285\n",
      "epoch 1: loss=9.183784484863281\n",
      "epoch 2: loss=9.364657402038574\n",
      "epoch 3: loss=8.605653762817383\n",
      "epoch 4: loss=8.464365005493164\n",
      "epoch 5: loss=8.79489517211914\n",
      "epoch 6: loss=8.254536628723145\n",
      "epoch 7: loss=6.919766902923584\n",
      "epoch 8: loss=6.553049564361572\n",
      "epoch 9: loss=6.452166557312012\n",
      "epoch 10: loss=5.7149224281311035\n",
      "epoch 11: loss=5.3822021484375\n",
      "epoch 12: loss=4.957533836364746\n",
      "epoch 13: loss=4.706061363220215\n",
      "epoch 14: loss=3.9848122596740723\n",
      "epoch 15: loss=3.4268429279327393\n",
      "epoch 16: loss=2.9741170406341553\n",
      "epoch 17: loss=2.8342952728271484\n",
      "epoch 18: loss=2.546072483062744\n",
      "epoch 19: loss=2.4178085327148438\n",
      "epoch 20: loss=2.2077860832214355\n",
      "epoch 21: loss=2.238260269165039\n",
      "epoch 22: loss=2.0870683193206787\n",
      "epoch 23: loss=2.0589184761047363\n",
      "epoch 24: loss=1.967070460319519\n",
      "epoch 25: loss=1.9320993423461914\n",
      "epoch 26: loss=1.8863871097564697\n",
      "epoch 27: loss=1.9142022132873535\n",
      "epoch 28: loss=1.8641475439071655\n",
      "epoch 29: loss=1.883765459060669\n",
      "epoch 30: loss=1.9167025089263916\n",
      "epoch 31: loss=1.8577766418457031\n",
      "epoch 32: loss=1.8508960008621216\n",
      "epoch 33: loss=1.8168342113494873\n",
      "epoch 34: loss=1.8271372318267822\n",
      "epoch 35: loss=1.8105449676513672\n",
      "epoch 36: loss=1.8142527341842651\n",
      "epoch 37: loss=1.8081400394439697\n",
      "epoch 38: loss=1.7622661590576172\n",
      "epoch 39: loss=1.780719518661499\n",
      "epoch 40: loss=1.7279236316680908\n",
      "epoch 41: loss=1.6942039728164673\n",
      "epoch 42: loss=1.6966619491577148\n",
      "epoch 43: loss=1.6429818868637085\n",
      "epoch 44: loss=1.660573124885559\n",
      "epoch 45: loss=1.65607750415802\n",
      "epoch 46: loss=1.6158483028411865\n",
      "epoch 47: loss=1.5908043384552002\n",
      "epoch 48: loss=1.5564709901809692\n",
      "epoch 49: loss=1.6064953804016113\n",
      "epoch 50: loss=1.5664024353027344\n",
      "epoch 51: loss=1.585718035697937\n",
      "epoch 52: loss=1.5669652223587036\n",
      "epoch 53: loss=1.5826396942138672\n",
      "epoch 54: loss=1.551945447921753\n",
      "epoch 55: loss=1.523246169090271\n",
      "epoch 56: loss=1.527343988418579\n",
      "epoch 57: loss=1.5241022109985352\n",
      "epoch 58: loss=1.4955224990844727\n",
      "epoch 59: loss=1.5095351934432983\n",
      "epoch 60: loss=1.4661818742752075\n",
      "epoch 61: loss=1.453708291053772\n",
      "epoch 62: loss=1.4639747142791748\n",
      "epoch 63: loss=1.4833507537841797\n",
      "epoch 64: loss=1.5069602727890015\n",
      "epoch 65: loss=1.453392505645752\n",
      "epoch 66: loss=1.4673057794570923\n",
      "epoch 67: loss=1.480177879333496\n",
      "epoch 68: loss=1.4636679887771606\n",
      "epoch 69: loss=1.503257155418396\n",
      "epoch 70: loss=1.4462664127349854\n",
      "epoch 71: loss=1.469868779182434\n",
      "epoch 72: loss=1.433542251586914\n",
      "epoch 73: loss=1.491528034210205\n",
      "epoch 74: loss=1.4202892780303955\n",
      "epoch 75: loss=1.411695122718811\n",
      "epoch 76: loss=1.4763163328170776\n",
      "epoch 77: loss=1.442732810974121\n",
      "epoch 78: loss=1.4317587614059448\n",
      "epoch 79: loss=1.4149200916290283\n",
      "epoch 80: loss=1.4517742395401\n",
      "epoch 81: loss=1.3807032108306885\n",
      "epoch 82: loss=1.3542149066925049\n",
      "epoch 83: loss=1.4492663145065308\n",
      "epoch 84: loss=1.4196012020111084\n",
      "epoch 85: loss=1.4059627056121826\n",
      "epoch 86: loss=1.4656554460525513\n",
      "epoch 87: loss=1.3951302766799927\n",
      "epoch 88: loss=1.3680567741394043\n",
      "epoch 89: loss=1.4420439004898071\n",
      "epoch 90: loss=1.4169087409973145\n",
      "epoch 91: loss=1.4014523029327393\n",
      "epoch 92: loss=1.380943775177002\n",
      "epoch 93: loss=1.4308444261550903\n",
      "epoch 94: loss=1.4195815324783325\n",
      "epoch 95: loss=1.379373550415039\n",
      "epoch 96: loss=1.4560989141464233\n",
      "epoch 97: loss=1.468950867652893\n",
      "epoch 98: loss=1.3971500396728516\n",
      "epoch 99: loss=1.4342200756072998\n",
      "epoch 100: loss=1.4177703857421875\n",
      "epoch 101: loss=1.4158860445022583\n",
      "epoch 102: loss=1.3862824440002441\n",
      "epoch 103: loss=1.392615795135498\n",
      "epoch 104: loss=1.3991804122924805\n",
      "epoch 105: loss=1.4745993614196777\n",
      "epoch 106: loss=1.4105911254882812\n",
      "epoch 107: loss=1.3602113723754883\n",
      "epoch 108: loss=1.4659534692764282\n",
      "epoch 109: loss=1.3830416202545166\n",
      "epoch 110: loss=1.3556768894195557\n",
      "epoch 111: loss=1.41282057762146\n",
      "epoch 112: loss=1.4018560647964478\n",
      "epoch 113: loss=1.4361652135849\n",
      "epoch 114: loss=1.381385087966919\n",
      "epoch 115: loss=1.3988614082336426\n",
      "epoch 116: loss=1.396598219871521\n",
      "epoch 117: loss=1.40589439868927\n",
      "epoch 118: loss=1.4279444217681885\n",
      "epoch 119: loss=1.4080660343170166\n",
      "epoch 120: loss=1.3870234489440918\n",
      "epoch 121: loss=1.4461101293563843\n",
      "epoch 122: loss=1.3974621295928955\n",
      "epoch 123: loss=1.3926963806152344\n",
      "epoch 124: loss=1.3862965106964111\n",
      "epoch 125: loss=1.3204530477523804\n",
      "epoch 126: loss=1.358911395072937\n",
      "epoch 127: loss=1.423367977142334\n",
      "epoch 128: loss=1.351744532585144\n",
      "epoch 129: loss=1.3969827890396118\n",
      "epoch 130: loss=1.384878158569336\n",
      "epoch 131: loss=1.3998104333877563\n",
      "epoch 132: loss=1.3713852167129517\n",
      "epoch 133: loss=1.4187326431274414\n",
      "epoch 134: loss=1.415642499923706\n",
      "epoch 135: loss=1.4235658645629883\n",
      "epoch 136: loss=1.3740010261535645\n",
      "epoch 137: loss=1.3524264097213745\n",
      "epoch 138: loss=1.4144532680511475\n",
      "epoch 139: loss=1.4287350177764893\n",
      "epoch 140: loss=1.451159954071045\n",
      "epoch 141: loss=1.384846568107605\n",
      "epoch 142: loss=1.3789030313491821\n",
      "epoch 143: loss=1.4008961915969849\n",
      "epoch 144: loss=1.414644479751587\n",
      "epoch 145: loss=1.4406545162200928\n",
      "epoch 146: loss=1.36863112449646\n",
      "epoch 147: loss=1.366955041885376\n",
      "epoch 148: loss=1.4123286008834839\n",
      "epoch 149: loss=1.3979849815368652\n",
      "epoch 150: loss=1.3876185417175293\n",
      "epoch 151: loss=1.3774023056030273\n",
      "epoch 152: loss=1.415543794631958\n",
      "epoch 153: loss=1.428707242012024\n",
      "epoch 154: loss=1.3901515007019043\n",
      "epoch 155: loss=1.4317784309387207\n",
      "epoch 156: loss=1.3858014345169067\n",
      "epoch 157: loss=1.3891762495040894\n",
      "epoch 158: loss=1.4287009239196777\n",
      "epoch 159: loss=1.4251128435134888\n",
      "epoch 160: loss=1.343530297279358\n",
      "epoch 161: loss=1.3682491779327393\n",
      "epoch 162: loss=1.3955284357070923\n",
      "epoch 163: loss=1.394106149673462\n",
      "epoch 164: loss=1.4171719551086426\n",
      "epoch 165: loss=1.387468695640564\n",
      "epoch 166: loss=1.3927085399627686\n",
      "epoch 167: loss=1.4369521141052246\n",
      "epoch 168: loss=1.390533208847046\n",
      "epoch 169: loss=1.3831576108932495\n",
      "epoch 170: loss=1.3998515605926514\n",
      "epoch 171: loss=1.4159823656082153\n",
      "epoch 172: loss=1.4013053178787231\n",
      "epoch 173: loss=1.3827283382415771\n",
      "epoch 174: loss=1.4416717290878296\n",
      "epoch 175: loss=1.3774844408035278\n",
      "epoch 176: loss=1.3510916233062744\n",
      "epoch 177: loss=1.3975799083709717\n",
      "epoch 178: loss=1.38686203956604\n",
      "epoch 179: loss=1.395545482635498\n",
      "epoch 180: loss=1.382836937904358\n",
      "epoch 181: loss=1.3765532970428467\n",
      "epoch 182: loss=1.449511170387268\n",
      "epoch 183: loss=1.399946928024292\n",
      "epoch 184: loss=1.4123857021331787\n",
      "epoch 185: loss=1.3521684408187866\n",
      "epoch 186: loss=1.386839509010315\n",
      "epoch 187: loss=1.3900761604309082\n",
      "epoch 188: loss=1.3721728324890137\n",
      "epoch 189: loss=1.3979111909866333\n",
      "epoch 190: loss=1.3535561561584473\n",
      "epoch 191: loss=1.383830189704895\n",
      "epoch 192: loss=1.3708378076553345\n",
      "epoch 193: loss=1.3983018398284912\n",
      "epoch 194: loss=1.3912944793701172\n",
      "epoch 195: loss=1.3365952968597412\n",
      "epoch 196: loss=1.3685444593429565\n",
      "epoch 197: loss=1.3255867958068848\n",
      "epoch 198: loss=1.3488898277282715\n",
      "epoch 199: loss=1.3643730878829956\n",
      "training patch with 1460 edges\n",
      "epoch 0: loss=10.11339282989502\n",
      "epoch 1: loss=9.43836498260498\n",
      "epoch 2: loss=9.732527732849121\n",
      "epoch 3: loss=9.530745506286621\n",
      "epoch 4: loss=8.598016738891602\n",
      "epoch 5: loss=7.816978931427002\n",
      "epoch 6: loss=7.228330135345459\n",
      "epoch 7: loss=6.015432834625244\n",
      "epoch 8: loss=5.843822479248047\n",
      "epoch 9: loss=6.049067497253418\n",
      "epoch 10: loss=5.166084289550781\n",
      "epoch 11: loss=4.69795036315918\n",
      "epoch 12: loss=3.948089599609375\n",
      "epoch 13: loss=3.24326753616333\n",
      "epoch 14: loss=2.9506664276123047\n",
      "epoch 15: loss=2.7062323093414307\n",
      "epoch 16: loss=2.5134377479553223\n",
      "epoch 17: loss=2.4534716606140137\n",
      "epoch 18: loss=2.2405824661254883\n",
      "epoch 19: loss=2.1693153381347656\n",
      "epoch 20: loss=2.0513694286346436\n",
      "epoch 21: loss=1.975643277168274\n",
      "epoch 22: loss=1.8499325513839722\n",
      "epoch 23: loss=1.8514580726623535\n",
      "epoch 24: loss=1.78117036819458\n",
      "epoch 25: loss=1.7874693870544434\n",
      "epoch 26: loss=1.7553014755249023\n",
      "epoch 27: loss=1.7437858581542969\n",
      "epoch 28: loss=1.7391738891601562\n",
      "epoch 29: loss=1.7152471542358398\n",
      "epoch 30: loss=1.7172808647155762\n",
      "epoch 31: loss=1.6677494049072266\n",
      "epoch 32: loss=1.6834616661071777\n",
      "epoch 33: loss=1.698272466659546\n",
      "epoch 34: loss=1.663292407989502\n",
      "epoch 35: loss=1.6771719455718994\n",
      "epoch 36: loss=1.6577873229980469\n",
      "epoch 37: loss=1.656226396560669\n",
      "epoch 38: loss=1.6492092609405518\n",
      "epoch 39: loss=1.606576919555664\n",
      "epoch 40: loss=1.6213399171829224\n",
      "epoch 41: loss=1.6076658964157104\n",
      "epoch 42: loss=1.595287561416626\n",
      "epoch 43: loss=1.5648746490478516\n",
      "epoch 44: loss=1.5629830360412598\n",
      "epoch 45: loss=1.5386343002319336\n",
      "epoch 46: loss=1.51438307762146\n",
      "epoch 47: loss=1.5230648517608643\n",
      "epoch 48: loss=1.4824732542037964\n",
      "epoch 49: loss=1.4542442560195923\n",
      "epoch 50: loss=1.4551708698272705\n",
      "epoch 51: loss=1.4949438571929932\n",
      "epoch 52: loss=1.4597728252410889\n",
      "epoch 53: loss=1.450070858001709\n",
      "epoch 54: loss=1.4325602054595947\n",
      "epoch 55: loss=1.4035879373550415\n",
      "epoch 56: loss=1.426954984664917\n",
      "epoch 57: loss=1.3937232494354248\n",
      "epoch 58: loss=1.395333170890808\n",
      "epoch 59: loss=1.3713531494140625\n",
      "epoch 60: loss=1.405440330505371\n",
      "epoch 61: loss=1.3845224380493164\n",
      "epoch 62: loss=1.3377649784088135\n",
      "epoch 63: loss=1.401747226715088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64: loss=1.397032618522644\n",
      "epoch 65: loss=1.3470523357391357\n",
      "epoch 66: loss=1.3328856229782104\n",
      "epoch 67: loss=1.3400508165359497\n",
      "epoch 68: loss=1.36090087890625\n",
      "epoch 69: loss=1.3383796215057373\n",
      "epoch 70: loss=1.3525524139404297\n",
      "epoch 71: loss=1.376031517982483\n",
      "epoch 72: loss=1.3801870346069336\n",
      "epoch 73: loss=1.3768770694732666\n",
      "epoch 74: loss=1.3417333364486694\n",
      "epoch 75: loss=1.326256513595581\n",
      "epoch 76: loss=1.3467978239059448\n",
      "epoch 77: loss=1.351711630821228\n",
      "epoch 78: loss=1.3357857465744019\n",
      "epoch 79: loss=1.3384915590286255\n",
      "epoch 80: loss=1.327064037322998\n",
      "epoch 81: loss=1.3289352655410767\n",
      "epoch 82: loss=1.358931541442871\n",
      "epoch 83: loss=1.3310191631317139\n",
      "epoch 84: loss=1.3176579475402832\n",
      "epoch 85: loss=1.3006891012191772\n",
      "epoch 86: loss=1.3390116691589355\n",
      "epoch 87: loss=1.3026093244552612\n",
      "epoch 88: loss=1.3052135705947876\n",
      "epoch 89: loss=1.3331364393234253\n",
      "epoch 90: loss=1.2996457815170288\n",
      "epoch 91: loss=1.2949130535125732\n",
      "epoch 92: loss=1.3029192686080933\n",
      "epoch 93: loss=1.277127742767334\n",
      "epoch 94: loss=1.2901171445846558\n",
      "epoch 95: loss=1.350380539894104\n",
      "epoch 96: loss=1.3108046054840088\n",
      "epoch 97: loss=1.294463872909546\n",
      "epoch 98: loss=1.2950317859649658\n",
      "epoch 99: loss=1.3123811483383179\n",
      "epoch 100: loss=1.277984380722046\n",
      "epoch 101: loss=1.294702410697937\n",
      "epoch 102: loss=1.2810349464416504\n",
      "epoch 103: loss=1.3166548013687134\n",
      "epoch 104: loss=1.3026533126831055\n",
      "epoch 105: loss=1.3329137563705444\n",
      "epoch 106: loss=1.2917556762695312\n",
      "epoch 107: loss=1.2860257625579834\n",
      "epoch 108: loss=1.324357509613037\n",
      "epoch 109: loss=1.301277756690979\n",
      "epoch 110: loss=1.2609806060791016\n",
      "epoch 111: loss=1.3062788248062134\n",
      "epoch 112: loss=1.3253214359283447\n",
      "epoch 113: loss=1.3303526639938354\n",
      "epoch 114: loss=1.2914228439331055\n",
      "epoch 115: loss=1.2741605043411255\n",
      "epoch 116: loss=1.2565346956253052\n",
      "epoch 117: loss=1.2759144306182861\n",
      "epoch 118: loss=1.2828495502471924\n",
      "epoch 119: loss=1.3166977167129517\n",
      "epoch 120: loss=1.2591731548309326\n",
      "epoch 121: loss=1.276531457901001\n",
      "epoch 122: loss=1.254638433456421\n",
      "epoch 123: loss=1.3055105209350586\n",
      "epoch 124: loss=1.253265142440796\n",
      "epoch 125: loss=1.289269208908081\n",
      "epoch 126: loss=1.2838177680969238\n",
      "epoch 127: loss=1.257388710975647\n",
      "epoch 128: loss=1.2512168884277344\n",
      "epoch 129: loss=1.3198726177215576\n",
      "epoch 130: loss=1.2666614055633545\n",
      "epoch 131: loss=1.2420988082885742\n",
      "epoch 132: loss=1.2809414863586426\n",
      "epoch 133: loss=1.2913482189178467\n",
      "epoch 134: loss=1.253718376159668\n",
      "epoch 135: loss=1.2523279190063477\n",
      "epoch 136: loss=1.276637315750122\n",
      "epoch 137: loss=1.2817296981811523\n",
      "epoch 138: loss=1.2538255453109741\n",
      "epoch 139: loss=1.277445912361145\n",
      "epoch 140: loss=1.2581079006195068\n",
      "epoch 141: loss=1.2564951181411743\n",
      "epoch 142: loss=1.2868236303329468\n",
      "epoch 143: loss=1.2868953943252563\n",
      "epoch 144: loss=1.294697880744934\n",
      "epoch 145: loss=1.252058744430542\n",
      "epoch 146: loss=1.2495932579040527\n",
      "epoch 147: loss=1.2933460474014282\n",
      "epoch 148: loss=1.2862999439239502\n",
      "epoch 149: loss=1.2594183683395386\n",
      "epoch 150: loss=1.2951232194900513\n",
      "epoch 151: loss=1.2865755558013916\n",
      "epoch 152: loss=1.2441681623458862\n",
      "epoch 153: loss=1.261405110359192\n",
      "epoch 154: loss=1.2738871574401855\n",
      "epoch 155: loss=1.2825745344161987\n",
      "epoch 156: loss=1.272629737854004\n",
      "epoch 157: loss=1.278743028640747\n",
      "epoch 158: loss=1.282609462738037\n",
      "epoch 159: loss=1.277807354927063\n",
      "epoch 160: loss=1.2689812183380127\n",
      "epoch 161: loss=1.2749576568603516\n",
      "epoch 162: loss=1.2613924741744995\n",
      "epoch 163: loss=1.2854644060134888\n",
      "epoch 164: loss=1.307139277458191\n",
      "epoch 165: loss=1.2572497129440308\n",
      "epoch 166: loss=1.2789759635925293\n",
      "epoch 167: loss=1.2336212396621704\n",
      "epoch 168: loss=1.2870495319366455\n",
      "epoch 169: loss=1.2597893476486206\n",
      "epoch 170: loss=1.2449214458465576\n",
      "epoch 171: loss=1.281967282295227\n",
      "epoch 172: loss=1.2550921440124512\n",
      "epoch 173: loss=1.2578299045562744\n",
      "epoch 174: loss=1.2514393329620361\n",
      "epoch 175: loss=1.2473281621932983\n",
      "epoch 176: loss=1.2780474424362183\n",
      "epoch 177: loss=1.2539819478988647\n",
      "epoch 178: loss=1.2524139881134033\n",
      "epoch 179: loss=1.2495956420898438\n",
      "epoch 180: loss=1.2486631870269775\n",
      "epoch 181: loss=1.2891470193862915\n",
      "epoch 182: loss=1.2523587942123413\n",
      "epoch 183: loss=1.2924623489379883\n",
      "epoch 184: loss=1.3084534406661987\n",
      "epoch 185: loss=1.2673386335372925\n",
      "epoch 186: loss=1.2502437829971313\n",
      "epoch 187: loss=1.2582975625991821\n",
      "epoch 188: loss=1.2730035781860352\n",
      "epoch 189: loss=1.2758426666259766\n",
      "epoch 190: loss=1.2433441877365112\n",
      "epoch 191: loss=1.233839511871338\n",
      "epoch 192: loss=1.246922492980957\n",
      "epoch 193: loss=1.2722017765045166\n",
      "epoch 194: loss=1.2780954837799072\n",
      "epoch 195: loss=1.2747275829315186\n",
      "epoch 196: loss=1.2670456171035767\n",
      "epoch 197: loss=1.2423932552337646\n",
      "epoch 198: loss=1.2905508279800415\n",
      "epoch 199: loss=1.2341711521148682\n",
      "training patch with 764 edges\n",
      "epoch 0: loss=9.579883575439453\n",
      "epoch 1: loss=9.599746704101562\n",
      "epoch 2: loss=9.664816856384277\n",
      "epoch 3: loss=10.22990608215332\n",
      "epoch 4: loss=8.887412071228027\n",
      "epoch 5: loss=8.635030746459961\n",
      "epoch 6: loss=8.962225914001465\n",
      "epoch 7: loss=7.252425670623779\n",
      "epoch 8: loss=7.001074314117432\n",
      "epoch 9: loss=6.973021507263184\n",
      "epoch 10: loss=6.115371227264404\n",
      "epoch 11: loss=5.974382400512695\n",
      "epoch 12: loss=5.346866607666016\n",
      "epoch 13: loss=4.59414005279541\n",
      "epoch 14: loss=4.350503444671631\n",
      "epoch 15: loss=3.479170560836792\n",
      "epoch 16: loss=3.0325591564178467\n",
      "epoch 17: loss=2.776693105697632\n",
      "epoch 18: loss=2.511953830718994\n",
      "epoch 19: loss=2.264683723449707\n",
      "epoch 20: loss=2.250354290008545\n",
      "epoch 21: loss=2.1422739028930664\n",
      "epoch 22: loss=2.277139902114868\n",
      "epoch 23: loss=2.1864047050476074\n",
      "epoch 24: loss=2.0880048274993896\n",
      "epoch 25: loss=1.9779272079467773\n",
      "epoch 26: loss=1.9981355667114258\n",
      "epoch 27: loss=1.9968764781951904\n",
      "epoch 28: loss=2.042309045791626\n",
      "epoch 29: loss=2.0581717491149902\n",
      "epoch 30: loss=2.0696349143981934\n",
      "epoch 31: loss=2.0333752632141113\n",
      "epoch 32: loss=2.0245766639709473\n",
      "epoch 33: loss=2.008636951446533\n",
      "epoch 34: loss=2.004415273666382\n",
      "epoch 35: loss=1.9993218183517456\n",
      "epoch 36: loss=1.9659910202026367\n",
      "epoch 37: loss=1.94720458984375\n",
      "epoch 38: loss=1.89802086353302\n",
      "epoch 39: loss=1.9211325645446777\n",
      "epoch 40: loss=1.8368167877197266\n",
      "epoch 41: loss=1.836496114730835\n",
      "epoch 42: loss=1.8137385845184326\n",
      "epoch 43: loss=1.7804924249649048\n",
      "epoch 44: loss=1.7821695804595947\n",
      "epoch 45: loss=1.7145910263061523\n",
      "epoch 46: loss=1.6663100719451904\n",
      "epoch 47: loss=1.6609106063842773\n",
      "epoch 48: loss=1.686311960220337\n",
      "epoch 49: loss=1.6115503311157227\n",
      "epoch 50: loss=1.6491271257400513\n",
      "epoch 51: loss=1.6324162483215332\n",
      "epoch 52: loss=1.5730791091918945\n",
      "epoch 53: loss=1.67081880569458\n",
      "epoch 54: loss=1.6752922534942627\n",
      "epoch 55: loss=1.60233473777771\n",
      "epoch 56: loss=1.5673046112060547\n",
      "epoch 57: loss=1.5177453756332397\n",
      "epoch 58: loss=1.5326523780822754\n",
      "epoch 59: loss=1.6039154529571533\n",
      "epoch 60: loss=1.631772518157959\n",
      "epoch 61: loss=1.5623213052749634\n",
      "epoch 62: loss=1.613236427307129\n",
      "epoch 63: loss=1.5487176179885864\n",
      "epoch 64: loss=1.5320265293121338\n",
      "epoch 65: loss=1.5281431674957275\n",
      "epoch 66: loss=1.543771505355835\n",
      "epoch 67: loss=1.5697249174118042\n",
      "epoch 68: loss=1.5431790351867676\n",
      "epoch 69: loss=1.5623555183410645\n",
      "epoch 70: loss=1.503953218460083\n",
      "epoch 71: loss=1.6541513204574585\n",
      "epoch 72: loss=1.51041841506958\n",
      "epoch 73: loss=1.5649417638778687\n",
      "epoch 74: loss=1.4854727983474731\n",
      "epoch 75: loss=1.598574161529541\n",
      "epoch 76: loss=1.5968327522277832\n",
      "epoch 77: loss=1.5072617530822754\n",
      "epoch 78: loss=1.549304485321045\n",
      "epoch 79: loss=1.530324101448059\n",
      "epoch 80: loss=1.546744704246521\n",
      "epoch 81: loss=1.5454238653182983\n",
      "epoch 82: loss=1.5474627017974854\n",
      "epoch 83: loss=1.5082088708877563\n",
      "epoch 84: loss=1.620718240737915\n",
      "epoch 85: loss=1.5572128295898438\n",
      "epoch 86: loss=1.5662336349487305\n",
      "epoch 87: loss=1.5641016960144043\n",
      "epoch 88: loss=1.4956868886947632\n",
      "epoch 89: loss=1.5400363206863403\n",
      "epoch 90: loss=1.5395671129226685\n",
      "epoch 91: loss=1.524427056312561\n",
      "epoch 92: loss=1.493841290473938\n",
      "epoch 93: loss=1.5534617900848389\n",
      "epoch 94: loss=1.4869911670684814\n",
      "epoch 95: loss=1.458612322807312\n",
      "epoch 96: loss=1.4951306581497192\n",
      "epoch 97: loss=1.5198771953582764\n",
      "epoch 98: loss=1.5213885307312012\n",
      "epoch 99: loss=1.5387232303619385\n",
      "epoch 100: loss=1.4947178363800049\n",
      "epoch 101: loss=1.5665072202682495\n",
      "epoch 102: loss=1.4790631532669067\n",
      "epoch 103: loss=1.533614993095398\n",
      "epoch 104: loss=1.4948809146881104\n",
      "epoch 105: loss=1.518984317779541\n",
      "epoch 106: loss=1.5674515962600708\n",
      "epoch 107: loss=1.542261004447937\n",
      "epoch 108: loss=1.5290892124176025\n",
      "epoch 109: loss=1.5035187005996704\n",
      "epoch 110: loss=1.5642904043197632\n",
      "epoch 111: loss=1.5057663917541504\n",
      "epoch 112: loss=1.58577561378479\n",
      "epoch 113: loss=1.4506759643554688\n",
      "epoch 114: loss=1.4701792001724243\n",
      "epoch 115: loss=1.5167155265808105\n",
      "epoch 116: loss=1.477860689163208\n",
      "epoch 117: loss=1.4918808937072754\n",
      "epoch 118: loss=1.4956257343292236\n",
      "epoch 119: loss=1.453690767288208\n",
      "epoch 120: loss=1.4936892986297607\n",
      "epoch 121: loss=1.4632434844970703\n",
      "epoch 122: loss=1.5112197399139404\n",
      "epoch 123: loss=1.4654524326324463\n",
      "epoch 124: loss=1.5140864849090576\n",
      "epoch 125: loss=1.5254337787628174\n",
      "epoch 126: loss=1.5077126026153564\n",
      "epoch 127: loss=1.51743745803833\n",
      "epoch 128: loss=1.4901220798492432\n",
      "epoch 129: loss=1.5153570175170898\n",
      "epoch 130: loss=1.4878655672073364\n",
      "epoch 131: loss=1.4791061878204346\n",
      "epoch 132: loss=1.5397424697875977\n",
      "epoch 133: loss=1.5406994819641113\n",
      "epoch 134: loss=1.534860610961914\n",
      "epoch 135: loss=1.4990029335021973\n",
      "epoch 136: loss=1.4348440170288086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137: loss=1.532376766204834\n",
      "epoch 138: loss=1.4738763570785522\n",
      "epoch 139: loss=1.4318956136703491\n",
      "epoch 140: loss=1.4709715843200684\n",
      "epoch 141: loss=1.4580556154251099\n",
      "epoch 142: loss=1.4547297954559326\n",
      "epoch 143: loss=1.492464303970337\n",
      "epoch 144: loss=1.4527391195297241\n",
      "epoch 145: loss=1.4440828561782837\n",
      "epoch 146: loss=1.5177778005599976\n",
      "epoch 147: loss=1.4493576288223267\n",
      "epoch 148: loss=1.470219612121582\n",
      "epoch 149: loss=1.5031921863555908\n",
      "epoch 150: loss=1.5084770917892456\n",
      "epoch 151: loss=1.5150458812713623\n",
      "epoch 152: loss=1.5027234554290771\n",
      "epoch 153: loss=1.411475658416748\n",
      "epoch 154: loss=1.4858770370483398\n",
      "epoch 155: loss=1.5297874212265015\n",
      "epoch 156: loss=1.475925326347351\n",
      "epoch 157: loss=1.4669452905654907\n",
      "epoch 158: loss=1.481466293334961\n",
      "epoch 159: loss=1.487472653388977\n",
      "epoch 160: loss=1.4980084896087646\n",
      "epoch 161: loss=1.5188720226287842\n",
      "epoch 162: loss=1.4224377870559692\n",
      "epoch 163: loss=1.5048060417175293\n",
      "epoch 164: loss=1.4651541709899902\n",
      "epoch 165: loss=1.4470627307891846\n",
      "epoch 166: loss=1.488008975982666\n",
      "epoch 167: loss=1.467747449874878\n",
      "epoch 168: loss=1.5205352306365967\n",
      "epoch 169: loss=1.4363231658935547\n",
      "epoch 170: loss=1.4656527042388916\n",
      "epoch 171: loss=1.4729273319244385\n",
      "epoch 172: loss=1.494920015335083\n",
      "epoch 173: loss=1.4672274589538574\n",
      "epoch 174: loss=1.4452228546142578\n",
      "epoch 175: loss=1.4998772144317627\n",
      "epoch 176: loss=1.4813530445098877\n",
      "epoch 177: loss=1.4966130256652832\n",
      "epoch 178: loss=1.5070054531097412\n",
      "epoch 179: loss=1.4780398607254028\n",
      "epoch 180: loss=1.5344330072402954\n",
      "epoch 181: loss=1.4882739782333374\n",
      "epoch 182: loss=1.571993112564087\n",
      "epoch 183: loss=1.5138812065124512\n",
      "epoch 184: loss=1.4697586297988892\n",
      "epoch 185: loss=1.4745690822601318\n",
      "epoch 186: loss=1.506587266921997\n",
      "epoch 187: loss=1.5100866556167603\n",
      "epoch 188: loss=1.4227396249771118\n",
      "epoch 189: loss=1.4254405498504639\n",
      "epoch 190: loss=1.4593634605407715\n",
      "epoch 191: loss=1.484682559967041\n",
      "epoch 192: loss=1.473084568977356\n",
      "epoch 193: loss=1.4462909698486328\n",
      "epoch 194: loss=1.4853005409240723\n",
      "epoch 195: loss=1.4893560409545898\n",
      "epoch 196: loss=1.5303864479064941\n",
      "epoch 197: loss=1.548763632774353\n",
      "epoch 198: loss=1.4600887298583984\n",
      "epoch 199: loss=1.4960112571716309\n",
      "training patch with 950 edges\n",
      "epoch 0: loss=9.869351387023926\n",
      "epoch 1: loss=9.384956359863281\n",
      "epoch 2: loss=9.887253761291504\n",
      "epoch 3: loss=8.95595932006836\n",
      "epoch 4: loss=8.12110424041748\n",
      "epoch 5: loss=7.858086585998535\n",
      "epoch 6: loss=7.667898178100586\n",
      "epoch 7: loss=6.781177997589111\n",
      "epoch 8: loss=6.598640441894531\n",
      "epoch 9: loss=6.001966953277588\n",
      "epoch 10: loss=5.80183219909668\n",
      "epoch 11: loss=5.169192790985107\n",
      "epoch 12: loss=4.701398849487305\n",
      "epoch 13: loss=3.9104621410369873\n",
      "epoch 14: loss=3.7231624126434326\n",
      "epoch 15: loss=3.4748377799987793\n",
      "epoch 16: loss=2.8636224269866943\n",
      "epoch 17: loss=2.496185541152954\n",
      "epoch 18: loss=2.3159890174865723\n",
      "epoch 19: loss=2.336731195449829\n",
      "epoch 20: loss=2.215534210205078\n",
      "epoch 21: loss=2.13740873336792\n",
      "epoch 22: loss=2.164626121520996\n",
      "epoch 23: loss=1.959580421447754\n",
      "epoch 24: loss=1.9553580284118652\n",
      "epoch 25: loss=1.9231244325637817\n",
      "epoch 26: loss=1.9239811897277832\n",
      "epoch 27: loss=1.8978486061096191\n",
      "epoch 28: loss=1.9489336013793945\n",
      "epoch 29: loss=1.9413964748382568\n",
      "epoch 30: loss=1.8782328367233276\n",
      "epoch 31: loss=1.8570823669433594\n",
      "epoch 32: loss=1.8556147813796997\n",
      "epoch 33: loss=1.8694086074829102\n",
      "epoch 34: loss=1.852805256843567\n",
      "epoch 35: loss=1.8502740859985352\n",
      "epoch 36: loss=1.863950252532959\n",
      "epoch 37: loss=1.820430040359497\n",
      "epoch 38: loss=1.8196189403533936\n",
      "epoch 39: loss=1.8424396514892578\n",
      "epoch 40: loss=1.8089556694030762\n",
      "epoch 41: loss=1.8109357357025146\n",
      "epoch 42: loss=1.7749263048171997\n",
      "epoch 43: loss=1.7433030605316162\n",
      "epoch 44: loss=1.7477437257766724\n",
      "epoch 45: loss=1.7350269556045532\n",
      "epoch 46: loss=1.7222959995269775\n",
      "epoch 47: loss=1.7126989364624023\n",
      "epoch 48: loss=1.670897364616394\n",
      "epoch 49: loss=1.6935203075408936\n",
      "epoch 50: loss=1.620516061782837\n",
      "epoch 51: loss=1.5697989463806152\n",
      "epoch 52: loss=1.572702407836914\n",
      "epoch 53: loss=1.5991748571395874\n",
      "epoch 54: loss=1.5793930292129517\n",
      "epoch 55: loss=1.5455100536346436\n",
      "epoch 56: loss=1.5301179885864258\n",
      "epoch 57: loss=1.6075584888458252\n",
      "epoch 58: loss=1.5574709177017212\n",
      "epoch 59: loss=1.5486741065979004\n",
      "epoch 60: loss=1.5379860401153564\n",
      "epoch 61: loss=1.5150444507598877\n",
      "epoch 62: loss=1.5000170469284058\n",
      "epoch 63: loss=1.503365159034729\n",
      "epoch 64: loss=1.4621984958648682\n",
      "epoch 65: loss=1.4847224950790405\n",
      "epoch 66: loss=1.505281925201416\n",
      "epoch 67: loss=1.504765510559082\n",
      "epoch 68: loss=1.4379346370697021\n",
      "epoch 69: loss=1.4496229887008667\n",
      "epoch 70: loss=1.4709091186523438\n",
      "epoch 71: loss=1.4623082876205444\n",
      "epoch 72: loss=1.443241834640503\n",
      "epoch 73: loss=1.4463680982589722\n",
      "epoch 74: loss=1.4629547595977783\n",
      "epoch 75: loss=1.4180583953857422\n",
      "epoch 76: loss=1.435159683227539\n",
      "epoch 77: loss=1.393176794052124\n",
      "epoch 78: loss=1.4404929876327515\n",
      "epoch 79: loss=1.4694628715515137\n",
      "epoch 80: loss=1.4399354457855225\n",
      "epoch 81: loss=1.4034756422042847\n",
      "epoch 82: loss=1.434950351715088\n",
      "epoch 83: loss=1.4108531475067139\n",
      "epoch 84: loss=1.4396229982376099\n",
      "epoch 85: loss=1.458645224571228\n",
      "epoch 86: loss=1.4721498489379883\n",
      "epoch 87: loss=1.4189014434814453\n",
      "epoch 88: loss=1.4772074222564697\n",
      "epoch 89: loss=1.3966691493988037\n",
      "epoch 90: loss=1.3655933141708374\n",
      "epoch 91: loss=1.4472872018814087\n",
      "epoch 92: loss=1.4674701690673828\n",
      "epoch 93: loss=1.3869163990020752\n",
      "epoch 94: loss=1.418723225593567\n",
      "epoch 95: loss=1.3831918239593506\n",
      "epoch 96: loss=1.4395357370376587\n",
      "epoch 97: loss=1.4021416902542114\n",
      "epoch 98: loss=1.3751311302185059\n",
      "epoch 99: loss=1.4045687913894653\n",
      "epoch 100: loss=1.4525995254516602\n",
      "epoch 101: loss=1.4222383499145508\n",
      "epoch 102: loss=1.4446723461151123\n",
      "epoch 103: loss=1.3936493396759033\n",
      "epoch 104: loss=1.4007112979888916\n",
      "epoch 105: loss=1.4160170555114746\n",
      "epoch 106: loss=1.3713257312774658\n",
      "epoch 107: loss=1.339870572090149\n",
      "epoch 108: loss=1.4212024211883545\n",
      "epoch 109: loss=1.4232426881790161\n",
      "epoch 110: loss=1.3913205862045288\n",
      "epoch 111: loss=1.4132285118103027\n",
      "epoch 112: loss=1.3891801834106445\n",
      "epoch 113: loss=1.3760628700256348\n",
      "epoch 114: loss=1.3998322486877441\n",
      "epoch 115: loss=1.4561972618103027\n",
      "epoch 116: loss=1.3962087631225586\n",
      "epoch 117: loss=1.3997498750686646\n",
      "epoch 118: loss=1.3590800762176514\n",
      "epoch 119: loss=1.402538537979126\n",
      "epoch 120: loss=1.3602800369262695\n",
      "epoch 121: loss=1.4245296716690063\n",
      "epoch 122: loss=1.4215645790100098\n",
      "epoch 123: loss=1.4220993518829346\n",
      "epoch 124: loss=1.3925502300262451\n",
      "epoch 125: loss=1.3921338319778442\n",
      "epoch 126: loss=1.3523527383804321\n",
      "epoch 127: loss=1.4127323627471924\n",
      "epoch 128: loss=1.390339970588684\n",
      "epoch 129: loss=1.384168267250061\n",
      "epoch 130: loss=1.333876371383667\n",
      "epoch 131: loss=1.3778390884399414\n",
      "epoch 132: loss=1.4008135795593262\n",
      "epoch 133: loss=1.403212308883667\n",
      "epoch 134: loss=1.3977638483047485\n",
      "epoch 135: loss=1.3758543729782104\n",
      "epoch 136: loss=1.4000215530395508\n",
      "epoch 137: loss=1.3860013484954834\n",
      "epoch 138: loss=1.3610972166061401\n",
      "epoch 139: loss=1.4239821434020996\n",
      "epoch 140: loss=1.383283257484436\n",
      "epoch 141: loss=1.395788311958313\n",
      "epoch 142: loss=1.4003430604934692\n",
      "epoch 143: loss=1.3757069110870361\n",
      "epoch 144: loss=1.3683401346206665\n",
      "epoch 145: loss=1.4208791255950928\n",
      "epoch 146: loss=1.3677401542663574\n",
      "epoch 147: loss=1.4059844017028809\n",
      "epoch 148: loss=1.3816442489624023\n",
      "epoch 149: loss=1.3689885139465332\n",
      "epoch 150: loss=1.3492521047592163\n",
      "epoch 151: loss=1.3755671977996826\n",
      "epoch 152: loss=1.366716980934143\n",
      "epoch 153: loss=1.3576020002365112\n",
      "epoch 154: loss=1.371377944946289\n",
      "epoch 155: loss=1.3695671558380127\n",
      "epoch 156: loss=1.4063684940338135\n",
      "epoch 157: loss=1.3419865369796753\n",
      "epoch 158: loss=1.4109097719192505\n",
      "epoch 159: loss=1.4023810625076294\n",
      "epoch 160: loss=1.3838903903961182\n",
      "epoch 161: loss=1.3579328060150146\n",
      "epoch 162: loss=1.4078953266143799\n",
      "epoch 163: loss=1.342583417892456\n",
      "epoch 164: loss=1.4066259860992432\n",
      "epoch 165: loss=1.3961749076843262\n",
      "epoch 166: loss=1.3329272270202637\n",
      "epoch 167: loss=1.3701646327972412\n",
      "epoch 168: loss=1.3836688995361328\n",
      "epoch 169: loss=1.3620243072509766\n",
      "epoch 170: loss=1.4024543762207031\n",
      "epoch 171: loss=1.3893072605133057\n",
      "epoch 172: loss=1.356152892112732\n",
      "epoch 173: loss=1.3662112951278687\n",
      "epoch 174: loss=1.3707064390182495\n",
      "epoch 175: loss=1.3357300758361816\n",
      "epoch 176: loss=1.4320393800735474\n",
      "epoch 177: loss=1.4084200859069824\n",
      "epoch 178: loss=1.3363126516342163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179: loss=1.4238388538360596\n",
      "epoch 180: loss=1.3702259063720703\n",
      "epoch 181: loss=1.3696706295013428\n",
      "epoch 182: loss=1.3860564231872559\n",
      "epoch 183: loss=1.403223991394043\n",
      "epoch 184: loss=1.3643031120300293\n",
      "epoch 185: loss=1.3680499792099\n",
      "epoch 186: loss=1.3573460578918457\n",
      "epoch 187: loss=1.3445360660552979\n",
      "epoch 188: loss=1.3836870193481445\n",
      "epoch 189: loss=1.4252315759658813\n",
      "epoch 190: loss=1.311418056488037\n",
      "epoch 191: loss=1.3946232795715332\n",
      "epoch 192: loss=1.40058434009552\n",
      "epoch 193: loss=1.3591868877410889\n",
      "epoch 194: loss=1.3454346656799316\n",
      "epoch 195: loss=1.3472630977630615\n",
      "epoch 196: loss=1.4086761474609375\n",
      "epoch 197: loss=1.3641208410263062\n",
      "epoch 198: loss=1.384692668914795\n",
      "epoch 199: loss=1.367511510848999\n",
      "training patch with 2922 edges\n",
      "epoch 0: loss=9.987658500671387\n",
      "epoch 1: loss=9.983416557312012\n",
      "epoch 2: loss=9.329851150512695\n",
      "epoch 3: loss=8.934526443481445\n",
      "epoch 4: loss=8.149428367614746\n",
      "epoch 5: loss=7.5486674308776855\n",
      "epoch 6: loss=6.788240909576416\n",
      "epoch 7: loss=6.20692253112793\n",
      "epoch 8: loss=5.711794376373291\n",
      "epoch 9: loss=5.399522304534912\n",
      "epoch 10: loss=4.8245625495910645\n",
      "epoch 11: loss=4.216300964355469\n",
      "epoch 12: loss=3.7854342460632324\n",
      "epoch 13: loss=3.051581382751465\n",
      "epoch 14: loss=2.7004785537719727\n",
      "epoch 15: loss=2.381359577178955\n",
      "epoch 16: loss=2.1144909858703613\n",
      "epoch 17: loss=2.030571699142456\n",
      "epoch 18: loss=1.8739032745361328\n",
      "epoch 19: loss=1.870843529701233\n",
      "epoch 20: loss=1.7875264883041382\n",
      "epoch 21: loss=1.6898505687713623\n",
      "epoch 22: loss=1.6364670991897583\n",
      "epoch 23: loss=1.6020376682281494\n",
      "epoch 24: loss=1.59213125705719\n",
      "epoch 25: loss=1.6101744174957275\n",
      "epoch 26: loss=1.5862571001052856\n",
      "epoch 27: loss=1.5858594179153442\n",
      "epoch 28: loss=1.5561728477478027\n",
      "epoch 29: loss=1.537264347076416\n",
      "epoch 30: loss=1.5549919605255127\n",
      "epoch 31: loss=1.531146764755249\n",
      "epoch 32: loss=1.5385138988494873\n",
      "epoch 33: loss=1.5328248739242554\n",
      "epoch 34: loss=1.52522873878479\n",
      "epoch 35: loss=1.5336931943893433\n",
      "epoch 36: loss=1.50686776638031\n",
      "epoch 37: loss=1.4987828731536865\n",
      "epoch 38: loss=1.4890847206115723\n",
      "epoch 39: loss=1.4770839214324951\n",
      "epoch 40: loss=1.4687174558639526\n",
      "epoch 41: loss=1.4520456790924072\n",
      "epoch 42: loss=1.4432395696640015\n",
      "epoch 43: loss=1.4174588918685913\n",
      "epoch 44: loss=1.3962470293045044\n",
      "epoch 45: loss=1.3741569519042969\n",
      "epoch 46: loss=1.3492169380187988\n",
      "epoch 47: loss=1.3260644674301147\n",
      "epoch 48: loss=1.2934014797210693\n",
      "epoch 49: loss=1.2763428688049316\n",
      "epoch 50: loss=1.2594884634017944\n",
      "epoch 51: loss=1.2496216297149658\n",
      "epoch 52: loss=1.2219992876052856\n",
      "epoch 53: loss=1.2183294296264648\n",
      "epoch 54: loss=1.2250123023986816\n",
      "epoch 55: loss=1.2114235162734985\n",
      "epoch 56: loss=1.1901435852050781\n",
      "epoch 57: loss=1.1959843635559082\n",
      "epoch 58: loss=1.2017011642456055\n",
      "epoch 59: loss=1.1999975442886353\n",
      "epoch 60: loss=1.213004231452942\n",
      "epoch 61: loss=1.1641408205032349\n",
      "epoch 62: loss=1.1631278991699219\n",
      "epoch 63: loss=1.154008388519287\n",
      "epoch 64: loss=1.1477373838424683\n",
      "epoch 65: loss=1.1480904817581177\n",
      "epoch 66: loss=1.1512043476104736\n",
      "epoch 67: loss=1.146253228187561\n",
      "epoch 68: loss=1.1511048078536987\n",
      "epoch 69: loss=1.154662847518921\n",
      "epoch 70: loss=1.1222323179244995\n",
      "epoch 71: loss=1.1317648887634277\n",
      "epoch 72: loss=1.1358290910720825\n",
      "epoch 73: loss=1.147018313407898\n",
      "epoch 74: loss=1.1209454536437988\n",
      "epoch 75: loss=1.1524444818496704\n",
      "epoch 76: loss=1.13360595703125\n",
      "epoch 77: loss=1.1369563341140747\n",
      "epoch 78: loss=1.1264128684997559\n",
      "epoch 79: loss=1.113160252571106\n",
      "epoch 80: loss=1.1197253465652466\n",
      "epoch 81: loss=1.0961565971374512\n",
      "epoch 82: loss=1.1269724369049072\n",
      "epoch 83: loss=1.1089786291122437\n",
      "epoch 84: loss=1.1107614040374756\n",
      "epoch 85: loss=1.1099357604980469\n",
      "epoch 86: loss=1.0911915302276611\n",
      "epoch 87: loss=1.1046698093414307\n",
      "epoch 88: loss=1.0953952074050903\n",
      "epoch 89: loss=1.0901689529418945\n",
      "epoch 90: loss=1.10993230342865\n",
      "epoch 91: loss=1.1194372177124023\n",
      "epoch 92: loss=1.1088303327560425\n",
      "epoch 93: loss=1.0963314771652222\n",
      "epoch 94: loss=1.1009902954101562\n",
      "epoch 95: loss=1.1063494682312012\n",
      "epoch 96: loss=1.0989618301391602\n",
      "epoch 97: loss=1.0916624069213867\n",
      "epoch 98: loss=1.09687340259552\n",
      "epoch 99: loss=1.1050746440887451\n",
      "epoch 100: loss=1.0978039503097534\n",
      "epoch 101: loss=1.1134331226348877\n",
      "epoch 102: loss=1.1048635244369507\n",
      "epoch 103: loss=1.0727618932724\n",
      "epoch 104: loss=1.0965843200683594\n",
      "epoch 105: loss=1.0774767398834229\n",
      "epoch 106: loss=1.1060463190078735\n",
      "epoch 107: loss=1.1042187213897705\n",
      "epoch 108: loss=1.0669103860855103\n",
      "epoch 109: loss=1.0859861373901367\n",
      "epoch 110: loss=1.0840610265731812\n",
      "epoch 111: loss=1.0680224895477295\n",
      "epoch 112: loss=1.078563928604126\n",
      "epoch 113: loss=1.0721880197525024\n",
      "epoch 114: loss=1.0859462022781372\n",
      "epoch 115: loss=1.0917953252792358\n",
      "epoch 116: loss=1.0928226709365845\n",
      "epoch 117: loss=1.0931791067123413\n",
      "epoch 118: loss=1.101591944694519\n",
      "epoch 119: loss=1.084574580192566\n",
      "epoch 120: loss=1.070452094078064\n",
      "epoch 121: loss=1.100600242614746\n",
      "epoch 122: loss=1.0609198808670044\n",
      "epoch 123: loss=1.0707427263259888\n",
      "epoch 124: loss=1.0770939588546753\n",
      "epoch 125: loss=1.0566574335098267\n",
      "epoch 126: loss=1.0791044235229492\n",
      "epoch 127: loss=1.082951307296753\n",
      "epoch 128: loss=1.0908417701721191\n",
      "epoch 129: loss=1.077547311782837\n",
      "epoch 130: loss=1.0756744146347046\n",
      "epoch 131: loss=1.0646140575408936\n",
      "epoch 132: loss=1.082302451133728\n",
      "epoch 133: loss=1.0655131340026855\n",
      "epoch 134: loss=1.0705184936523438\n",
      "epoch 135: loss=1.0781798362731934\n",
      "epoch 136: loss=1.0697832107543945\n",
      "epoch 137: loss=1.0522598028182983\n",
      "epoch 138: loss=1.0559873580932617\n",
      "epoch 139: loss=1.0639146566390991\n",
      "epoch 140: loss=1.0667486190795898\n",
      "epoch 141: loss=1.073899745941162\n",
      "epoch 142: loss=1.0658247470855713\n",
      "epoch 143: loss=1.0755479335784912\n",
      "epoch 144: loss=1.0838373899459839\n",
      "epoch 145: loss=1.0673496723175049\n",
      "epoch 146: loss=1.057978630065918\n",
      "epoch 147: loss=1.0603426694869995\n",
      "epoch 148: loss=1.0746432542800903\n",
      "epoch 149: loss=1.0510095357894897\n",
      "epoch 150: loss=1.0752277374267578\n",
      "epoch 151: loss=1.051879644393921\n",
      "epoch 152: loss=1.044110894203186\n",
      "epoch 153: loss=1.0649735927581787\n",
      "epoch 154: loss=1.056463599205017\n",
      "epoch 155: loss=1.067111849784851\n",
      "epoch 156: loss=1.0804075002670288\n",
      "epoch 157: loss=1.0687819719314575\n",
      "epoch 158: loss=1.065853238105774\n",
      "epoch 159: loss=1.0637600421905518\n",
      "epoch 160: loss=1.0538814067840576\n",
      "epoch 161: loss=1.0659713745117188\n",
      "epoch 162: loss=1.0783549547195435\n",
      "epoch 163: loss=1.0574634075164795\n",
      "epoch 164: loss=1.0675125122070312\n",
      "epoch 165: loss=1.0625405311584473\n",
      "epoch 166: loss=1.0763893127441406\n",
      "epoch 167: loss=1.062973976135254\n",
      "epoch 168: loss=1.066378116607666\n",
      "epoch 169: loss=1.0659971237182617\n",
      "epoch 170: loss=1.0714219808578491\n",
      "epoch 171: loss=1.055179238319397\n",
      "epoch 172: loss=1.0517247915267944\n",
      "epoch 173: loss=1.0708351135253906\n",
      "epoch 174: loss=1.0682427883148193\n",
      "epoch 175: loss=1.0675444602966309\n",
      "epoch 176: loss=1.0578867197036743\n",
      "epoch 177: loss=1.0508092641830444\n",
      "epoch 178: loss=1.0541448593139648\n",
      "epoch 179: loss=1.0632814168930054\n",
      "epoch 180: loss=1.0476353168487549\n",
      "epoch 181: loss=1.0605746507644653\n",
      "epoch 182: loss=1.0396863222122192\n",
      "epoch 183: loss=1.0611333847045898\n",
      "epoch 184: loss=1.0718464851379395\n",
      "epoch 185: loss=1.0645544528961182\n",
      "epoch 186: loss=1.0561736822128296\n",
      "epoch 187: loss=1.0549888610839844\n",
      "epoch 188: loss=1.0623705387115479\n",
      "epoch 189: loss=1.0793378353118896\n",
      "epoch 190: loss=1.0458505153656006\n",
      "epoch 191: loss=1.0701138973236084\n",
      "epoch 192: loss=1.0622994899749756\n",
      "epoch 193: loss=1.0603163242340088\n",
      "epoch 194: loss=1.056295394897461\n",
      "epoch 195: loss=1.0693899393081665\n",
      "epoch 196: loss=1.0563294887542725\n",
      "epoch 197: loss=1.0603331327438354\n",
      "epoch 198: loss=1.0530983209609985\n",
      "epoch 199: loss=1.0603277683258057\n",
      "training patch with 1698 edges\n",
      "epoch 0: loss=10.33828353881836\n",
      "epoch 1: loss=10.059985160827637\n",
      "epoch 2: loss=9.107532501220703\n",
      "epoch 3: loss=8.48593521118164\n",
      "epoch 4: loss=8.345170974731445\n",
      "epoch 5: loss=7.638891696929932\n",
      "epoch 6: loss=7.51740026473999\n",
      "epoch 7: loss=6.299649238586426\n",
      "epoch 8: loss=6.53132438659668\n",
      "epoch 9: loss=5.579063415527344\n",
      "epoch 10: loss=5.13421630859375\n",
      "epoch 11: loss=4.222779273986816\n",
      "epoch 12: loss=3.6816341876983643\n",
      "epoch 13: loss=3.127197027206421\n",
      "epoch 14: loss=2.7108638286590576\n",
      "epoch 15: loss=2.4005956649780273\n",
      "epoch 16: loss=2.1381444931030273\n",
      "epoch 17: loss=2.0437567234039307\n",
      "epoch 18: loss=2.0082311630249023\n",
      "epoch 19: loss=1.8967955112457275\n",
      "epoch 20: loss=1.8710012435913086\n",
      "epoch 21: loss=1.8260514736175537\n",
      "epoch 22: loss=1.7832542657852173\n",
      "epoch 23: loss=1.7627809047698975\n",
      "epoch 24: loss=1.763081669807434\n",
      "epoch 25: loss=1.7638251781463623\n",
      "epoch 26: loss=1.7276443243026733\n",
      "epoch 27: loss=1.7349621057510376\n",
      "epoch 28: loss=1.7356176376342773\n",
      "epoch 29: loss=1.7122383117675781\n",
      "epoch 30: loss=1.7086005210876465\n",
      "epoch 31: loss=1.7059053182601929\n",
      "epoch 32: loss=1.7048392295837402\n",
      "epoch 33: loss=1.6902960538864136\n",
      "epoch 34: loss=1.681799054145813\n",
      "epoch 35: loss=1.6783454418182373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36: loss=1.6735354661941528\n",
      "epoch 37: loss=1.642440676689148\n",
      "epoch 38: loss=1.6384176015853882\n",
      "epoch 39: loss=1.616451382637024\n",
      "epoch 40: loss=1.5992279052734375\n",
      "epoch 41: loss=1.5732245445251465\n",
      "epoch 42: loss=1.5512152910232544\n",
      "epoch 43: loss=1.5268280506134033\n",
      "epoch 44: loss=1.4974517822265625\n",
      "epoch 45: loss=1.4661509990692139\n",
      "epoch 46: loss=1.4433410167694092\n",
      "epoch 47: loss=1.4418134689331055\n",
      "epoch 48: loss=1.406266689300537\n",
      "epoch 49: loss=1.4094001054763794\n",
      "epoch 50: loss=1.4055969715118408\n",
      "epoch 51: loss=1.3631172180175781\n",
      "epoch 52: loss=1.3514437675476074\n",
      "epoch 53: loss=1.3587162494659424\n",
      "epoch 54: loss=1.3475877046585083\n",
      "epoch 55: loss=1.3313161134719849\n",
      "epoch 56: loss=1.3541836738586426\n",
      "epoch 57: loss=1.3271825313568115\n",
      "epoch 58: loss=1.3381593227386475\n",
      "epoch 59: loss=1.335990071296692\n",
      "epoch 60: loss=1.3440015316009521\n",
      "epoch 61: loss=1.2958579063415527\n",
      "epoch 62: loss=1.2874317169189453\n",
      "epoch 63: loss=1.2865164279937744\n",
      "epoch 64: loss=1.2889959812164307\n",
      "epoch 65: loss=1.2953317165374756\n",
      "epoch 66: loss=1.3166710138320923\n",
      "epoch 67: loss=1.2802097797393799\n",
      "epoch 68: loss=1.295626163482666\n",
      "epoch 69: loss=1.2318458557128906\n",
      "epoch 70: loss=1.2489721775054932\n",
      "epoch 71: loss=1.2698132991790771\n",
      "epoch 72: loss=1.2949997186660767\n",
      "epoch 73: loss=1.2647641897201538\n",
      "epoch 74: loss=1.2536545991897583\n",
      "epoch 75: loss=1.262630820274353\n",
      "epoch 76: loss=1.2766215801239014\n",
      "epoch 77: loss=1.2536520957946777\n",
      "epoch 78: loss=1.2767263650894165\n",
      "epoch 79: loss=1.26753568649292\n",
      "epoch 80: loss=1.261286973953247\n",
      "epoch 81: loss=1.2519919872283936\n",
      "epoch 82: loss=1.263509750366211\n",
      "epoch 83: loss=1.253698468208313\n",
      "epoch 84: loss=1.2456309795379639\n",
      "epoch 85: loss=1.2635314464569092\n",
      "epoch 86: loss=1.2310174703598022\n",
      "epoch 87: loss=1.269681692123413\n",
      "epoch 88: loss=1.2575690746307373\n",
      "epoch 89: loss=1.252751111984253\n",
      "epoch 90: loss=1.2488560676574707\n",
      "epoch 91: loss=1.2366663217544556\n",
      "epoch 92: loss=1.241943359375\n",
      "epoch 93: loss=1.224012851715088\n",
      "epoch 94: loss=1.23329496383667\n",
      "epoch 95: loss=1.2224289178848267\n",
      "epoch 96: loss=1.2311186790466309\n",
      "epoch 97: loss=1.2411326169967651\n",
      "epoch 98: loss=1.2374740839004517\n",
      "epoch 99: loss=1.2368090152740479\n",
      "epoch 100: loss=1.1879193782806396\n",
      "epoch 101: loss=1.2518391609191895\n",
      "epoch 102: loss=1.2147510051727295\n",
      "epoch 103: loss=1.2352796792984009\n",
      "epoch 104: loss=1.2031714916229248\n",
      "epoch 105: loss=1.2177462577819824\n",
      "epoch 106: loss=1.2147737741470337\n",
      "epoch 107: loss=1.2895809412002563\n",
      "epoch 108: loss=1.2151257991790771\n",
      "epoch 109: loss=1.2367830276489258\n",
      "epoch 110: loss=1.1880168914794922\n",
      "epoch 111: loss=1.223595380783081\n",
      "epoch 112: loss=1.218424916267395\n",
      "epoch 113: loss=1.2025494575500488\n",
      "epoch 114: loss=1.1957690715789795\n",
      "epoch 115: loss=1.225114107131958\n",
      "epoch 116: loss=1.2109659910202026\n",
      "epoch 117: loss=1.2124087810516357\n",
      "epoch 118: loss=1.2331892251968384\n",
      "epoch 119: loss=1.1986191272735596\n",
      "epoch 120: loss=1.1783748865127563\n",
      "epoch 121: loss=1.1865580081939697\n",
      "epoch 122: loss=1.1908295154571533\n",
      "epoch 123: loss=1.2192332744598389\n",
      "epoch 124: loss=1.223734736442566\n",
      "epoch 125: loss=1.2118921279907227\n",
      "epoch 126: loss=1.2211250066757202\n",
      "epoch 127: loss=1.2131608724594116\n",
      "epoch 128: loss=1.2221325635910034\n",
      "epoch 129: loss=1.2295942306518555\n",
      "epoch 130: loss=1.2036328315734863\n",
      "epoch 131: loss=1.1936687231063843\n",
      "epoch 132: loss=1.2058368921279907\n",
      "epoch 133: loss=1.2410097122192383\n",
      "epoch 134: loss=1.203544020652771\n",
      "epoch 135: loss=1.2117098569869995\n",
      "epoch 136: loss=1.2046735286712646\n",
      "epoch 137: loss=1.171522855758667\n",
      "epoch 138: loss=1.2100027799606323\n",
      "epoch 139: loss=1.1827547550201416\n",
      "epoch 140: loss=1.2365018129348755\n",
      "epoch 141: loss=1.2164071798324585\n",
      "epoch 142: loss=1.214189052581787\n",
      "epoch 143: loss=1.1904267072677612\n",
      "epoch 144: loss=1.2066582441329956\n",
      "epoch 145: loss=1.2100088596343994\n",
      "epoch 146: loss=1.2033344507217407\n",
      "epoch 147: loss=1.219435453414917\n",
      "epoch 148: loss=1.2039802074432373\n",
      "epoch 149: loss=1.2223589420318604\n",
      "epoch 150: loss=1.2030649185180664\n",
      "epoch 151: loss=1.1886181831359863\n",
      "epoch 152: loss=1.1837105751037598\n",
      "epoch 153: loss=1.2172348499298096\n",
      "epoch 154: loss=1.2297601699829102\n",
      "epoch 155: loss=1.1810481548309326\n",
      "epoch 156: loss=1.210746169090271\n",
      "epoch 157: loss=1.1750792264938354\n",
      "epoch 158: loss=1.2217785120010376\n",
      "epoch 159: loss=1.2264074087142944\n",
      "epoch 160: loss=1.2109370231628418\n",
      "epoch 161: loss=1.172805666923523\n",
      "epoch 162: loss=1.1839367151260376\n",
      "epoch 163: loss=1.2103042602539062\n",
      "epoch 164: loss=1.1803157329559326\n",
      "epoch 165: loss=1.1993720531463623\n",
      "epoch 166: loss=1.2022895812988281\n",
      "epoch 167: loss=1.1854294538497925\n",
      "epoch 168: loss=1.2097269296646118\n",
      "epoch 169: loss=1.1522071361541748\n",
      "epoch 170: loss=1.2128108739852905\n",
      "epoch 171: loss=1.1876487731933594\n",
      "epoch 172: loss=1.1989861726760864\n",
      "epoch 173: loss=1.1986843347549438\n",
      "epoch 174: loss=1.187948226928711\n",
      "epoch 175: loss=1.2179319858551025\n",
      "epoch 176: loss=1.1953258514404297\n",
      "epoch 177: loss=1.2239059209823608\n",
      "epoch 178: loss=1.203373908996582\n",
      "epoch 179: loss=1.201682448387146\n",
      "epoch 180: loss=1.1959693431854248\n",
      "epoch 181: loss=1.1982883214950562\n",
      "epoch 182: loss=1.1924992799758911\n",
      "epoch 183: loss=1.2239766120910645\n",
      "epoch 184: loss=1.2148609161376953\n",
      "epoch 185: loss=1.1909935474395752\n",
      "epoch 186: loss=1.1860209703445435\n",
      "epoch 187: loss=1.1892130374908447\n",
      "epoch 188: loss=1.213331699371338\n",
      "epoch 189: loss=1.1981239318847656\n",
      "epoch 190: loss=1.1990418434143066\n",
      "epoch 191: loss=1.1819733381271362\n",
      "epoch 192: loss=1.183671236038208\n",
      "epoch 193: loss=1.200493574142456\n",
      "epoch 194: loss=1.1772830486297607\n",
      "epoch 195: loss=1.1836738586425781\n",
      "epoch 196: loss=1.1840746402740479\n",
      "epoch 197: loss=1.155403971672058\n",
      "epoch 198: loss=1.1728273630142212\n",
      "epoch 199: loss=1.1794259548187256\n",
      "training patch with 670 edges\n",
      "epoch 0: loss=10.857585906982422\n",
      "epoch 1: loss=9.555509567260742\n",
      "epoch 2: loss=8.902534484863281\n",
      "epoch 3: loss=8.280305862426758\n",
      "epoch 4: loss=9.165572166442871\n",
      "epoch 5: loss=7.613738059997559\n",
      "epoch 6: loss=7.8675713539123535\n",
      "epoch 7: loss=7.802502155303955\n",
      "epoch 8: loss=7.016533374786377\n",
      "epoch 9: loss=6.574569225311279\n",
      "epoch 10: loss=5.758757591247559\n",
      "epoch 11: loss=5.5951313972473145\n",
      "epoch 12: loss=5.056608200073242\n",
      "epoch 13: loss=4.812302589416504\n",
      "epoch 14: loss=3.7742459774017334\n",
      "epoch 15: loss=3.695695161819458\n",
      "epoch 16: loss=3.2457854747772217\n",
      "epoch 17: loss=2.8023715019226074\n",
      "epoch 18: loss=2.5892715454101562\n",
      "epoch 19: loss=2.41204833984375\n",
      "epoch 20: loss=2.252706289291382\n",
      "epoch 21: loss=2.179715633392334\n",
      "epoch 22: loss=2.382633686065674\n",
      "epoch 23: loss=2.20383882522583\n",
      "epoch 24: loss=2.102236747741699\n",
      "epoch 25: loss=2.04811692237854\n",
      "epoch 26: loss=2.0666255950927734\n",
      "epoch 27: loss=2.075453519821167\n",
      "epoch 28: loss=2.0525856018066406\n",
      "epoch 29: loss=2.0903329849243164\n",
      "epoch 30: loss=2.087451934814453\n",
      "epoch 31: loss=2.078183650970459\n",
      "epoch 32: loss=2.0647337436676025\n",
      "epoch 33: loss=2.0253653526306152\n",
      "epoch 34: loss=2.0342965126037598\n",
      "epoch 35: loss=2.0025346279144287\n",
      "epoch 36: loss=2.0123202800750732\n",
      "epoch 37: loss=2.024976968765259\n",
      "epoch 38: loss=1.9856972694396973\n",
      "epoch 39: loss=1.9956166744232178\n",
      "epoch 40: loss=1.9525642395019531\n",
      "epoch 41: loss=1.929750680923462\n",
      "epoch 42: loss=1.9138821363449097\n",
      "epoch 43: loss=1.8957912921905518\n",
      "epoch 44: loss=1.8884778022766113\n",
      "epoch 45: loss=1.8820521831512451\n",
      "epoch 46: loss=1.888900637626648\n",
      "epoch 47: loss=1.8090424537658691\n",
      "epoch 48: loss=1.828178882598877\n",
      "epoch 49: loss=1.7834579944610596\n",
      "epoch 50: loss=1.7735271453857422\n",
      "epoch 51: loss=1.7641592025756836\n",
      "epoch 52: loss=1.7767802476882935\n",
      "epoch 53: loss=1.7447410821914673\n",
      "epoch 54: loss=1.6999953985214233\n",
      "epoch 55: loss=1.67965829372406\n",
      "epoch 56: loss=1.7043094635009766\n",
      "epoch 57: loss=1.6925709247589111\n",
      "epoch 58: loss=1.6432445049285889\n",
      "epoch 59: loss=1.6381773948669434\n",
      "epoch 60: loss=1.6081774234771729\n",
      "epoch 61: loss=1.675771951675415\n",
      "epoch 62: loss=1.675572395324707\n",
      "epoch 63: loss=1.6576895713806152\n",
      "epoch 64: loss=1.6162502765655518\n",
      "epoch 65: loss=1.6460208892822266\n",
      "epoch 66: loss=1.5805668830871582\n",
      "epoch 67: loss=1.6130924224853516\n",
      "epoch 68: loss=1.6036708354949951\n",
      "epoch 69: loss=1.619252324104309\n",
      "epoch 70: loss=1.6510943174362183\n",
      "epoch 71: loss=1.6552608013153076\n",
      "epoch 72: loss=1.524224042892456\n",
      "epoch 73: loss=1.574892520904541\n",
      "epoch 74: loss=1.5511534214019775\n",
      "epoch 75: loss=1.6060006618499756\n",
      "epoch 76: loss=1.5982190370559692\n",
      "epoch 77: loss=1.5423338413238525\n",
      "epoch 78: loss=1.6606448888778687\n",
      "epoch 79: loss=1.5679655075073242\n",
      "epoch 80: loss=1.5721862316131592\n",
      "epoch 81: loss=1.6147500276565552\n",
      "epoch 82: loss=1.5089623928070068\n",
      "epoch 83: loss=1.644374132156372\n",
      "epoch 84: loss=1.6204001903533936\n",
      "epoch 85: loss=1.5649583339691162\n",
      "epoch 86: loss=1.6054408550262451\n",
      "epoch 87: loss=1.566626787185669\n",
      "epoch 88: loss=1.5794614553451538\n",
      "epoch 89: loss=1.617105484008789\n",
      "epoch 90: loss=1.563744306564331\n",
      "epoch 91: loss=1.5805959701538086\n",
      "epoch 92: loss=1.515051007270813\n",
      "epoch 93: loss=1.5749086141586304\n",
      "epoch 94: loss=1.5652108192443848\n",
      "epoch 95: loss=1.5655152797698975\n",
      "epoch 96: loss=1.526229977607727\n",
      "epoch 97: loss=1.574933648109436\n",
      "epoch 98: loss=1.4856455326080322\n",
      "epoch 99: loss=1.543969988822937\n",
      "epoch 100: loss=1.6148015260696411\n",
      "epoch 101: loss=1.5145717859268188\n",
      "epoch 102: loss=1.626953363418579\n",
      "epoch 103: loss=1.5214345455169678\n",
      "epoch 104: loss=1.481134295463562\n",
      "epoch 105: loss=1.537118673324585\n",
      "epoch 106: loss=1.5112711191177368\n",
      "epoch 107: loss=1.5362060070037842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108: loss=1.562869668006897\n",
      "epoch 109: loss=1.5091352462768555\n",
      "epoch 110: loss=1.5792436599731445\n",
      "epoch 111: loss=1.5766047239303589\n",
      "epoch 112: loss=1.5613847970962524\n",
      "epoch 113: loss=1.519221305847168\n",
      "epoch 114: loss=1.5222392082214355\n",
      "epoch 115: loss=1.5834065675735474\n",
      "epoch 116: loss=1.5471428632736206\n",
      "epoch 117: loss=1.6305519342422485\n",
      "epoch 118: loss=1.5591439008712769\n",
      "epoch 119: loss=1.5673060417175293\n",
      "epoch 120: loss=1.5287179946899414\n",
      "epoch 121: loss=1.5535343885421753\n",
      "epoch 122: loss=1.5213998556137085\n",
      "epoch 123: loss=1.5676409006118774\n",
      "epoch 124: loss=1.505983591079712\n",
      "epoch 125: loss=1.509416103363037\n",
      "epoch 126: loss=1.5306205749511719\n",
      "epoch 127: loss=1.4955189228057861\n",
      "epoch 128: loss=1.5550060272216797\n",
      "epoch 129: loss=1.5554382801055908\n",
      "epoch 130: loss=1.5190509557724\n",
      "epoch 131: loss=1.5271261930465698\n",
      "epoch 132: loss=1.4906257390975952\n",
      "epoch 133: loss=1.5157545804977417\n",
      "epoch 134: loss=1.5283644199371338\n",
      "epoch 135: loss=1.511836290359497\n",
      "epoch 136: loss=1.4796559810638428\n",
      "epoch 137: loss=1.5478360652923584\n",
      "epoch 138: loss=1.4667378664016724\n",
      "epoch 139: loss=1.5349576473236084\n",
      "epoch 140: loss=1.4993948936462402\n",
      "epoch 141: loss=1.5051478147506714\n",
      "epoch 142: loss=1.511120080947876\n",
      "epoch 143: loss=1.4902873039245605\n",
      "epoch 144: loss=1.4958895444869995\n",
      "epoch 145: loss=1.5281479358673096\n",
      "epoch 146: loss=1.5204358100891113\n",
      "epoch 147: loss=1.5098176002502441\n",
      "epoch 148: loss=1.4922908544540405\n",
      "epoch 149: loss=1.5028536319732666\n",
      "epoch 150: loss=1.5033622980117798\n",
      "epoch 151: loss=1.5476202964782715\n",
      "epoch 152: loss=1.5583715438842773\n",
      "epoch 153: loss=1.4580986499786377\n",
      "epoch 154: loss=1.551196575164795\n",
      "epoch 155: loss=1.4811756610870361\n",
      "epoch 156: loss=1.5163273811340332\n",
      "epoch 157: loss=1.5077773332595825\n",
      "epoch 158: loss=1.5648140907287598\n",
      "epoch 159: loss=1.581784963607788\n",
      "epoch 160: loss=1.4418563842773438\n",
      "epoch 161: loss=1.511680006980896\n",
      "epoch 162: loss=1.5161367654800415\n",
      "epoch 163: loss=1.5549834966659546\n",
      "epoch 164: loss=1.51448392868042\n",
      "epoch 165: loss=1.487134337425232\n",
      "epoch 166: loss=1.5599654912948608\n",
      "epoch 167: loss=1.5234832763671875\n",
      "epoch 168: loss=1.4922823905944824\n",
      "epoch 169: loss=1.5113112926483154\n",
      "epoch 170: loss=1.4201805591583252\n",
      "epoch 171: loss=1.5226367712020874\n",
      "epoch 172: loss=1.5352262258529663\n",
      "epoch 173: loss=1.53521728515625\n",
      "epoch 174: loss=1.5132755041122437\n",
      "epoch 175: loss=1.4780845642089844\n",
      "epoch 176: loss=1.5615432262420654\n",
      "epoch 177: loss=1.5262657403945923\n",
      "epoch 178: loss=1.5589827299118042\n",
      "epoch 179: loss=1.5432592630386353\n",
      "epoch 180: loss=1.5545090436935425\n",
      "epoch 181: loss=1.4976484775543213\n",
      "epoch 182: loss=1.540182113647461\n",
      "epoch 183: loss=1.5012567043304443\n",
      "epoch 184: loss=1.4958144426345825\n",
      "epoch 185: loss=1.484031081199646\n",
      "epoch 186: loss=1.4319993257522583\n",
      "epoch 187: loss=1.5059258937835693\n",
      "epoch 188: loss=1.5251445770263672\n",
      "epoch 189: loss=1.4706952571868896\n",
      "epoch 190: loss=1.507683277130127\n",
      "epoch 191: loss=1.536346673965454\n",
      "epoch 192: loss=1.4750897884368896\n",
      "epoch 193: loss=1.4816035032272339\n",
      "epoch 194: loss=1.5084969997406006\n",
      "epoch 195: loss=1.4987016916275024\n",
      "epoch 196: loss=1.529146432876587\n",
      "epoch 197: loss=1.5309504270553589\n",
      "epoch 198: loss=1.4584277868270874\n",
      "epoch 199: loss=1.5199894905090332\n",
      "training patch with 1602 edges\n",
      "epoch 0: loss=9.660024642944336\n",
      "epoch 1: loss=10.174193382263184\n",
      "epoch 2: loss=9.400976181030273\n",
      "epoch 3: loss=8.402692794799805\n",
      "epoch 4: loss=8.458321571350098\n",
      "epoch 5: loss=8.001757621765137\n",
      "epoch 6: loss=7.177203178405762\n",
      "epoch 7: loss=6.536821365356445\n",
      "epoch 8: loss=5.594574451446533\n",
      "epoch 9: loss=5.643285751342773\n",
      "epoch 10: loss=4.590134620666504\n",
      "epoch 11: loss=4.118410110473633\n",
      "epoch 12: loss=4.036654472351074\n",
      "epoch 13: loss=3.28448748588562\n",
      "epoch 14: loss=2.877058506011963\n",
      "epoch 15: loss=2.4716997146606445\n",
      "epoch 16: loss=2.2288658618927\n",
      "epoch 17: loss=2.1160738468170166\n",
      "epoch 18: loss=2.0327110290527344\n",
      "epoch 19: loss=1.9368959665298462\n",
      "epoch 20: loss=1.909202218055725\n",
      "epoch 21: loss=1.8199762105941772\n",
      "epoch 22: loss=1.7629342079162598\n",
      "epoch 23: loss=1.72720468044281\n",
      "epoch 24: loss=1.7671374082565308\n",
      "epoch 25: loss=1.7842732667922974\n",
      "epoch 26: loss=1.757724642753601\n",
      "epoch 27: loss=1.7397809028625488\n",
      "epoch 28: loss=1.7209382057189941\n",
      "epoch 29: loss=1.71382737159729\n",
      "epoch 30: loss=1.7080466747283936\n",
      "epoch 31: loss=1.6996654272079468\n",
      "epoch 32: loss=1.7064403295516968\n",
      "epoch 33: loss=1.6946576833724976\n",
      "epoch 34: loss=1.6782333850860596\n",
      "epoch 35: loss=1.6737213134765625\n",
      "epoch 36: loss=1.6522313356399536\n",
      "epoch 37: loss=1.647057056427002\n",
      "epoch 38: loss=1.6224963665008545\n",
      "epoch 39: loss=1.6237355470657349\n",
      "epoch 40: loss=1.5862759351730347\n",
      "epoch 41: loss=1.5902669429779053\n",
      "epoch 42: loss=1.5625361204147339\n",
      "epoch 43: loss=1.5322315692901611\n",
      "epoch 44: loss=1.5236613750457764\n",
      "epoch 45: loss=1.505169153213501\n",
      "epoch 46: loss=1.4838184118270874\n",
      "epoch 47: loss=1.4423428773880005\n",
      "epoch 48: loss=1.3958227634429932\n",
      "epoch 49: loss=1.392403483390808\n",
      "epoch 50: loss=1.3581401109695435\n",
      "epoch 51: loss=1.347182035446167\n",
      "epoch 52: loss=1.3386739492416382\n",
      "epoch 53: loss=1.317830204963684\n",
      "epoch 54: loss=1.309746265411377\n",
      "epoch 55: loss=1.3087513446807861\n",
      "epoch 56: loss=1.315971851348877\n",
      "epoch 57: loss=1.3149783611297607\n",
      "epoch 58: loss=1.3203285932540894\n",
      "epoch 59: loss=1.3233168125152588\n",
      "epoch 60: loss=1.3148763179779053\n",
      "epoch 61: loss=1.2926883697509766\n",
      "epoch 62: loss=1.2953259944915771\n",
      "epoch 63: loss=1.2895972728729248\n",
      "epoch 64: loss=1.2714372873306274\n",
      "epoch 65: loss=1.2880337238311768\n",
      "epoch 66: loss=1.2743141651153564\n",
      "epoch 67: loss=1.2746801376342773\n",
      "epoch 68: loss=1.2803056240081787\n",
      "epoch 69: loss=1.2692623138427734\n",
      "epoch 70: loss=1.2452160120010376\n",
      "epoch 71: loss=1.2598466873168945\n",
      "epoch 72: loss=1.2532782554626465\n",
      "epoch 73: loss=1.2503423690795898\n",
      "epoch 74: loss=1.2364474534988403\n",
      "epoch 75: loss=1.2787611484527588\n",
      "epoch 76: loss=1.2370799779891968\n",
      "epoch 77: loss=1.24666166305542\n",
      "epoch 78: loss=1.2780979871749878\n",
      "epoch 79: loss=1.2908674478530884\n",
      "epoch 80: loss=1.2515238523483276\n",
      "epoch 81: loss=1.2148096561431885\n",
      "epoch 82: loss=1.2196996212005615\n",
      "epoch 83: loss=1.2601932287216187\n",
      "epoch 84: loss=1.2282273769378662\n",
      "epoch 85: loss=1.2484593391418457\n",
      "epoch 86: loss=1.2298853397369385\n",
      "epoch 87: loss=1.2413966655731201\n",
      "epoch 88: loss=1.2301549911499023\n",
      "epoch 89: loss=1.209370493888855\n",
      "epoch 90: loss=1.2472532987594604\n",
      "epoch 91: loss=1.2475504875183105\n",
      "epoch 92: loss=1.2516977787017822\n",
      "epoch 93: loss=1.2101494073867798\n",
      "epoch 94: loss=1.216003179550171\n",
      "epoch 95: loss=1.2464933395385742\n",
      "epoch 96: loss=1.2091237306594849\n",
      "epoch 97: loss=1.209159255027771\n",
      "epoch 98: loss=1.2557685375213623\n",
      "epoch 99: loss=1.2566888332366943\n",
      "epoch 100: loss=1.2136492729187012\n",
      "epoch 101: loss=1.1977269649505615\n",
      "epoch 102: loss=1.187280297279358\n",
      "epoch 103: loss=1.2073359489440918\n",
      "epoch 104: loss=1.197599172592163\n",
      "epoch 105: loss=1.2220888137817383\n",
      "epoch 106: loss=1.2265262603759766\n",
      "epoch 107: loss=1.2093836069107056\n",
      "epoch 108: loss=1.2200651168823242\n",
      "epoch 109: loss=1.2076894044876099\n",
      "epoch 110: loss=1.2019435167312622\n",
      "epoch 111: loss=1.2145451307296753\n",
      "epoch 112: loss=1.220029592514038\n",
      "epoch 113: loss=1.215937852859497\n",
      "epoch 114: loss=1.2161054611206055\n",
      "epoch 115: loss=1.2121585607528687\n",
      "epoch 116: loss=1.1978427171707153\n",
      "epoch 117: loss=1.2146884202957153\n",
      "epoch 118: loss=1.2144869565963745\n",
      "epoch 119: loss=1.201221227645874\n",
      "epoch 120: loss=1.2164870500564575\n",
      "epoch 121: loss=1.2335975170135498\n",
      "epoch 122: loss=1.1986461877822876\n",
      "epoch 123: loss=1.2194042205810547\n",
      "epoch 124: loss=1.1744030714035034\n",
      "epoch 125: loss=1.2099825143814087\n",
      "epoch 126: loss=1.2263139486312866\n",
      "epoch 127: loss=1.21661376953125\n",
      "epoch 128: loss=1.1860339641571045\n",
      "epoch 129: loss=1.1962168216705322\n",
      "epoch 130: loss=1.1846022605895996\n",
      "epoch 131: loss=1.1894631385803223\n",
      "epoch 132: loss=1.183024287223816\n",
      "epoch 133: loss=1.1836669445037842\n",
      "epoch 134: loss=1.2069064378738403\n",
      "epoch 135: loss=1.187804102897644\n",
      "epoch 136: loss=1.1989246606826782\n",
      "epoch 137: loss=1.2023019790649414\n",
      "epoch 138: loss=1.1997184753417969\n",
      "epoch 139: loss=1.2091305255889893\n",
      "epoch 140: loss=1.2153651714324951\n",
      "epoch 141: loss=1.2469321489334106\n",
      "epoch 142: loss=1.1918303966522217\n",
      "epoch 143: loss=1.165355920791626\n",
      "epoch 144: loss=1.18473482131958\n",
      "epoch 145: loss=1.1893677711486816\n",
      "epoch 146: loss=1.1855846643447876\n",
      "epoch 147: loss=1.2055171728134155\n",
      "epoch 148: loss=1.1894861459732056\n",
      "epoch 149: loss=1.19985032081604\n",
      "epoch 150: loss=1.1888536214828491\n",
      "epoch 151: loss=1.1946505308151245\n",
      "epoch 152: loss=1.1653497219085693\n",
      "epoch 153: loss=1.1887141466140747\n",
      "epoch 154: loss=1.1943410634994507\n",
      "epoch 155: loss=1.2099369764328003\n",
      "epoch 156: loss=1.1832594871520996\n",
      "epoch 157: loss=1.2022755146026611\n",
      "epoch 158: loss=1.1850788593292236\n",
      "epoch 159: loss=1.1732103824615479\n",
      "epoch 160: loss=1.1681393384933472\n",
      "epoch 161: loss=1.2017216682434082\n",
      "epoch 162: loss=1.1764204502105713\n",
      "epoch 163: loss=1.1759212017059326\n",
      "epoch 164: loss=1.195271611213684\n",
      "epoch 165: loss=1.1911354064941406\n",
      "epoch 166: loss=1.1940903663635254\n",
      "epoch 167: loss=1.1796565055847168\n",
      "epoch 168: loss=1.2059533596038818\n",
      "epoch 169: loss=1.2089793682098389\n",
      "epoch 170: loss=1.197859764099121\n",
      "epoch 171: loss=1.183075189590454\n",
      "epoch 172: loss=1.1788268089294434\n",
      "epoch 173: loss=1.1907509565353394\n",
      "epoch 174: loss=1.2169468402862549\n",
      "epoch 175: loss=1.1734097003936768\n",
      "epoch 176: loss=1.1627624034881592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177: loss=1.2059273719787598\n",
      "epoch 178: loss=1.1969809532165527\n",
      "epoch 179: loss=1.1759095191955566\n",
      "epoch 180: loss=1.1907044649124146\n",
      "epoch 181: loss=1.1896722316741943\n",
      "epoch 182: loss=1.1855309009552002\n",
      "epoch 183: loss=1.2131314277648926\n",
      "epoch 184: loss=1.1566697359085083\n",
      "epoch 185: loss=1.1823694705963135\n",
      "epoch 186: loss=1.1639797687530518\n",
      "epoch 187: loss=1.192611575126648\n",
      "epoch 188: loss=1.1678544282913208\n",
      "epoch 189: loss=1.189589500427246\n",
      "epoch 190: loss=1.1826329231262207\n",
      "epoch 191: loss=1.138852596282959\n",
      "epoch 192: loss=1.219312310218811\n",
      "epoch 193: loss=1.1795167922973633\n",
      "epoch 194: loss=1.1829991340637207\n",
      "epoch 195: loss=1.1979093551635742\n",
      "epoch 196: loss=1.1836357116699219\n",
      "epoch 197: loss=1.1923106908798218\n",
      "epoch 198: loss=1.175908088684082\n",
      "epoch 199: loss=1.1820931434631348\n",
      "training patch with 1800 edges\n",
      "epoch 0: loss=10.330387115478516\n",
      "epoch 1: loss=10.31013298034668\n",
      "epoch 2: loss=9.101110458374023\n",
      "epoch 3: loss=8.566712379455566\n",
      "epoch 4: loss=8.407970428466797\n",
      "epoch 5: loss=8.316904067993164\n",
      "epoch 6: loss=7.599987506866455\n",
      "epoch 7: loss=7.044799327850342\n",
      "epoch 8: loss=6.846738338470459\n",
      "epoch 9: loss=5.826646327972412\n",
      "epoch 10: loss=5.33962345123291\n",
      "epoch 11: loss=5.018313407897949\n",
      "epoch 12: loss=4.1944990158081055\n",
      "epoch 13: loss=3.4697813987731934\n",
      "epoch 14: loss=3.111393451690674\n",
      "epoch 15: loss=2.693535089492798\n",
      "epoch 16: loss=2.3759634494781494\n",
      "epoch 17: loss=2.1374714374542236\n",
      "epoch 18: loss=1.9994555711746216\n",
      "epoch 19: loss=1.9825096130371094\n",
      "epoch 20: loss=1.9364949464797974\n",
      "epoch 21: loss=1.8581924438476562\n",
      "epoch 22: loss=1.7958729267120361\n",
      "epoch 23: loss=1.748089075088501\n",
      "epoch 24: loss=1.7375794649124146\n",
      "epoch 25: loss=1.7410738468170166\n",
      "epoch 26: loss=1.7352981567382812\n",
      "epoch 27: loss=1.7535710334777832\n",
      "epoch 28: loss=1.6951996088027954\n",
      "epoch 29: loss=1.711362600326538\n",
      "epoch 30: loss=1.6675610542297363\n",
      "epoch 31: loss=1.6779321432113647\n",
      "epoch 32: loss=1.680582046508789\n",
      "epoch 33: loss=1.6584320068359375\n",
      "epoch 34: loss=1.6439419984817505\n",
      "epoch 35: loss=1.6308131217956543\n",
      "epoch 36: loss=1.6322444677352905\n",
      "epoch 37: loss=1.6088725328445435\n",
      "epoch 38: loss=1.593425989151001\n",
      "epoch 39: loss=1.5737159252166748\n",
      "epoch 40: loss=1.5537620782852173\n",
      "epoch 41: loss=1.5484439134597778\n",
      "epoch 42: loss=1.5184799432754517\n",
      "epoch 43: loss=1.5254185199737549\n",
      "epoch 44: loss=1.5050280094146729\n",
      "epoch 45: loss=1.4921116828918457\n",
      "epoch 46: loss=1.461764931678772\n",
      "epoch 47: loss=1.4692790508270264\n",
      "epoch 48: loss=1.4829647541046143\n",
      "epoch 49: loss=1.4438657760620117\n",
      "epoch 50: loss=1.436629295349121\n",
      "epoch 51: loss=1.4166333675384521\n",
      "epoch 52: loss=1.4040355682373047\n",
      "epoch 53: loss=1.3936516046524048\n",
      "epoch 54: loss=1.3956563472747803\n",
      "epoch 55: loss=1.3775131702423096\n",
      "epoch 56: loss=1.3561451435089111\n",
      "epoch 57: loss=1.3894000053405762\n",
      "epoch 58: loss=1.373450517654419\n",
      "epoch 59: loss=1.3393727540969849\n",
      "epoch 60: loss=1.3272125720977783\n",
      "epoch 61: loss=1.3532390594482422\n",
      "epoch 62: loss=1.3401213884353638\n",
      "epoch 63: loss=1.3113114833831787\n",
      "epoch 64: loss=1.3398913145065308\n",
      "epoch 65: loss=1.3105480670928955\n",
      "epoch 66: loss=1.313693881034851\n",
      "epoch 67: loss=1.3025619983673096\n",
      "epoch 68: loss=1.291092872619629\n",
      "epoch 69: loss=1.3204294443130493\n",
      "epoch 70: loss=1.318467617034912\n",
      "epoch 71: loss=1.2680467367172241\n",
      "epoch 72: loss=1.3113534450531006\n",
      "epoch 73: loss=1.272796630859375\n",
      "epoch 74: loss=1.303898811340332\n",
      "epoch 75: loss=1.2772281169891357\n",
      "epoch 76: loss=1.2739229202270508\n",
      "epoch 77: loss=1.3238725662231445\n",
      "epoch 78: loss=1.2664432525634766\n",
      "epoch 79: loss=1.2995620965957642\n",
      "epoch 80: loss=1.2901395559310913\n",
      "epoch 81: loss=1.271465539932251\n",
      "epoch 82: loss=1.2378175258636475\n",
      "epoch 83: loss=1.2593443393707275\n",
      "epoch 84: loss=1.280208945274353\n",
      "epoch 85: loss=1.2404972314834595\n",
      "epoch 86: loss=1.260750412940979\n",
      "epoch 87: loss=1.2950718402862549\n",
      "epoch 88: loss=1.2572981119155884\n",
      "epoch 89: loss=1.2603975534439087\n",
      "epoch 90: loss=1.2756272554397583\n",
      "epoch 91: loss=1.2580199241638184\n",
      "epoch 92: loss=1.2494316101074219\n",
      "epoch 93: loss=1.2846400737762451\n",
      "epoch 94: loss=1.2456464767456055\n",
      "epoch 95: loss=1.2653089761734009\n",
      "epoch 96: loss=1.2506189346313477\n",
      "epoch 97: loss=1.2535287141799927\n",
      "epoch 98: loss=1.2858362197875977\n",
      "epoch 99: loss=1.253562092781067\n",
      "epoch 100: loss=1.2469425201416016\n",
      "epoch 101: loss=1.240638256072998\n",
      "epoch 102: loss=1.2397111654281616\n",
      "epoch 103: loss=1.245297908782959\n",
      "epoch 104: loss=1.2244126796722412\n",
      "epoch 105: loss=1.242847204208374\n",
      "epoch 106: loss=1.2298506498336792\n",
      "epoch 107: loss=1.2493078708648682\n",
      "epoch 108: loss=1.2334280014038086\n",
      "epoch 109: loss=1.2618762254714966\n",
      "epoch 110: loss=1.2378426790237427\n",
      "epoch 111: loss=1.2615628242492676\n",
      "epoch 112: loss=1.2407362461090088\n",
      "epoch 113: loss=1.2164416313171387\n",
      "epoch 114: loss=1.2257747650146484\n",
      "epoch 115: loss=1.2088704109191895\n",
      "epoch 116: loss=1.220145344734192\n",
      "epoch 117: loss=1.2175676822662354\n",
      "epoch 118: loss=1.2316336631774902\n",
      "epoch 119: loss=1.2311325073242188\n",
      "epoch 120: loss=1.228786826133728\n",
      "epoch 121: loss=1.2266802787780762\n",
      "epoch 122: loss=1.2333904504776\n",
      "epoch 123: loss=1.2166428565979004\n",
      "epoch 124: loss=1.2287986278533936\n",
      "epoch 125: loss=1.2291027307510376\n",
      "epoch 126: loss=1.2310163974761963\n",
      "epoch 127: loss=1.2331128120422363\n",
      "epoch 128: loss=1.2169758081436157\n",
      "epoch 129: loss=1.2356634140014648\n",
      "epoch 130: loss=1.2141053676605225\n",
      "epoch 131: loss=1.2377747297286987\n",
      "epoch 132: loss=1.233335256576538\n",
      "epoch 133: loss=1.2444039583206177\n",
      "epoch 134: loss=1.2463443279266357\n",
      "epoch 135: loss=1.2485709190368652\n",
      "epoch 136: loss=1.249405860900879\n",
      "epoch 137: loss=1.226076602935791\n",
      "epoch 138: loss=1.2273204326629639\n",
      "epoch 139: loss=1.2277878522872925\n",
      "epoch 140: loss=1.248868465423584\n",
      "epoch 141: loss=1.2184922695159912\n",
      "epoch 142: loss=1.2392024993896484\n",
      "epoch 143: loss=1.1947823762893677\n",
      "epoch 144: loss=1.2452363967895508\n",
      "epoch 145: loss=1.2059211730957031\n",
      "epoch 146: loss=1.2153464555740356\n",
      "epoch 147: loss=1.2508225440979004\n",
      "epoch 148: loss=1.2367802858352661\n",
      "epoch 149: loss=1.200561761856079\n",
      "epoch 150: loss=1.2496297359466553\n",
      "epoch 151: loss=1.2262771129608154\n",
      "epoch 152: loss=1.2346270084381104\n",
      "epoch 153: loss=1.2576189041137695\n",
      "epoch 154: loss=1.240495204925537\n",
      "epoch 155: loss=1.2196284532546997\n",
      "epoch 156: loss=1.2373826503753662\n",
      "epoch 157: loss=1.2521212100982666\n",
      "epoch 158: loss=1.2042181491851807\n",
      "epoch 159: loss=1.2158852815628052\n",
      "epoch 160: loss=1.2274233102798462\n",
      "epoch 161: loss=1.2287129163742065\n",
      "epoch 162: loss=1.239072561264038\n",
      "epoch 163: loss=1.2248950004577637\n",
      "epoch 164: loss=1.2223191261291504\n",
      "epoch 165: loss=1.2302100658416748\n",
      "epoch 166: loss=1.2145426273345947\n",
      "epoch 167: loss=1.1999568939208984\n",
      "epoch 168: loss=1.2173770666122437\n",
      "epoch 169: loss=1.208648681640625\n",
      "epoch 170: loss=1.2110155820846558\n",
      "epoch 171: loss=1.195401906967163\n",
      "epoch 172: loss=1.217397689819336\n",
      "epoch 173: loss=1.1945875883102417\n",
      "epoch 174: loss=1.2154541015625\n",
      "epoch 175: loss=1.1826540231704712\n",
      "epoch 176: loss=1.223449945449829\n",
      "epoch 177: loss=1.1862410306930542\n",
      "epoch 178: loss=1.2313710451126099\n",
      "epoch 179: loss=1.214621663093567\n",
      "epoch 180: loss=1.1960190534591675\n",
      "epoch 181: loss=1.1967049837112427\n",
      "epoch 182: loss=1.2286889553070068\n",
      "epoch 183: loss=1.2452059984207153\n",
      "epoch 184: loss=1.193727970123291\n",
      "epoch 185: loss=1.2163670063018799\n",
      "epoch 186: loss=1.220049500465393\n",
      "epoch 187: loss=1.1788020133972168\n",
      "epoch 188: loss=1.2065160274505615\n",
      "epoch 189: loss=1.2269742488861084\n",
      "epoch 190: loss=1.2037227153778076\n",
      "epoch 191: loss=1.1945430040359497\n",
      "epoch 192: loss=1.1954407691955566\n",
      "epoch 193: loss=1.2022063732147217\n",
      "epoch 194: loss=1.2257194519042969\n",
      "epoch 195: loss=1.1999375820159912\n",
      "epoch 196: loss=1.1942497491836548\n",
      "epoch 197: loss=1.206732988357544\n",
      "epoch 198: loss=1.2278393507003784\n",
      "epoch 199: loss=1.2087732553482056\n",
      "training patch with 1844 edges\n",
      "epoch 0: loss=10.170981407165527\n",
      "epoch 1: loss=9.512191772460938\n",
      "epoch 2: loss=9.53670883178711\n",
      "epoch 3: loss=8.907134056091309\n",
      "epoch 4: loss=8.81241226196289\n",
      "epoch 5: loss=8.121342658996582\n",
      "epoch 6: loss=7.272820949554443\n",
      "epoch 7: loss=6.6498517990112305\n",
      "epoch 8: loss=5.749943256378174\n",
      "epoch 9: loss=5.49033784866333\n",
      "epoch 10: loss=5.1897292137146\n",
      "epoch 11: loss=4.543051242828369\n",
      "epoch 12: loss=3.973482847213745\n",
      "epoch 13: loss=3.2408664226531982\n",
      "epoch 14: loss=2.8816397190093994\n",
      "epoch 15: loss=2.5232582092285156\n",
      "epoch 16: loss=2.2080912590026855\n",
      "epoch 17: loss=2.0489420890808105\n",
      "epoch 18: loss=2.0461924076080322\n",
      "epoch 19: loss=1.9613057374954224\n",
      "epoch 20: loss=1.9072192907333374\n",
      "epoch 21: loss=1.7928999662399292\n",
      "epoch 22: loss=1.7087879180908203\n",
      "epoch 23: loss=1.7230517864227295\n",
      "epoch 24: loss=1.6977685689926147\n",
      "epoch 25: loss=1.7272727489471436\n",
      "epoch 26: loss=1.6897412538528442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27: loss=1.65915846824646\n",
      "epoch 28: loss=1.6524717807769775\n",
      "epoch 29: loss=1.6480867862701416\n",
      "epoch 30: loss=1.6538045406341553\n",
      "epoch 31: loss=1.6497230529785156\n",
      "epoch 32: loss=1.6394246816635132\n",
      "epoch 33: loss=1.6353020668029785\n",
      "epoch 34: loss=1.6278027296066284\n",
      "epoch 35: loss=1.621756672859192\n",
      "epoch 36: loss=1.6061660051345825\n",
      "epoch 37: loss=1.595893383026123\n",
      "epoch 38: loss=1.5835820436477661\n",
      "epoch 39: loss=1.5682671070098877\n",
      "epoch 40: loss=1.5493475198745728\n",
      "epoch 41: loss=1.541345238685608\n",
      "epoch 42: loss=1.5220394134521484\n",
      "epoch 43: loss=1.5005838871002197\n",
      "epoch 44: loss=1.4865282773971558\n",
      "epoch 45: loss=1.4691095352172852\n",
      "epoch 46: loss=1.4414373636245728\n",
      "epoch 47: loss=1.4161689281463623\n",
      "epoch 48: loss=1.3975268602371216\n",
      "epoch 49: loss=1.3927381038665771\n",
      "epoch 50: loss=1.3960528373718262\n",
      "epoch 51: loss=1.3579561710357666\n",
      "epoch 52: loss=1.3842344284057617\n",
      "epoch 53: loss=1.3599731922149658\n",
      "epoch 54: loss=1.3325657844543457\n",
      "epoch 55: loss=1.3541069030761719\n",
      "epoch 56: loss=1.362175703048706\n",
      "epoch 57: loss=1.320847511291504\n",
      "epoch 58: loss=1.3179701566696167\n",
      "epoch 59: loss=1.302843451499939\n",
      "epoch 60: loss=1.2777782678604126\n",
      "epoch 61: loss=1.2562886476516724\n",
      "epoch 62: loss=1.2783780097961426\n",
      "epoch 63: loss=1.2742881774902344\n",
      "epoch 64: loss=1.2554409503936768\n",
      "epoch 65: loss=1.2508091926574707\n",
      "epoch 66: loss=1.2583518028259277\n",
      "epoch 67: loss=1.2498664855957031\n",
      "epoch 68: loss=1.2349241971969604\n",
      "epoch 69: loss=1.2553105354309082\n",
      "epoch 70: loss=1.2405288219451904\n",
      "epoch 71: loss=1.2120598554611206\n",
      "epoch 72: loss=1.2225936651229858\n",
      "epoch 73: loss=1.2418286800384521\n",
      "epoch 74: loss=1.2268164157867432\n",
      "epoch 75: loss=1.2319588661193848\n",
      "epoch 76: loss=1.2199442386627197\n",
      "epoch 77: loss=1.2435176372528076\n",
      "epoch 78: loss=1.2504979372024536\n",
      "epoch 79: loss=1.2045331001281738\n",
      "epoch 80: loss=1.2389622926712036\n",
      "epoch 81: loss=1.2283220291137695\n",
      "epoch 82: loss=1.217326045036316\n",
      "epoch 83: loss=1.2160184383392334\n",
      "epoch 84: loss=1.2128558158874512\n",
      "epoch 85: loss=1.2016009092330933\n",
      "epoch 86: loss=1.2087969779968262\n",
      "epoch 87: loss=1.1933605670928955\n",
      "epoch 88: loss=1.2203129529953003\n",
      "epoch 89: loss=1.2312663793563843\n",
      "epoch 90: loss=1.2255934476852417\n",
      "epoch 91: loss=1.2287912368774414\n",
      "epoch 92: loss=1.2170155048370361\n",
      "epoch 93: loss=1.1904823780059814\n",
      "epoch 94: loss=1.2082570791244507\n",
      "epoch 95: loss=1.2081189155578613\n",
      "epoch 96: loss=1.194898009300232\n",
      "epoch 97: loss=1.1859225034713745\n",
      "epoch 98: loss=1.2328331470489502\n",
      "epoch 99: loss=1.1668039560317993\n",
      "epoch 100: loss=1.1949141025543213\n",
      "epoch 101: loss=1.1861826181411743\n",
      "epoch 102: loss=1.17171049118042\n",
      "epoch 103: loss=1.2311890125274658\n",
      "epoch 104: loss=1.1905462741851807\n",
      "epoch 105: loss=1.1967158317565918\n",
      "epoch 106: loss=1.2031974792480469\n",
      "epoch 107: loss=1.1727622747421265\n",
      "epoch 108: loss=1.2000041007995605\n",
      "epoch 109: loss=1.2033201456069946\n",
      "epoch 110: loss=1.1934856176376343\n",
      "epoch 111: loss=1.1861928701400757\n",
      "epoch 112: loss=1.1879374980926514\n",
      "epoch 113: loss=1.2204816341400146\n",
      "epoch 114: loss=1.2029666900634766\n",
      "epoch 115: loss=1.1979472637176514\n",
      "epoch 116: loss=1.1971094608306885\n",
      "epoch 117: loss=1.197204828262329\n",
      "epoch 118: loss=1.2152231931686401\n",
      "epoch 119: loss=1.1815818548202515\n",
      "epoch 120: loss=1.1949217319488525\n",
      "epoch 121: loss=1.1679513454437256\n",
      "epoch 122: loss=1.1817505359649658\n",
      "epoch 123: loss=1.1804685592651367\n",
      "epoch 124: loss=1.1871699094772339\n",
      "epoch 125: loss=1.168241262435913\n",
      "epoch 126: loss=1.1745942831039429\n",
      "epoch 127: loss=1.178423523902893\n",
      "epoch 128: loss=1.188011646270752\n",
      "epoch 129: loss=1.1954025030136108\n",
      "epoch 130: loss=1.1649354696273804\n",
      "epoch 131: loss=1.1893846988677979\n",
      "epoch 132: loss=1.1615233421325684\n",
      "epoch 133: loss=1.1567976474761963\n",
      "epoch 134: loss=1.1956090927124023\n",
      "epoch 135: loss=1.1994402408599854\n",
      "epoch 136: loss=1.1869521141052246\n",
      "epoch 137: loss=1.1750845909118652\n",
      "epoch 138: loss=1.189720630645752\n",
      "epoch 139: loss=1.183086633682251\n",
      "epoch 140: loss=1.1558749675750732\n",
      "epoch 141: loss=1.1736351251602173\n",
      "epoch 142: loss=1.1883854866027832\n",
      "epoch 143: loss=1.1897860765457153\n",
      "epoch 144: loss=1.1567293405532837\n",
      "epoch 145: loss=1.1746697425842285\n",
      "epoch 146: loss=1.2177212238311768\n",
      "epoch 147: loss=1.2183825969696045\n",
      "epoch 148: loss=1.1839303970336914\n",
      "epoch 149: loss=1.163915991783142\n",
      "epoch 150: loss=1.1584322452545166\n",
      "epoch 151: loss=1.1493504047393799\n",
      "epoch 152: loss=1.2058193683624268\n",
      "epoch 153: loss=1.168792486190796\n",
      "epoch 154: loss=1.1795271635055542\n",
      "epoch 155: loss=1.1492054462432861\n",
      "epoch 156: loss=1.1672011613845825\n",
      "epoch 157: loss=1.1687113046646118\n",
      "epoch 158: loss=1.1896789073944092\n",
      "epoch 159: loss=1.1570405960083008\n",
      "epoch 160: loss=1.1794953346252441\n",
      "epoch 161: loss=1.1656303405761719\n",
      "epoch 162: loss=1.168407678604126\n",
      "epoch 163: loss=1.1479482650756836\n",
      "epoch 164: loss=1.182875394821167\n",
      "epoch 165: loss=1.172533392906189\n",
      "epoch 166: loss=1.1629709005355835\n",
      "epoch 167: loss=1.1712658405303955\n",
      "epoch 168: loss=1.1519627571105957\n",
      "epoch 169: loss=1.20076584815979\n",
      "epoch 170: loss=1.1560981273651123\n",
      "epoch 171: loss=1.1823413372039795\n",
      "epoch 172: loss=1.1264137029647827\n",
      "epoch 173: loss=1.1828396320343018\n",
      "epoch 174: loss=1.168776512145996\n",
      "epoch 175: loss=1.1703619956970215\n",
      "epoch 176: loss=1.1547746658325195\n",
      "epoch 177: loss=1.1713179349899292\n",
      "epoch 178: loss=1.1588879823684692\n",
      "epoch 179: loss=1.1569644212722778\n",
      "epoch 180: loss=1.179592490196228\n",
      "epoch 181: loss=1.1512128114700317\n",
      "epoch 182: loss=1.170348048210144\n",
      "epoch 183: loss=1.1438913345336914\n",
      "epoch 184: loss=1.1637592315673828\n",
      "epoch 185: loss=1.1710041761398315\n",
      "epoch 186: loss=1.1975150108337402\n",
      "epoch 187: loss=1.1763168573379517\n",
      "epoch 188: loss=1.1789673566818237\n",
      "epoch 189: loss=1.1681612730026245\n",
      "epoch 190: loss=1.1699392795562744\n",
      "epoch 191: loss=1.1579509973526\n",
      "epoch 192: loss=1.1396610736846924\n",
      "epoch 193: loss=1.1808366775512695\n",
      "epoch 194: loss=1.1563345193862915\n",
      "epoch 195: loss=1.1862876415252686\n",
      "epoch 196: loss=1.1879302263259888\n",
      "epoch 197: loss=1.1897485256195068\n",
      "epoch 198: loss=1.175137996673584\n",
      "epoch 199: loss=1.139559268951416\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3197261ee3ca4707a4cbf65550e389ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 8077.80615234375\n",
      "Epoch 10, Loss: 2623.33740234375\n",
      "Epoch 20, Loss: 1532.9849853515625\n",
      "Epoch 30, Loss: 1199.971435546875\n",
      "Epoch 40, Loss: 1077.2939453125\n",
      "Epoch 50, Loss: 1030.8553466796875\n",
      "Epoch 60, Loss: 1010.716064453125\n",
      "Epoch 70, Loss: 1001.9193725585938\n",
      "Epoch 80, Loss: 997.3817138671875\n",
      "Epoch 90, Loss: 994.7672119140625\n",
      "Epoch 100, Loss: 993.0696411132812\n",
      "Epoch 110, Loss: 991.8570556640625\n",
      "Epoch 120, Loss: 990.9320068359375\n",
      "Epoch 130, Loss: 990.19580078125\n",
      "Epoch 140, Loss: 989.5938720703125\n",
      "Epoch 150, Loss: 989.091796875\n",
      "Epoch 160, Loss: 988.6676025390625\n",
      "Epoch 170, Loss: 988.304443359375\n",
      "Epoch 180, Loss: 987.9906005859375\n",
      "Epoch 190, Loss: 987.7169799804688\n",
      "training patch with 2032 edges\n",
      "epoch 0: loss=14.00002384185791\n",
      "epoch 1: loss=14.272027015686035\n",
      "epoch 2: loss=12.732370376586914\n",
      "epoch 3: loss=13.064271926879883\n",
      "epoch 4: loss=12.419297218322754\n",
      "epoch 5: loss=12.138401985168457\n",
      "epoch 6: loss=11.00676441192627\n",
      "epoch 7: loss=10.271615028381348\n",
      "epoch 8: loss=9.615346908569336\n",
      "epoch 9: loss=10.081666946411133\n",
      "epoch 10: loss=9.516637802124023\n",
      "epoch 11: loss=7.889228343963623\n",
      "epoch 12: loss=7.011515140533447\n",
      "epoch 13: loss=6.041815757751465\n",
      "epoch 14: loss=4.98792028427124\n",
      "epoch 15: loss=4.547177314758301\n",
      "epoch 16: loss=3.8227522373199463\n",
      "epoch 17: loss=3.6331069469451904\n",
      "epoch 18: loss=3.3271522521972656\n",
      "epoch 19: loss=3.1134400367736816\n",
      "epoch 20: loss=2.7546045780181885\n",
      "epoch 21: loss=2.5810368061065674\n",
      "epoch 22: loss=2.3157315254211426\n",
      "epoch 23: loss=2.2095460891723633\n",
      "epoch 24: loss=2.15346097946167\n",
      "epoch 25: loss=2.136950731277466\n",
      "epoch 26: loss=2.079676866531372\n",
      "epoch 27: loss=2.0644454956054688\n",
      "epoch 28: loss=2.025269031524658\n",
      "epoch 29: loss=1.9632971286773682\n",
      "epoch 30: loss=1.9360430240631104\n",
      "epoch 31: loss=1.948826551437378\n",
      "epoch 32: loss=1.9599242210388184\n",
      "epoch 33: loss=1.9826250076293945\n",
      "epoch 34: loss=1.9327681064605713\n",
      "epoch 35: loss=1.9388468265533447\n",
      "epoch 36: loss=1.9175269603729248\n",
      "epoch 37: loss=1.9283556938171387\n",
      "epoch 38: loss=1.943779706954956\n",
      "epoch 39: loss=1.9243718385696411\n",
      "epoch 40: loss=1.900580883026123\n",
      "epoch 41: loss=1.897133469581604\n",
      "epoch 42: loss=1.8794546127319336\n",
      "epoch 43: loss=1.8718366622924805\n",
      "epoch 44: loss=1.8509881496429443\n",
      "epoch 45: loss=1.8331959247589111\n",
      "epoch 46: loss=1.8287162780761719\n",
      "epoch 47: loss=1.7591769695281982\n",
      "epoch 48: loss=1.7741265296936035\n",
      "epoch 49: loss=1.7512426376342773\n",
      "epoch 50: loss=1.7413134574890137\n",
      "epoch 51: loss=1.716475009918213\n",
      "epoch 52: loss=1.7146222591400146\n",
      "epoch 53: loss=1.6976349353790283\n",
      "epoch 54: loss=1.7093465328216553\n",
      "epoch 55: loss=1.694753885269165\n",
      "epoch 56: loss=1.6638898849487305\n",
      "epoch 57: loss=1.6884523630142212\n",
      "epoch 58: loss=1.6303575038909912\n",
      "epoch 59: loss=1.6572685241699219\n",
      "epoch 60: loss=1.6699490547180176\n",
      "epoch 61: loss=1.6678646802902222\n",
      "epoch 62: loss=1.620882272720337\n",
      "epoch 63: loss=1.6432570219039917\n",
      "epoch 64: loss=1.5739835500717163\n",
      "epoch 65: loss=1.5857419967651367\n",
      "epoch 66: loss=1.584371566772461\n",
      "epoch 67: loss=1.5807230472564697\n",
      "epoch 68: loss=1.5856540203094482\n",
      "epoch 69: loss=1.5731332302093506\n",
      "epoch 70: loss=1.5565751791000366\n",
      "epoch 71: loss=1.572385549545288\n",
      "epoch 72: loss=1.549837350845337\n",
      "epoch 73: loss=1.5371105670928955\n",
      "epoch 74: loss=1.554413914680481\n",
      "epoch 75: loss=1.561692714691162\n",
      "epoch 76: loss=1.5291247367858887\n",
      "epoch 77: loss=1.4991034269332886\n",
      "epoch 78: loss=1.4945710897445679\n",
      "epoch 79: loss=1.5259413719177246\n",
      "epoch 80: loss=1.5253396034240723\n",
      "epoch 81: loss=1.509477138519287\n",
      "epoch 82: loss=1.4847607612609863\n",
      "epoch 83: loss=1.494704246520996\n",
      "epoch 84: loss=1.496520757675171\n",
      "epoch 85: loss=1.5504032373428345\n",
      "epoch 86: loss=1.5126919746398926\n",
      "epoch 87: loss=1.49052894115448\n",
      "epoch 88: loss=1.527906894683838\n",
      "epoch 89: loss=1.5030242204666138\n",
      "epoch 90: loss=1.5162134170532227\n",
      "epoch 91: loss=1.4959150552749634\n",
      "epoch 92: loss=1.474578619003296\n",
      "epoch 93: loss=1.5072143077850342\n",
      "epoch 94: loss=1.4628280401229858\n",
      "epoch 95: loss=1.5055932998657227\n",
      "epoch 96: loss=1.4776549339294434\n",
      "epoch 97: loss=1.4984627962112427\n",
      "epoch 98: loss=1.4817113876342773\n",
      "epoch 99: loss=1.4601709842681885\n",
      "epoch 100: loss=1.5024175643920898\n",
      "epoch 101: loss=1.4888592958450317\n",
      "epoch 102: loss=1.4683072566986084\n",
      "epoch 103: loss=1.4952292442321777\n",
      "epoch 104: loss=1.4818449020385742\n",
      "epoch 105: loss=1.4835456609725952\n",
      "epoch 106: loss=1.4605156183242798\n",
      "epoch 107: loss=1.467759370803833\n",
      "epoch 108: loss=1.4726879596710205\n",
      "epoch 109: loss=1.4701415300369263\n",
      "epoch 110: loss=1.4797158241271973\n",
      "epoch 111: loss=1.463616967201233\n",
      "epoch 112: loss=1.4659874439239502\n",
      "epoch 113: loss=1.4409929513931274\n",
      "epoch 114: loss=1.4590179920196533\n",
      "epoch 115: loss=1.4650237560272217\n",
      "epoch 116: loss=1.4882057905197144\n",
      "epoch 117: loss=1.4545741081237793\n",
      "epoch 118: loss=1.4579530954360962\n",
      "epoch 119: loss=1.4639936685562134\n",
      "epoch 120: loss=1.491852879524231\n",
      "epoch 121: loss=1.4489823579788208\n",
      "epoch 122: loss=1.489072561264038\n",
      "epoch 123: loss=1.4709911346435547\n",
      "epoch 124: loss=1.4544121026992798\n",
      "epoch 125: loss=1.4413518905639648\n",
      "epoch 126: loss=1.4871478080749512\n",
      "epoch 127: loss=1.454386591911316\n",
      "epoch 128: loss=1.4640804529190063\n",
      "epoch 129: loss=1.4593440294265747\n",
      "epoch 130: loss=1.4587914943695068\n",
      "epoch 131: loss=1.4561903476715088\n",
      "epoch 132: loss=1.4626226425170898\n",
      "epoch 133: loss=1.4577746391296387\n",
      "epoch 134: loss=1.4861421585083008\n",
      "epoch 135: loss=1.4364243745803833\n",
      "epoch 136: loss=1.4394031763076782\n",
      "epoch 137: loss=1.4408855438232422\n",
      "epoch 138: loss=1.439653754234314\n",
      "epoch 139: loss=1.4702755212783813\n",
      "epoch 140: loss=1.4510095119476318\n",
      "epoch 141: loss=1.4606077671051025\n",
      "epoch 142: loss=1.4326915740966797\n",
      "epoch 143: loss=1.4538041353225708\n",
      "epoch 144: loss=1.4679193496704102\n",
      "epoch 145: loss=1.4294732809066772\n",
      "epoch 146: loss=1.4600801467895508\n",
      "epoch 147: loss=1.4307923316955566\n",
      "epoch 148: loss=1.4648354053497314\n",
      "epoch 149: loss=1.4448912143707275\n",
      "epoch 150: loss=1.4522604942321777\n",
      "epoch 151: loss=1.459230899810791\n",
      "epoch 152: loss=1.4545873403549194\n",
      "epoch 153: loss=1.4375832080841064\n",
      "epoch 154: loss=1.4274550676345825\n",
      "epoch 155: loss=1.4399473667144775\n",
      "epoch 156: loss=1.4351661205291748\n",
      "epoch 157: loss=1.448775291442871\n",
      "epoch 158: loss=1.4674135446548462\n",
      "epoch 159: loss=1.4205379486083984\n",
      "epoch 160: loss=1.461275339126587\n",
      "epoch 161: loss=1.4427359104156494\n",
      "epoch 162: loss=1.475022554397583\n",
      "epoch 163: loss=1.4252598285675049\n",
      "epoch 164: loss=1.4487998485565186\n",
      "epoch 165: loss=1.4246549606323242\n",
      "epoch 166: loss=1.4466278553009033\n",
      "epoch 167: loss=1.4333419799804688\n",
      "epoch 168: loss=1.42196786403656\n",
      "epoch 169: loss=1.4441375732421875\n",
      "epoch 170: loss=1.4100821018218994\n",
      "epoch 171: loss=1.4257454872131348\n",
      "epoch 172: loss=1.416137933731079\n",
      "epoch 173: loss=1.454174280166626\n",
      "epoch 174: loss=1.4129459857940674\n",
      "epoch 175: loss=1.4491209983825684\n",
      "epoch 176: loss=1.4190099239349365\n",
      "epoch 177: loss=1.433990716934204\n",
      "epoch 178: loss=1.4719794988632202\n",
      "epoch 179: loss=1.4314141273498535\n",
      "epoch 180: loss=1.4456162452697754\n",
      "epoch 181: loss=1.4200546741485596\n",
      "epoch 182: loss=1.441159963607788\n",
      "epoch 183: loss=1.4446529150009155\n",
      "epoch 184: loss=1.4607371091842651\n",
      "epoch 185: loss=1.4556727409362793\n",
      "epoch 186: loss=1.4408094882965088\n",
      "epoch 187: loss=1.4757241010665894\n",
      "epoch 188: loss=1.448972463607788\n",
      "epoch 189: loss=1.4722840785980225\n",
      "epoch 190: loss=1.45493483543396\n",
      "epoch 191: loss=1.4404457807540894\n",
      "epoch 192: loss=1.4478439092636108\n",
      "epoch 193: loss=1.4149779081344604\n",
      "epoch 194: loss=1.4346312284469604\n",
      "epoch 195: loss=1.4458117485046387\n",
      "epoch 196: loss=1.4265896081924438\n",
      "epoch 197: loss=1.4594078063964844\n",
      "epoch 198: loss=1.4539997577667236\n",
      "epoch 199: loss=1.4390544891357422\n",
      "training patch with 1946 edges\n",
      "epoch 0: loss=14.262487411499023\n",
      "epoch 1: loss=13.72541332244873\n",
      "epoch 2: loss=13.775736808776855\n",
      "epoch 3: loss=12.919177055358887\n",
      "epoch 4: loss=12.05250358581543\n",
      "epoch 5: loss=11.94870376586914\n",
      "epoch 6: loss=12.006304740905762\n",
      "epoch 7: loss=10.457731246948242\n",
      "epoch 8: loss=10.495696067810059\n",
      "epoch 9: loss=11.121963500976562\n",
      "epoch 10: loss=9.714048385620117\n",
      "epoch 11: loss=8.937073707580566\n",
      "epoch 12: loss=7.847553253173828\n",
      "epoch 13: loss=6.374691963195801\n",
      "epoch 14: loss=5.658537864685059\n",
      "epoch 15: loss=5.08909273147583\n",
      "epoch 16: loss=4.520733833312988\n",
      "epoch 17: loss=3.9364142417907715\n",
      "epoch 18: loss=3.4280898571014404\n",
      "epoch 19: loss=3.26825213432312\n",
      "epoch 20: loss=3.103118419647217\n",
      "epoch 21: loss=2.7707455158233643\n",
      "epoch 22: loss=2.5030014514923096\n",
      "epoch 23: loss=2.3011319637298584\n",
      "epoch 24: loss=2.1842715740203857\n",
      "epoch 25: loss=2.1174306869506836\n",
      "epoch 26: loss=2.1645853519439697\n",
      "epoch 27: loss=2.169706106185913\n",
      "epoch 28: loss=2.1334080696105957\n",
      "epoch 29: loss=2.0512332916259766\n",
      "epoch 30: loss=1.9925260543823242\n",
      "epoch 31: loss=1.985649585723877\n",
      "epoch 32: loss=1.9726202487945557\n",
      "epoch 33: loss=2.0029001235961914\n",
      "epoch 34: loss=2.0091030597686768\n",
      "epoch 35: loss=1.9865014553070068\n",
      "epoch 36: loss=1.9626801013946533\n",
      "epoch 37: loss=1.9855014085769653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38: loss=1.962239146232605\n",
      "epoch 39: loss=1.9512302875518799\n",
      "epoch 40: loss=1.9427547454833984\n",
      "epoch 41: loss=1.9440717697143555\n",
      "epoch 42: loss=1.9057927131652832\n",
      "epoch 43: loss=1.9000184535980225\n",
      "epoch 44: loss=1.8914005756378174\n",
      "epoch 45: loss=1.8513497114181519\n",
      "epoch 46: loss=1.8636088371276855\n",
      "epoch 47: loss=1.8369743824005127\n",
      "epoch 48: loss=1.8261299133300781\n",
      "epoch 49: loss=1.7838518619537354\n",
      "epoch 50: loss=1.7642890214920044\n",
      "epoch 51: loss=1.7409746646881104\n",
      "epoch 52: loss=1.734924554824829\n",
      "epoch 53: loss=1.6963300704956055\n",
      "epoch 54: loss=1.683297872543335\n",
      "epoch 55: loss=1.6711647510528564\n",
      "epoch 56: loss=1.679785966873169\n",
      "epoch 57: loss=1.641173243522644\n",
      "epoch 58: loss=1.627107858657837\n",
      "epoch 59: loss=1.6186683177947998\n",
      "epoch 60: loss=1.625932216644287\n",
      "epoch 61: loss=1.6205263137817383\n",
      "epoch 62: loss=1.6000237464904785\n",
      "epoch 63: loss=1.5896120071411133\n",
      "epoch 64: loss=1.5816614627838135\n",
      "epoch 65: loss=1.5869691371917725\n",
      "epoch 66: loss=1.593140721321106\n",
      "epoch 67: loss=1.5945217609405518\n",
      "epoch 68: loss=1.5760893821716309\n",
      "epoch 69: loss=1.541502833366394\n",
      "epoch 70: loss=1.5231434106826782\n",
      "epoch 71: loss=1.562154769897461\n",
      "epoch 72: loss=1.546998143196106\n",
      "epoch 73: loss=1.5280770063400269\n",
      "epoch 74: loss=1.5567072629928589\n",
      "epoch 75: loss=1.5386264324188232\n",
      "epoch 76: loss=1.5353935956954956\n",
      "epoch 77: loss=1.558388113975525\n",
      "epoch 78: loss=1.5528961420059204\n",
      "epoch 79: loss=1.550392508506775\n",
      "epoch 80: loss=1.5290732383728027\n",
      "epoch 81: loss=1.5187432765960693\n",
      "epoch 82: loss=1.5119370222091675\n",
      "epoch 83: loss=1.5282435417175293\n",
      "epoch 84: loss=1.5311659574508667\n",
      "epoch 85: loss=1.542097568511963\n",
      "epoch 86: loss=1.537970781326294\n",
      "epoch 87: loss=1.5240275859832764\n",
      "epoch 88: loss=1.5101318359375\n",
      "epoch 89: loss=1.55019211769104\n",
      "epoch 90: loss=1.5520730018615723\n",
      "epoch 91: loss=1.5024523735046387\n",
      "epoch 92: loss=1.5240201950073242\n",
      "epoch 93: loss=1.4756605625152588\n",
      "epoch 94: loss=1.5007821321487427\n",
      "epoch 95: loss=1.4767223596572876\n",
      "epoch 96: loss=1.5020495653152466\n",
      "epoch 97: loss=1.5408871173858643\n",
      "epoch 98: loss=1.4846946001052856\n",
      "epoch 99: loss=1.5119123458862305\n",
      "epoch 100: loss=1.5094943046569824\n",
      "epoch 101: loss=1.4963935613632202\n",
      "epoch 102: loss=1.4886658191680908\n",
      "epoch 103: loss=1.5232326984405518\n",
      "epoch 104: loss=1.5124397277832031\n",
      "epoch 105: loss=1.4938368797302246\n",
      "epoch 106: loss=1.4770748615264893\n",
      "epoch 107: loss=1.4756983518600464\n",
      "epoch 108: loss=1.4811673164367676\n",
      "epoch 109: loss=1.5571589469909668\n",
      "epoch 110: loss=1.4857945442199707\n",
      "epoch 111: loss=1.4900718927383423\n",
      "epoch 112: loss=1.496088981628418\n",
      "epoch 113: loss=1.506648063659668\n",
      "epoch 114: loss=1.5100983381271362\n",
      "epoch 115: loss=1.4852606058120728\n",
      "epoch 116: loss=1.4841172695159912\n",
      "epoch 117: loss=1.5117318630218506\n",
      "epoch 118: loss=1.5209263563156128\n",
      "epoch 119: loss=1.4541443586349487\n",
      "epoch 120: loss=1.4762868881225586\n",
      "epoch 121: loss=1.4995033740997314\n",
      "epoch 122: loss=1.5000929832458496\n",
      "epoch 123: loss=1.538778305053711\n",
      "epoch 124: loss=1.474914789199829\n",
      "epoch 125: loss=1.4959406852722168\n",
      "epoch 126: loss=1.4615144729614258\n",
      "epoch 127: loss=1.4443491697311401\n",
      "epoch 128: loss=1.4793665409088135\n",
      "epoch 129: loss=1.4861596822738647\n",
      "epoch 130: loss=1.493161916732788\n",
      "epoch 131: loss=1.477002501487732\n",
      "epoch 132: loss=1.4818313121795654\n",
      "epoch 133: loss=1.4712655544281006\n",
      "epoch 134: loss=1.4822325706481934\n",
      "epoch 135: loss=1.4692131280899048\n",
      "epoch 136: loss=1.4636807441711426\n",
      "epoch 137: loss=1.4599788188934326\n",
      "epoch 138: loss=1.462160587310791\n",
      "epoch 139: loss=1.460601806640625\n",
      "epoch 140: loss=1.4379050731658936\n",
      "epoch 141: loss=1.4487533569335938\n",
      "epoch 142: loss=1.463936448097229\n",
      "epoch 143: loss=1.4555109739303589\n",
      "epoch 144: loss=1.501204490661621\n",
      "epoch 145: loss=1.452422022819519\n",
      "epoch 146: loss=1.439713478088379\n",
      "epoch 147: loss=1.4761985540390015\n",
      "epoch 148: loss=1.4511120319366455\n",
      "epoch 149: loss=1.4690693616867065\n",
      "epoch 150: loss=1.4434077739715576\n",
      "epoch 151: loss=1.4280049800872803\n",
      "epoch 152: loss=1.4688303470611572\n",
      "epoch 153: loss=1.4593502283096313\n",
      "epoch 154: loss=1.4663636684417725\n",
      "epoch 155: loss=1.5000126361846924\n",
      "epoch 156: loss=1.4415701627731323\n",
      "epoch 157: loss=1.4590976238250732\n",
      "epoch 158: loss=1.4877829551696777\n",
      "epoch 159: loss=1.4919333457946777\n",
      "epoch 160: loss=1.4736406803131104\n",
      "epoch 161: loss=1.4534298181533813\n",
      "epoch 162: loss=1.465537667274475\n",
      "epoch 163: loss=1.455947995185852\n",
      "epoch 164: loss=1.4475661516189575\n",
      "epoch 165: loss=1.458891749382019\n",
      "epoch 166: loss=1.4454619884490967\n",
      "epoch 167: loss=1.4413137435913086\n",
      "epoch 168: loss=1.4661555290222168\n",
      "epoch 169: loss=1.4934252500534058\n",
      "epoch 170: loss=1.4704558849334717\n",
      "epoch 171: loss=1.4450737237930298\n",
      "epoch 172: loss=1.499496579170227\n",
      "epoch 173: loss=1.439316749572754\n",
      "epoch 174: loss=1.4766124486923218\n",
      "epoch 175: loss=1.4392224550247192\n",
      "epoch 176: loss=1.4602622985839844\n",
      "epoch 177: loss=1.4276790618896484\n",
      "epoch 178: loss=1.446170449256897\n",
      "epoch 179: loss=1.4508312940597534\n",
      "epoch 180: loss=1.466773509979248\n",
      "epoch 181: loss=1.468114972114563\n",
      "epoch 182: loss=1.4780781269073486\n",
      "epoch 183: loss=1.443772315979004\n",
      "epoch 184: loss=1.4475630521774292\n",
      "epoch 185: loss=1.4940130710601807\n",
      "epoch 186: loss=1.4786401987075806\n",
      "epoch 187: loss=1.4153623580932617\n",
      "epoch 188: loss=1.4774210453033447\n",
      "epoch 189: loss=1.4639239311218262\n",
      "epoch 190: loss=1.4630917310714722\n",
      "epoch 191: loss=1.471935510635376\n",
      "epoch 192: loss=1.4504506587982178\n",
      "epoch 193: loss=1.483978271484375\n",
      "epoch 194: loss=1.4667489528656006\n",
      "epoch 195: loss=1.4379689693450928\n",
      "epoch 196: loss=1.4380297660827637\n",
      "epoch 197: loss=1.451676607131958\n",
      "epoch 198: loss=1.4753068685531616\n",
      "epoch 199: loss=1.4210550785064697\n",
      "training patch with 1878 edges\n",
      "epoch 0: loss=14.091322898864746\n",
      "epoch 1: loss=13.6107816696167\n",
      "epoch 2: loss=13.452529907226562\n",
      "epoch 3: loss=13.113893508911133\n",
      "epoch 4: loss=12.761381149291992\n",
      "epoch 5: loss=10.522252082824707\n",
      "epoch 6: loss=10.958239555358887\n",
      "epoch 7: loss=10.206350326538086\n",
      "epoch 8: loss=11.06497859954834\n",
      "epoch 9: loss=10.864638328552246\n",
      "epoch 10: loss=9.4999418258667\n",
      "epoch 11: loss=8.739813804626465\n",
      "epoch 12: loss=7.1260085105896\n",
      "epoch 13: loss=6.441835403442383\n",
      "epoch 14: loss=5.267434120178223\n",
      "epoch 15: loss=4.847794532775879\n",
      "epoch 16: loss=4.523500442504883\n",
      "epoch 17: loss=3.848621129989624\n",
      "epoch 18: loss=3.572490692138672\n",
      "epoch 19: loss=3.418637990951538\n",
      "epoch 20: loss=3.0823001861572266\n",
      "epoch 21: loss=2.7780489921569824\n",
      "epoch 22: loss=2.5370123386383057\n",
      "epoch 23: loss=2.3533458709716797\n",
      "epoch 24: loss=2.242645263671875\n",
      "epoch 25: loss=2.194655179977417\n",
      "epoch 26: loss=2.191335916519165\n",
      "epoch 27: loss=2.169262170791626\n",
      "epoch 28: loss=2.1366209983825684\n",
      "epoch 29: loss=2.0823841094970703\n",
      "epoch 30: loss=2.0386152267456055\n",
      "epoch 31: loss=2.067542791366577\n",
      "epoch 32: loss=2.050262212753296\n",
      "epoch 33: loss=2.0760810375213623\n",
      "epoch 34: loss=2.054358720779419\n",
      "epoch 35: loss=2.03261137008667\n",
      "epoch 36: loss=2.0232625007629395\n",
      "epoch 37: loss=2.0274415016174316\n",
      "epoch 38: loss=2.0056302547454834\n",
      "epoch 39: loss=2.0263075828552246\n",
      "epoch 40: loss=2.0159964561462402\n",
      "epoch 41: loss=1.983944296836853\n",
      "epoch 42: loss=2.01751708984375\n",
      "epoch 43: loss=1.953376054763794\n",
      "epoch 44: loss=1.929140329360962\n",
      "epoch 45: loss=1.910860538482666\n",
      "epoch 46: loss=1.9195823669433594\n",
      "epoch 47: loss=1.889310359954834\n",
      "epoch 48: loss=1.8555489778518677\n",
      "epoch 49: loss=1.8405548334121704\n",
      "epoch 50: loss=1.7907459735870361\n",
      "epoch 51: loss=1.7815852165222168\n",
      "epoch 52: loss=1.7619162797927856\n",
      "epoch 53: loss=1.7534608840942383\n",
      "epoch 54: loss=1.7304526567459106\n",
      "epoch 55: loss=1.6961429119110107\n",
      "epoch 56: loss=1.736929178237915\n",
      "epoch 57: loss=1.701106309890747\n",
      "epoch 58: loss=1.6628098487854004\n",
      "epoch 59: loss=1.698369026184082\n",
      "epoch 60: loss=1.7188704013824463\n",
      "epoch 61: loss=1.6906838417053223\n",
      "epoch 62: loss=1.6719900369644165\n",
      "epoch 63: loss=1.7010250091552734\n",
      "epoch 64: loss=1.6788359880447388\n",
      "epoch 65: loss=1.6750521659851074\n",
      "epoch 66: loss=1.666316270828247\n",
      "epoch 67: loss=1.6735177040100098\n",
      "epoch 68: loss=1.6852729320526123\n",
      "epoch 69: loss=1.6694941520690918\n",
      "epoch 70: loss=1.645626187324524\n",
      "epoch 71: loss=1.6207997798919678\n",
      "epoch 72: loss=1.679722547531128\n",
      "epoch 73: loss=1.625137209892273\n",
      "epoch 74: loss=1.664513349533081\n",
      "epoch 75: loss=1.5984220504760742\n",
      "epoch 76: loss=1.6671935319900513\n",
      "epoch 77: loss=1.6389588117599487\n",
      "epoch 78: loss=1.6787116527557373\n",
      "epoch 79: loss=1.6550002098083496\n",
      "epoch 80: loss=1.630291223526001\n",
      "epoch 81: loss=1.641742467880249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82: loss=1.6227667331695557\n",
      "epoch 83: loss=1.6248562335968018\n",
      "epoch 84: loss=1.6223034858703613\n",
      "epoch 85: loss=1.6365132331848145\n",
      "epoch 86: loss=1.5895448923110962\n",
      "epoch 87: loss=1.6304442882537842\n",
      "epoch 88: loss=1.5894200801849365\n",
      "epoch 89: loss=1.6540244817733765\n",
      "epoch 90: loss=1.610903024673462\n",
      "epoch 91: loss=1.6119956970214844\n",
      "epoch 92: loss=1.6253080368041992\n",
      "epoch 93: loss=1.6132842302322388\n",
      "epoch 94: loss=1.5960049629211426\n",
      "epoch 95: loss=1.5941401720046997\n",
      "epoch 96: loss=1.5910289287567139\n",
      "epoch 97: loss=1.5745022296905518\n",
      "epoch 98: loss=1.585917592048645\n",
      "epoch 99: loss=1.6044365167617798\n",
      "epoch 100: loss=1.6334115266799927\n",
      "epoch 101: loss=1.5869617462158203\n",
      "epoch 102: loss=1.59483003616333\n",
      "epoch 103: loss=1.5954105854034424\n",
      "epoch 104: loss=1.6062108278274536\n",
      "epoch 105: loss=1.610130786895752\n",
      "epoch 106: loss=1.5980033874511719\n",
      "epoch 107: loss=1.6023759841918945\n",
      "epoch 108: loss=1.5732651948928833\n",
      "epoch 109: loss=1.5673720836639404\n",
      "epoch 110: loss=1.5937931537628174\n",
      "epoch 111: loss=1.5905029773712158\n",
      "epoch 112: loss=1.5918434858322144\n",
      "epoch 113: loss=1.6410768032073975\n",
      "epoch 114: loss=1.6152278184890747\n",
      "epoch 115: loss=1.5512259006500244\n",
      "epoch 116: loss=1.601421594619751\n",
      "epoch 117: loss=1.5701658725738525\n",
      "epoch 118: loss=1.571387767791748\n",
      "epoch 119: loss=1.5725808143615723\n",
      "epoch 120: loss=1.626546859741211\n",
      "epoch 121: loss=1.6098899841308594\n",
      "epoch 122: loss=1.601025104522705\n",
      "epoch 123: loss=1.5628671646118164\n",
      "epoch 124: loss=1.601438283920288\n",
      "epoch 125: loss=1.5618867874145508\n",
      "epoch 126: loss=1.5818703174591064\n",
      "epoch 127: loss=1.5954773426055908\n",
      "epoch 128: loss=1.5454559326171875\n",
      "epoch 129: loss=1.6210201978683472\n",
      "epoch 130: loss=1.5535907745361328\n",
      "epoch 131: loss=1.5872232913970947\n",
      "epoch 132: loss=1.5466296672821045\n",
      "epoch 133: loss=1.5764914751052856\n",
      "epoch 134: loss=1.5851080417633057\n",
      "epoch 135: loss=1.534609079360962\n",
      "epoch 136: loss=1.5875821113586426\n",
      "epoch 137: loss=1.5625617504119873\n",
      "epoch 138: loss=1.5850716829299927\n",
      "epoch 139: loss=1.5958021879196167\n",
      "epoch 140: loss=1.5730836391448975\n",
      "epoch 141: loss=1.5779961347579956\n",
      "epoch 142: loss=1.589320421218872\n",
      "epoch 143: loss=1.6256041526794434\n",
      "epoch 144: loss=1.571349859237671\n",
      "epoch 145: loss=1.5561037063598633\n",
      "epoch 146: loss=1.6039162874221802\n",
      "epoch 147: loss=1.5771021842956543\n",
      "epoch 148: loss=1.5516612529754639\n",
      "epoch 149: loss=1.574280023574829\n",
      "epoch 150: loss=1.548039197921753\n",
      "epoch 151: loss=1.5709593296051025\n",
      "epoch 152: loss=1.5563809871673584\n",
      "epoch 153: loss=1.5773391723632812\n",
      "epoch 154: loss=1.5488251447677612\n",
      "epoch 155: loss=1.5555007457733154\n",
      "epoch 156: loss=1.564239740371704\n",
      "epoch 157: loss=1.5572346448898315\n",
      "epoch 158: loss=1.5597951412200928\n",
      "epoch 159: loss=1.5818959474563599\n",
      "epoch 160: loss=1.5641934871673584\n",
      "epoch 161: loss=1.575382113456726\n",
      "epoch 162: loss=1.568730115890503\n",
      "epoch 163: loss=1.5421345233917236\n",
      "epoch 164: loss=1.5485868453979492\n",
      "epoch 165: loss=1.5632410049438477\n",
      "epoch 166: loss=1.5642426013946533\n",
      "epoch 167: loss=1.5407480001449585\n",
      "epoch 168: loss=1.5868867635726929\n",
      "epoch 169: loss=1.5423723459243774\n",
      "epoch 170: loss=1.5905210971832275\n",
      "epoch 171: loss=1.5499054193496704\n",
      "epoch 172: loss=1.5155134201049805\n",
      "epoch 173: loss=1.5668292045593262\n",
      "epoch 174: loss=1.5863600969314575\n",
      "epoch 175: loss=1.56685209274292\n",
      "epoch 176: loss=1.5552151203155518\n",
      "epoch 177: loss=1.5747771263122559\n",
      "epoch 178: loss=1.5910160541534424\n",
      "epoch 179: loss=1.5986719131469727\n",
      "epoch 180: loss=1.5603079795837402\n",
      "epoch 181: loss=1.534072995185852\n",
      "epoch 182: loss=1.5527400970458984\n",
      "epoch 183: loss=1.5243102312088013\n",
      "epoch 184: loss=1.5829689502716064\n",
      "epoch 185: loss=1.547922134399414\n",
      "epoch 186: loss=1.5912230014801025\n",
      "epoch 187: loss=1.5458605289459229\n",
      "epoch 188: loss=1.5232763290405273\n",
      "epoch 189: loss=1.5638738870620728\n",
      "epoch 190: loss=1.5560157299041748\n",
      "epoch 191: loss=1.579197645187378\n",
      "epoch 192: loss=1.5546536445617676\n",
      "epoch 193: loss=1.5445504188537598\n",
      "epoch 194: loss=1.5461355447769165\n",
      "epoch 195: loss=1.5278193950653076\n",
      "epoch 196: loss=1.525331735610962\n",
      "epoch 197: loss=1.5489511489868164\n",
      "epoch 198: loss=1.5420526266098022\n",
      "epoch 199: loss=1.521954894065857\n",
      "training patch with 2784 edges\n",
      "epoch 0: loss=14.43342113494873\n",
      "epoch 1: loss=13.512005805969238\n",
      "epoch 2: loss=13.086871147155762\n",
      "epoch 3: loss=13.344979286193848\n",
      "epoch 4: loss=12.168878555297852\n",
      "epoch 5: loss=11.951704025268555\n",
      "epoch 6: loss=11.50156021118164\n",
      "epoch 7: loss=10.428605079650879\n",
      "epoch 8: loss=9.96277141571045\n",
      "epoch 9: loss=10.093399047851562\n",
      "epoch 10: loss=9.202630043029785\n",
      "epoch 11: loss=8.458359718322754\n",
      "epoch 12: loss=7.373238563537598\n",
      "epoch 13: loss=5.9669976234436035\n",
      "epoch 14: loss=5.215331077575684\n",
      "epoch 15: loss=4.62871789932251\n",
      "epoch 16: loss=3.9900498390197754\n",
      "epoch 17: loss=3.539552688598633\n",
      "epoch 18: loss=3.054133892059326\n",
      "epoch 19: loss=2.882073402404785\n",
      "epoch 20: loss=2.6922659873962402\n",
      "epoch 21: loss=2.5361270904541016\n",
      "epoch 22: loss=2.2224783897399902\n",
      "epoch 23: loss=2.109471321105957\n",
      "epoch 24: loss=2.011265993118286\n",
      "epoch 25: loss=1.948685646057129\n",
      "epoch 26: loss=1.9993228912353516\n",
      "epoch 27: loss=1.953791856765747\n",
      "epoch 28: loss=1.8807414770126343\n",
      "epoch 29: loss=1.8275266885757446\n",
      "epoch 30: loss=1.8410457372665405\n",
      "epoch 31: loss=1.8493773937225342\n",
      "epoch 32: loss=1.8475629091262817\n",
      "epoch 33: loss=1.8409342765808105\n",
      "epoch 34: loss=1.8462696075439453\n",
      "epoch 35: loss=1.838883638381958\n",
      "epoch 36: loss=1.8271081447601318\n",
      "epoch 37: loss=1.82502281665802\n",
      "epoch 38: loss=1.8037463426589966\n",
      "epoch 39: loss=1.8100669384002686\n",
      "epoch 40: loss=1.8027777671813965\n",
      "epoch 41: loss=1.7980034351348877\n",
      "epoch 42: loss=1.7807079553604126\n",
      "epoch 43: loss=1.7733014822006226\n",
      "epoch 44: loss=1.7547036409378052\n",
      "epoch 45: loss=1.7454206943511963\n",
      "epoch 46: loss=1.7384204864501953\n",
      "epoch 47: loss=1.7214617729187012\n",
      "epoch 48: loss=1.7009140253067017\n",
      "epoch 49: loss=1.6803123950958252\n",
      "epoch 50: loss=1.6581841707229614\n",
      "epoch 51: loss=1.640876293182373\n",
      "epoch 52: loss=1.6468751430511475\n",
      "epoch 53: loss=1.604660987854004\n",
      "epoch 54: loss=1.6037639379501343\n",
      "epoch 55: loss=1.566532850265503\n",
      "epoch 56: loss=1.5561147928237915\n",
      "epoch 57: loss=1.5296489000320435\n",
      "epoch 58: loss=1.5067572593688965\n",
      "epoch 59: loss=1.5355472564697266\n",
      "epoch 60: loss=1.4989650249481201\n",
      "epoch 61: loss=1.4934892654418945\n",
      "epoch 62: loss=1.5196443796157837\n",
      "epoch 63: loss=1.4880754947662354\n",
      "epoch 64: loss=1.500194787979126\n",
      "epoch 65: loss=1.506007432937622\n",
      "epoch 66: loss=1.5088958740234375\n",
      "epoch 67: loss=1.494157075881958\n",
      "epoch 68: loss=1.4887577295303345\n",
      "epoch 69: loss=1.4867767095565796\n",
      "epoch 70: loss=1.468654751777649\n",
      "epoch 71: loss=1.4670358896255493\n",
      "epoch 72: loss=1.4577547311782837\n",
      "epoch 73: loss=1.4716622829437256\n",
      "epoch 74: loss=1.4923228025436401\n",
      "epoch 75: loss=1.4598671197891235\n",
      "epoch 76: loss=1.4504656791687012\n",
      "epoch 77: loss=1.4563052654266357\n",
      "epoch 78: loss=1.446414589881897\n",
      "epoch 79: loss=1.4598318338394165\n",
      "epoch 80: loss=1.4508386850357056\n",
      "epoch 81: loss=1.439448356628418\n",
      "epoch 82: loss=1.4572861194610596\n",
      "epoch 83: loss=1.4411709308624268\n",
      "epoch 84: loss=1.4255222082138062\n",
      "epoch 85: loss=1.4358270168304443\n",
      "epoch 86: loss=1.4395387172698975\n",
      "epoch 87: loss=1.4199738502502441\n",
      "epoch 88: loss=1.4081368446350098\n",
      "epoch 89: loss=1.4190993309020996\n",
      "epoch 90: loss=1.4037998914718628\n",
      "epoch 91: loss=1.4008287191390991\n",
      "epoch 92: loss=1.4086588621139526\n",
      "epoch 93: loss=1.400866150856018\n",
      "epoch 94: loss=1.4109761714935303\n",
      "epoch 95: loss=1.4119514226913452\n",
      "epoch 96: loss=1.3998879194259644\n",
      "epoch 97: loss=1.411686897277832\n",
      "epoch 98: loss=1.412086009979248\n",
      "epoch 99: loss=1.3914639949798584\n",
      "epoch 100: loss=1.3963427543640137\n",
      "epoch 101: loss=1.391021728515625\n",
      "epoch 102: loss=1.413094162940979\n",
      "epoch 103: loss=1.3900995254516602\n",
      "epoch 104: loss=1.3778495788574219\n",
      "epoch 105: loss=1.4121513366699219\n",
      "epoch 106: loss=1.3849029541015625\n",
      "epoch 107: loss=1.3922545909881592\n",
      "epoch 108: loss=1.3860418796539307\n",
      "epoch 109: loss=1.380592703819275\n",
      "epoch 110: loss=1.3926445245742798\n",
      "epoch 111: loss=1.3973637819290161\n",
      "epoch 112: loss=1.368098258972168\n",
      "epoch 113: loss=1.3927569389343262\n",
      "epoch 114: loss=1.3636609315872192\n",
      "epoch 115: loss=1.3927713632583618\n",
      "epoch 116: loss=1.3702449798583984\n",
      "epoch 117: loss=1.3558944463729858\n",
      "epoch 118: loss=1.3923038244247437\n",
      "epoch 119: loss=1.3743071556091309\n",
      "epoch 120: loss=1.3508456945419312\n",
      "epoch 121: loss=1.387230634689331\n",
      "epoch 122: loss=1.4003667831420898\n",
      "epoch 123: loss=1.357521891593933\n",
      "epoch 124: loss=1.3636784553527832\n",
      "epoch 125: loss=1.373172402381897\n",
      "epoch 126: loss=1.3847748041152954\n",
      "epoch 127: loss=1.3773078918457031\n",
      "epoch 128: loss=1.374418020248413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129: loss=1.3689197301864624\n",
      "epoch 130: loss=1.3674511909484863\n",
      "epoch 131: loss=1.3737646341323853\n",
      "epoch 132: loss=1.3538429737091064\n",
      "epoch 133: loss=1.3969377279281616\n",
      "epoch 134: loss=1.3643618822097778\n",
      "epoch 135: loss=1.362801194190979\n",
      "epoch 136: loss=1.3619632720947266\n",
      "epoch 137: loss=1.3497008085250854\n",
      "epoch 138: loss=1.3623639345169067\n",
      "epoch 139: loss=1.3601545095443726\n",
      "epoch 140: loss=1.369797706604004\n",
      "epoch 141: loss=1.3622196912765503\n",
      "epoch 142: loss=1.3635966777801514\n",
      "epoch 143: loss=1.3465839624404907\n",
      "epoch 144: loss=1.3686885833740234\n",
      "epoch 145: loss=1.3681962490081787\n",
      "epoch 146: loss=1.3580307960510254\n",
      "epoch 147: loss=1.3653969764709473\n",
      "epoch 148: loss=1.3760545253753662\n",
      "epoch 149: loss=1.3762493133544922\n",
      "epoch 150: loss=1.360374927520752\n",
      "epoch 151: loss=1.3511778116226196\n",
      "epoch 152: loss=1.3430612087249756\n",
      "epoch 153: loss=1.356445074081421\n",
      "epoch 154: loss=1.316713809967041\n",
      "epoch 155: loss=1.3684813976287842\n",
      "epoch 156: loss=1.3563488721847534\n",
      "epoch 157: loss=1.3406367301940918\n",
      "epoch 158: loss=1.3637511730194092\n",
      "epoch 159: loss=1.3499398231506348\n",
      "epoch 160: loss=1.3630146980285645\n",
      "epoch 161: loss=1.3514347076416016\n",
      "epoch 162: loss=1.334965467453003\n",
      "epoch 163: loss=1.3440366983413696\n",
      "epoch 164: loss=1.3476624488830566\n",
      "epoch 165: loss=1.3562555313110352\n",
      "epoch 166: loss=1.323352575302124\n",
      "epoch 167: loss=1.3399980068206787\n",
      "epoch 168: loss=1.357151985168457\n",
      "epoch 169: loss=1.3614554405212402\n",
      "epoch 170: loss=1.3309895992279053\n",
      "epoch 171: loss=1.353081464767456\n",
      "epoch 172: loss=1.3258339166641235\n",
      "epoch 173: loss=1.3650885820388794\n",
      "epoch 174: loss=1.348655343055725\n",
      "epoch 175: loss=1.3490829467773438\n",
      "epoch 176: loss=1.3398574590682983\n",
      "epoch 177: loss=1.3401260375976562\n",
      "epoch 178: loss=1.3396040201187134\n",
      "epoch 179: loss=1.3416976928710938\n",
      "epoch 180: loss=1.3328726291656494\n",
      "epoch 181: loss=1.358970046043396\n",
      "epoch 182: loss=1.3465962409973145\n",
      "epoch 183: loss=1.3348783254623413\n",
      "epoch 184: loss=1.340002417564392\n",
      "epoch 185: loss=1.3357373476028442\n",
      "epoch 186: loss=1.3440190553665161\n",
      "epoch 187: loss=1.3217031955718994\n",
      "epoch 188: loss=1.3348299264907837\n",
      "epoch 189: loss=1.3345576524734497\n",
      "epoch 190: loss=1.3468348979949951\n",
      "epoch 191: loss=1.3048522472381592\n",
      "epoch 192: loss=1.3430002927780151\n",
      "epoch 193: loss=1.3383948802947998\n",
      "epoch 194: loss=1.3582520484924316\n",
      "epoch 195: loss=1.3587790727615356\n",
      "epoch 196: loss=1.3425137996673584\n",
      "epoch 197: loss=1.3449833393096924\n",
      "epoch 198: loss=1.3579307794570923\n",
      "epoch 199: loss=1.3203637599945068\n",
      "training patch with 1652 edges\n",
      "epoch 0: loss=13.284643173217773\n",
      "epoch 1: loss=14.016167640686035\n",
      "epoch 2: loss=13.443628311157227\n",
      "epoch 3: loss=13.209980964660645\n",
      "epoch 4: loss=13.016606330871582\n",
      "epoch 5: loss=12.385029792785645\n",
      "epoch 6: loss=11.517974853515625\n",
      "epoch 7: loss=11.158013343811035\n",
      "epoch 8: loss=10.7398681640625\n",
      "epoch 9: loss=10.902162551879883\n",
      "epoch 10: loss=11.07123851776123\n",
      "epoch 11: loss=9.651525497436523\n",
      "epoch 12: loss=8.287946701049805\n",
      "epoch 13: loss=7.910790920257568\n",
      "epoch 14: loss=6.89186429977417\n",
      "epoch 15: loss=6.098194122314453\n",
      "epoch 16: loss=5.368752956390381\n",
      "epoch 17: loss=4.59260368347168\n",
      "epoch 18: loss=4.22491455078125\n",
      "epoch 19: loss=3.8199663162231445\n",
      "epoch 20: loss=3.4462404251098633\n",
      "epoch 21: loss=3.191178560256958\n",
      "epoch 22: loss=3.0589375495910645\n",
      "epoch 23: loss=2.7019944190979004\n",
      "epoch 24: loss=2.488386631011963\n",
      "epoch 25: loss=2.2152466773986816\n",
      "epoch 26: loss=2.276123285293579\n",
      "epoch 27: loss=2.221818208694458\n",
      "epoch 28: loss=2.271470069885254\n",
      "epoch 29: loss=2.1426751613616943\n",
      "epoch 30: loss=2.0739355087280273\n",
      "epoch 31: loss=2.064085006713867\n",
      "epoch 32: loss=2.0746207237243652\n",
      "epoch 33: loss=2.0954480171203613\n",
      "epoch 34: loss=2.0853350162506104\n",
      "epoch 35: loss=2.080979824066162\n",
      "epoch 36: loss=2.040072441101074\n",
      "epoch 37: loss=2.035334825515747\n",
      "epoch 38: loss=2.0259010791778564\n",
      "epoch 39: loss=2.038520097732544\n",
      "epoch 40: loss=2.0285873413085938\n",
      "epoch 41: loss=2.011533260345459\n",
      "epoch 42: loss=1.9884865283966064\n",
      "epoch 43: loss=1.9686827659606934\n",
      "epoch 44: loss=1.9570659399032593\n",
      "epoch 45: loss=1.9262099266052246\n",
      "epoch 46: loss=1.9092555046081543\n",
      "epoch 47: loss=1.9131377935409546\n",
      "epoch 48: loss=1.9029258489608765\n",
      "epoch 49: loss=1.8815823793411255\n",
      "epoch 50: loss=1.8280441761016846\n",
      "epoch 51: loss=1.8087862730026245\n",
      "epoch 52: loss=1.8237892389297485\n",
      "epoch 53: loss=1.7967675924301147\n",
      "epoch 54: loss=1.7760276794433594\n",
      "epoch 55: loss=1.7541186809539795\n",
      "epoch 56: loss=1.7530841827392578\n",
      "epoch 57: loss=1.7623403072357178\n",
      "epoch 58: loss=1.766047716140747\n",
      "epoch 59: loss=1.7393882274627686\n",
      "epoch 60: loss=1.7534308433532715\n",
      "epoch 61: loss=1.7006902694702148\n",
      "epoch 62: loss=1.7247556447982788\n",
      "epoch 63: loss=1.716904878616333\n",
      "epoch 64: loss=1.7393505573272705\n",
      "epoch 65: loss=1.688181757926941\n",
      "epoch 66: loss=1.6601001024246216\n",
      "epoch 67: loss=1.685708999633789\n",
      "epoch 68: loss=1.6832292079925537\n",
      "epoch 69: loss=1.6866319179534912\n",
      "epoch 70: loss=1.6515159606933594\n",
      "epoch 71: loss=1.6458663940429688\n",
      "epoch 72: loss=1.6652053594589233\n",
      "epoch 73: loss=1.6394942998886108\n",
      "epoch 74: loss=1.6877365112304688\n",
      "epoch 75: loss=1.691603422164917\n",
      "epoch 76: loss=1.6682251691818237\n",
      "epoch 77: loss=1.6401935815811157\n",
      "epoch 78: loss=1.6548737287521362\n",
      "epoch 79: loss=1.6615617275238037\n",
      "epoch 80: loss=1.6312386989593506\n",
      "epoch 81: loss=1.5874227285385132\n",
      "epoch 82: loss=1.6124944686889648\n",
      "epoch 83: loss=1.6410257816314697\n",
      "epoch 84: loss=1.6408348083496094\n",
      "epoch 85: loss=1.6417183876037598\n",
      "epoch 86: loss=1.614378571510315\n",
      "epoch 87: loss=1.6268508434295654\n",
      "epoch 88: loss=1.6007616519927979\n",
      "epoch 89: loss=1.5415782928466797\n",
      "epoch 90: loss=1.6358389854431152\n",
      "epoch 91: loss=1.6581535339355469\n",
      "epoch 92: loss=1.60228431224823\n",
      "epoch 93: loss=1.59242844581604\n",
      "epoch 94: loss=1.596482753753662\n",
      "epoch 95: loss=1.6359349489212036\n",
      "epoch 96: loss=1.6124820709228516\n",
      "epoch 97: loss=1.5983412265777588\n",
      "epoch 98: loss=1.6089613437652588\n",
      "epoch 99: loss=1.616909146308899\n",
      "epoch 100: loss=1.6169898509979248\n",
      "epoch 101: loss=1.5629984140396118\n",
      "epoch 102: loss=1.61637544631958\n",
      "epoch 103: loss=1.58390212059021\n",
      "epoch 104: loss=1.5650197267532349\n",
      "epoch 105: loss=1.5830082893371582\n",
      "epoch 106: loss=1.5962638854980469\n",
      "epoch 107: loss=1.5648012161254883\n",
      "epoch 108: loss=1.598588466644287\n",
      "epoch 109: loss=1.5737106800079346\n",
      "epoch 110: loss=1.5629807710647583\n",
      "epoch 111: loss=1.6285345554351807\n",
      "epoch 112: loss=1.5756359100341797\n",
      "epoch 113: loss=1.546473503112793\n",
      "epoch 114: loss=1.583122968673706\n",
      "epoch 115: loss=1.5570366382598877\n",
      "epoch 116: loss=1.5964338779449463\n",
      "epoch 117: loss=1.5957129001617432\n",
      "epoch 118: loss=1.5547356605529785\n",
      "epoch 119: loss=1.5941743850708008\n",
      "epoch 120: loss=1.5379207134246826\n",
      "epoch 121: loss=1.6217195987701416\n",
      "epoch 122: loss=1.5489503145217896\n",
      "epoch 123: loss=1.5630462169647217\n",
      "epoch 124: loss=1.5827062129974365\n",
      "epoch 125: loss=1.5246641635894775\n",
      "epoch 126: loss=1.5917491912841797\n",
      "epoch 127: loss=1.5400333404541016\n",
      "epoch 128: loss=1.560835838317871\n",
      "epoch 129: loss=1.5621955394744873\n",
      "epoch 130: loss=1.5361413955688477\n",
      "epoch 131: loss=1.5628247261047363\n",
      "epoch 132: loss=1.5827515125274658\n",
      "epoch 133: loss=1.559478998184204\n",
      "epoch 134: loss=1.6052485704421997\n",
      "epoch 135: loss=1.5663442611694336\n",
      "epoch 136: loss=1.578847050666809\n",
      "epoch 137: loss=1.546246886253357\n",
      "epoch 138: loss=1.5459728240966797\n",
      "epoch 139: loss=1.5215024948120117\n",
      "epoch 140: loss=1.5389602184295654\n",
      "epoch 141: loss=1.5929421186447144\n",
      "epoch 142: loss=1.5872468948364258\n",
      "epoch 143: loss=1.570180892944336\n",
      "epoch 144: loss=1.553467035293579\n",
      "epoch 145: loss=1.5402982234954834\n",
      "epoch 146: loss=1.4932599067687988\n",
      "epoch 147: loss=1.5791219472885132\n",
      "epoch 148: loss=1.5543060302734375\n",
      "epoch 149: loss=1.5473623275756836\n",
      "epoch 150: loss=1.5480387210845947\n",
      "epoch 151: loss=1.5842831134796143\n",
      "epoch 152: loss=1.601043939590454\n",
      "epoch 153: loss=1.5433411598205566\n",
      "epoch 154: loss=1.5351283550262451\n",
      "epoch 155: loss=1.6380574703216553\n",
      "epoch 156: loss=1.5525743961334229\n",
      "epoch 157: loss=1.5379135608673096\n",
      "epoch 158: loss=1.5404574871063232\n",
      "epoch 159: loss=1.5281877517700195\n",
      "epoch 160: loss=1.5764741897583008\n",
      "epoch 161: loss=1.592628002166748\n",
      "epoch 162: loss=1.5449473857879639\n",
      "epoch 163: loss=1.5969445705413818\n",
      "epoch 164: loss=1.5632245540618896\n",
      "epoch 165: loss=1.5490450859069824\n",
      "epoch 166: loss=1.5980689525604248\n",
      "epoch 167: loss=1.5198500156402588\n",
      "epoch 168: loss=1.5136890411376953\n",
      "epoch 169: loss=1.5507465600967407\n",
      "epoch 170: loss=1.5456428527832031\n",
      "epoch 171: loss=1.5429599285125732\n",
      "epoch 172: loss=1.521470546722412\n",
      "epoch 173: loss=1.5337963104248047\n",
      "epoch 174: loss=1.501455307006836\n",
      "epoch 175: loss=1.6098663806915283\n",
      "epoch 176: loss=1.5415260791778564\n",
      "epoch 177: loss=1.5706298351287842\n",
      "epoch 178: loss=1.5665833950042725\n",
      "epoch 179: loss=1.5345020294189453\n",
      "epoch 180: loss=1.5419621467590332\n",
      "epoch 181: loss=1.5447559356689453\n",
      "epoch 182: loss=1.5849417448043823\n",
      "epoch 183: loss=1.549532175064087\n",
      "epoch 184: loss=1.5775041580200195\n",
      "epoch 185: loss=1.5779073238372803\n",
      "epoch 186: loss=1.5331501960754395\n",
      "epoch 187: loss=1.5493590831756592\n",
      "epoch 188: loss=1.5563780069351196\n",
      "epoch 189: loss=1.5550882816314697\n",
      "epoch 190: loss=1.567975640296936\n",
      "epoch 191: loss=1.5210058689117432\n",
      "epoch 192: loss=1.5831631422042847\n",
      "epoch 193: loss=1.536088228225708\n",
      "epoch 194: loss=1.5389982461929321\n",
      "epoch 195: loss=1.5670303106307983\n",
      "epoch 196: loss=1.5560429096221924\n",
      "epoch 197: loss=1.5507175922393799\n",
      "epoch 198: loss=1.5352513790130615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199: loss=1.5539863109588623\n",
      "training patch with 840 edges\n",
      "epoch 0: loss=13.940494537353516\n",
      "epoch 1: loss=13.412606239318848\n",
      "epoch 2: loss=13.25840950012207\n",
      "epoch 3: loss=12.58890438079834\n",
      "epoch 4: loss=13.861491203308105\n",
      "epoch 5: loss=13.912618637084961\n",
      "epoch 6: loss=11.364879608154297\n",
      "epoch 7: loss=11.879650115966797\n",
      "epoch 8: loss=11.322492599487305\n",
      "epoch 9: loss=10.98593521118164\n",
      "epoch 10: loss=11.605193138122559\n",
      "epoch 11: loss=10.310929298400879\n",
      "epoch 12: loss=10.509175300598145\n",
      "epoch 13: loss=10.404808044433594\n",
      "epoch 14: loss=9.042551040649414\n",
      "epoch 15: loss=8.036214828491211\n",
      "epoch 16: loss=7.1458892822265625\n",
      "epoch 17: loss=6.534218788146973\n",
      "epoch 18: loss=6.123630523681641\n",
      "epoch 19: loss=5.267767906188965\n",
      "epoch 20: loss=4.820030689239502\n",
      "epoch 21: loss=4.309475898742676\n",
      "epoch 22: loss=3.9888362884521484\n",
      "epoch 23: loss=3.666001081466675\n",
      "epoch 24: loss=3.652834177017212\n",
      "epoch 25: loss=3.461865186691284\n",
      "epoch 26: loss=3.226827621459961\n",
      "epoch 27: loss=2.8361032009124756\n",
      "epoch 28: loss=2.77850604057312\n",
      "epoch 29: loss=2.6236109733581543\n",
      "epoch 30: loss=2.4671499729156494\n",
      "epoch 31: loss=2.6065638065338135\n",
      "epoch 32: loss=2.5523483753204346\n",
      "epoch 33: loss=2.5427234172821045\n",
      "epoch 34: loss=2.5105717182159424\n",
      "epoch 35: loss=2.407928466796875\n",
      "epoch 36: loss=2.4486587047576904\n",
      "epoch 37: loss=2.3438994884490967\n",
      "epoch 38: loss=2.44477915763855\n",
      "epoch 39: loss=2.38663387298584\n",
      "epoch 40: loss=2.4335334300994873\n",
      "epoch 41: loss=2.3510255813598633\n",
      "epoch 42: loss=2.366485118865967\n",
      "epoch 43: loss=2.3347089290618896\n",
      "epoch 44: loss=2.3330419063568115\n",
      "epoch 45: loss=2.3218297958374023\n",
      "epoch 46: loss=2.291512966156006\n",
      "epoch 47: loss=2.2547643184661865\n",
      "epoch 48: loss=2.2662882804870605\n",
      "epoch 49: loss=2.226377010345459\n",
      "epoch 50: loss=2.169529914855957\n",
      "epoch 51: loss=2.1334547996520996\n",
      "epoch 52: loss=2.141636371612549\n",
      "epoch 53: loss=2.0738484859466553\n",
      "epoch 54: loss=2.1232049465179443\n",
      "epoch 55: loss=2.056565999984741\n",
      "epoch 56: loss=2.0634541511535645\n",
      "epoch 57: loss=2.089737892150879\n",
      "epoch 58: loss=2.0632870197296143\n",
      "epoch 59: loss=2.0432868003845215\n",
      "epoch 60: loss=2.000978469848633\n",
      "epoch 61: loss=2.0209293365478516\n",
      "epoch 62: loss=2.0105504989624023\n",
      "epoch 63: loss=1.9952731132507324\n",
      "epoch 64: loss=2.009911060333252\n",
      "epoch 65: loss=2.050626277923584\n",
      "epoch 66: loss=2.0034942626953125\n",
      "epoch 67: loss=2.0179271697998047\n",
      "epoch 68: loss=1.95085608959198\n",
      "epoch 69: loss=1.9895167350769043\n",
      "epoch 70: loss=1.933527946472168\n",
      "epoch 71: loss=1.9944190979003906\n",
      "epoch 72: loss=2.047013282775879\n",
      "epoch 73: loss=1.981967568397522\n",
      "epoch 74: loss=2.000150442123413\n",
      "epoch 75: loss=1.9242875576019287\n",
      "epoch 76: loss=2.036966323852539\n",
      "epoch 77: loss=2.0037431716918945\n",
      "epoch 78: loss=1.922152042388916\n",
      "epoch 79: loss=1.921972393989563\n",
      "epoch 80: loss=1.9461923837661743\n",
      "epoch 81: loss=1.9711664915084839\n",
      "epoch 82: loss=1.908820390701294\n",
      "epoch 83: loss=1.9085137844085693\n",
      "epoch 84: loss=1.9169585704803467\n",
      "epoch 85: loss=1.9983141422271729\n",
      "epoch 86: loss=1.9246766567230225\n",
      "epoch 87: loss=1.9262150526046753\n",
      "epoch 88: loss=2.034943103790283\n",
      "epoch 89: loss=1.9750410318374634\n",
      "epoch 90: loss=1.9814324378967285\n",
      "epoch 91: loss=1.954465627670288\n",
      "epoch 92: loss=1.891767144203186\n",
      "epoch 93: loss=1.9875950813293457\n",
      "epoch 94: loss=1.948675274848938\n",
      "epoch 95: loss=1.885899305343628\n",
      "epoch 96: loss=1.941691279411316\n",
      "epoch 97: loss=1.9493597745895386\n",
      "epoch 98: loss=1.9359569549560547\n",
      "epoch 99: loss=1.9696760177612305\n",
      "epoch 100: loss=1.9527714252471924\n",
      "epoch 101: loss=1.9796421527862549\n",
      "epoch 102: loss=1.8791189193725586\n",
      "epoch 103: loss=1.9486896991729736\n",
      "epoch 104: loss=1.9323713779449463\n",
      "epoch 105: loss=1.9186569452285767\n",
      "epoch 106: loss=1.9396930932998657\n",
      "epoch 107: loss=1.9152452945709229\n",
      "epoch 108: loss=1.9345126152038574\n",
      "epoch 109: loss=1.9364979267120361\n",
      "epoch 110: loss=1.895826816558838\n",
      "epoch 111: loss=1.8878556489944458\n",
      "epoch 112: loss=1.9577503204345703\n",
      "epoch 113: loss=1.9672092199325562\n",
      "epoch 114: loss=1.9267799854278564\n",
      "epoch 115: loss=1.9761450290679932\n",
      "epoch 116: loss=1.9136137962341309\n",
      "epoch 117: loss=1.9903168678283691\n",
      "epoch 118: loss=1.838254690170288\n",
      "epoch 119: loss=1.9160668849945068\n",
      "epoch 120: loss=1.9038854837417603\n",
      "epoch 121: loss=1.8977279663085938\n",
      "epoch 122: loss=1.941804051399231\n",
      "epoch 123: loss=1.9185092449188232\n",
      "epoch 124: loss=1.89707350730896\n",
      "epoch 125: loss=1.9513096809387207\n",
      "epoch 126: loss=1.8798431158065796\n",
      "epoch 127: loss=1.946748971939087\n",
      "epoch 128: loss=1.9582765102386475\n",
      "epoch 129: loss=1.9789549112319946\n",
      "epoch 130: loss=1.910245656967163\n",
      "epoch 131: loss=1.8867144584655762\n",
      "epoch 132: loss=1.8808684349060059\n",
      "epoch 133: loss=1.8553712368011475\n",
      "epoch 134: loss=1.9273102283477783\n",
      "epoch 135: loss=1.9121785163879395\n",
      "epoch 136: loss=1.8925936222076416\n",
      "epoch 137: loss=1.9577105045318604\n",
      "epoch 138: loss=1.8748936653137207\n",
      "epoch 139: loss=1.8966352939605713\n",
      "epoch 140: loss=1.882007122039795\n",
      "epoch 141: loss=1.9335708618164062\n",
      "epoch 142: loss=1.9219893217086792\n",
      "epoch 143: loss=1.9663589000701904\n",
      "epoch 144: loss=1.9320874214172363\n",
      "epoch 145: loss=1.8693580627441406\n",
      "epoch 146: loss=1.9223623275756836\n",
      "epoch 147: loss=1.903926134109497\n",
      "epoch 148: loss=1.9206740856170654\n",
      "epoch 149: loss=2.0096335411071777\n",
      "epoch 150: loss=1.9071414470672607\n",
      "epoch 151: loss=1.956939935684204\n",
      "epoch 152: loss=1.9365841150283813\n",
      "epoch 153: loss=1.8620331287384033\n",
      "epoch 154: loss=1.8945825099945068\n",
      "epoch 155: loss=2.0020358562469482\n",
      "epoch 156: loss=1.9141466617584229\n",
      "epoch 157: loss=1.924680233001709\n",
      "epoch 158: loss=1.9310047626495361\n",
      "epoch 159: loss=1.8683393001556396\n",
      "epoch 160: loss=1.9621646404266357\n",
      "epoch 161: loss=1.9255101680755615\n",
      "epoch 162: loss=1.9454824924468994\n",
      "epoch 163: loss=1.8169240951538086\n",
      "epoch 164: loss=1.8919353485107422\n",
      "epoch 165: loss=1.8810887336730957\n",
      "epoch 166: loss=1.926068663597107\n",
      "epoch 167: loss=1.8844411373138428\n",
      "epoch 168: loss=1.8704884052276611\n",
      "epoch 169: loss=1.8649537563323975\n",
      "epoch 170: loss=1.8767249584197998\n",
      "epoch 171: loss=1.8909800052642822\n",
      "epoch 172: loss=1.9303205013275146\n",
      "epoch 173: loss=1.8999848365783691\n",
      "epoch 174: loss=1.9261422157287598\n",
      "epoch 175: loss=1.9444643259048462\n",
      "epoch 176: loss=1.9312020540237427\n",
      "epoch 177: loss=1.9178869724273682\n",
      "epoch 178: loss=1.9148619174957275\n",
      "epoch 179: loss=1.9857478141784668\n",
      "epoch 180: loss=1.953711748123169\n",
      "epoch 181: loss=1.9571208953857422\n",
      "epoch 182: loss=1.897890329360962\n",
      "epoch 183: loss=1.9226102828979492\n",
      "epoch 184: loss=1.8800489902496338\n",
      "epoch 185: loss=1.8385802507400513\n",
      "epoch 186: loss=1.8692015409469604\n",
      "epoch 187: loss=1.868506669998169\n",
      "epoch 188: loss=1.8985865116119385\n",
      "epoch 189: loss=1.8883002996444702\n",
      "epoch 190: loss=1.9051687717437744\n",
      "epoch 191: loss=1.8078348636627197\n",
      "epoch 192: loss=1.907633900642395\n",
      "epoch 193: loss=1.8949527740478516\n",
      "epoch 194: loss=1.869659662246704\n",
      "epoch 195: loss=1.9290189743041992\n",
      "epoch 196: loss=1.924159049987793\n",
      "epoch 197: loss=1.9468119144439697\n",
      "epoch 198: loss=1.9577744007110596\n",
      "epoch 199: loss=1.8625178337097168\n",
      "training patch with 1460 edges\n",
      "epoch 0: loss=14.560059547424316\n",
      "epoch 1: loss=14.313516616821289\n",
      "epoch 2: loss=13.719377517700195\n",
      "epoch 3: loss=12.498229026794434\n",
      "epoch 4: loss=13.260416030883789\n",
      "epoch 5: loss=12.34488582611084\n",
      "epoch 6: loss=12.051630973815918\n",
      "epoch 7: loss=11.170145988464355\n",
      "epoch 8: loss=10.861555099487305\n",
      "epoch 9: loss=10.954924583435059\n",
      "epoch 10: loss=10.73780345916748\n",
      "epoch 11: loss=9.735905647277832\n",
      "epoch 12: loss=8.86917495727539\n",
      "epoch 13: loss=8.123318672180176\n",
      "epoch 14: loss=6.664124011993408\n",
      "epoch 15: loss=5.973968982696533\n",
      "epoch 16: loss=5.662478923797607\n",
      "epoch 17: loss=4.888627052307129\n",
      "epoch 18: loss=4.761061191558838\n",
      "epoch 19: loss=4.156369686126709\n",
      "epoch 20: loss=3.6989195346832275\n",
      "epoch 21: loss=3.544386625289917\n",
      "epoch 22: loss=3.4244377613067627\n",
      "epoch 23: loss=3.178274631500244\n",
      "epoch 24: loss=2.8382201194763184\n",
      "epoch 25: loss=2.529616594314575\n",
      "epoch 26: loss=2.4596617221832275\n",
      "epoch 27: loss=2.3195438385009766\n",
      "epoch 28: loss=2.3724677562713623\n",
      "epoch 29: loss=2.342893123626709\n",
      "epoch 30: loss=2.3005788326263428\n",
      "epoch 31: loss=2.230933666229248\n",
      "epoch 32: loss=2.165220260620117\n",
      "epoch 33: loss=2.1450436115264893\n",
      "epoch 34: loss=2.1411056518554688\n",
      "epoch 35: loss=2.173640251159668\n",
      "epoch 36: loss=2.146649122238159\n",
      "epoch 37: loss=2.1725027561187744\n",
      "epoch 38: loss=2.128629684448242\n",
      "epoch 39: loss=2.1241917610168457\n",
      "epoch 40: loss=2.1045496463775635\n",
      "epoch 41: loss=2.0955188274383545\n",
      "epoch 42: loss=2.1038143634796143\n",
      "epoch 43: loss=2.093754291534424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44: loss=2.058520555496216\n",
      "epoch 45: loss=2.0881834030151367\n",
      "epoch 46: loss=2.0627353191375732\n",
      "epoch 47: loss=2.0408411026000977\n",
      "epoch 48: loss=2.022247314453125\n",
      "epoch 49: loss=1.9941591024398804\n",
      "epoch 50: loss=1.9720447063446045\n",
      "epoch 51: loss=1.9644299745559692\n",
      "epoch 52: loss=1.9601466655731201\n",
      "epoch 53: loss=1.9540138244628906\n",
      "epoch 54: loss=1.887585163116455\n",
      "epoch 55: loss=1.886716604232788\n",
      "epoch 56: loss=1.893463373184204\n",
      "epoch 57: loss=1.866856575012207\n",
      "epoch 58: loss=1.842603087425232\n",
      "epoch 59: loss=1.842844843864441\n",
      "epoch 60: loss=1.870003342628479\n",
      "epoch 61: loss=1.8546173572540283\n",
      "epoch 62: loss=1.8759361505508423\n",
      "epoch 63: loss=1.839081883430481\n",
      "epoch 64: loss=1.821309208869934\n",
      "epoch 65: loss=1.8256558179855347\n",
      "epoch 66: loss=1.8753294944763184\n",
      "epoch 67: loss=1.8108476400375366\n",
      "epoch 68: loss=1.802741527557373\n",
      "epoch 69: loss=1.7852044105529785\n",
      "epoch 70: loss=1.8060740232467651\n",
      "epoch 71: loss=1.7655023336410522\n",
      "epoch 72: loss=1.816792607307434\n",
      "epoch 73: loss=1.835261583328247\n",
      "epoch 74: loss=1.7712558507919312\n",
      "epoch 75: loss=1.7582405805587769\n",
      "epoch 76: loss=1.7346402406692505\n",
      "epoch 77: loss=1.8048286437988281\n",
      "epoch 78: loss=1.8353097438812256\n",
      "epoch 79: loss=1.7374769449234009\n",
      "epoch 80: loss=1.7704464197158813\n",
      "epoch 81: loss=1.7326552867889404\n",
      "epoch 82: loss=1.7912836074829102\n",
      "epoch 83: loss=1.7418447732925415\n",
      "epoch 84: loss=1.7453975677490234\n",
      "epoch 85: loss=1.7581777572631836\n",
      "epoch 86: loss=1.8217889070510864\n",
      "epoch 87: loss=1.7121539115905762\n",
      "epoch 88: loss=1.7542884349822998\n",
      "epoch 89: loss=1.7303286790847778\n",
      "epoch 90: loss=1.7619409561157227\n",
      "epoch 91: loss=1.7471007108688354\n",
      "epoch 92: loss=1.721614122390747\n",
      "epoch 93: loss=1.7088027000427246\n",
      "epoch 94: loss=1.766998052597046\n",
      "epoch 95: loss=1.7293033599853516\n",
      "epoch 96: loss=1.731959581375122\n",
      "epoch 97: loss=1.7153685092926025\n",
      "epoch 98: loss=1.7291189432144165\n",
      "epoch 99: loss=1.7200005054473877\n",
      "epoch 100: loss=1.6940436363220215\n",
      "epoch 101: loss=1.7153065204620361\n",
      "epoch 102: loss=1.6992177963256836\n",
      "epoch 103: loss=1.7772445678710938\n",
      "epoch 104: loss=1.6982085704803467\n",
      "epoch 105: loss=1.6981077194213867\n",
      "epoch 106: loss=1.667933702468872\n",
      "epoch 107: loss=1.7746663093566895\n",
      "epoch 108: loss=1.6968121528625488\n",
      "epoch 109: loss=1.7110881805419922\n",
      "epoch 110: loss=1.7286641597747803\n",
      "epoch 111: loss=1.7054870128631592\n",
      "epoch 112: loss=1.7494488954544067\n",
      "epoch 113: loss=1.717910885810852\n",
      "epoch 114: loss=1.698362946510315\n",
      "epoch 115: loss=1.6905274391174316\n",
      "epoch 116: loss=1.732424259185791\n",
      "epoch 117: loss=1.7347712516784668\n",
      "epoch 118: loss=1.7181651592254639\n",
      "epoch 119: loss=1.7007231712341309\n",
      "epoch 120: loss=1.695380449295044\n",
      "epoch 121: loss=1.6718083620071411\n",
      "epoch 122: loss=1.6923822164535522\n",
      "epoch 123: loss=1.7130794525146484\n",
      "epoch 124: loss=1.7087957859039307\n",
      "epoch 125: loss=1.6830518245697021\n",
      "epoch 126: loss=1.714569091796875\n",
      "epoch 127: loss=1.7219908237457275\n",
      "epoch 128: loss=1.6919279098510742\n",
      "epoch 129: loss=1.6887017488479614\n",
      "epoch 130: loss=1.7115906476974487\n",
      "epoch 131: loss=1.732116937637329\n",
      "epoch 132: loss=1.6498899459838867\n",
      "epoch 133: loss=1.6679632663726807\n",
      "epoch 134: loss=1.6823883056640625\n",
      "epoch 135: loss=1.7073122262954712\n",
      "epoch 136: loss=1.6686677932739258\n",
      "epoch 137: loss=1.706478238105774\n",
      "epoch 138: loss=1.6793268918991089\n",
      "epoch 139: loss=1.6558449268341064\n",
      "epoch 140: loss=1.7276034355163574\n",
      "epoch 141: loss=1.6926549673080444\n",
      "epoch 142: loss=1.7019500732421875\n",
      "epoch 143: loss=1.6448454856872559\n",
      "epoch 144: loss=1.693253517150879\n",
      "epoch 145: loss=1.7036323547363281\n",
      "epoch 146: loss=1.6991312503814697\n",
      "epoch 147: loss=1.7179034948349\n",
      "epoch 148: loss=1.6646170616149902\n",
      "epoch 149: loss=1.7015039920806885\n",
      "epoch 150: loss=1.642893671989441\n",
      "epoch 151: loss=1.6657639741897583\n",
      "epoch 152: loss=1.6787538528442383\n",
      "epoch 153: loss=1.6293303966522217\n",
      "epoch 154: loss=1.6843962669372559\n",
      "epoch 155: loss=1.6898913383483887\n",
      "epoch 156: loss=1.645895004272461\n",
      "epoch 157: loss=1.6870982646942139\n",
      "epoch 158: loss=1.7259531021118164\n",
      "epoch 159: loss=1.6417014598846436\n",
      "epoch 160: loss=1.6600770950317383\n",
      "epoch 161: loss=1.649147391319275\n",
      "epoch 162: loss=1.700145959854126\n",
      "epoch 163: loss=1.6839487552642822\n",
      "epoch 164: loss=1.6601158380508423\n",
      "epoch 165: loss=1.6560934782028198\n",
      "epoch 166: loss=1.6477563381195068\n",
      "epoch 167: loss=1.704423189163208\n",
      "epoch 168: loss=1.6961007118225098\n",
      "epoch 169: loss=1.6258256435394287\n",
      "epoch 170: loss=1.6614453792572021\n",
      "epoch 171: loss=1.6415555477142334\n",
      "epoch 172: loss=1.6664053201675415\n",
      "epoch 173: loss=1.711313009262085\n",
      "epoch 174: loss=1.6817481517791748\n",
      "epoch 175: loss=1.6578572988510132\n",
      "epoch 176: loss=1.6492807865142822\n",
      "epoch 177: loss=1.6846797466278076\n",
      "epoch 178: loss=1.668603777885437\n",
      "epoch 179: loss=1.6540740728378296\n",
      "epoch 180: loss=1.7022242546081543\n",
      "epoch 181: loss=1.6759077310562134\n",
      "epoch 182: loss=1.6777243614196777\n",
      "epoch 183: loss=1.6450104713439941\n",
      "epoch 184: loss=1.6708319187164307\n",
      "epoch 185: loss=1.6418778896331787\n",
      "epoch 186: loss=1.630918264389038\n",
      "epoch 187: loss=1.6312006711959839\n",
      "epoch 188: loss=1.6598997116088867\n",
      "epoch 189: loss=1.6599094867706299\n",
      "epoch 190: loss=1.6839780807495117\n",
      "epoch 191: loss=1.680854082107544\n",
      "epoch 192: loss=1.6570719480514526\n",
      "epoch 193: loss=1.6492540836334229\n",
      "epoch 194: loss=1.6931263208389282\n",
      "epoch 195: loss=1.6491930484771729\n",
      "epoch 196: loss=1.6622626781463623\n",
      "epoch 197: loss=1.6396148204803467\n",
      "epoch 198: loss=1.653712511062622\n",
      "epoch 199: loss=1.6447665691375732\n",
      "training patch with 764 edges\n",
      "epoch 0: loss=14.805802345275879\n",
      "epoch 1: loss=14.172382354736328\n",
      "epoch 2: loss=13.413237571716309\n",
      "epoch 3: loss=13.010002136230469\n",
      "epoch 4: loss=12.958938598632812\n",
      "epoch 5: loss=12.535970687866211\n",
      "epoch 6: loss=11.696301460266113\n",
      "epoch 7: loss=12.308900833129883\n",
      "epoch 8: loss=10.935393333435059\n",
      "epoch 9: loss=12.242778778076172\n",
      "epoch 10: loss=11.738543510437012\n",
      "epoch 11: loss=10.501643180847168\n",
      "epoch 12: loss=10.278494834899902\n",
      "epoch 13: loss=9.464253425598145\n",
      "epoch 14: loss=8.438769340515137\n",
      "epoch 15: loss=7.633713245391846\n",
      "epoch 16: loss=5.791752338409424\n",
      "epoch 17: loss=5.2815117835998535\n",
      "epoch 18: loss=4.993598937988281\n",
      "epoch 19: loss=4.525694847106934\n",
      "epoch 20: loss=3.9903969764709473\n",
      "epoch 21: loss=3.6942293643951416\n",
      "epoch 22: loss=3.685899496078491\n",
      "epoch 23: loss=3.604520559310913\n",
      "epoch 24: loss=3.2207179069519043\n",
      "epoch 25: loss=2.9325525760650635\n",
      "epoch 26: loss=2.8841052055358887\n",
      "epoch 27: loss=2.9018235206604004\n",
      "epoch 28: loss=2.86159086227417\n",
      "epoch 29: loss=2.8557958602905273\n",
      "epoch 30: loss=2.8710532188415527\n",
      "epoch 31: loss=2.708865165710449\n",
      "epoch 32: loss=2.692429304122925\n",
      "epoch 33: loss=2.6948771476745605\n",
      "epoch 34: loss=2.6541712284088135\n",
      "epoch 35: loss=2.6940836906433105\n",
      "epoch 36: loss=2.6844208240509033\n",
      "epoch 37: loss=2.649846315383911\n",
      "epoch 38: loss=2.6304116249084473\n",
      "epoch 39: loss=2.6040072441101074\n",
      "epoch 40: loss=2.5390143394470215\n",
      "epoch 41: loss=2.5734033584594727\n",
      "epoch 42: loss=2.510101318359375\n",
      "epoch 43: loss=2.492513656616211\n",
      "epoch 44: loss=2.448544502258301\n",
      "epoch 45: loss=2.4879255294799805\n",
      "epoch 46: loss=2.419863700866699\n",
      "epoch 47: loss=2.3668360710144043\n",
      "epoch 48: loss=2.3892393112182617\n",
      "epoch 49: loss=2.3809289932250977\n",
      "epoch 50: loss=2.3184545040130615\n",
      "epoch 51: loss=2.352325439453125\n",
      "epoch 52: loss=2.2975730895996094\n",
      "epoch 53: loss=2.2312960624694824\n",
      "epoch 54: loss=2.322939872741699\n",
      "epoch 55: loss=2.2242233753204346\n",
      "epoch 56: loss=2.3599472045898438\n",
      "epoch 57: loss=2.28762149810791\n",
      "epoch 58: loss=2.280015468597412\n",
      "epoch 59: loss=2.3503575325012207\n",
      "epoch 60: loss=2.3108139038085938\n",
      "epoch 61: loss=2.21718168258667\n",
      "epoch 62: loss=2.316816806793213\n",
      "epoch 63: loss=2.276345729827881\n",
      "epoch 64: loss=2.248936414718628\n",
      "epoch 65: loss=2.210099935531616\n",
      "epoch 66: loss=2.237488031387329\n",
      "epoch 67: loss=2.224032163619995\n",
      "epoch 68: loss=2.179103136062622\n",
      "epoch 69: loss=2.136260747909546\n",
      "epoch 70: loss=2.2132019996643066\n",
      "epoch 71: loss=2.1322171688079834\n",
      "epoch 72: loss=2.1164517402648926\n",
      "epoch 73: loss=2.212097406387329\n",
      "epoch 74: loss=2.111374616622925\n",
      "epoch 75: loss=2.196761131286621\n",
      "epoch 76: loss=2.0709517002105713\n",
      "epoch 77: loss=2.0994081497192383\n",
      "epoch 78: loss=2.1543281078338623\n",
      "epoch 79: loss=2.2321128845214844\n",
      "epoch 80: loss=2.1597166061401367\n",
      "epoch 81: loss=2.106994867324829\n",
      "epoch 82: loss=2.133645534515381\n",
      "epoch 83: loss=2.1318044662475586\n",
      "epoch 84: loss=2.1682229042053223\n",
      "epoch 85: loss=2.1949620246887207\n",
      "epoch 86: loss=2.089573860168457\n",
      "epoch 87: loss=2.1388275623321533\n",
      "epoch 88: loss=2.0494823455810547\n",
      "epoch 89: loss=2.1845602989196777\n",
      "epoch 90: loss=2.2339062690734863\n",
      "epoch 91: loss=2.0789554119110107\n",
      "epoch 92: loss=2.200495719909668\n",
      "epoch 93: loss=2.1129982471466064\n",
      "epoch 94: loss=2.150162696838379\n",
      "epoch 95: loss=2.1634135246276855\n",
      "epoch 96: loss=2.0885348320007324\n",
      "epoch 97: loss=2.1089625358581543\n",
      "epoch 98: loss=2.0839908123016357\n",
      "epoch 99: loss=2.128617286682129\n",
      "epoch 100: loss=2.082430362701416\n",
      "epoch 101: loss=2.1725568771362305\n",
      "epoch 102: loss=2.1905417442321777\n",
      "epoch 103: loss=2.1025595664978027\n",
      "epoch 104: loss=2.0959081649780273\n",
      "epoch 105: loss=2.1475865840911865\n",
      "epoch 106: loss=2.097576379776001\n",
      "epoch 107: loss=2.053332805633545\n",
      "epoch 108: loss=2.115778684616089\n",
      "epoch 109: loss=2.1088693141937256\n",
      "epoch 110: loss=2.148606300354004\n",
      "epoch 111: loss=2.132932662963867\n",
      "epoch 112: loss=2.1270432472229004\n",
      "epoch 113: loss=2.141801118850708\n",
      "epoch 114: loss=2.170541763305664\n",
      "epoch 115: loss=2.0597574710845947\n",
      "epoch 116: loss=2.072263717651367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117: loss=2.1207094192504883\n",
      "epoch 118: loss=2.085275173187256\n",
      "epoch 119: loss=2.0755183696746826\n",
      "epoch 120: loss=2.0940327644348145\n",
      "epoch 121: loss=2.174149990081787\n",
      "epoch 122: loss=2.130819320678711\n",
      "epoch 123: loss=2.1602418422698975\n",
      "epoch 124: loss=2.191556930541992\n",
      "epoch 125: loss=2.0490894317626953\n",
      "epoch 126: loss=2.1522629261016846\n",
      "epoch 127: loss=2.2014904022216797\n",
      "epoch 128: loss=2.106407880783081\n",
      "epoch 129: loss=2.0851552486419678\n",
      "epoch 130: loss=2.202291488647461\n",
      "epoch 131: loss=2.1477017402648926\n",
      "epoch 132: loss=2.1103391647338867\n",
      "epoch 133: loss=2.1604502201080322\n",
      "epoch 134: loss=2.159839153289795\n",
      "epoch 135: loss=2.0640869140625\n",
      "epoch 136: loss=2.02764630317688\n",
      "epoch 137: loss=2.1276750564575195\n",
      "epoch 138: loss=2.069471836090088\n",
      "epoch 139: loss=2.178396224975586\n",
      "epoch 140: loss=2.0144686698913574\n",
      "epoch 141: loss=2.0684988498687744\n",
      "epoch 142: loss=2.0993711948394775\n",
      "epoch 143: loss=2.0340747833251953\n",
      "epoch 144: loss=2.083906412124634\n",
      "epoch 145: loss=2.103337287902832\n",
      "epoch 146: loss=2.1723361015319824\n",
      "epoch 147: loss=2.0539121627807617\n",
      "epoch 148: loss=2.1113858222961426\n",
      "epoch 149: loss=2.0278730392456055\n",
      "epoch 150: loss=2.060256004333496\n",
      "epoch 151: loss=2.1356024742126465\n",
      "epoch 152: loss=2.090023994445801\n",
      "epoch 153: loss=2.0642635822296143\n",
      "epoch 154: loss=2.0614328384399414\n",
      "epoch 155: loss=2.100677490234375\n",
      "epoch 156: loss=2.0467357635498047\n",
      "epoch 157: loss=2.1931650638580322\n",
      "epoch 158: loss=2.0922391414642334\n",
      "epoch 159: loss=2.0790369510650635\n",
      "epoch 160: loss=2.0283892154693604\n",
      "epoch 161: loss=2.0839929580688477\n",
      "epoch 162: loss=2.067809581756592\n",
      "epoch 163: loss=2.0730433464050293\n",
      "epoch 164: loss=2.130159616470337\n",
      "epoch 165: loss=2.053006649017334\n",
      "epoch 166: loss=2.0923757553100586\n",
      "epoch 167: loss=2.094886064529419\n",
      "epoch 168: loss=2.033921480178833\n",
      "epoch 169: loss=2.033876895904541\n",
      "epoch 170: loss=2.0184855461120605\n",
      "epoch 171: loss=2.109402656555176\n",
      "epoch 172: loss=2.078723907470703\n",
      "epoch 173: loss=2.135166883468628\n",
      "epoch 174: loss=2.1377251148223877\n",
      "epoch 175: loss=2.008200168609619\n",
      "epoch 176: loss=2.0524075031280518\n",
      "epoch 177: loss=2.102534294128418\n",
      "epoch 178: loss=2.1401124000549316\n",
      "epoch 179: loss=2.0896761417388916\n",
      "epoch 180: loss=2.070096731185913\n",
      "epoch 181: loss=2.091508150100708\n",
      "epoch 182: loss=2.1158089637756348\n",
      "epoch 183: loss=1.996222734451294\n",
      "epoch 184: loss=2.0111093521118164\n",
      "epoch 185: loss=2.087038278579712\n",
      "epoch 186: loss=2.181624412536621\n",
      "epoch 187: loss=2.0567493438720703\n",
      "epoch 188: loss=2.0918633937835693\n",
      "epoch 189: loss=1.9785761833190918\n",
      "epoch 190: loss=2.0773868560791016\n",
      "epoch 191: loss=2.05141544342041\n",
      "epoch 192: loss=2.0032458305358887\n",
      "epoch 193: loss=2.13539981842041\n",
      "epoch 194: loss=2.0994606018066406\n",
      "epoch 195: loss=2.10550594329834\n",
      "epoch 196: loss=2.0977864265441895\n",
      "epoch 197: loss=1.9616161584854126\n",
      "epoch 198: loss=2.115428924560547\n",
      "epoch 199: loss=2.060983419418335\n",
      "training patch with 950 edges\n",
      "epoch 0: loss=14.243600845336914\n",
      "epoch 1: loss=14.3475341796875\n",
      "epoch 2: loss=14.563977241516113\n",
      "epoch 3: loss=13.369926452636719\n",
      "epoch 4: loss=13.382000923156738\n",
      "epoch 5: loss=12.094653129577637\n",
      "epoch 6: loss=12.246271133422852\n",
      "epoch 7: loss=10.172520637512207\n",
      "epoch 8: loss=10.836688041687012\n",
      "epoch 9: loss=10.422228813171387\n",
      "epoch 10: loss=10.91987419128418\n",
      "epoch 11: loss=10.806926727294922\n",
      "epoch 12: loss=9.096710205078125\n",
      "epoch 13: loss=9.118969917297363\n",
      "epoch 14: loss=7.760889053344727\n",
      "epoch 15: loss=6.388803482055664\n",
      "epoch 16: loss=6.104838848114014\n",
      "epoch 17: loss=5.824808597564697\n",
      "epoch 18: loss=5.033489227294922\n",
      "epoch 19: loss=4.514615535736084\n",
      "epoch 20: loss=4.297911643981934\n",
      "epoch 21: loss=3.9157309532165527\n",
      "epoch 22: loss=3.7660350799560547\n",
      "epoch 23: loss=3.5023715496063232\n",
      "epoch 24: loss=3.337066173553467\n",
      "epoch 25: loss=2.8872928619384766\n",
      "epoch 26: loss=2.7364187240600586\n",
      "epoch 27: loss=2.6141767501831055\n",
      "epoch 28: loss=2.495952844619751\n",
      "epoch 29: loss=2.516770124435425\n",
      "epoch 30: loss=2.554520845413208\n",
      "epoch 31: loss=2.550539016723633\n",
      "epoch 32: loss=2.4578022956848145\n",
      "epoch 33: loss=2.4237561225891113\n",
      "epoch 34: loss=2.434255361557007\n",
      "epoch 35: loss=2.436115264892578\n",
      "epoch 36: loss=2.442495107650757\n",
      "epoch 37: loss=2.4735803604125977\n",
      "epoch 38: loss=2.407024621963501\n",
      "epoch 39: loss=2.3902363777160645\n",
      "epoch 40: loss=2.397294044494629\n",
      "epoch 41: loss=2.3662362098693848\n",
      "epoch 42: loss=2.365671157836914\n",
      "epoch 43: loss=2.3871982097625732\n",
      "epoch 44: loss=2.33803129196167\n",
      "epoch 45: loss=2.3554539680480957\n",
      "epoch 46: loss=2.273198127746582\n",
      "epoch 47: loss=2.2649965286254883\n",
      "epoch 48: loss=2.2669925689697266\n",
      "epoch 49: loss=2.270296096801758\n",
      "epoch 50: loss=2.331969738006592\n",
      "epoch 51: loss=2.1913084983825684\n",
      "epoch 52: loss=2.226731300354004\n",
      "epoch 53: loss=2.211644172668457\n",
      "epoch 54: loss=2.148610830307007\n",
      "epoch 55: loss=2.1607208251953125\n",
      "epoch 56: loss=2.1304385662078857\n",
      "epoch 57: loss=2.0640878677368164\n",
      "epoch 58: loss=2.0728445053100586\n",
      "epoch 59: loss=2.1301305294036865\n",
      "epoch 60: loss=2.022135019302368\n",
      "epoch 61: loss=2.072073459625244\n",
      "epoch 62: loss=2.065786123275757\n",
      "epoch 63: loss=2.109832286834717\n",
      "epoch 64: loss=2.0739328861236572\n",
      "epoch 65: loss=2.0291409492492676\n",
      "epoch 66: loss=1.9950225353240967\n",
      "epoch 67: loss=2.0200092792510986\n",
      "epoch 68: loss=2.1075806617736816\n",
      "epoch 69: loss=2.052229881286621\n",
      "epoch 70: loss=2.061474561691284\n",
      "epoch 71: loss=1.9850637912750244\n",
      "epoch 72: loss=1.8947827816009521\n",
      "epoch 73: loss=1.9967619180679321\n",
      "epoch 74: loss=2.028571605682373\n",
      "epoch 75: loss=1.9559298753738403\n",
      "epoch 76: loss=1.972883939743042\n",
      "epoch 77: loss=1.998855471611023\n",
      "epoch 78: loss=1.9770336151123047\n",
      "epoch 79: loss=1.9782499074935913\n",
      "epoch 80: loss=2.0214364528656006\n",
      "epoch 81: loss=2.0255541801452637\n",
      "epoch 82: loss=1.9531108140945435\n",
      "epoch 83: loss=1.9983265399932861\n",
      "epoch 84: loss=1.96531081199646\n",
      "epoch 85: loss=1.9138035774230957\n",
      "epoch 86: loss=1.984566330909729\n",
      "epoch 87: loss=2.0251646041870117\n",
      "epoch 88: loss=1.9329884052276611\n",
      "epoch 89: loss=1.9566929340362549\n",
      "epoch 90: loss=1.9870474338531494\n",
      "epoch 91: loss=1.9485431909561157\n",
      "epoch 92: loss=1.9216316938400269\n",
      "epoch 93: loss=1.9419941902160645\n",
      "epoch 94: loss=1.9322535991668701\n",
      "epoch 95: loss=1.907233476638794\n",
      "epoch 96: loss=1.9260578155517578\n",
      "epoch 97: loss=1.9279778003692627\n",
      "epoch 98: loss=1.900393009185791\n",
      "epoch 99: loss=1.8860576152801514\n",
      "epoch 100: loss=1.908888339996338\n",
      "epoch 101: loss=1.9549078941345215\n",
      "epoch 102: loss=1.9383156299591064\n",
      "epoch 103: loss=1.94679856300354\n",
      "epoch 104: loss=1.934854507446289\n",
      "epoch 105: loss=1.9665422439575195\n",
      "epoch 106: loss=1.9152562618255615\n",
      "epoch 107: loss=1.9291932582855225\n",
      "epoch 108: loss=1.91227388381958\n",
      "epoch 109: loss=1.9433043003082275\n",
      "epoch 110: loss=1.9385087490081787\n",
      "epoch 111: loss=1.9337866306304932\n",
      "epoch 112: loss=1.9378626346588135\n",
      "epoch 113: loss=1.93155837059021\n",
      "epoch 114: loss=1.8989903926849365\n",
      "epoch 115: loss=1.8682165145874023\n",
      "epoch 116: loss=1.9132726192474365\n",
      "epoch 117: loss=1.8186132907867432\n",
      "epoch 118: loss=1.92457914352417\n",
      "epoch 119: loss=1.8949090242385864\n",
      "epoch 120: loss=1.9272587299346924\n",
      "epoch 121: loss=1.8770537376403809\n",
      "epoch 122: loss=1.8895376920700073\n",
      "epoch 123: loss=1.8949384689331055\n",
      "epoch 124: loss=1.9486380815505981\n",
      "epoch 125: loss=1.972019910812378\n",
      "epoch 126: loss=1.8753139972686768\n",
      "epoch 127: loss=1.9519603252410889\n",
      "epoch 128: loss=1.8679522275924683\n",
      "epoch 129: loss=1.980591893196106\n",
      "epoch 130: loss=1.9250648021697998\n",
      "epoch 131: loss=1.9319243431091309\n",
      "epoch 132: loss=1.9831390380859375\n",
      "epoch 133: loss=1.9184763431549072\n",
      "epoch 134: loss=1.9729559421539307\n",
      "epoch 135: loss=1.8954075574874878\n",
      "epoch 136: loss=1.895928978919983\n",
      "epoch 137: loss=1.875646948814392\n",
      "epoch 138: loss=1.9531805515289307\n",
      "epoch 139: loss=1.900278091430664\n",
      "epoch 140: loss=1.9057154655456543\n",
      "epoch 141: loss=1.8799431324005127\n",
      "epoch 142: loss=1.9232323169708252\n",
      "epoch 143: loss=1.8919167518615723\n",
      "epoch 144: loss=1.932037115097046\n",
      "epoch 145: loss=1.9193246364593506\n",
      "epoch 146: loss=1.951797604560852\n",
      "epoch 147: loss=1.8582454919815063\n",
      "epoch 148: loss=1.902852177619934\n",
      "epoch 149: loss=1.8702762126922607\n",
      "epoch 150: loss=1.8671157360076904\n",
      "epoch 151: loss=1.907278060913086\n",
      "epoch 152: loss=1.9220166206359863\n",
      "epoch 153: loss=1.8506141901016235\n",
      "epoch 154: loss=1.9022303819656372\n",
      "epoch 155: loss=1.8857805728912354\n",
      "epoch 156: loss=1.8547358512878418\n",
      "epoch 157: loss=1.9351716041564941\n",
      "epoch 158: loss=1.9157427549362183\n",
      "epoch 159: loss=1.920983076095581\n",
      "epoch 160: loss=1.865574836730957\n",
      "epoch 161: loss=1.902311086654663\n",
      "epoch 162: loss=1.8000105619430542\n",
      "epoch 163: loss=1.8660974502563477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164: loss=1.933161973953247\n",
      "epoch 165: loss=1.8793505430221558\n",
      "epoch 166: loss=1.8563439846038818\n",
      "epoch 167: loss=1.88430917263031\n",
      "epoch 168: loss=1.9600169658660889\n",
      "epoch 169: loss=1.9172230958938599\n",
      "epoch 170: loss=1.9072456359863281\n",
      "epoch 171: loss=1.8659064769744873\n",
      "epoch 172: loss=1.8483057022094727\n",
      "epoch 173: loss=1.9256901741027832\n",
      "epoch 174: loss=1.870866060256958\n",
      "epoch 175: loss=1.9246885776519775\n",
      "epoch 176: loss=1.8902721405029297\n",
      "epoch 177: loss=1.8917570114135742\n",
      "epoch 178: loss=1.9358124732971191\n",
      "epoch 179: loss=1.9051969051361084\n",
      "epoch 180: loss=1.8734214305877686\n",
      "epoch 181: loss=1.8723599910736084\n",
      "epoch 182: loss=1.8697576522827148\n",
      "epoch 183: loss=1.941056489944458\n",
      "epoch 184: loss=1.8798136711120605\n",
      "epoch 185: loss=1.8308926820755005\n",
      "epoch 186: loss=1.9004781246185303\n",
      "epoch 187: loss=1.881174921989441\n",
      "epoch 188: loss=1.8797111511230469\n",
      "epoch 189: loss=1.8351960182189941\n",
      "epoch 190: loss=1.9520481824874878\n",
      "epoch 191: loss=1.90659761428833\n",
      "epoch 192: loss=1.895949363708496\n",
      "epoch 193: loss=1.8805201053619385\n",
      "epoch 194: loss=1.8965203762054443\n",
      "epoch 195: loss=1.933100938796997\n",
      "epoch 196: loss=1.902694582939148\n",
      "epoch 197: loss=1.8205657005310059\n",
      "epoch 198: loss=1.8971693515777588\n",
      "epoch 199: loss=1.868321180343628\n",
      "training patch with 2922 edges\n",
      "epoch 0: loss=13.848984718322754\n",
      "epoch 1: loss=13.996700286865234\n",
      "epoch 2: loss=13.978824615478516\n",
      "epoch 3: loss=13.169498443603516\n",
      "epoch 4: loss=12.475608825683594\n",
      "epoch 5: loss=12.501984596252441\n",
      "epoch 6: loss=10.938310623168945\n",
      "epoch 7: loss=10.342144966125488\n",
      "epoch 8: loss=10.175898551940918\n",
      "epoch 9: loss=9.682845115661621\n",
      "epoch 10: loss=9.631125450134277\n",
      "epoch 11: loss=8.24341106414795\n",
      "epoch 12: loss=6.8617119789123535\n",
      "epoch 13: loss=5.6184306144714355\n",
      "epoch 14: loss=4.757880210876465\n",
      "epoch 15: loss=4.148915767669678\n",
      "epoch 16: loss=3.643847703933716\n",
      "epoch 17: loss=3.420886993408203\n",
      "epoch 18: loss=3.0007567405700684\n",
      "epoch 19: loss=2.8193845748901367\n",
      "epoch 20: loss=2.640310764312744\n",
      "epoch 21: loss=2.438788890838623\n",
      "epoch 22: loss=2.1936452388763428\n",
      "epoch 23: loss=2.041707992553711\n",
      "epoch 24: loss=1.9811934232711792\n",
      "epoch 25: loss=1.9541611671447754\n",
      "epoch 26: loss=1.9433021545410156\n",
      "epoch 27: loss=1.9320980310440063\n",
      "epoch 28: loss=1.886587381362915\n",
      "epoch 29: loss=1.8471684455871582\n",
      "epoch 30: loss=1.816989779472351\n",
      "epoch 31: loss=1.8080224990844727\n",
      "epoch 32: loss=1.8124165534973145\n",
      "epoch 33: loss=1.8063831329345703\n",
      "epoch 34: loss=1.8259313106536865\n",
      "epoch 35: loss=1.812190294265747\n",
      "epoch 36: loss=1.7964961528778076\n",
      "epoch 37: loss=1.7996127605438232\n",
      "epoch 38: loss=1.7800819873809814\n",
      "epoch 39: loss=1.7764191627502441\n",
      "epoch 40: loss=1.7781240940093994\n",
      "epoch 41: loss=1.7826611995697021\n",
      "epoch 42: loss=1.7711511850357056\n",
      "epoch 43: loss=1.7533080577850342\n",
      "epoch 44: loss=1.7471339702606201\n",
      "epoch 45: loss=1.7372808456420898\n",
      "epoch 46: loss=1.7290087938308716\n",
      "epoch 47: loss=1.7197989225387573\n",
      "epoch 48: loss=1.6909822225570679\n",
      "epoch 49: loss=1.6809931993484497\n",
      "epoch 50: loss=1.6677230596542358\n",
      "epoch 51: loss=1.6522399187088013\n",
      "epoch 52: loss=1.6470295190811157\n",
      "epoch 53: loss=1.6521224975585938\n",
      "epoch 54: loss=1.6185643672943115\n",
      "epoch 55: loss=1.6168479919433594\n",
      "epoch 56: loss=1.5908136367797852\n",
      "epoch 57: loss=1.562208890914917\n",
      "epoch 58: loss=1.5434809923171997\n",
      "epoch 59: loss=1.5313018560409546\n",
      "epoch 60: loss=1.528873324394226\n",
      "epoch 61: loss=1.5018349885940552\n",
      "epoch 62: loss=1.4822574853897095\n",
      "epoch 63: loss=1.4710421562194824\n",
      "epoch 64: loss=1.4622702598571777\n",
      "epoch 65: loss=1.4491684436798096\n",
      "epoch 66: loss=1.430029273033142\n",
      "epoch 67: loss=1.4328389167785645\n",
      "epoch 68: loss=1.4103312492370605\n",
      "epoch 69: loss=1.4236316680908203\n",
      "epoch 70: loss=1.3962163925170898\n",
      "epoch 71: loss=1.4202004671096802\n",
      "epoch 72: loss=1.4150381088256836\n",
      "epoch 73: loss=1.4299707412719727\n",
      "epoch 74: loss=1.4112660884857178\n",
      "epoch 75: loss=1.398789644241333\n",
      "epoch 76: loss=1.400031328201294\n",
      "epoch 77: loss=1.3781330585479736\n",
      "epoch 78: loss=1.385632872581482\n",
      "epoch 79: loss=1.3943899869918823\n",
      "epoch 80: loss=1.3809990882873535\n",
      "epoch 81: loss=1.368053674697876\n",
      "epoch 82: loss=1.3472583293914795\n",
      "epoch 83: loss=1.3906853199005127\n",
      "epoch 84: loss=1.3567824363708496\n",
      "epoch 85: loss=1.3639487028121948\n",
      "epoch 86: loss=1.346364974975586\n",
      "epoch 87: loss=1.3465323448181152\n",
      "epoch 88: loss=1.3681877851486206\n",
      "epoch 89: loss=1.3352328538894653\n",
      "epoch 90: loss=1.3674383163452148\n",
      "epoch 91: loss=1.339930772781372\n",
      "epoch 92: loss=1.351314902305603\n",
      "epoch 93: loss=1.3386489152908325\n",
      "epoch 94: loss=1.3539860248565674\n",
      "epoch 95: loss=1.3582913875579834\n",
      "epoch 96: loss=1.3439000844955444\n",
      "epoch 97: loss=1.3493773937225342\n",
      "epoch 98: loss=1.3428940773010254\n",
      "epoch 99: loss=1.3120214939117432\n",
      "epoch 100: loss=1.3393388986587524\n",
      "epoch 101: loss=1.3332566022872925\n",
      "epoch 102: loss=1.3317996263504028\n",
      "epoch 103: loss=1.3253153562545776\n",
      "epoch 104: loss=1.3569599390029907\n",
      "epoch 105: loss=1.3565633296966553\n",
      "epoch 106: loss=1.3161125183105469\n",
      "epoch 107: loss=1.3042782545089722\n",
      "epoch 108: loss=1.310272455215454\n",
      "epoch 109: loss=1.3200730085372925\n",
      "epoch 110: loss=1.338609218597412\n",
      "epoch 111: loss=1.3229762315750122\n",
      "epoch 112: loss=1.325505256652832\n",
      "epoch 113: loss=1.3357888460159302\n",
      "epoch 114: loss=1.3369728326797485\n",
      "epoch 115: loss=1.305628776550293\n",
      "epoch 116: loss=1.3018604516983032\n",
      "epoch 117: loss=1.3039180040359497\n",
      "epoch 118: loss=1.3227002620697021\n",
      "epoch 119: loss=1.3037620782852173\n",
      "epoch 120: loss=1.321155071258545\n",
      "epoch 121: loss=1.3393535614013672\n",
      "epoch 122: loss=1.308699131011963\n",
      "epoch 123: loss=1.3297467231750488\n",
      "epoch 124: loss=1.3246641159057617\n",
      "epoch 125: loss=1.3080734014511108\n",
      "epoch 126: loss=1.3260561227798462\n",
      "epoch 127: loss=1.2950488328933716\n",
      "epoch 128: loss=1.3139913082122803\n",
      "epoch 129: loss=1.320876121520996\n",
      "epoch 130: loss=1.3051238059997559\n",
      "epoch 131: loss=1.3232991695404053\n",
      "epoch 132: loss=1.294769048690796\n",
      "epoch 133: loss=1.3161876201629639\n",
      "epoch 134: loss=1.309574842453003\n",
      "epoch 135: loss=1.3118029832839966\n",
      "epoch 136: loss=1.3023419380187988\n",
      "epoch 137: loss=1.312614917755127\n",
      "epoch 138: loss=1.3064686059951782\n",
      "epoch 139: loss=1.3147584199905396\n",
      "epoch 140: loss=1.305482268333435\n",
      "epoch 141: loss=1.3319852352142334\n",
      "epoch 142: loss=1.2825329303741455\n",
      "epoch 143: loss=1.3005971908569336\n",
      "epoch 144: loss=1.3087652921676636\n",
      "epoch 145: loss=1.3061766624450684\n",
      "epoch 146: loss=1.3270013332366943\n",
      "epoch 147: loss=1.2978912591934204\n",
      "epoch 148: loss=1.3119990825653076\n",
      "epoch 149: loss=1.3139382600784302\n",
      "epoch 150: loss=1.317903995513916\n",
      "epoch 151: loss=1.3006421327590942\n",
      "epoch 152: loss=1.2821831703186035\n",
      "epoch 153: loss=1.32127845287323\n",
      "epoch 154: loss=1.3187861442565918\n",
      "epoch 155: loss=1.305426836013794\n",
      "epoch 156: loss=1.2957717180252075\n",
      "epoch 157: loss=1.3002910614013672\n",
      "epoch 158: loss=1.308404803276062\n",
      "epoch 159: loss=1.308060884475708\n",
      "epoch 160: loss=1.2792106866836548\n",
      "epoch 161: loss=1.285793423652649\n",
      "epoch 162: loss=1.2889947891235352\n",
      "epoch 163: loss=1.3092522621154785\n",
      "epoch 164: loss=1.3081185817718506\n",
      "epoch 165: loss=1.3141448497772217\n",
      "epoch 166: loss=1.3008391857147217\n",
      "epoch 167: loss=1.3146940469741821\n",
      "epoch 168: loss=1.2826834917068481\n",
      "epoch 169: loss=1.309721827507019\n",
      "epoch 170: loss=1.2894130945205688\n",
      "epoch 171: loss=1.2986781597137451\n",
      "epoch 172: loss=1.314622163772583\n",
      "epoch 173: loss=1.2902907133102417\n",
      "epoch 174: loss=1.2985135316848755\n",
      "epoch 175: loss=1.2947452068328857\n",
      "epoch 176: loss=1.3041082620620728\n",
      "epoch 177: loss=1.3008184432983398\n",
      "epoch 178: loss=1.2872225046157837\n",
      "epoch 179: loss=1.303819179534912\n",
      "epoch 180: loss=1.2940560579299927\n",
      "epoch 181: loss=1.3018627166748047\n",
      "epoch 182: loss=1.2955012321472168\n",
      "epoch 183: loss=1.2992887496948242\n",
      "epoch 184: loss=1.300927758216858\n",
      "epoch 185: loss=1.2837287187576294\n",
      "epoch 186: loss=1.2977088689804077\n",
      "epoch 187: loss=1.31624436378479\n",
      "epoch 188: loss=1.3074939250946045\n",
      "epoch 189: loss=1.2871578931808472\n",
      "epoch 190: loss=1.2913504838943481\n",
      "epoch 191: loss=1.2820382118225098\n",
      "epoch 192: loss=1.2706968784332275\n",
      "epoch 193: loss=1.2975425720214844\n",
      "epoch 194: loss=1.3039895296096802\n",
      "epoch 195: loss=1.293020248413086\n",
      "epoch 196: loss=1.2885138988494873\n",
      "epoch 197: loss=1.2653502225875854\n",
      "epoch 198: loss=1.2852504253387451\n",
      "epoch 199: loss=1.3034974336624146\n",
      "training patch with 1698 edges\n",
      "epoch 0: loss=13.906660079956055\n",
      "epoch 1: loss=14.10072135925293\n",
      "epoch 2: loss=14.260995864868164\n",
      "epoch 3: loss=12.80002212524414\n",
      "epoch 4: loss=12.525704383850098\n",
      "epoch 5: loss=11.259893417358398\n",
      "epoch 6: loss=11.182486534118652\n",
      "epoch 7: loss=10.602425575256348\n",
      "epoch 8: loss=10.456543922424316\n",
      "epoch 9: loss=9.72131633758545\n",
      "epoch 10: loss=9.342629432678223\n",
      "epoch 11: loss=7.972438812255859\n",
      "epoch 12: loss=6.413017749786377\n",
      "epoch 13: loss=5.403236389160156\n",
      "epoch 14: loss=4.847357749938965\n",
      "epoch 15: loss=4.396726608276367\n",
      "epoch 16: loss=3.526817560195923\n",
      "epoch 17: loss=3.3444559574127197\n",
      "epoch 18: loss=3.106382369995117\n",
      "epoch 19: loss=2.8915233612060547\n",
      "epoch 20: loss=2.8053882122039795\n",
      "epoch 21: loss=2.4780845642089844\n",
      "epoch 22: loss=2.265225887298584\n",
      "epoch 23: loss=2.171757459640503\n",
      "epoch 24: loss=2.2389683723449707\n",
      "epoch 25: loss=2.179760694503784\n",
      "epoch 26: loss=2.211214065551758\n",
      "epoch 27: loss=2.2025885581970215\n",
      "epoch 28: loss=2.1131863594055176\n",
      "epoch 29: loss=2.1075804233551025\n",
      "epoch 30: loss=2.140516996383667\n",
      "epoch 31: loss=2.12062406539917\n",
      "epoch 32: loss=2.111287832260132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33: loss=2.1186912059783936\n",
      "epoch 34: loss=2.1014816761016846\n",
      "epoch 35: loss=2.1113274097442627\n",
      "epoch 36: loss=2.1029908657073975\n",
      "epoch 37: loss=2.0860910415649414\n",
      "epoch 38: loss=2.0912156105041504\n",
      "epoch 39: loss=2.0504488945007324\n",
      "epoch 40: loss=2.035093069076538\n",
      "epoch 41: loss=2.0398809909820557\n",
      "epoch 42: loss=2.010589599609375\n",
      "epoch 43: loss=2.003873348236084\n",
      "epoch 44: loss=1.9921753406524658\n",
      "epoch 45: loss=1.9788744449615479\n",
      "epoch 46: loss=1.958174467086792\n",
      "epoch 47: loss=1.9238603115081787\n",
      "epoch 48: loss=1.902759075164795\n",
      "epoch 49: loss=1.9032676219940186\n",
      "epoch 50: loss=1.8632278442382812\n",
      "epoch 51: loss=1.8448545932769775\n",
      "epoch 52: loss=1.832416296005249\n",
      "epoch 53: loss=1.7925901412963867\n",
      "epoch 54: loss=1.7904467582702637\n",
      "epoch 55: loss=1.7635773420333862\n",
      "epoch 56: loss=1.7680259943008423\n",
      "epoch 57: loss=1.7271854877471924\n",
      "epoch 58: loss=1.7232170104980469\n",
      "epoch 59: loss=1.6906027793884277\n",
      "epoch 60: loss=1.6453421115875244\n",
      "epoch 61: loss=1.6923109292984009\n",
      "epoch 62: loss=1.6676371097564697\n",
      "epoch 63: loss=1.660512089729309\n",
      "epoch 64: loss=1.6246118545532227\n",
      "epoch 65: loss=1.6379377841949463\n",
      "epoch 66: loss=1.628736972808838\n",
      "epoch 67: loss=1.6503119468688965\n",
      "epoch 68: loss=1.6608667373657227\n",
      "epoch 69: loss=1.6226956844329834\n",
      "epoch 70: loss=1.6676149368286133\n",
      "epoch 71: loss=1.6593263149261475\n",
      "epoch 72: loss=1.6556360721588135\n",
      "epoch 73: loss=1.666938066482544\n",
      "epoch 74: loss=1.5918898582458496\n",
      "epoch 75: loss=1.5858227014541626\n",
      "epoch 76: loss=1.6390700340270996\n",
      "epoch 77: loss=1.6390371322631836\n",
      "epoch 78: loss=1.6095399856567383\n",
      "epoch 79: loss=1.6344044208526611\n",
      "epoch 80: loss=1.5538668632507324\n",
      "epoch 81: loss=1.6189148426055908\n",
      "epoch 82: loss=1.5802820920944214\n",
      "epoch 83: loss=1.591506838798523\n",
      "epoch 84: loss=1.5938196182250977\n",
      "epoch 85: loss=1.5619213581085205\n",
      "epoch 86: loss=1.626117467880249\n",
      "epoch 87: loss=1.6138441562652588\n",
      "epoch 88: loss=1.6346936225891113\n",
      "epoch 89: loss=1.5918428897857666\n",
      "epoch 90: loss=1.6018385887145996\n",
      "epoch 91: loss=1.5906553268432617\n",
      "epoch 92: loss=1.6069319248199463\n",
      "epoch 93: loss=1.5915884971618652\n",
      "epoch 94: loss=1.5996520519256592\n",
      "epoch 95: loss=1.5969536304473877\n",
      "epoch 96: loss=1.593139410018921\n",
      "epoch 97: loss=1.562441110610962\n",
      "epoch 98: loss=1.5765948295593262\n",
      "epoch 99: loss=1.632064700126648\n",
      "epoch 100: loss=1.5880024433135986\n",
      "epoch 101: loss=1.5995314121246338\n",
      "epoch 102: loss=1.5852175951004028\n",
      "epoch 103: loss=1.5739967823028564\n",
      "epoch 104: loss=1.581984043121338\n",
      "epoch 105: loss=1.5655395984649658\n",
      "epoch 106: loss=1.5478957891464233\n",
      "epoch 107: loss=1.590250015258789\n",
      "epoch 108: loss=1.552699089050293\n",
      "epoch 109: loss=1.569828748703003\n",
      "epoch 110: loss=1.5753693580627441\n",
      "epoch 111: loss=1.577656865119934\n",
      "epoch 112: loss=1.569803237915039\n",
      "epoch 113: loss=1.5516531467437744\n",
      "epoch 114: loss=1.523524284362793\n",
      "epoch 115: loss=1.5778874158859253\n",
      "epoch 116: loss=1.5528589487075806\n",
      "epoch 117: loss=1.6137349605560303\n",
      "epoch 118: loss=1.5884838104248047\n",
      "epoch 119: loss=1.566256046295166\n",
      "epoch 120: loss=1.576110601425171\n",
      "epoch 121: loss=1.5857880115509033\n",
      "epoch 122: loss=1.5645134449005127\n",
      "epoch 123: loss=1.544745922088623\n",
      "epoch 124: loss=1.5893906354904175\n",
      "epoch 125: loss=1.5495635271072388\n",
      "epoch 126: loss=1.5844638347625732\n",
      "epoch 127: loss=1.5290076732635498\n",
      "epoch 128: loss=1.5568175315856934\n",
      "epoch 129: loss=1.5419518947601318\n",
      "epoch 130: loss=1.5701818466186523\n",
      "epoch 131: loss=1.542866587638855\n",
      "epoch 132: loss=1.5663459300994873\n",
      "epoch 133: loss=1.560520052909851\n",
      "epoch 134: loss=1.5916576385498047\n",
      "epoch 135: loss=1.5523626804351807\n",
      "epoch 136: loss=1.5620231628417969\n",
      "epoch 137: loss=1.5756821632385254\n",
      "epoch 138: loss=1.5652037858963013\n",
      "epoch 139: loss=1.5580737590789795\n",
      "epoch 140: loss=1.5111358165740967\n",
      "epoch 141: loss=1.540649652481079\n",
      "epoch 142: loss=1.5538519620895386\n",
      "epoch 143: loss=1.5583581924438477\n",
      "epoch 144: loss=1.5649062395095825\n",
      "epoch 145: loss=1.5640013217926025\n",
      "epoch 146: loss=1.5473896265029907\n",
      "epoch 147: loss=1.578528642654419\n",
      "epoch 148: loss=1.5247122049331665\n",
      "epoch 149: loss=1.55049467086792\n",
      "epoch 150: loss=1.5887387990951538\n",
      "epoch 151: loss=1.569507360458374\n",
      "epoch 152: loss=1.54620361328125\n",
      "epoch 153: loss=1.5727581977844238\n",
      "epoch 154: loss=1.5216110944747925\n",
      "epoch 155: loss=1.5298998355865479\n",
      "epoch 156: loss=1.5366407632827759\n",
      "epoch 157: loss=1.5775809288024902\n",
      "epoch 158: loss=1.5374436378479004\n",
      "epoch 159: loss=1.5599923133850098\n",
      "epoch 160: loss=1.5730559825897217\n",
      "epoch 161: loss=1.5406262874603271\n",
      "epoch 162: loss=1.5847210884094238\n",
      "epoch 163: loss=1.558424472808838\n",
      "epoch 164: loss=1.5480363368988037\n",
      "epoch 165: loss=1.5577538013458252\n",
      "epoch 166: loss=1.5240755081176758\n",
      "epoch 167: loss=1.5241832733154297\n",
      "epoch 168: loss=1.534501314163208\n",
      "epoch 169: loss=1.5943540334701538\n",
      "epoch 170: loss=1.558009386062622\n",
      "epoch 171: loss=1.5373828411102295\n",
      "epoch 172: loss=1.535395860671997\n",
      "epoch 173: loss=1.5553693771362305\n",
      "epoch 174: loss=1.5733375549316406\n",
      "epoch 175: loss=1.532473087310791\n",
      "epoch 176: loss=1.5136733055114746\n",
      "epoch 177: loss=1.5542230606079102\n",
      "epoch 178: loss=1.5472614765167236\n",
      "epoch 179: loss=1.550950288772583\n",
      "epoch 180: loss=1.5694912672042847\n",
      "epoch 181: loss=1.5337433815002441\n",
      "epoch 182: loss=1.5357208251953125\n",
      "epoch 183: loss=1.5012656450271606\n",
      "epoch 184: loss=1.507822871208191\n",
      "epoch 185: loss=1.5193418264389038\n",
      "epoch 186: loss=1.527700424194336\n",
      "epoch 187: loss=1.5352592468261719\n",
      "epoch 188: loss=1.4972946643829346\n",
      "epoch 189: loss=1.5430498123168945\n",
      "epoch 190: loss=1.5466971397399902\n",
      "epoch 191: loss=1.533058524131775\n",
      "epoch 192: loss=1.5531151294708252\n",
      "epoch 193: loss=1.5464115142822266\n",
      "epoch 194: loss=1.5450448989868164\n",
      "epoch 195: loss=1.563600778579712\n",
      "epoch 196: loss=1.5591013431549072\n",
      "epoch 197: loss=1.5320460796356201\n",
      "epoch 198: loss=1.5327332019805908\n",
      "epoch 199: loss=1.5245163440704346\n",
      "training patch with 670 edges\n",
      "epoch 0: loss=14.853381156921387\n",
      "epoch 1: loss=12.993792533874512\n",
      "epoch 2: loss=13.61219310760498\n",
      "epoch 3: loss=13.630290985107422\n",
      "epoch 4: loss=12.470073699951172\n",
      "epoch 5: loss=12.989739418029785\n",
      "epoch 6: loss=12.54118824005127\n",
      "epoch 7: loss=11.560548782348633\n",
      "epoch 8: loss=11.329660415649414\n",
      "epoch 9: loss=12.066365242004395\n",
      "epoch 10: loss=11.288330078125\n",
      "epoch 11: loss=11.106449127197266\n",
      "epoch 12: loss=10.336400032043457\n",
      "epoch 13: loss=9.022722244262695\n",
      "epoch 14: loss=8.388203620910645\n",
      "epoch 15: loss=7.337252616882324\n",
      "epoch 16: loss=6.84583854675293\n",
      "epoch 17: loss=6.4145708084106445\n",
      "epoch 18: loss=5.682803630828857\n",
      "epoch 19: loss=5.0118021965026855\n",
      "epoch 20: loss=4.429471492767334\n",
      "epoch 21: loss=4.0801897048950195\n",
      "epoch 22: loss=3.7909109592437744\n",
      "epoch 23: loss=3.402647018432617\n",
      "epoch 24: loss=3.5467593669891357\n",
      "epoch 25: loss=2.965928554534912\n",
      "epoch 26: loss=3.076253652572632\n",
      "epoch 27: loss=2.8251848220825195\n",
      "epoch 28: loss=2.750354766845703\n",
      "epoch 29: loss=2.7767696380615234\n",
      "epoch 30: loss=2.792705535888672\n",
      "epoch 31: loss=2.8768553733825684\n",
      "epoch 32: loss=2.781872510910034\n",
      "epoch 33: loss=2.6871495246887207\n",
      "epoch 34: loss=2.6662545204162598\n",
      "epoch 35: loss=2.7367947101593018\n",
      "epoch 36: loss=2.6876590251922607\n",
      "epoch 37: loss=2.6950666904449463\n",
      "epoch 38: loss=2.677030086517334\n",
      "epoch 39: loss=2.656240463256836\n",
      "epoch 40: loss=2.6798901557922363\n",
      "epoch 41: loss=2.662393569946289\n",
      "epoch 42: loss=2.6389310359954834\n",
      "epoch 43: loss=2.568378448486328\n",
      "epoch 44: loss=2.506178379058838\n",
      "epoch 45: loss=2.519073963165283\n",
      "epoch 46: loss=2.559652328491211\n",
      "epoch 47: loss=2.414001941680908\n",
      "epoch 48: loss=2.498626708984375\n",
      "epoch 49: loss=2.538193464279175\n",
      "epoch 50: loss=2.406698703765869\n",
      "epoch 51: loss=2.386488437652588\n",
      "epoch 52: loss=2.424434185028076\n",
      "epoch 53: loss=2.4294514656066895\n",
      "epoch 54: loss=2.3886289596557617\n",
      "epoch 55: loss=2.4206182956695557\n",
      "epoch 56: loss=2.3902878761291504\n",
      "epoch 57: loss=2.3824057579040527\n",
      "epoch 58: loss=2.309365749359131\n",
      "epoch 59: loss=2.3149302005767822\n",
      "epoch 60: loss=2.359600782394409\n",
      "epoch 61: loss=2.349407196044922\n",
      "epoch 62: loss=2.4159464836120605\n",
      "epoch 63: loss=2.3312132358551025\n",
      "epoch 64: loss=2.3309855461120605\n",
      "epoch 65: loss=2.3241519927978516\n",
      "epoch 66: loss=2.2122185230255127\n",
      "epoch 67: loss=2.3207178115844727\n",
      "epoch 68: loss=2.2895069122314453\n",
      "epoch 69: loss=2.248847246170044\n",
      "epoch 70: loss=2.2230300903320312\n",
      "epoch 71: loss=2.2446184158325195\n",
      "epoch 72: loss=2.2466039657592773\n",
      "epoch 73: loss=2.2446539402008057\n",
      "epoch 74: loss=2.1845169067382812\n",
      "epoch 75: loss=2.1964428424835205\n",
      "epoch 76: loss=2.2357230186462402\n",
      "epoch 77: loss=2.174072742462158\n",
      "epoch 78: loss=2.207254409790039\n",
      "epoch 79: loss=2.1974799633026123\n",
      "epoch 80: loss=2.1579525470733643\n",
      "epoch 81: loss=2.248763084411621\n",
      "epoch 82: loss=2.1739652156829834\n",
      "epoch 83: loss=2.2929325103759766\n",
      "epoch 84: loss=2.2488293647766113\n",
      "epoch 85: loss=2.2638163566589355\n",
      "epoch 86: loss=2.2147421836853027\n",
      "epoch 87: loss=2.1178548336029053\n",
      "epoch 88: loss=2.270911693572998\n",
      "epoch 89: loss=2.1778581142425537\n",
      "epoch 90: loss=2.241459369659424\n",
      "epoch 91: loss=2.152891159057617\n",
      "epoch 92: loss=2.189053773880005\n",
      "epoch 93: loss=2.155341625213623\n",
      "epoch 94: loss=2.1915881633758545\n",
      "epoch 95: loss=2.1895270347595215\n",
      "epoch 96: loss=2.228494644165039\n",
      "epoch 97: loss=2.1249747276306152\n",
      "epoch 98: loss=2.192117691040039\n",
      "epoch 99: loss=2.1518287658691406\n",
      "epoch 100: loss=2.096367359161377\n",
      "epoch 101: loss=2.224215507507324\n",
      "epoch 102: loss=2.237039089202881\n",
      "epoch 103: loss=2.1336002349853516\n",
      "epoch 104: loss=2.1651248931884766\n",
      "epoch 105: loss=2.2057337760925293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106: loss=2.224477767944336\n",
      "epoch 107: loss=2.148466110229492\n",
      "epoch 108: loss=2.0821382999420166\n",
      "epoch 109: loss=2.126169204711914\n",
      "epoch 110: loss=2.2568705081939697\n",
      "epoch 111: loss=2.1482675075531006\n",
      "epoch 112: loss=2.161282539367676\n",
      "epoch 113: loss=2.154284954071045\n",
      "epoch 114: loss=2.1712162494659424\n",
      "epoch 115: loss=2.196047067642212\n",
      "epoch 116: loss=2.191452741622925\n",
      "epoch 117: loss=2.2260360717773438\n",
      "epoch 118: loss=2.0914249420166016\n",
      "epoch 119: loss=2.0816922187805176\n",
      "epoch 120: loss=2.090363025665283\n",
      "epoch 121: loss=2.2526087760925293\n",
      "epoch 122: loss=2.0976860523223877\n",
      "epoch 123: loss=2.1092405319213867\n",
      "epoch 124: loss=2.170088529586792\n",
      "epoch 125: loss=2.162245512008667\n",
      "epoch 126: loss=2.092694044113159\n",
      "epoch 127: loss=2.2217068672180176\n",
      "epoch 128: loss=2.189754009246826\n",
      "epoch 129: loss=2.11356782913208\n",
      "epoch 130: loss=2.1558420658111572\n",
      "epoch 131: loss=2.079360246658325\n",
      "epoch 132: loss=2.110053062438965\n",
      "epoch 133: loss=2.0205931663513184\n",
      "epoch 134: loss=2.1995925903320312\n",
      "epoch 135: loss=2.169556140899658\n",
      "epoch 136: loss=2.2317681312561035\n",
      "epoch 137: loss=2.198256492614746\n",
      "epoch 138: loss=2.171767234802246\n",
      "epoch 139: loss=2.1488542556762695\n",
      "epoch 140: loss=2.1142578125\n",
      "epoch 141: loss=2.0791752338409424\n",
      "epoch 142: loss=2.081512928009033\n",
      "epoch 143: loss=2.1790270805358887\n",
      "epoch 144: loss=2.1742753982543945\n",
      "epoch 145: loss=2.0523571968078613\n",
      "epoch 146: loss=2.1356403827667236\n",
      "epoch 147: loss=2.1627116203308105\n",
      "epoch 148: loss=2.1257433891296387\n",
      "epoch 149: loss=2.054471254348755\n",
      "epoch 150: loss=2.143770217895508\n",
      "epoch 151: loss=2.0916500091552734\n",
      "epoch 152: loss=2.1960177421569824\n",
      "epoch 153: loss=2.1454873085021973\n",
      "epoch 154: loss=2.1518948078155518\n",
      "epoch 155: loss=2.1078085899353027\n",
      "epoch 156: loss=2.158642053604126\n",
      "epoch 157: loss=2.2696263790130615\n",
      "epoch 158: loss=2.110630989074707\n",
      "epoch 159: loss=2.173579692840576\n",
      "epoch 160: loss=2.0501604080200195\n",
      "epoch 161: loss=2.137394428253174\n",
      "epoch 162: loss=2.085179567337036\n",
      "epoch 163: loss=2.2020668983459473\n",
      "epoch 164: loss=2.15734601020813\n",
      "epoch 165: loss=2.186317205429077\n",
      "epoch 166: loss=2.1200709342956543\n",
      "epoch 167: loss=2.1324691772460938\n",
      "epoch 168: loss=2.200239419937134\n",
      "epoch 169: loss=2.1329259872436523\n",
      "epoch 170: loss=2.1418895721435547\n",
      "epoch 171: loss=2.0957674980163574\n",
      "epoch 172: loss=2.085932731628418\n",
      "epoch 173: loss=2.119959592819214\n",
      "epoch 174: loss=2.066615104675293\n",
      "epoch 175: loss=2.0771775245666504\n",
      "epoch 176: loss=2.056224822998047\n",
      "epoch 177: loss=2.1009292602539062\n",
      "epoch 178: loss=2.161158323287964\n",
      "epoch 179: loss=2.143216848373413\n",
      "epoch 180: loss=2.1449265480041504\n",
      "epoch 181: loss=2.092884063720703\n",
      "epoch 182: loss=2.1440699100494385\n",
      "epoch 183: loss=2.152764081954956\n",
      "epoch 184: loss=2.1894755363464355\n",
      "epoch 185: loss=2.191836357116699\n",
      "epoch 186: loss=2.161731481552124\n",
      "epoch 187: loss=2.1020302772521973\n",
      "epoch 188: loss=2.146017074584961\n",
      "epoch 189: loss=2.1542272567749023\n",
      "epoch 190: loss=2.0822391510009766\n",
      "epoch 191: loss=2.1428143978118896\n",
      "epoch 192: loss=2.0648927688598633\n",
      "epoch 193: loss=2.0277113914489746\n",
      "epoch 194: loss=2.167050361633301\n",
      "epoch 195: loss=2.099555015563965\n",
      "epoch 196: loss=2.2382164001464844\n",
      "epoch 197: loss=2.0893476009368896\n",
      "epoch 198: loss=2.0706238746643066\n",
      "epoch 199: loss=2.131441593170166\n",
      "training patch with 1602 edges\n",
      "epoch 0: loss=14.650664329528809\n",
      "epoch 1: loss=13.898244857788086\n",
      "epoch 2: loss=13.991378784179688\n",
      "epoch 3: loss=13.230375289916992\n",
      "epoch 4: loss=12.70785140991211\n",
      "epoch 5: loss=11.926092147827148\n",
      "epoch 6: loss=10.81495475769043\n",
      "epoch 7: loss=10.435819625854492\n",
      "epoch 8: loss=10.356213569641113\n",
      "epoch 9: loss=10.50957202911377\n",
      "epoch 10: loss=9.906401634216309\n",
      "epoch 11: loss=9.514259338378906\n",
      "epoch 12: loss=8.219005584716797\n",
      "epoch 13: loss=6.951080799102783\n",
      "epoch 14: loss=5.835353374481201\n",
      "epoch 15: loss=5.11392068862915\n",
      "epoch 16: loss=4.738779067993164\n",
      "epoch 17: loss=4.047106742858887\n",
      "epoch 18: loss=3.7580296993255615\n",
      "epoch 19: loss=3.5116822719573975\n",
      "epoch 20: loss=3.2493793964385986\n",
      "epoch 21: loss=3.010763168334961\n",
      "epoch 22: loss=2.612064838409424\n",
      "epoch 23: loss=2.4818320274353027\n",
      "epoch 24: loss=2.3125534057617188\n",
      "epoch 25: loss=2.2867965698242188\n",
      "epoch 26: loss=2.230747699737549\n",
      "epoch 27: loss=2.251668930053711\n",
      "epoch 28: loss=2.151024580001831\n",
      "epoch 29: loss=2.126739025115967\n",
      "epoch 30: loss=2.091024875640869\n",
      "epoch 31: loss=2.0924367904663086\n",
      "epoch 32: loss=2.1181204319000244\n",
      "epoch 33: loss=2.090796947479248\n",
      "epoch 34: loss=2.0824856758117676\n",
      "epoch 35: loss=2.104358434677124\n",
      "epoch 36: loss=2.0900282859802246\n",
      "epoch 37: loss=2.061767578125\n",
      "epoch 38: loss=2.022632360458374\n",
      "epoch 39: loss=2.029750347137451\n",
      "epoch 40: loss=2.033553123474121\n",
      "epoch 41: loss=2.0562801361083984\n",
      "epoch 42: loss=2.023977041244507\n",
      "epoch 43: loss=1.9982414245605469\n",
      "epoch 44: loss=1.9453654289245605\n",
      "epoch 45: loss=1.928222417831421\n",
      "epoch 46: loss=1.9192259311676025\n",
      "epoch 47: loss=1.9145760536193848\n",
      "epoch 48: loss=1.867171287536621\n",
      "epoch 49: loss=1.8622088432312012\n",
      "epoch 50: loss=1.8203965425491333\n",
      "epoch 51: loss=1.818558692932129\n",
      "epoch 52: loss=1.7945866584777832\n",
      "epoch 53: loss=1.7601830959320068\n",
      "epoch 54: loss=1.7420686483383179\n",
      "epoch 55: loss=1.7512474060058594\n",
      "epoch 56: loss=1.7268965244293213\n",
      "epoch 57: loss=1.7183055877685547\n",
      "epoch 58: loss=1.7066855430603027\n",
      "epoch 59: loss=1.6983349323272705\n",
      "epoch 60: loss=1.7097352743148804\n",
      "epoch 61: loss=1.6750887632369995\n",
      "epoch 62: loss=1.6618998050689697\n",
      "epoch 63: loss=1.685750126838684\n",
      "epoch 64: loss=1.6472409963607788\n",
      "epoch 65: loss=1.6375164985656738\n",
      "epoch 66: loss=1.6175358295440674\n",
      "epoch 67: loss=1.6259745359420776\n",
      "epoch 68: loss=1.6275179386138916\n",
      "epoch 69: loss=1.662459135055542\n",
      "epoch 70: loss=1.6089825630187988\n",
      "epoch 71: loss=1.6146752834320068\n",
      "epoch 72: loss=1.6407462358474731\n",
      "epoch 73: loss=1.6190282106399536\n",
      "epoch 74: loss=1.6422581672668457\n",
      "epoch 75: loss=1.618320345878601\n",
      "epoch 76: loss=1.627847671508789\n",
      "epoch 77: loss=1.6315317153930664\n",
      "epoch 78: loss=1.597474455833435\n",
      "epoch 79: loss=1.6023664474487305\n",
      "epoch 80: loss=1.6266777515411377\n",
      "epoch 81: loss=1.6044691801071167\n",
      "epoch 82: loss=1.643946647644043\n",
      "epoch 83: loss=1.6284129619598389\n",
      "epoch 84: loss=1.6015994548797607\n",
      "epoch 85: loss=1.6008919477462769\n",
      "epoch 86: loss=1.555457353591919\n",
      "epoch 87: loss=1.5746588706970215\n",
      "epoch 88: loss=1.5711686611175537\n",
      "epoch 89: loss=1.6094777584075928\n",
      "epoch 90: loss=1.5191329717636108\n",
      "epoch 91: loss=1.5571866035461426\n",
      "epoch 92: loss=1.6340347528457642\n",
      "epoch 93: loss=1.5905979871749878\n",
      "epoch 94: loss=1.5741190910339355\n",
      "epoch 95: loss=1.553424596786499\n",
      "epoch 96: loss=1.560154914855957\n",
      "epoch 97: loss=1.576668381690979\n",
      "epoch 98: loss=1.532322645187378\n",
      "epoch 99: loss=1.5737977027893066\n",
      "epoch 100: loss=1.6039365530014038\n",
      "epoch 101: loss=1.5821533203125\n",
      "epoch 102: loss=1.5587246417999268\n",
      "epoch 103: loss=1.6152982711791992\n",
      "epoch 104: loss=1.5890439748764038\n",
      "epoch 105: loss=1.5762708187103271\n",
      "epoch 106: loss=1.576310157775879\n",
      "epoch 107: loss=1.5640475749969482\n",
      "epoch 108: loss=1.5521615743637085\n",
      "epoch 109: loss=1.570630669593811\n",
      "epoch 110: loss=1.5598258972167969\n",
      "epoch 111: loss=1.5793492794036865\n",
      "epoch 112: loss=1.5252959728240967\n",
      "epoch 113: loss=1.5551798343658447\n",
      "epoch 114: loss=1.509982943534851\n",
      "epoch 115: loss=1.5585908889770508\n",
      "epoch 116: loss=1.5796091556549072\n",
      "epoch 117: loss=1.5135056972503662\n",
      "epoch 118: loss=1.5734398365020752\n",
      "epoch 119: loss=1.5661811828613281\n",
      "epoch 120: loss=1.575601577758789\n",
      "epoch 121: loss=1.5098258256912231\n",
      "epoch 122: loss=1.5557782649993896\n",
      "epoch 123: loss=1.554178237915039\n",
      "epoch 124: loss=1.5440945625305176\n",
      "epoch 125: loss=1.5230865478515625\n",
      "epoch 126: loss=1.5127713680267334\n",
      "epoch 127: loss=1.5203572511672974\n",
      "epoch 128: loss=1.5708017349243164\n",
      "epoch 129: loss=1.5228700637817383\n",
      "epoch 130: loss=1.5624871253967285\n",
      "epoch 131: loss=1.5167276859283447\n",
      "epoch 132: loss=1.5589320659637451\n",
      "epoch 133: loss=1.545810341835022\n",
      "epoch 134: loss=1.5434637069702148\n",
      "epoch 135: loss=1.5580052137374878\n",
      "epoch 136: loss=1.5352685451507568\n",
      "epoch 137: loss=1.522371768951416\n",
      "epoch 138: loss=1.5504652261734009\n",
      "epoch 139: loss=1.5753337144851685\n",
      "epoch 140: loss=1.5257604122161865\n",
      "epoch 141: loss=1.5751577615737915\n",
      "epoch 142: loss=1.5113388299942017\n",
      "epoch 143: loss=1.5503582954406738\n",
      "epoch 144: loss=1.5621693134307861\n",
      "epoch 145: loss=1.5322954654693604\n",
      "epoch 146: loss=1.5116853713989258\n",
      "epoch 147: loss=1.5443402528762817\n",
      "epoch 148: loss=1.5691465139389038\n",
      "epoch 149: loss=1.5257855653762817\n",
      "epoch 150: loss=1.5363638401031494\n",
      "epoch 151: loss=1.5482490062713623\n",
      "epoch 152: loss=1.561956763267517\n",
      "epoch 153: loss=1.5647661685943604\n",
      "epoch 154: loss=1.5148217678070068\n",
      "epoch 155: loss=1.516618013381958\n",
      "epoch 156: loss=1.5666024684906006\n",
      "epoch 157: loss=1.5682430267333984\n",
      "epoch 158: loss=1.527902603149414\n",
      "epoch 159: loss=1.5729260444641113\n",
      "epoch 160: loss=1.5706133842468262\n",
      "epoch 161: loss=1.5626132488250732\n",
      "epoch 162: loss=1.5728230476379395\n",
      "epoch 163: loss=1.5703063011169434\n",
      "epoch 164: loss=1.5350501537322998\n",
      "epoch 165: loss=1.5206221342086792\n",
      "epoch 166: loss=1.5027234554290771\n",
      "epoch 167: loss=1.5407028198242188\n",
      "epoch 168: loss=1.544400930404663\n",
      "epoch 169: loss=1.5784577131271362\n",
      "epoch 170: loss=1.4864110946655273\n",
      "epoch 171: loss=1.52622389793396\n",
      "epoch 172: loss=1.548980474472046\n",
      "epoch 173: loss=1.496253490447998\n",
      "epoch 174: loss=1.543290615081787\n",
      "epoch 175: loss=1.5377602577209473\n",
      "epoch 176: loss=1.5053141117095947\n",
      "epoch 177: loss=1.5624581575393677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178: loss=1.551706075668335\n",
      "epoch 179: loss=1.5179883241653442\n",
      "epoch 180: loss=1.5329461097717285\n",
      "epoch 181: loss=1.5589888095855713\n",
      "epoch 182: loss=1.527919054031372\n",
      "epoch 183: loss=1.5452507734298706\n",
      "epoch 184: loss=1.5257134437561035\n",
      "epoch 185: loss=1.533801555633545\n",
      "epoch 186: loss=1.5511200428009033\n",
      "epoch 187: loss=1.541183590888977\n",
      "epoch 188: loss=1.5462148189544678\n",
      "epoch 189: loss=1.5188753604888916\n",
      "epoch 190: loss=1.5548195838928223\n",
      "epoch 191: loss=1.5130544900894165\n",
      "epoch 192: loss=1.5267397165298462\n",
      "epoch 193: loss=1.5392881631851196\n",
      "epoch 194: loss=1.524159550666809\n",
      "epoch 195: loss=1.5293853282928467\n",
      "epoch 196: loss=1.531738042831421\n",
      "epoch 197: loss=1.5378837585449219\n",
      "epoch 198: loss=1.5266242027282715\n",
      "epoch 199: loss=1.5505436658859253\n",
      "training patch with 1800 edges\n",
      "epoch 0: loss=13.876662254333496\n",
      "epoch 1: loss=14.185436248779297\n",
      "epoch 2: loss=13.51861572265625\n",
      "epoch 3: loss=13.178776741027832\n",
      "epoch 4: loss=12.15367603302002\n",
      "epoch 5: loss=12.707438468933105\n",
      "epoch 6: loss=11.886281967163086\n",
      "epoch 7: loss=10.472874641418457\n",
      "epoch 8: loss=10.431690216064453\n",
      "epoch 9: loss=10.389639854431152\n",
      "epoch 10: loss=9.505694389343262\n",
      "epoch 11: loss=8.124332427978516\n",
      "epoch 12: loss=7.076512336730957\n",
      "epoch 13: loss=5.7327141761779785\n",
      "epoch 14: loss=4.942237854003906\n",
      "epoch 15: loss=4.559623718261719\n",
      "epoch 16: loss=4.023538112640381\n",
      "epoch 17: loss=3.6682674884796143\n",
      "epoch 18: loss=3.1861801147460938\n",
      "epoch 19: loss=3.158583402633667\n",
      "epoch 20: loss=2.854559898376465\n",
      "epoch 21: loss=2.581105947494507\n",
      "epoch 22: loss=2.306868076324463\n",
      "epoch 23: loss=2.2821409702301025\n",
      "epoch 24: loss=2.2322452068328857\n",
      "epoch 25: loss=2.240211248397827\n",
      "epoch 26: loss=2.2058043479919434\n",
      "epoch 27: loss=2.138803482055664\n",
      "epoch 28: loss=2.1325325965881348\n",
      "epoch 29: loss=2.1058712005615234\n",
      "epoch 30: loss=2.1445937156677246\n",
      "epoch 31: loss=2.1377081871032715\n",
      "epoch 32: loss=2.1111435890197754\n",
      "epoch 33: loss=2.117142677307129\n",
      "epoch 34: loss=2.1160078048706055\n",
      "epoch 35: loss=2.100710868835449\n",
      "epoch 36: loss=2.107071876525879\n",
      "epoch 37: loss=2.136122941970825\n",
      "epoch 38: loss=2.0935888290405273\n",
      "epoch 39: loss=2.0571539402008057\n",
      "epoch 40: loss=2.0515284538269043\n",
      "epoch 41: loss=2.050391435623169\n",
      "epoch 42: loss=2.032747268676758\n",
      "epoch 43: loss=2.0029516220092773\n",
      "epoch 44: loss=2.016103506088257\n",
      "epoch 45: loss=1.9994146823883057\n",
      "epoch 46: loss=1.9643800258636475\n",
      "epoch 47: loss=1.9532182216644287\n",
      "epoch 48: loss=1.9288883209228516\n",
      "epoch 49: loss=1.907157063484192\n",
      "epoch 50: loss=1.898716688156128\n",
      "epoch 51: loss=1.8845906257629395\n",
      "epoch 52: loss=1.9035346508026123\n",
      "epoch 53: loss=1.861903429031372\n",
      "epoch 54: loss=1.8480558395385742\n",
      "epoch 55: loss=1.864753246307373\n",
      "epoch 56: loss=1.842052936553955\n",
      "epoch 57: loss=1.8258893489837646\n",
      "epoch 58: loss=1.82761812210083\n",
      "epoch 59: loss=1.801578402519226\n",
      "epoch 60: loss=1.7856309413909912\n",
      "epoch 61: loss=1.8452227115631104\n",
      "epoch 62: loss=1.8258693218231201\n",
      "epoch 63: loss=1.7989102602005005\n",
      "epoch 64: loss=1.7895867824554443\n",
      "epoch 65: loss=1.8153040409088135\n",
      "epoch 66: loss=1.7858970165252686\n",
      "epoch 67: loss=1.7379255294799805\n",
      "epoch 68: loss=1.7650551795959473\n",
      "epoch 69: loss=1.7410398721694946\n",
      "epoch 70: loss=1.7465038299560547\n",
      "epoch 71: loss=1.7100285291671753\n",
      "epoch 72: loss=1.7065731287002563\n",
      "epoch 73: loss=1.7329970598220825\n",
      "epoch 74: loss=1.7139990329742432\n",
      "epoch 75: loss=1.7172329425811768\n",
      "epoch 76: loss=1.7099390029907227\n",
      "epoch 77: loss=1.6959820985794067\n",
      "epoch 78: loss=1.6734511852264404\n",
      "epoch 79: loss=1.6425139904022217\n",
      "epoch 80: loss=1.6882948875427246\n",
      "epoch 81: loss=1.667330265045166\n",
      "epoch 82: loss=1.6763889789581299\n",
      "epoch 83: loss=1.6815578937530518\n",
      "epoch 84: loss=1.654527187347412\n",
      "epoch 85: loss=1.6555254459381104\n",
      "epoch 86: loss=1.6446709632873535\n",
      "epoch 87: loss=1.6597496271133423\n",
      "epoch 88: loss=1.629632592201233\n",
      "epoch 89: loss=1.6969976425170898\n",
      "epoch 90: loss=1.6482670307159424\n",
      "epoch 91: loss=1.6449329853057861\n",
      "epoch 92: loss=1.643680453300476\n",
      "epoch 93: loss=1.6588311195373535\n",
      "epoch 94: loss=1.6687493324279785\n",
      "epoch 95: loss=1.6325597763061523\n",
      "epoch 96: loss=1.6435387134552002\n",
      "epoch 97: loss=1.5711479187011719\n",
      "epoch 98: loss=1.6404539346694946\n",
      "epoch 99: loss=1.6010017395019531\n",
      "epoch 100: loss=1.6544945240020752\n",
      "epoch 101: loss=1.6393892765045166\n",
      "epoch 102: loss=1.6020267009735107\n",
      "epoch 103: loss=1.6128809452056885\n",
      "epoch 104: loss=1.6291022300720215\n",
      "epoch 105: loss=1.5791528224945068\n",
      "epoch 106: loss=1.6176677942276\n",
      "epoch 107: loss=1.6359941959381104\n",
      "epoch 108: loss=1.6290531158447266\n",
      "epoch 109: loss=1.6233432292938232\n",
      "epoch 110: loss=1.5895240306854248\n",
      "epoch 111: loss=1.5710833072662354\n",
      "epoch 112: loss=1.6395004987716675\n",
      "epoch 113: loss=1.6048439741134644\n",
      "epoch 114: loss=1.6084645986557007\n",
      "epoch 115: loss=1.597287654876709\n",
      "epoch 116: loss=1.610183835029602\n",
      "epoch 117: loss=1.6109908819198608\n",
      "epoch 118: loss=1.5806087255477905\n",
      "epoch 119: loss=1.5995206832885742\n",
      "epoch 120: loss=1.579888105392456\n",
      "epoch 121: loss=1.6749440431594849\n",
      "epoch 122: loss=1.5912941694259644\n",
      "epoch 123: loss=1.6239893436431885\n",
      "epoch 124: loss=1.6043312549591064\n",
      "epoch 125: loss=1.5988092422485352\n",
      "epoch 126: loss=1.5779109001159668\n",
      "epoch 127: loss=1.623138666152954\n",
      "epoch 128: loss=1.5921975374221802\n",
      "epoch 129: loss=1.6066086292266846\n",
      "epoch 130: loss=1.6228455305099487\n",
      "epoch 131: loss=1.6235913038253784\n",
      "epoch 132: loss=1.6103073358535767\n",
      "epoch 133: loss=1.5953673124313354\n",
      "epoch 134: loss=1.615576982498169\n",
      "epoch 135: loss=1.5758068561553955\n",
      "epoch 136: loss=1.601454496383667\n",
      "epoch 137: loss=1.5954142808914185\n",
      "epoch 138: loss=1.6094759702682495\n",
      "epoch 139: loss=1.5979560613632202\n",
      "epoch 140: loss=1.6134676933288574\n",
      "epoch 141: loss=1.597265362739563\n",
      "epoch 142: loss=1.5827054977416992\n",
      "epoch 143: loss=1.5585672855377197\n",
      "epoch 144: loss=1.6385090351104736\n",
      "epoch 145: loss=1.5858964920043945\n",
      "epoch 146: loss=1.5882360935211182\n",
      "epoch 147: loss=1.5667550563812256\n",
      "epoch 148: loss=1.6465567350387573\n",
      "epoch 149: loss=1.5623135566711426\n",
      "epoch 150: loss=1.6125637292861938\n",
      "epoch 151: loss=1.5920615196228027\n",
      "epoch 152: loss=1.6408731937408447\n",
      "epoch 153: loss=1.5631805658340454\n",
      "epoch 154: loss=1.596951961517334\n",
      "epoch 155: loss=1.6145908832550049\n",
      "epoch 156: loss=1.5874671936035156\n",
      "epoch 157: loss=1.568055510520935\n",
      "epoch 158: loss=1.594573974609375\n",
      "epoch 159: loss=1.5578844547271729\n",
      "epoch 160: loss=1.5739984512329102\n",
      "epoch 161: loss=1.5679502487182617\n",
      "epoch 162: loss=1.5474679470062256\n",
      "epoch 163: loss=1.568166732788086\n",
      "epoch 164: loss=1.5801637172698975\n",
      "epoch 165: loss=1.5517585277557373\n",
      "epoch 166: loss=1.5729658603668213\n",
      "epoch 167: loss=1.561211347579956\n",
      "epoch 168: loss=1.5863289833068848\n",
      "epoch 169: loss=1.5516226291656494\n",
      "epoch 170: loss=1.590247631072998\n",
      "epoch 171: loss=1.562685489654541\n",
      "epoch 172: loss=1.6052544116973877\n",
      "epoch 173: loss=1.5446686744689941\n",
      "epoch 174: loss=1.587265968322754\n",
      "epoch 175: loss=1.5418596267700195\n",
      "epoch 176: loss=1.5439612865447998\n",
      "epoch 177: loss=1.5495617389678955\n",
      "epoch 178: loss=1.6205506324768066\n",
      "epoch 179: loss=1.5790517330169678\n",
      "epoch 180: loss=1.5837163925170898\n",
      "epoch 181: loss=1.5802363157272339\n",
      "epoch 182: loss=1.5426799058914185\n",
      "epoch 183: loss=1.5811841487884521\n",
      "epoch 184: loss=1.5725889205932617\n",
      "epoch 185: loss=1.573976755142212\n",
      "epoch 186: loss=1.564427375793457\n",
      "epoch 187: loss=1.5417449474334717\n",
      "epoch 188: loss=1.5900452136993408\n",
      "epoch 189: loss=1.6137008666992188\n",
      "epoch 190: loss=1.5927517414093018\n",
      "epoch 191: loss=1.5678406953811646\n",
      "epoch 192: loss=1.5517677068710327\n",
      "epoch 193: loss=1.5361535549163818\n",
      "epoch 194: loss=1.5606051683425903\n",
      "epoch 195: loss=1.5791631937026978\n",
      "epoch 196: loss=1.5675523281097412\n",
      "epoch 197: loss=1.5483561754226685\n",
      "epoch 198: loss=1.5595957040786743\n",
      "epoch 199: loss=1.559034824371338\n",
      "training patch with 1844 edges\n",
      "epoch 0: loss=13.963406562805176\n",
      "epoch 1: loss=13.149575233459473\n",
      "epoch 2: loss=13.258293151855469\n",
      "epoch 3: loss=13.682494163513184\n",
      "epoch 4: loss=12.488988876342773\n",
      "epoch 5: loss=12.275274276733398\n",
      "epoch 6: loss=10.604052543640137\n",
      "epoch 7: loss=10.170337677001953\n",
      "epoch 8: loss=10.357518196105957\n",
      "epoch 9: loss=9.76424503326416\n",
      "epoch 10: loss=8.98056411743164\n",
      "epoch 11: loss=7.770677089691162\n",
      "epoch 12: loss=7.180492877960205\n",
      "epoch 13: loss=5.850637435913086\n",
      "epoch 14: loss=5.03878927230835\n",
      "epoch 15: loss=4.48315954208374\n",
      "epoch 16: loss=4.118108749389648\n",
      "epoch 17: loss=3.455005168914795\n",
      "epoch 18: loss=3.350526809692383\n",
      "epoch 19: loss=3.046105146408081\n",
      "epoch 20: loss=2.860973834991455\n",
      "epoch 21: loss=2.7132272720336914\n",
      "epoch 22: loss=2.3542895317077637\n",
      "epoch 23: loss=2.3334498405456543\n",
      "epoch 24: loss=2.192258596420288\n",
      "epoch 25: loss=2.1922967433929443\n",
      "epoch 26: loss=2.1941022872924805\n",
      "epoch 27: loss=2.102217674255371\n",
      "epoch 28: loss=2.0814108848571777\n",
      "epoch 29: loss=2.0199522972106934\n",
      "epoch 30: loss=1.9757018089294434\n",
      "epoch 31: loss=2.0230724811553955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32: loss=2.040038824081421\n",
      "epoch 33: loss=2.041733503341675\n",
      "epoch 34: loss=1.9978605508804321\n",
      "epoch 35: loss=1.9923157691955566\n",
      "epoch 36: loss=1.9935351610183716\n",
      "epoch 37: loss=1.9903151988983154\n",
      "epoch 38: loss=1.9949455261230469\n",
      "epoch 39: loss=1.9822033643722534\n",
      "epoch 40: loss=1.9776241779327393\n",
      "epoch 41: loss=1.9537509679794312\n",
      "epoch 42: loss=1.9244030714035034\n",
      "epoch 43: loss=1.910902738571167\n",
      "epoch 44: loss=1.89973783493042\n",
      "epoch 45: loss=1.8710416555404663\n",
      "epoch 46: loss=1.8458940982818604\n",
      "epoch 47: loss=1.8230881690979004\n",
      "epoch 48: loss=1.7996338605880737\n",
      "epoch 49: loss=1.7992725372314453\n",
      "epoch 50: loss=1.7783684730529785\n",
      "epoch 51: loss=1.7090632915496826\n",
      "epoch 52: loss=1.748128056526184\n",
      "epoch 53: loss=1.7146304845809937\n",
      "epoch 54: loss=1.7337119579315186\n",
      "epoch 55: loss=1.6844842433929443\n",
      "epoch 56: loss=1.6944365501403809\n",
      "epoch 57: loss=1.6888434886932373\n",
      "epoch 58: loss=1.696478009223938\n",
      "epoch 59: loss=1.6860520839691162\n",
      "epoch 60: loss=1.6930651664733887\n",
      "epoch 61: loss=1.6486496925354004\n",
      "epoch 62: loss=1.671015977859497\n",
      "epoch 63: loss=1.6229031085968018\n",
      "epoch 64: loss=1.6745867729187012\n",
      "epoch 65: loss=1.6244685649871826\n",
      "epoch 66: loss=1.6384148597717285\n",
      "epoch 67: loss=1.6093977689743042\n",
      "epoch 68: loss=1.6092240810394287\n",
      "epoch 69: loss=1.6086416244506836\n",
      "epoch 70: loss=1.594038963317871\n",
      "epoch 71: loss=1.5866749286651611\n",
      "epoch 72: loss=1.5916016101837158\n",
      "epoch 73: loss=1.574999451637268\n",
      "epoch 74: loss=1.5541725158691406\n",
      "epoch 75: loss=1.5786826610565186\n",
      "epoch 76: loss=1.625871181488037\n",
      "epoch 77: loss=1.5821717977523804\n",
      "epoch 78: loss=1.556588053703308\n",
      "epoch 79: loss=1.5600059032440186\n",
      "epoch 80: loss=1.5801721811294556\n",
      "epoch 81: loss=1.569870948791504\n",
      "epoch 82: loss=1.5375785827636719\n",
      "epoch 83: loss=1.535522699356079\n",
      "epoch 84: loss=1.5573766231536865\n",
      "epoch 85: loss=1.5702848434448242\n",
      "epoch 86: loss=1.5748296976089478\n",
      "epoch 87: loss=1.5317952632904053\n",
      "epoch 88: loss=1.55607271194458\n",
      "epoch 89: loss=1.5561814308166504\n",
      "epoch 90: loss=1.5987085103988647\n",
      "epoch 91: loss=1.558213472366333\n",
      "epoch 92: loss=1.5221366882324219\n",
      "epoch 93: loss=1.5518951416015625\n",
      "epoch 94: loss=1.6047346591949463\n",
      "epoch 95: loss=1.5362658500671387\n",
      "epoch 96: loss=1.5350894927978516\n",
      "epoch 97: loss=1.5256969928741455\n",
      "epoch 98: loss=1.548159122467041\n",
      "epoch 99: loss=1.5279662609100342\n",
      "epoch 100: loss=1.5380887985229492\n",
      "epoch 101: loss=1.5399129390716553\n",
      "epoch 102: loss=1.5194191932678223\n",
      "epoch 103: loss=1.5002501010894775\n",
      "epoch 104: loss=1.549797773361206\n",
      "epoch 105: loss=1.5001506805419922\n",
      "epoch 106: loss=1.534726619720459\n",
      "epoch 107: loss=1.5561084747314453\n",
      "epoch 108: loss=1.4926477670669556\n",
      "epoch 109: loss=1.4812304973602295\n",
      "epoch 110: loss=1.531531810760498\n",
      "epoch 111: loss=1.5135364532470703\n",
      "epoch 112: loss=1.5108978748321533\n",
      "epoch 113: loss=1.5059571266174316\n",
      "epoch 114: loss=1.5398119688034058\n",
      "epoch 115: loss=1.5115082263946533\n",
      "epoch 116: loss=1.531179428100586\n",
      "epoch 117: loss=1.523636817932129\n",
      "epoch 118: loss=1.5667386054992676\n",
      "epoch 119: loss=1.5270107984542847\n",
      "epoch 120: loss=1.5453059673309326\n",
      "epoch 121: loss=1.4943134784698486\n",
      "epoch 122: loss=1.544509768486023\n",
      "epoch 123: loss=1.5286643505096436\n",
      "epoch 124: loss=1.5435981750488281\n",
      "epoch 125: loss=1.5180318355560303\n",
      "epoch 126: loss=1.4917619228363037\n",
      "epoch 127: loss=1.4922341108322144\n",
      "epoch 128: loss=1.507368564605713\n",
      "epoch 129: loss=1.5121638774871826\n",
      "epoch 130: loss=1.5067130327224731\n",
      "epoch 131: loss=1.5212936401367188\n",
      "epoch 132: loss=1.5481302738189697\n",
      "epoch 133: loss=1.496675729751587\n",
      "epoch 134: loss=1.5197569131851196\n",
      "epoch 135: loss=1.5287073850631714\n",
      "epoch 136: loss=1.489774465560913\n",
      "epoch 137: loss=1.5033214092254639\n",
      "epoch 138: loss=1.5311949253082275\n",
      "epoch 139: loss=1.5133496522903442\n",
      "epoch 140: loss=1.505776047706604\n",
      "epoch 141: loss=1.475337266921997\n",
      "epoch 142: loss=1.4958035945892334\n",
      "epoch 143: loss=1.4999504089355469\n",
      "epoch 144: loss=1.481332540512085\n",
      "epoch 145: loss=1.537372350692749\n",
      "epoch 146: loss=1.5266562700271606\n",
      "epoch 147: loss=1.5109384059906006\n",
      "epoch 148: loss=1.5074728727340698\n",
      "epoch 149: loss=1.4609155654907227\n",
      "epoch 150: loss=1.4885410070419312\n",
      "epoch 151: loss=1.541402816772461\n",
      "epoch 152: loss=1.5002650022506714\n",
      "epoch 153: loss=1.5497479438781738\n",
      "epoch 154: loss=1.4818243980407715\n",
      "epoch 155: loss=1.5099828243255615\n",
      "epoch 156: loss=1.5277944803237915\n",
      "epoch 157: loss=1.5118112564086914\n",
      "epoch 158: loss=1.4825643301010132\n",
      "epoch 159: loss=1.4869272708892822\n",
      "epoch 160: loss=1.4919824600219727\n",
      "epoch 161: loss=1.4973822832107544\n",
      "epoch 162: loss=1.507608413696289\n",
      "epoch 163: loss=1.5114920139312744\n",
      "epoch 164: loss=1.4760854244232178\n",
      "epoch 165: loss=1.487318992614746\n",
      "epoch 166: loss=1.4912524223327637\n",
      "epoch 167: loss=1.5213265419006348\n",
      "epoch 168: loss=1.4982020854949951\n",
      "epoch 169: loss=1.5196049213409424\n",
      "epoch 170: loss=1.497771978378296\n",
      "epoch 171: loss=1.5076582431793213\n",
      "epoch 172: loss=1.520357608795166\n",
      "epoch 173: loss=1.51784086227417\n",
      "epoch 174: loss=1.5092853307724\n",
      "epoch 175: loss=1.4971815347671509\n",
      "epoch 176: loss=1.483931064605713\n",
      "epoch 177: loss=1.4956623315811157\n",
      "epoch 178: loss=1.5202836990356445\n",
      "epoch 179: loss=1.4603947401046753\n",
      "epoch 180: loss=1.4968352317810059\n",
      "epoch 181: loss=1.5180280208587646\n",
      "epoch 182: loss=1.4966027736663818\n",
      "epoch 183: loss=1.502892017364502\n",
      "epoch 184: loss=1.4731595516204834\n",
      "epoch 185: loss=1.5016340017318726\n",
      "epoch 186: loss=1.5008244514465332\n",
      "epoch 187: loss=1.5114104747772217\n",
      "epoch 188: loss=1.5170855522155762\n",
      "epoch 189: loss=1.4893666505813599\n",
      "epoch 190: loss=1.4827420711517334\n",
      "epoch 191: loss=1.4996895790100098\n",
      "epoch 192: loss=1.5118770599365234\n",
      "epoch 193: loss=1.4646843671798706\n",
      "epoch 194: loss=1.4690507650375366\n",
      "epoch 195: loss=1.5088248252868652\n",
      "epoch 196: loss=1.5165756940841675\n",
      "epoch 197: loss=1.4938290119171143\n",
      "epoch 198: loss=1.5131374597549438\n",
      "epoch 199: loss=1.5036180019378662\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4717b13519234688aa6ffab325dd9efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 8187.408203125\n",
      "Epoch 10, Loss: 3886.13623046875\n",
      "Epoch 20, Loss: 2059.331787109375\n",
      "Epoch 30, Loss: 1551.68896484375\n",
      "Epoch 40, Loss: 1401.252685546875\n",
      "Epoch 50, Loss: 1340.8914794921875\n",
      "Epoch 60, Loss: 1320.072509765625\n",
      "Epoch 70, Loss: 1279.670654296875\n",
      "Epoch 80, Loss: 1268.1881103515625\n",
      "Epoch 90, Loss: 1323.9696044921875\n",
      "Epoch 100, Loss: 1255.9935302734375\n",
      "Epoch 110, Loss: 1253.42236328125\n",
      "Epoch 120, Loss: 1252.4644775390625\n",
      "Epoch 130, Loss: 1269.3819580078125\n",
      "Epoch 140, Loss: 1252.149658203125\n",
      "Epoch 150, Loss: 1259.4139404296875\n",
      "Epoch 160, Loss: 1264.245361328125\n",
      "Epoch 170, Loss: 1243.4825439453125\n",
      "Epoch 180, Loss: 1251.0787353515625\n",
      "Epoch 190, Loss: 1247.122802734375\n",
      "training patch with 2032 edges\n",
      "epoch 0: loss=18.33304214477539\n",
      "epoch 1: loss=18.347562789916992\n",
      "epoch 2: loss=18.182926177978516\n",
      "epoch 3: loss=18.219743728637695\n",
      "epoch 4: loss=17.05641746520996\n",
      "epoch 5: loss=17.053579330444336\n",
      "epoch 6: loss=17.03606414794922\n",
      "epoch 7: loss=16.638023376464844\n",
      "epoch 8: loss=16.37265396118164\n",
      "epoch 9: loss=17.97493553161621\n",
      "epoch 10: loss=18.133617401123047\n",
      "epoch 11: loss=17.547142028808594\n",
      "epoch 12: loss=16.320018768310547\n",
      "epoch 13: loss=14.781050682067871\n",
      "epoch 14: loss=14.036699295043945\n",
      "epoch 15: loss=13.387751579284668\n",
      "epoch 16: loss=12.30049991607666\n",
      "epoch 17: loss=11.39684772491455\n",
      "epoch 18: loss=11.522005081176758\n",
      "epoch 19: loss=10.979985237121582\n",
      "epoch 20: loss=9.99176025390625\n",
      "epoch 21: loss=9.126852989196777\n",
      "epoch 22: loss=8.401212692260742\n",
      "epoch 23: loss=8.139432907104492\n",
      "epoch 24: loss=7.491513729095459\n",
      "epoch 25: loss=6.357866287231445\n",
      "epoch 26: loss=5.8779096603393555\n",
      "epoch 27: loss=4.77888298034668\n",
      "epoch 28: loss=4.35213565826416\n",
      "epoch 29: loss=4.070620536804199\n",
      "epoch 30: loss=3.7564404010772705\n",
      "epoch 31: loss=3.540931463241577\n",
      "epoch 32: loss=3.437356472015381\n",
      "epoch 33: loss=3.0814287662506104\n",
      "epoch 34: loss=2.8454360961914062\n",
      "epoch 35: loss=2.8172342777252197\n",
      "epoch 36: loss=2.7557029724121094\n",
      "epoch 37: loss=2.7711312770843506\n",
      "epoch 38: loss=2.659329414367676\n",
      "epoch 39: loss=2.5505123138427734\n",
      "epoch 40: loss=2.5608859062194824\n",
      "epoch 41: loss=2.568948268890381\n",
      "epoch 42: loss=2.5974020957946777\n",
      "epoch 43: loss=2.6108031272888184\n",
      "epoch 44: loss=2.5431923866271973\n",
      "epoch 45: loss=2.592583417892456\n",
      "epoch 46: loss=2.59132719039917\n",
      "epoch 47: loss=2.552290678024292\n",
      "epoch 48: loss=2.4927444458007812\n",
      "epoch 49: loss=2.5248284339904785\n",
      "epoch 50: loss=2.4962806701660156\n",
      "epoch 51: loss=2.4560155868530273\n",
      "epoch 52: loss=2.4527807235717773\n",
      "epoch 53: loss=2.4625251293182373\n",
      "epoch 54: loss=2.4354023933410645\n",
      "epoch 55: loss=2.434414863586426\n",
      "epoch 56: loss=2.3822522163391113\n",
      "epoch 57: loss=2.3609347343444824\n",
      "epoch 58: loss=2.3307037353515625\n",
      "epoch 59: loss=2.3690974712371826\n",
      "epoch 60: loss=2.3316352367401123\n",
      "epoch 61: loss=2.3110909461975098\n",
      "epoch 62: loss=2.299406051635742\n",
      "epoch 63: loss=2.301212787628174\n",
      "epoch 64: loss=2.288257122039795\n",
      "epoch 65: loss=2.271939277648926\n",
      "epoch 66: loss=2.2270877361297607\n",
      "epoch 67: loss=2.257925510406494\n",
      "epoch 68: loss=2.194207191467285\n",
      "epoch 69: loss=2.2182540893554688\n",
      "epoch 70: loss=2.2020881175994873\n",
      "epoch 71: loss=2.160263776779175\n",
      "epoch 72: loss=2.237525463104248\n",
      "epoch 73: loss=2.2227249145507812\n",
      "epoch 74: loss=2.1918277740478516\n",
      "epoch 75: loss=2.1711831092834473\n",
      "epoch 76: loss=2.160632610321045\n",
      "epoch 77: loss=2.1844916343688965\n",
      "epoch 78: loss=2.1752445697784424\n",
      "epoch 79: loss=2.1827731132507324\n",
      "epoch 80: loss=2.1724424362182617\n",
      "epoch 81: loss=2.1488680839538574\n",
      "epoch 82: loss=2.2222604751586914\n",
      "epoch 83: loss=2.1472315788269043\n",
      "epoch 84: loss=2.1721696853637695\n",
      "epoch 85: loss=2.1380178928375244\n",
      "epoch 86: loss=2.145399808883667\n",
      "epoch 87: loss=2.1520743370056152\n",
      "epoch 88: loss=2.095916271209717\n",
      "epoch 89: loss=2.141552686691284\n",
      "epoch 90: loss=2.1143975257873535\n",
      "epoch 91: loss=2.1377272605895996\n",
      "epoch 92: loss=2.1220529079437256\n",
      "epoch 93: loss=2.1057090759277344\n",
      "epoch 94: loss=2.1181695461273193\n",
      "epoch 95: loss=2.1195755004882812\n",
      "epoch 96: loss=2.095067024230957\n",
      "epoch 97: loss=2.1012401580810547\n",
      "epoch 98: loss=2.1210315227508545\n",
      "epoch 99: loss=2.082530975341797\n",
      "epoch 100: loss=2.093461513519287\n",
      "epoch 101: loss=2.151602029800415\n",
      "epoch 102: loss=2.1093478202819824\n",
      "epoch 103: loss=2.0964176654815674\n",
      "epoch 104: loss=2.089717149734497\n",
      "epoch 105: loss=2.0833630561828613\n",
      "epoch 106: loss=2.0490283966064453\n",
      "epoch 107: loss=2.024050712585449\n",
      "epoch 108: loss=2.0582189559936523\n",
      "epoch 109: loss=2.092176675796509\n",
      "epoch 110: loss=2.060913324356079\n",
      "epoch 111: loss=2.0468990802764893\n",
      "epoch 112: loss=2.0614330768585205\n",
      "epoch 113: loss=2.049238681793213\n",
      "epoch 114: loss=2.075106143951416\n",
      "epoch 115: loss=2.103752613067627\n",
      "epoch 116: loss=2.052330255508423\n",
      "epoch 117: loss=2.0961532592773438\n",
      "epoch 118: loss=2.088833808898926\n",
      "epoch 119: loss=2.051090717315674\n",
      "epoch 120: loss=2.09102463722229\n",
      "epoch 121: loss=2.1004366874694824\n",
      "epoch 122: loss=2.0936570167541504\n",
      "epoch 123: loss=2.0788114070892334\n",
      "epoch 124: loss=2.09218168258667\n",
      "epoch 125: loss=2.0477101802825928\n",
      "epoch 126: loss=2.083468437194824\n",
      "epoch 127: loss=2.067239284515381\n",
      "epoch 128: loss=2.080441951751709\n",
      "epoch 129: loss=2.0767157077789307\n",
      "epoch 130: loss=2.0602591037750244\n",
      "epoch 131: loss=2.053727149963379\n",
      "epoch 132: loss=2.074099063873291\n",
      "epoch 133: loss=2.0704824924468994\n",
      "epoch 134: loss=2.061283588409424\n",
      "epoch 135: loss=2.087982177734375\n",
      "epoch 136: loss=2.063878059387207\n",
      "epoch 137: loss=2.0600597858428955\n",
      "epoch 138: loss=2.058302164077759\n",
      "epoch 139: loss=2.0525708198547363\n",
      "epoch 140: loss=2.0563507080078125\n",
      "epoch 141: loss=2.0467774868011475\n",
      "epoch 142: loss=2.0577783584594727\n",
      "epoch 143: loss=2.038736343383789\n",
      "epoch 144: loss=2.05364990234375\n",
      "epoch 145: loss=2.0948429107666016\n",
      "epoch 146: loss=2.0722224712371826\n",
      "epoch 147: loss=2.0294997692108154\n",
      "epoch 148: loss=2.070239782333374\n",
      "epoch 149: loss=2.067054033279419\n",
      "epoch 150: loss=2.031527519226074\n",
      "epoch 151: loss=2.0974531173706055\n",
      "epoch 152: loss=2.007685899734497\n",
      "epoch 153: loss=2.0863027572631836\n",
      "epoch 154: loss=2.0523223876953125\n",
      "epoch 155: loss=2.07635498046875\n",
      "epoch 156: loss=2.083308696746826\n",
      "epoch 157: loss=2.0382485389709473\n",
      "epoch 158: loss=2.009939670562744\n",
      "epoch 159: loss=2.099278450012207\n",
      "epoch 160: loss=2.0515623092651367\n",
      "epoch 161: loss=2.058581829071045\n",
      "epoch 162: loss=2.0465126037597656\n",
      "epoch 163: loss=2.050445079803467\n",
      "epoch 164: loss=2.045567512512207\n",
      "epoch 165: loss=2.0820021629333496\n",
      "epoch 166: loss=2.0605225563049316\n",
      "epoch 167: loss=2.0858497619628906\n",
      "epoch 168: loss=2.045306921005249\n",
      "epoch 169: loss=2.0422301292419434\n",
      "epoch 170: loss=2.038273811340332\n",
      "epoch 171: loss=2.0785045623779297\n",
      "epoch 172: loss=2.0867557525634766\n",
      "epoch 173: loss=2.0622119903564453\n",
      "epoch 174: loss=2.03877592086792\n",
      "epoch 175: loss=2.0369577407836914\n",
      "epoch 176: loss=2.033629894256592\n",
      "epoch 177: loss=2.0702853202819824\n",
      "epoch 178: loss=2.04888653755188\n",
      "epoch 179: loss=2.0372366905212402\n",
      "epoch 180: loss=2.040107250213623\n",
      "epoch 181: loss=2.096308708190918\n",
      "epoch 182: loss=2.083601474761963\n",
      "epoch 183: loss=2.0305275917053223\n",
      "epoch 184: loss=2.047532796859741\n",
      "epoch 185: loss=2.0644116401672363\n",
      "epoch 186: loss=2.021916627883911\n",
      "epoch 187: loss=2.068897008895874\n",
      "epoch 188: loss=2.0669522285461426\n",
      "epoch 189: loss=2.08202862739563\n",
      "epoch 190: loss=2.076831817626953\n",
      "epoch 191: loss=2.04445743560791\n",
      "epoch 192: loss=2.0870156288146973\n",
      "epoch 193: loss=2.035011053085327\n",
      "epoch 194: loss=2.035994529724121\n",
      "epoch 195: loss=2.06166410446167\n",
      "epoch 196: loss=2.05255389213562\n",
      "epoch 197: loss=2.0328798294067383\n",
      "epoch 198: loss=2.003145217895508\n",
      "epoch 199: loss=2.0261151790618896\n",
      "training patch with 1946 edges\n",
      "epoch 0: loss=18.38048553466797\n",
      "epoch 1: loss=17.69825553894043\n",
      "epoch 2: loss=18.22910499572754\n",
      "epoch 3: loss=17.74713134765625\n",
      "epoch 4: loss=17.944944381713867\n",
      "epoch 5: loss=16.07356834411621\n",
      "epoch 6: loss=17.170194625854492\n",
      "epoch 7: loss=16.749563217163086\n",
      "epoch 8: loss=18.07045555114746\n",
      "epoch 9: loss=19.577543258666992\n",
      "epoch 10: loss=18.75067710876465\n",
      "epoch 11: loss=17.628259658813477\n",
      "epoch 12: loss=16.304168701171875\n",
      "epoch 13: loss=14.488789558410645\n",
      "epoch 14: loss=13.388603210449219\n",
      "epoch 15: loss=12.790294647216797\n",
      "epoch 16: loss=12.163613319396973\n",
      "epoch 17: loss=11.34382152557373\n",
      "epoch 18: loss=10.970677375793457\n",
      "epoch 19: loss=10.033684730529785\n",
      "epoch 20: loss=9.834254264831543\n",
      "epoch 21: loss=9.66016960144043\n",
      "epoch 22: loss=8.676027297973633\n",
      "epoch 23: loss=7.776724338531494\n",
      "epoch 24: loss=6.6992645263671875\n",
      "epoch 25: loss=5.89063835144043\n",
      "epoch 26: loss=5.1273193359375\n",
      "epoch 27: loss=4.633705139160156\n",
      "epoch 28: loss=4.104618549346924\n",
      "epoch 29: loss=3.900033950805664\n",
      "epoch 30: loss=3.802351236343384\n",
      "epoch 31: loss=3.3334195613861084\n",
      "epoch 32: loss=3.173527240753174\n",
      "epoch 33: loss=2.95457124710083\n",
      "epoch 34: loss=2.7941949367523193\n",
      "epoch 35: loss=2.8909082412719727\n",
      "epoch 36: loss=2.8445475101470947\n",
      "epoch 37: loss=2.7103800773620605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38: loss=2.6775972843170166\n",
      "epoch 39: loss=2.720820426940918\n",
      "epoch 40: loss=2.6688003540039062\n",
      "epoch 41: loss=2.7317802906036377\n",
      "epoch 42: loss=2.699014663696289\n",
      "epoch 43: loss=2.7184128761291504\n",
      "epoch 44: loss=2.6719565391540527\n",
      "epoch 45: loss=2.6899077892303467\n",
      "epoch 46: loss=2.6221799850463867\n",
      "epoch 47: loss=2.6371450424194336\n",
      "epoch 48: loss=2.621270179748535\n",
      "epoch 49: loss=2.613344192504883\n",
      "epoch 50: loss=2.601684331893921\n",
      "epoch 51: loss=2.57794189453125\n",
      "epoch 52: loss=2.5497241020202637\n",
      "epoch 53: loss=2.55222749710083\n",
      "epoch 54: loss=2.525132179260254\n",
      "epoch 55: loss=2.455202102661133\n",
      "epoch 56: loss=2.518105983734131\n",
      "epoch 57: loss=2.4652466773986816\n",
      "epoch 58: loss=2.4338197708129883\n",
      "epoch 59: loss=2.4218525886535645\n",
      "epoch 60: loss=2.3900890350341797\n",
      "epoch 61: loss=2.374176263809204\n",
      "epoch 62: loss=2.323434591293335\n",
      "epoch 63: loss=2.347411632537842\n",
      "epoch 64: loss=2.3388705253601074\n",
      "epoch 65: loss=2.3287720680236816\n",
      "epoch 66: loss=2.297210693359375\n",
      "epoch 67: loss=2.295276403427124\n",
      "epoch 68: loss=2.2807302474975586\n",
      "epoch 69: loss=2.2631990909576416\n",
      "epoch 70: loss=2.2588257789611816\n",
      "epoch 71: loss=2.275193452835083\n",
      "epoch 72: loss=2.230269432067871\n",
      "epoch 73: loss=2.2039718627929688\n",
      "epoch 74: loss=2.214329481124878\n",
      "epoch 75: loss=2.207486629486084\n",
      "epoch 76: loss=2.2032670974731445\n",
      "epoch 77: loss=2.1824145317077637\n",
      "epoch 78: loss=2.1883506774902344\n",
      "epoch 79: loss=2.292618751525879\n",
      "epoch 80: loss=2.2135772705078125\n",
      "epoch 81: loss=2.1840882301330566\n",
      "epoch 82: loss=2.1774027347564697\n",
      "epoch 83: loss=2.26723575592041\n",
      "epoch 84: loss=2.1934237480163574\n",
      "epoch 85: loss=2.167160987854004\n",
      "epoch 86: loss=2.22641921043396\n",
      "epoch 87: loss=2.2186319828033447\n",
      "epoch 88: loss=2.1787850856781006\n",
      "epoch 89: loss=2.173783302307129\n",
      "epoch 90: loss=2.1589486598968506\n",
      "epoch 91: loss=2.2050609588623047\n",
      "epoch 92: loss=2.1849722862243652\n",
      "epoch 93: loss=2.195777654647827\n",
      "epoch 94: loss=2.169959783554077\n",
      "epoch 95: loss=2.1639392375946045\n",
      "epoch 96: loss=2.150526285171509\n",
      "epoch 97: loss=2.1897380352020264\n",
      "epoch 98: loss=2.1316466331481934\n",
      "epoch 99: loss=2.187446355819702\n",
      "epoch 100: loss=2.137641668319702\n",
      "epoch 101: loss=2.1501598358154297\n",
      "epoch 102: loss=2.154906749725342\n",
      "epoch 103: loss=2.1135940551757812\n",
      "epoch 104: loss=2.0922789573669434\n",
      "epoch 105: loss=2.1401681900024414\n",
      "epoch 106: loss=2.144447088241577\n",
      "epoch 107: loss=2.160853624343872\n",
      "epoch 108: loss=2.117063522338867\n",
      "epoch 109: loss=2.1785809993743896\n",
      "epoch 110: loss=2.1563494205474854\n",
      "epoch 111: loss=2.1380112171173096\n",
      "epoch 112: loss=2.136111259460449\n",
      "epoch 113: loss=2.1248672008514404\n",
      "epoch 114: loss=2.1087682247161865\n",
      "epoch 115: loss=2.1615564823150635\n",
      "epoch 116: loss=2.0891621112823486\n",
      "epoch 117: loss=2.166104793548584\n",
      "epoch 118: loss=2.168375015258789\n",
      "epoch 119: loss=2.120387554168701\n",
      "epoch 120: loss=2.1250340938568115\n",
      "epoch 121: loss=2.138920307159424\n",
      "epoch 122: loss=2.1054155826568604\n",
      "epoch 123: loss=2.108257532119751\n",
      "epoch 124: loss=2.0872371196746826\n",
      "epoch 125: loss=2.1309688091278076\n",
      "epoch 126: loss=2.0734951496124268\n",
      "epoch 127: loss=2.096890926361084\n",
      "epoch 128: loss=2.1889989376068115\n",
      "epoch 129: loss=2.092301845550537\n",
      "epoch 130: loss=2.096437454223633\n",
      "epoch 131: loss=2.099879264831543\n",
      "epoch 132: loss=2.111280918121338\n",
      "epoch 133: loss=2.1055214405059814\n",
      "epoch 134: loss=2.0969862937927246\n",
      "epoch 135: loss=2.1117351055145264\n",
      "epoch 136: loss=2.0918591022491455\n",
      "epoch 137: loss=2.1546382904052734\n",
      "epoch 138: loss=2.1393747329711914\n",
      "epoch 139: loss=2.040046215057373\n",
      "epoch 140: loss=2.083590507507324\n",
      "epoch 141: loss=2.1366147994995117\n",
      "epoch 142: loss=2.1198036670684814\n",
      "epoch 143: loss=2.0559544563293457\n",
      "epoch 144: loss=2.1163904666900635\n",
      "epoch 145: loss=2.088711738586426\n",
      "epoch 146: loss=2.0432119369506836\n",
      "epoch 147: loss=2.077155828475952\n",
      "epoch 148: loss=2.093783378601074\n",
      "epoch 149: loss=2.1211960315704346\n",
      "epoch 150: loss=2.063066005706787\n",
      "epoch 151: loss=2.1083624362945557\n",
      "epoch 152: loss=2.1232614517211914\n",
      "epoch 153: loss=2.0716207027435303\n",
      "epoch 154: loss=2.050737142562866\n",
      "epoch 155: loss=2.065427780151367\n",
      "epoch 156: loss=2.08968186378479\n",
      "epoch 157: loss=2.1086068153381348\n",
      "epoch 158: loss=2.092535972595215\n",
      "epoch 159: loss=2.100435733795166\n",
      "epoch 160: loss=2.061457395553589\n",
      "epoch 161: loss=2.092954397201538\n",
      "epoch 162: loss=2.0871353149414062\n",
      "epoch 163: loss=2.0852909088134766\n",
      "epoch 164: loss=2.0757455825805664\n",
      "epoch 165: loss=2.0575172901153564\n",
      "epoch 166: loss=2.03792405128479\n",
      "epoch 167: loss=2.085170030593872\n",
      "epoch 168: loss=2.0349156856536865\n",
      "epoch 169: loss=2.09828782081604\n",
      "epoch 170: loss=2.099471092224121\n",
      "epoch 171: loss=2.110912322998047\n",
      "epoch 172: loss=2.0723443031311035\n",
      "epoch 173: loss=2.095367431640625\n",
      "epoch 174: loss=2.1531665325164795\n",
      "epoch 175: loss=2.1067137718200684\n",
      "epoch 176: loss=2.0390102863311768\n",
      "epoch 177: loss=2.03350830078125\n",
      "epoch 178: loss=2.0999388694763184\n",
      "epoch 179: loss=2.1052520275115967\n",
      "epoch 180: loss=2.106330394744873\n",
      "epoch 181: loss=2.0892436504364014\n",
      "epoch 182: loss=2.0363364219665527\n",
      "epoch 183: loss=2.0784966945648193\n",
      "epoch 184: loss=2.069612979888916\n",
      "epoch 185: loss=2.057359218597412\n",
      "epoch 186: loss=2.104842185974121\n",
      "epoch 187: loss=2.0925159454345703\n",
      "epoch 188: loss=2.0841054916381836\n",
      "epoch 189: loss=2.0801985263824463\n",
      "epoch 190: loss=2.0472214221954346\n",
      "epoch 191: loss=2.0958621501922607\n",
      "epoch 192: loss=2.078749418258667\n",
      "epoch 193: loss=2.0674362182617188\n",
      "epoch 194: loss=2.0938282012939453\n",
      "epoch 195: loss=2.045295476913452\n",
      "epoch 196: loss=2.016364574432373\n",
      "epoch 197: loss=2.066523790359497\n",
      "epoch 198: loss=2.066039562225342\n",
      "epoch 199: loss=2.0641322135925293\n",
      "training patch with 1878 edges\n",
      "epoch 0: loss=18.627904891967773\n",
      "epoch 1: loss=17.973129272460938\n",
      "epoch 2: loss=17.605941772460938\n",
      "epoch 3: loss=18.352670669555664\n",
      "epoch 4: loss=17.518051147460938\n",
      "epoch 5: loss=17.06495475769043\n",
      "epoch 6: loss=17.2029972076416\n",
      "epoch 7: loss=17.032161712646484\n",
      "epoch 8: loss=16.27190589904785\n",
      "epoch 9: loss=17.073495864868164\n",
      "epoch 10: loss=19.152002334594727\n",
      "epoch 11: loss=18.129785537719727\n",
      "epoch 12: loss=17.312030792236328\n",
      "epoch 13: loss=15.459878921508789\n",
      "epoch 14: loss=13.786293029785156\n",
      "epoch 15: loss=12.619807243347168\n",
      "epoch 16: loss=12.794575691223145\n",
      "epoch 17: loss=12.115007400512695\n",
      "epoch 18: loss=10.812996864318848\n",
      "epoch 19: loss=10.804610252380371\n",
      "epoch 20: loss=9.996252059936523\n",
      "epoch 21: loss=9.485255241394043\n",
      "epoch 22: loss=8.468106269836426\n",
      "epoch 23: loss=8.486050605773926\n",
      "epoch 24: loss=7.2906646728515625\n",
      "epoch 25: loss=6.392236232757568\n",
      "epoch 26: loss=5.489889144897461\n",
      "epoch 27: loss=4.719958782196045\n",
      "epoch 28: loss=4.088901042938232\n",
      "epoch 29: loss=4.023223876953125\n",
      "epoch 30: loss=3.6757752895355225\n",
      "epoch 31: loss=3.681215286254883\n",
      "epoch 32: loss=3.397287368774414\n",
      "epoch 33: loss=3.0915474891662598\n",
      "epoch 34: loss=2.884124517440796\n",
      "epoch 35: loss=2.845698833465576\n",
      "epoch 36: loss=2.932467460632324\n",
      "epoch 37: loss=2.8846981525421143\n",
      "epoch 38: loss=2.918689012527466\n",
      "epoch 39: loss=2.763453722000122\n",
      "epoch 40: loss=2.7168173789978027\n",
      "epoch 41: loss=2.7598726749420166\n",
      "epoch 42: loss=2.8210017681121826\n",
      "epoch 43: loss=2.7897584438323975\n",
      "epoch 44: loss=2.766779899597168\n",
      "epoch 45: loss=2.751828670501709\n",
      "epoch 46: loss=2.74084210395813\n",
      "epoch 47: loss=2.7544941902160645\n",
      "epoch 48: loss=2.7035584449768066\n",
      "epoch 49: loss=2.680887222290039\n",
      "epoch 50: loss=2.6333158016204834\n",
      "epoch 51: loss=2.6273889541625977\n",
      "epoch 52: loss=2.6321136951446533\n",
      "epoch 53: loss=2.6302080154418945\n",
      "epoch 54: loss=2.570525884628296\n",
      "epoch 55: loss=2.564086437225342\n",
      "epoch 56: loss=2.5296876430511475\n",
      "epoch 57: loss=2.531674861907959\n",
      "epoch 58: loss=2.4716897010803223\n",
      "epoch 59: loss=2.497227668762207\n",
      "epoch 60: loss=2.5139658451080322\n",
      "epoch 61: loss=2.4381346702575684\n",
      "epoch 62: loss=2.4376795291900635\n",
      "epoch 63: loss=2.4066274166107178\n",
      "epoch 64: loss=2.461637258529663\n",
      "epoch 65: loss=2.453645706176758\n",
      "epoch 66: loss=2.397357225418091\n",
      "epoch 67: loss=2.3664774894714355\n",
      "epoch 68: loss=2.4081389904022217\n",
      "epoch 69: loss=2.3331243991851807\n",
      "epoch 70: loss=2.4068517684936523\n",
      "epoch 71: loss=2.367445468902588\n",
      "epoch 72: loss=2.4144701957702637\n",
      "epoch 73: loss=2.3788304328918457\n",
      "epoch 74: loss=2.3798112869262695\n",
      "epoch 75: loss=2.2952356338500977\n",
      "epoch 76: loss=2.3863463401794434\n",
      "epoch 77: loss=2.320697546005249\n",
      "epoch 78: loss=2.330104351043701\n",
      "epoch 79: loss=2.382739782333374\n",
      "epoch 80: loss=2.3210833072662354\n",
      "epoch 81: loss=2.3180413246154785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82: loss=2.3257627487182617\n",
      "epoch 83: loss=2.341282844543457\n",
      "epoch 84: loss=2.3643829822540283\n",
      "epoch 85: loss=2.325650691986084\n",
      "epoch 86: loss=2.342834949493408\n",
      "epoch 87: loss=2.3270246982574463\n",
      "epoch 88: loss=2.389462471008301\n",
      "epoch 89: loss=2.3861818313598633\n",
      "epoch 90: loss=2.321096420288086\n",
      "epoch 91: loss=2.3405349254608154\n",
      "epoch 92: loss=2.331312656402588\n",
      "epoch 93: loss=2.2713656425476074\n",
      "epoch 94: loss=2.3193607330322266\n",
      "epoch 95: loss=2.323326587677002\n",
      "epoch 96: loss=2.350292205810547\n",
      "epoch 97: loss=2.3182384967803955\n",
      "epoch 98: loss=2.2926597595214844\n",
      "epoch 99: loss=2.2853221893310547\n",
      "epoch 100: loss=2.3460288047790527\n",
      "epoch 101: loss=2.267655611038208\n",
      "epoch 102: loss=2.333998680114746\n",
      "epoch 103: loss=2.2762794494628906\n",
      "epoch 104: loss=2.3471732139587402\n",
      "epoch 105: loss=2.3409066200256348\n",
      "epoch 106: loss=2.329403877258301\n",
      "epoch 107: loss=2.275099277496338\n",
      "epoch 108: loss=2.3238301277160645\n",
      "epoch 109: loss=2.332944393157959\n",
      "epoch 110: loss=2.2888710498809814\n",
      "epoch 111: loss=2.3114423751831055\n",
      "epoch 112: loss=2.3178043365478516\n",
      "epoch 113: loss=2.294926166534424\n",
      "epoch 114: loss=2.2866175174713135\n",
      "epoch 115: loss=2.2945971488952637\n",
      "epoch 116: loss=2.2686705589294434\n",
      "epoch 117: loss=2.313985824584961\n",
      "epoch 118: loss=2.2994496822357178\n",
      "epoch 119: loss=2.303631067276001\n",
      "epoch 120: loss=2.2873520851135254\n",
      "epoch 121: loss=2.228508949279785\n",
      "epoch 122: loss=2.2697930335998535\n",
      "epoch 123: loss=2.315934419631958\n",
      "epoch 124: loss=2.2770228385925293\n",
      "epoch 125: loss=2.2589852809906006\n",
      "epoch 126: loss=2.2735793590545654\n",
      "epoch 127: loss=2.319359302520752\n",
      "epoch 128: loss=2.2715656757354736\n",
      "epoch 129: loss=2.238304615020752\n",
      "epoch 130: loss=2.27719783782959\n",
      "epoch 131: loss=2.2804746627807617\n",
      "epoch 132: loss=2.2594077587127686\n",
      "epoch 133: loss=2.2982494831085205\n",
      "epoch 134: loss=2.257920265197754\n",
      "epoch 135: loss=2.293717861175537\n",
      "epoch 136: loss=2.222031593322754\n",
      "epoch 137: loss=2.285867214202881\n",
      "epoch 138: loss=2.2776620388031006\n",
      "epoch 139: loss=2.308281898498535\n",
      "epoch 140: loss=2.272712230682373\n",
      "epoch 141: loss=2.3028531074523926\n",
      "epoch 142: loss=2.2720417976379395\n",
      "epoch 143: loss=2.245471715927124\n",
      "epoch 144: loss=2.2651047706604004\n",
      "epoch 145: loss=2.238023519515991\n",
      "epoch 146: loss=2.2818222045898438\n",
      "epoch 147: loss=2.26405668258667\n",
      "epoch 148: loss=2.2401177883148193\n",
      "epoch 149: loss=2.257739543914795\n",
      "epoch 150: loss=2.279862880706787\n",
      "epoch 151: loss=2.2458839416503906\n",
      "epoch 152: loss=2.2410483360290527\n",
      "epoch 153: loss=2.245455026626587\n",
      "epoch 154: loss=2.236180305480957\n",
      "epoch 155: loss=2.208042621612549\n",
      "epoch 156: loss=2.2096874713897705\n",
      "epoch 157: loss=2.238612174987793\n",
      "epoch 158: loss=2.2614219188690186\n",
      "epoch 159: loss=2.234440803527832\n",
      "epoch 160: loss=2.2260823249816895\n",
      "epoch 161: loss=2.2599945068359375\n",
      "epoch 162: loss=2.2477874755859375\n",
      "epoch 163: loss=2.277844190597534\n",
      "epoch 164: loss=2.2161808013916016\n",
      "epoch 165: loss=2.237678050994873\n",
      "epoch 166: loss=2.2687735557556152\n",
      "epoch 167: loss=2.246504545211792\n",
      "epoch 168: loss=2.233912229537964\n",
      "epoch 169: loss=2.2361412048339844\n",
      "epoch 170: loss=2.225600242614746\n",
      "epoch 171: loss=2.296830415725708\n",
      "epoch 172: loss=2.2437682151794434\n",
      "epoch 173: loss=2.2942395210266113\n",
      "epoch 174: loss=2.2684266567230225\n",
      "epoch 175: loss=2.160626173019409\n",
      "epoch 176: loss=2.1953296661376953\n",
      "epoch 177: loss=2.2643277645111084\n",
      "epoch 178: loss=2.2301220893859863\n",
      "epoch 179: loss=2.263267993927002\n",
      "epoch 180: loss=2.228949785232544\n",
      "epoch 181: loss=2.242058038711548\n",
      "epoch 182: loss=2.2946295738220215\n",
      "epoch 183: loss=2.225454330444336\n",
      "epoch 184: loss=2.2555487155914307\n",
      "epoch 185: loss=2.2016618251800537\n",
      "epoch 186: loss=2.257380247116089\n",
      "epoch 187: loss=2.1798956394195557\n",
      "epoch 188: loss=2.263965129852295\n",
      "epoch 189: loss=2.2650718688964844\n",
      "epoch 190: loss=2.2429277896881104\n",
      "epoch 191: loss=2.2654709815979004\n",
      "epoch 192: loss=2.257805109024048\n",
      "epoch 193: loss=2.2292275428771973\n",
      "epoch 194: loss=2.217184543609619\n",
      "epoch 195: loss=2.2749216556549072\n",
      "epoch 196: loss=2.23020339012146\n",
      "epoch 197: loss=2.2219009399414062\n",
      "epoch 198: loss=2.243075132369995\n",
      "epoch 199: loss=2.2934622764587402\n",
      "training patch with 2784 edges\n",
      "epoch 0: loss=18.17293930053711\n",
      "epoch 1: loss=18.409992218017578\n",
      "epoch 2: loss=18.571645736694336\n",
      "epoch 3: loss=18.050994873046875\n",
      "epoch 4: loss=18.126737594604492\n",
      "epoch 5: loss=16.557619094848633\n",
      "epoch 6: loss=15.490948677062988\n",
      "epoch 7: loss=16.153594970703125\n",
      "epoch 8: loss=17.861108779907227\n",
      "epoch 9: loss=19.089420318603516\n",
      "epoch 10: loss=18.091354370117188\n",
      "epoch 11: loss=16.960323333740234\n",
      "epoch 12: loss=14.723164558410645\n",
      "epoch 13: loss=13.01655387878418\n",
      "epoch 14: loss=12.393716812133789\n",
      "epoch 15: loss=11.246001243591309\n",
      "epoch 16: loss=11.15912914276123\n",
      "epoch 17: loss=10.678746223449707\n",
      "epoch 18: loss=9.825069427490234\n",
      "epoch 19: loss=8.743520736694336\n",
      "epoch 20: loss=8.262064933776855\n",
      "epoch 21: loss=7.769617557525635\n",
      "epoch 22: loss=6.561707019805908\n",
      "epoch 23: loss=5.883975505828857\n",
      "epoch 24: loss=5.110351085662842\n",
      "epoch 25: loss=4.217840194702148\n",
      "epoch 26: loss=3.8417084217071533\n",
      "epoch 27: loss=3.443499803543091\n",
      "epoch 28: loss=3.3206515312194824\n",
      "epoch 29: loss=3.1234259605407715\n",
      "epoch 30: loss=2.9727742671966553\n",
      "epoch 31: loss=2.6451096534729004\n",
      "epoch 32: loss=2.596543788909912\n",
      "epoch 33: loss=2.446016788482666\n",
      "epoch 34: loss=2.5314407348632812\n",
      "epoch 35: loss=2.488288640975952\n",
      "epoch 36: loss=2.3888702392578125\n",
      "epoch 37: loss=2.374880313873291\n",
      "epoch 38: loss=2.3948142528533936\n",
      "epoch 39: loss=2.3896007537841797\n",
      "epoch 40: loss=2.4187729358673096\n",
      "epoch 41: loss=2.4103643894195557\n",
      "epoch 42: loss=2.402170181274414\n",
      "epoch 43: loss=2.4147531986236572\n",
      "epoch 44: loss=2.4026923179626465\n",
      "epoch 45: loss=2.3712263107299805\n",
      "epoch 46: loss=2.373713493347168\n",
      "epoch 47: loss=2.3389792442321777\n",
      "epoch 48: loss=2.339399814605713\n",
      "epoch 49: loss=2.3315367698669434\n",
      "epoch 50: loss=2.3431553840637207\n",
      "epoch 51: loss=2.29840087890625\n",
      "epoch 52: loss=2.2812695503234863\n",
      "epoch 53: loss=2.2634999752044678\n",
      "epoch 54: loss=2.249624729156494\n",
      "epoch 55: loss=2.226698398590088\n",
      "epoch 56: loss=2.216214179992676\n",
      "epoch 57: loss=2.1892848014831543\n",
      "epoch 58: loss=2.178776979446411\n",
      "epoch 59: loss=2.1721014976501465\n",
      "epoch 60: loss=2.1529276371002197\n",
      "epoch 61: loss=2.1487507820129395\n",
      "epoch 62: loss=2.079821825027466\n",
      "epoch 63: loss=2.072251558303833\n",
      "epoch 64: loss=2.070024251937866\n",
      "epoch 65: loss=2.0748400688171387\n",
      "epoch 66: loss=2.0450429916381836\n",
      "epoch 67: loss=2.062699794769287\n",
      "epoch 68: loss=2.047607421875\n",
      "epoch 69: loss=2.0845015048980713\n",
      "epoch 70: loss=2.033871650695801\n",
      "epoch 71: loss=2.0354201793670654\n",
      "epoch 72: loss=2.013878345489502\n",
      "epoch 73: loss=2.029123544692993\n",
      "epoch 74: loss=2.0086076259613037\n",
      "epoch 75: loss=2.01071834564209\n",
      "epoch 76: loss=1.9907116889953613\n",
      "epoch 77: loss=1.9850444793701172\n",
      "epoch 78: loss=2.0082836151123047\n",
      "epoch 79: loss=1.9950275421142578\n",
      "epoch 80: loss=1.9802956581115723\n",
      "epoch 81: loss=1.969977855682373\n",
      "epoch 82: loss=1.9420709609985352\n",
      "epoch 83: loss=1.96968412399292\n",
      "epoch 84: loss=1.9702177047729492\n",
      "epoch 85: loss=1.959409475326538\n",
      "epoch 86: loss=1.9483609199523926\n",
      "epoch 87: loss=1.9889438152313232\n",
      "epoch 88: loss=2.0055410861968994\n",
      "epoch 89: loss=1.8872921466827393\n",
      "epoch 90: loss=1.922006607055664\n",
      "epoch 91: loss=1.964870810508728\n",
      "epoch 92: loss=1.9230539798736572\n",
      "epoch 93: loss=1.9501700401306152\n",
      "epoch 94: loss=1.960078477859497\n",
      "epoch 95: loss=1.9348890781402588\n",
      "epoch 96: loss=1.952711820602417\n",
      "epoch 97: loss=1.9198367595672607\n",
      "epoch 98: loss=1.9393694400787354\n",
      "epoch 99: loss=1.9273946285247803\n",
      "epoch 100: loss=1.9505871534347534\n",
      "epoch 101: loss=1.9261127710342407\n",
      "epoch 102: loss=1.9206870794296265\n",
      "epoch 103: loss=1.9242873191833496\n",
      "epoch 104: loss=1.9535619020462036\n",
      "epoch 105: loss=1.9262080192565918\n",
      "epoch 106: loss=1.9351129531860352\n",
      "epoch 107: loss=1.8905518054962158\n",
      "epoch 108: loss=1.9089179039001465\n",
      "epoch 109: loss=1.9073035717010498\n",
      "epoch 110: loss=1.938671350479126\n",
      "epoch 111: loss=1.921327829360962\n",
      "epoch 112: loss=1.8836358785629272\n",
      "epoch 113: loss=1.9032742977142334\n",
      "epoch 114: loss=1.9113941192626953\n",
      "epoch 115: loss=1.9097485542297363\n",
      "epoch 116: loss=1.8861005306243896\n",
      "epoch 117: loss=1.9087198972702026\n",
      "epoch 118: loss=1.9139372110366821\n",
      "epoch 119: loss=1.8702877759933472\n",
      "epoch 120: loss=1.8870407342910767\n",
      "epoch 121: loss=1.8851451873779297\n",
      "epoch 122: loss=1.8814481496810913\n",
      "epoch 123: loss=1.8846216201782227\n",
      "epoch 124: loss=1.8882030248641968\n",
      "epoch 125: loss=1.8744078874588013\n",
      "epoch 126: loss=1.9060077667236328\n",
      "epoch 127: loss=1.8823356628417969\n",
      "epoch 128: loss=1.8525590896606445\n",
      "epoch 129: loss=1.9051841497421265\n",
      "epoch 130: loss=1.8685956001281738\n",
      "epoch 131: loss=1.8667715787887573\n",
      "epoch 132: loss=1.8384921550750732\n",
      "epoch 133: loss=1.877854347229004\n",
      "epoch 134: loss=1.8889274597167969\n",
      "epoch 135: loss=1.8632419109344482\n",
      "epoch 136: loss=1.8804879188537598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137: loss=1.8969279527664185\n",
      "epoch 138: loss=1.9105663299560547\n",
      "epoch 139: loss=1.8867900371551514\n",
      "epoch 140: loss=1.865997552871704\n",
      "epoch 141: loss=1.8958449363708496\n",
      "epoch 142: loss=1.861472725868225\n",
      "epoch 143: loss=1.8940258026123047\n",
      "epoch 144: loss=1.863931655883789\n",
      "epoch 145: loss=1.8864494562149048\n",
      "epoch 146: loss=1.8626019954681396\n",
      "epoch 147: loss=1.8683706521987915\n",
      "epoch 148: loss=1.8548064231872559\n",
      "epoch 149: loss=1.896970272064209\n",
      "epoch 150: loss=1.8600236177444458\n",
      "epoch 151: loss=1.8594660758972168\n",
      "epoch 152: loss=1.8244109153747559\n",
      "epoch 153: loss=1.8686408996582031\n",
      "epoch 154: loss=1.8410266637802124\n",
      "epoch 155: loss=1.8670588731765747\n",
      "epoch 156: loss=1.8577907085418701\n",
      "epoch 157: loss=1.8996024131774902\n",
      "epoch 158: loss=1.921343445777893\n",
      "epoch 159: loss=1.8456274271011353\n",
      "epoch 160: loss=1.869586706161499\n",
      "epoch 161: loss=1.8880953788757324\n",
      "epoch 162: loss=1.889170527458191\n",
      "epoch 163: loss=1.8713339567184448\n",
      "epoch 164: loss=1.8817486763000488\n",
      "epoch 165: loss=1.8789844512939453\n",
      "epoch 166: loss=1.8963847160339355\n",
      "epoch 167: loss=1.880492091178894\n",
      "epoch 168: loss=1.856414794921875\n",
      "epoch 169: loss=1.8620507717132568\n",
      "epoch 170: loss=1.8648722171783447\n",
      "epoch 171: loss=1.8693439960479736\n",
      "epoch 172: loss=1.866695523262024\n",
      "epoch 173: loss=1.8759021759033203\n",
      "epoch 174: loss=1.8625807762145996\n",
      "epoch 175: loss=1.841252326965332\n",
      "epoch 176: loss=1.8869597911834717\n",
      "epoch 177: loss=1.8412766456604004\n",
      "epoch 178: loss=1.8844294548034668\n",
      "epoch 179: loss=1.8665404319763184\n",
      "epoch 180: loss=1.8208426237106323\n",
      "epoch 181: loss=1.828906774520874\n",
      "epoch 182: loss=1.8749498128890991\n",
      "epoch 183: loss=1.8442479372024536\n",
      "epoch 184: loss=1.866231083869934\n",
      "epoch 185: loss=1.8521026372909546\n",
      "epoch 186: loss=1.8484628200531006\n",
      "epoch 187: loss=1.8579531908035278\n",
      "epoch 188: loss=1.8784794807434082\n",
      "epoch 189: loss=1.8383378982543945\n",
      "epoch 190: loss=1.8283770084381104\n",
      "epoch 191: loss=1.8806525468826294\n",
      "epoch 192: loss=1.8822355270385742\n",
      "epoch 193: loss=1.8571357727050781\n",
      "epoch 194: loss=1.824883222579956\n",
      "epoch 195: loss=1.8756550550460815\n",
      "epoch 196: loss=1.8455408811569214\n",
      "epoch 197: loss=1.813262939453125\n",
      "epoch 198: loss=1.8881661891937256\n",
      "epoch 199: loss=1.8360251188278198\n",
      "training patch with 1652 edges\n",
      "epoch 0: loss=18.602783203125\n",
      "epoch 1: loss=18.39063835144043\n",
      "epoch 2: loss=18.94838523864746\n",
      "epoch 3: loss=17.773691177368164\n",
      "epoch 4: loss=17.752042770385742\n",
      "epoch 5: loss=16.871179580688477\n",
      "epoch 6: loss=16.77864646911621\n",
      "epoch 7: loss=16.535808563232422\n",
      "epoch 8: loss=17.502038955688477\n",
      "epoch 9: loss=18.371976852416992\n",
      "epoch 10: loss=19.239072799682617\n",
      "epoch 11: loss=17.775108337402344\n",
      "epoch 12: loss=16.387813568115234\n",
      "epoch 13: loss=15.152669906616211\n",
      "epoch 14: loss=13.922961235046387\n",
      "epoch 15: loss=13.25882625579834\n",
      "epoch 16: loss=12.414311408996582\n",
      "epoch 17: loss=12.182138442993164\n",
      "epoch 18: loss=11.623371124267578\n",
      "epoch 19: loss=10.771708488464355\n",
      "epoch 20: loss=10.237195014953613\n",
      "epoch 21: loss=9.593826293945312\n",
      "epoch 22: loss=8.342439651489258\n",
      "epoch 23: loss=8.194708824157715\n",
      "epoch 24: loss=7.51796817779541\n",
      "epoch 25: loss=6.0150837898254395\n",
      "epoch 26: loss=5.733224868774414\n",
      "epoch 27: loss=4.936903953552246\n",
      "epoch 28: loss=4.477171421051025\n",
      "epoch 29: loss=4.062641143798828\n",
      "epoch 30: loss=3.981084108352661\n",
      "epoch 31: loss=3.7790369987487793\n",
      "epoch 32: loss=3.5733156204223633\n",
      "epoch 33: loss=3.211466073989868\n",
      "epoch 34: loss=3.097348690032959\n",
      "epoch 35: loss=2.9193410873413086\n",
      "epoch 36: loss=3.1113271713256836\n",
      "epoch 37: loss=3.030930519104004\n",
      "epoch 38: loss=2.8796629905700684\n",
      "epoch 39: loss=2.8565421104431152\n",
      "epoch 40: loss=2.8518190383911133\n",
      "epoch 41: loss=2.8507823944091797\n",
      "epoch 42: loss=2.8998665809631348\n",
      "epoch 43: loss=2.8445324897766113\n",
      "epoch 44: loss=2.8318591117858887\n",
      "epoch 45: loss=2.8392839431762695\n",
      "epoch 46: loss=2.826777458190918\n",
      "epoch 47: loss=2.8551278114318848\n",
      "epoch 48: loss=2.7769713401794434\n",
      "epoch 49: loss=2.7357282638549805\n",
      "epoch 50: loss=2.717658042907715\n",
      "epoch 51: loss=2.7346887588500977\n",
      "epoch 52: loss=2.7192583084106445\n",
      "epoch 53: loss=2.6285400390625\n",
      "epoch 54: loss=2.662139892578125\n",
      "epoch 55: loss=2.6696319580078125\n",
      "epoch 56: loss=2.6157751083374023\n",
      "epoch 57: loss=2.6059858798980713\n",
      "epoch 58: loss=2.579650402069092\n",
      "epoch 59: loss=2.526853322982788\n",
      "epoch 60: loss=2.486248016357422\n",
      "epoch 61: loss=2.5053889751434326\n",
      "epoch 62: loss=2.46596097946167\n",
      "epoch 63: loss=2.5254061222076416\n",
      "epoch 64: loss=2.483327865600586\n",
      "epoch 65: loss=2.432058811187744\n",
      "epoch 66: loss=2.441990852355957\n",
      "epoch 67: loss=2.5126967430114746\n",
      "epoch 68: loss=2.4403066635131836\n",
      "epoch 69: loss=2.4466910362243652\n",
      "epoch 70: loss=2.389430522918701\n",
      "epoch 71: loss=2.3757662773132324\n",
      "epoch 72: loss=2.3585145473480225\n",
      "epoch 73: loss=2.4113876819610596\n",
      "epoch 74: loss=2.39721941947937\n",
      "epoch 75: loss=2.386647939682007\n",
      "epoch 76: loss=2.3800225257873535\n",
      "epoch 77: loss=2.331503391265869\n",
      "epoch 78: loss=2.3387317657470703\n",
      "epoch 79: loss=2.334665298461914\n",
      "epoch 80: loss=2.3779165744781494\n",
      "epoch 81: loss=2.3267722129821777\n",
      "epoch 82: loss=2.278083324432373\n",
      "epoch 83: loss=2.3308682441711426\n",
      "epoch 84: loss=2.2910380363464355\n",
      "epoch 85: loss=2.3404791355133057\n",
      "epoch 86: loss=2.320774555206299\n",
      "epoch 87: loss=2.3184709548950195\n",
      "epoch 88: loss=2.3277950286865234\n",
      "epoch 89: loss=2.356889486312866\n",
      "epoch 90: loss=2.3871729373931885\n",
      "epoch 91: loss=2.338846206665039\n",
      "epoch 92: loss=2.341977596282959\n",
      "epoch 93: loss=2.328951358795166\n",
      "epoch 94: loss=2.291555404663086\n",
      "epoch 95: loss=2.2764816284179688\n",
      "epoch 96: loss=2.3316078186035156\n",
      "epoch 97: loss=2.2845802307128906\n",
      "epoch 98: loss=2.3409154415130615\n",
      "epoch 99: loss=2.3544557094573975\n",
      "epoch 100: loss=2.2661609649658203\n",
      "epoch 101: loss=2.287449598312378\n",
      "epoch 102: loss=2.400454521179199\n",
      "epoch 103: loss=2.288902759552002\n",
      "epoch 104: loss=2.376530170440674\n",
      "epoch 105: loss=2.2754249572753906\n",
      "epoch 106: loss=2.326549530029297\n",
      "epoch 107: loss=2.350238561630249\n",
      "epoch 108: loss=2.253995895385742\n",
      "epoch 109: loss=2.298710823059082\n",
      "epoch 110: loss=2.257753849029541\n",
      "epoch 111: loss=2.3122706413269043\n",
      "epoch 112: loss=2.2530083656311035\n",
      "epoch 113: loss=2.3011932373046875\n",
      "epoch 114: loss=2.2869932651519775\n",
      "epoch 115: loss=2.3084750175476074\n",
      "epoch 116: loss=2.2591006755828857\n",
      "epoch 117: loss=2.267200469970703\n",
      "epoch 118: loss=2.2548890113830566\n",
      "epoch 119: loss=2.2895259857177734\n",
      "epoch 120: loss=2.2675046920776367\n",
      "epoch 121: loss=2.238795042037964\n",
      "epoch 122: loss=2.334350347518921\n",
      "epoch 123: loss=2.2538976669311523\n",
      "epoch 124: loss=2.3054676055908203\n",
      "epoch 125: loss=2.2961273193359375\n",
      "epoch 126: loss=2.2855374813079834\n",
      "epoch 127: loss=2.2284557819366455\n",
      "epoch 128: loss=2.2869858741760254\n",
      "epoch 129: loss=2.2603554725646973\n",
      "epoch 130: loss=2.2857394218444824\n",
      "epoch 131: loss=2.2429237365722656\n",
      "epoch 132: loss=2.25557017326355\n",
      "epoch 133: loss=2.309056282043457\n",
      "epoch 134: loss=2.264188766479492\n",
      "epoch 135: loss=2.323529005050659\n",
      "epoch 136: loss=2.259719133377075\n",
      "epoch 137: loss=2.2758727073669434\n",
      "epoch 138: loss=2.221295118331909\n",
      "epoch 139: loss=2.216280937194824\n",
      "epoch 140: loss=2.2169573307037354\n",
      "epoch 141: loss=2.3068466186523438\n",
      "epoch 142: loss=2.243802309036255\n",
      "epoch 143: loss=2.2854418754577637\n",
      "epoch 144: loss=2.297394275665283\n",
      "epoch 145: loss=2.280315399169922\n",
      "epoch 146: loss=2.3009181022644043\n",
      "epoch 147: loss=2.2996063232421875\n",
      "epoch 148: loss=2.2264504432678223\n",
      "epoch 149: loss=2.301624298095703\n",
      "epoch 150: loss=2.233879566192627\n",
      "epoch 151: loss=2.229257106781006\n",
      "epoch 152: loss=2.239044189453125\n",
      "epoch 153: loss=2.2604551315307617\n",
      "epoch 154: loss=2.296778678894043\n",
      "epoch 155: loss=2.3082776069641113\n",
      "epoch 156: loss=2.2805511951446533\n",
      "epoch 157: loss=2.2264671325683594\n",
      "epoch 158: loss=2.3295722007751465\n",
      "epoch 159: loss=2.277351140975952\n",
      "epoch 160: loss=2.3189897537231445\n",
      "epoch 161: loss=2.1881184577941895\n",
      "epoch 162: loss=2.2525382041931152\n",
      "epoch 163: loss=2.3062920570373535\n",
      "epoch 164: loss=2.2193171977996826\n",
      "epoch 165: loss=2.205806255340576\n",
      "epoch 166: loss=2.2386856079101562\n",
      "epoch 167: loss=2.3238422870635986\n",
      "epoch 168: loss=2.2391934394836426\n",
      "epoch 169: loss=2.2780091762542725\n",
      "epoch 170: loss=2.265657901763916\n",
      "epoch 171: loss=2.2216544151306152\n",
      "epoch 172: loss=2.2277252674102783\n",
      "epoch 173: loss=2.2915892601013184\n",
      "epoch 174: loss=2.2361438274383545\n",
      "epoch 175: loss=2.2631723880767822\n",
      "epoch 176: loss=2.3022613525390625\n",
      "epoch 177: loss=2.228032350540161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178: loss=2.271496534347534\n",
      "epoch 179: loss=2.238940715789795\n",
      "epoch 180: loss=2.2857167720794678\n",
      "epoch 181: loss=2.1968252658843994\n",
      "epoch 182: loss=2.2380118370056152\n",
      "epoch 183: loss=2.2324516773223877\n",
      "epoch 184: loss=2.211669921875\n",
      "epoch 185: loss=2.264383316040039\n",
      "epoch 186: loss=2.196373462677002\n",
      "epoch 187: loss=2.2283101081848145\n",
      "epoch 188: loss=2.2472152709960938\n",
      "epoch 189: loss=2.259397029876709\n",
      "epoch 190: loss=2.216829538345337\n",
      "epoch 191: loss=2.2280609607696533\n",
      "epoch 192: loss=2.1915743350982666\n",
      "epoch 193: loss=2.2032434940338135\n",
      "epoch 194: loss=2.2678065299987793\n",
      "epoch 195: loss=2.2330284118652344\n",
      "epoch 196: loss=2.2260406017303467\n",
      "epoch 197: loss=2.240598678588867\n",
      "epoch 198: loss=2.2717971801757812\n",
      "epoch 199: loss=2.2935709953308105\n",
      "training patch with 840 edges\n",
      "epoch 0: loss=18.41390037536621\n",
      "epoch 1: loss=18.593538284301758\n",
      "epoch 2: loss=17.98867416381836\n",
      "epoch 3: loss=18.63905906677246\n",
      "epoch 4: loss=17.61916160583496\n",
      "epoch 5: loss=16.94210433959961\n",
      "epoch 6: loss=17.351102828979492\n",
      "epoch 7: loss=16.532649993896484\n",
      "epoch 8: loss=16.938400268554688\n",
      "epoch 9: loss=17.276046752929688\n",
      "epoch 10: loss=18.056123733520508\n",
      "epoch 11: loss=20.126323699951172\n",
      "epoch 12: loss=18.847665786743164\n",
      "epoch 13: loss=18.492799758911133\n",
      "epoch 14: loss=19.189809799194336\n",
      "epoch 15: loss=17.16534423828125\n",
      "epoch 16: loss=16.94718360900879\n",
      "epoch 17: loss=15.203877449035645\n",
      "epoch 18: loss=14.623468399047852\n",
      "epoch 19: loss=14.47588062286377\n",
      "epoch 20: loss=14.11519718170166\n",
      "epoch 21: loss=14.251238822937012\n",
      "epoch 22: loss=13.078890800476074\n",
      "epoch 23: loss=13.372679710388184\n",
      "epoch 24: loss=12.151307106018066\n",
      "epoch 25: loss=11.996926307678223\n",
      "epoch 26: loss=11.628811836242676\n",
      "epoch 27: loss=12.81673526763916\n",
      "epoch 28: loss=11.484750747680664\n",
      "epoch 29: loss=10.542400360107422\n",
      "epoch 30: loss=9.999460220336914\n",
      "epoch 31: loss=8.987298965454102\n",
      "epoch 32: loss=7.525211811065674\n",
      "epoch 33: loss=7.871248722076416\n",
      "epoch 34: loss=7.479578495025635\n",
      "epoch 35: loss=6.498676776885986\n",
      "epoch 36: loss=5.8488993644714355\n",
      "epoch 37: loss=5.509576797485352\n",
      "epoch 38: loss=5.741057395935059\n",
      "epoch 39: loss=4.990894317626953\n",
      "epoch 40: loss=4.878457546234131\n",
      "epoch 41: loss=4.253095626831055\n",
      "epoch 42: loss=4.1366777420043945\n",
      "epoch 43: loss=3.9311952590942383\n",
      "epoch 44: loss=3.693258762359619\n",
      "epoch 45: loss=3.6296305656433105\n",
      "epoch 46: loss=3.7431092262268066\n",
      "epoch 47: loss=3.671419620513916\n",
      "epoch 48: loss=3.5333917140960693\n",
      "epoch 49: loss=3.505941390991211\n",
      "epoch 50: loss=3.333625316619873\n",
      "epoch 51: loss=3.448131799697876\n",
      "epoch 52: loss=3.5268726348876953\n",
      "epoch 53: loss=3.53794002532959\n",
      "epoch 54: loss=3.4058194160461426\n",
      "epoch 55: loss=3.3110227584838867\n",
      "epoch 56: loss=3.2396693229675293\n",
      "epoch 57: loss=3.2490735054016113\n",
      "epoch 58: loss=3.3103747367858887\n",
      "epoch 59: loss=3.2908153533935547\n",
      "epoch 60: loss=3.2303786277770996\n",
      "epoch 61: loss=3.1944668292999268\n",
      "epoch 62: loss=3.2295238971710205\n",
      "epoch 63: loss=3.134641647338867\n",
      "epoch 64: loss=3.133955717086792\n",
      "epoch 65: loss=3.111713409423828\n",
      "epoch 66: loss=3.1442294120788574\n",
      "epoch 67: loss=3.202859878540039\n",
      "epoch 68: loss=3.1524107456207275\n",
      "epoch 69: loss=3.009197235107422\n",
      "epoch 70: loss=3.0687661170959473\n",
      "epoch 71: loss=3.072549343109131\n",
      "epoch 72: loss=3.0599894523620605\n",
      "epoch 73: loss=3.1877894401550293\n",
      "epoch 74: loss=3.0246384143829346\n",
      "epoch 75: loss=3.0784363746643066\n",
      "epoch 76: loss=2.9690213203430176\n",
      "epoch 77: loss=2.995939016342163\n",
      "epoch 78: loss=3.07407283782959\n",
      "epoch 79: loss=3.0441761016845703\n",
      "epoch 80: loss=3.0122017860412598\n",
      "epoch 81: loss=3.0550239086151123\n",
      "epoch 82: loss=3.1553566455841064\n",
      "epoch 83: loss=2.9636263847351074\n",
      "epoch 84: loss=3.0208373069763184\n",
      "epoch 85: loss=3.0574429035186768\n",
      "epoch 86: loss=2.8809947967529297\n",
      "epoch 87: loss=2.9336695671081543\n",
      "epoch 88: loss=3.020336151123047\n",
      "epoch 89: loss=2.8912439346313477\n",
      "epoch 90: loss=3.0296883583068848\n",
      "epoch 91: loss=2.974209785461426\n",
      "epoch 92: loss=2.9500010013580322\n",
      "epoch 93: loss=3.0932111740112305\n",
      "epoch 94: loss=3.021608352661133\n",
      "epoch 95: loss=2.9553890228271484\n",
      "epoch 96: loss=2.9918837547302246\n",
      "epoch 97: loss=2.963529348373413\n",
      "epoch 98: loss=3.0083155632019043\n",
      "epoch 99: loss=2.955227851867676\n",
      "epoch 100: loss=3.0845746994018555\n",
      "epoch 101: loss=2.996448516845703\n",
      "epoch 102: loss=3.084987163543701\n",
      "epoch 103: loss=2.9128410816192627\n",
      "epoch 104: loss=2.9270615577697754\n",
      "epoch 105: loss=3.0002074241638184\n",
      "epoch 106: loss=2.9712471961975098\n",
      "epoch 107: loss=2.933370590209961\n",
      "epoch 108: loss=3.0138421058654785\n",
      "epoch 109: loss=3.015441417694092\n",
      "epoch 110: loss=2.9198427200317383\n",
      "epoch 111: loss=3.0667724609375\n",
      "epoch 112: loss=2.9036667346954346\n",
      "epoch 113: loss=2.930410623550415\n",
      "epoch 114: loss=2.9835641384124756\n",
      "epoch 115: loss=3.036897897720337\n",
      "epoch 116: loss=3.059715509414673\n",
      "epoch 117: loss=2.8867697715759277\n",
      "epoch 118: loss=2.951502799987793\n",
      "epoch 119: loss=2.8116812705993652\n",
      "epoch 120: loss=2.98488187789917\n",
      "epoch 121: loss=2.9555869102478027\n",
      "epoch 122: loss=3.018232822418213\n",
      "epoch 123: loss=3.1068921089172363\n",
      "epoch 124: loss=3.015714168548584\n",
      "epoch 125: loss=2.8648970127105713\n",
      "epoch 126: loss=3.015322208404541\n",
      "epoch 127: loss=2.9646334648132324\n",
      "epoch 128: loss=3.0049996376037598\n",
      "epoch 129: loss=2.937094211578369\n",
      "epoch 130: loss=2.9321296215057373\n",
      "epoch 131: loss=3.014897346496582\n",
      "epoch 132: loss=3.053276777267456\n",
      "epoch 133: loss=2.9665815830230713\n",
      "epoch 134: loss=2.9647345542907715\n",
      "epoch 135: loss=2.908809185028076\n",
      "epoch 136: loss=2.917484998703003\n",
      "epoch 137: loss=2.9293785095214844\n",
      "epoch 138: loss=2.8999481201171875\n",
      "epoch 139: loss=2.9460947513580322\n",
      "epoch 140: loss=2.8982105255126953\n",
      "epoch 141: loss=2.8774685859680176\n",
      "epoch 142: loss=2.9114837646484375\n",
      "epoch 143: loss=2.904721975326538\n",
      "epoch 144: loss=2.9105589389801025\n",
      "epoch 145: loss=2.8701438903808594\n",
      "epoch 146: loss=2.921142101287842\n",
      "epoch 147: loss=2.9066548347473145\n",
      "epoch 148: loss=2.9953489303588867\n",
      "epoch 149: loss=2.9269957542419434\n",
      "epoch 150: loss=2.9393467903137207\n",
      "epoch 151: loss=2.8550667762756348\n",
      "epoch 152: loss=3.037998676300049\n",
      "epoch 153: loss=2.9675607681274414\n",
      "epoch 154: loss=2.822817325592041\n",
      "epoch 155: loss=2.9425816535949707\n",
      "epoch 156: loss=2.9445528984069824\n",
      "epoch 157: loss=2.948922634124756\n",
      "epoch 158: loss=2.9268639087677\n",
      "epoch 159: loss=2.9045844078063965\n",
      "epoch 160: loss=2.879634380340576\n",
      "epoch 161: loss=3.075580596923828\n",
      "epoch 162: loss=2.957834243774414\n",
      "epoch 163: loss=2.8980798721313477\n",
      "epoch 164: loss=2.9181313514709473\n",
      "epoch 165: loss=2.8770978450775146\n",
      "epoch 166: loss=2.902146816253662\n",
      "epoch 167: loss=2.8274893760681152\n",
      "epoch 168: loss=2.944883346557617\n",
      "epoch 169: loss=2.8823745250701904\n",
      "epoch 170: loss=2.915323495864868\n",
      "epoch 171: loss=2.9042601585388184\n",
      "epoch 172: loss=2.968482494354248\n",
      "epoch 173: loss=3.013258218765259\n",
      "epoch 174: loss=2.9268898963928223\n",
      "epoch 175: loss=2.9307162761688232\n",
      "epoch 176: loss=2.8785037994384766\n",
      "epoch 177: loss=2.936549663543701\n",
      "epoch 178: loss=2.8705615997314453\n",
      "epoch 179: loss=2.9372498989105225\n",
      "epoch 180: loss=2.839277744293213\n",
      "epoch 181: loss=2.874342441558838\n",
      "epoch 182: loss=2.9928383827209473\n",
      "epoch 183: loss=2.9468722343444824\n",
      "epoch 184: loss=2.8225388526916504\n",
      "epoch 185: loss=2.9492287635803223\n",
      "epoch 186: loss=2.804699182510376\n",
      "epoch 187: loss=2.900073528289795\n",
      "epoch 188: loss=2.8967528343200684\n",
      "epoch 189: loss=2.9376673698425293\n",
      "epoch 190: loss=2.9487948417663574\n",
      "epoch 191: loss=2.943451166152954\n",
      "epoch 192: loss=2.822798013687134\n",
      "epoch 193: loss=2.9577341079711914\n",
      "epoch 194: loss=2.9349489212036133\n",
      "epoch 195: loss=2.8560791015625\n",
      "epoch 196: loss=2.9062235355377197\n",
      "epoch 197: loss=2.974696397781372\n",
      "epoch 198: loss=2.935023546218872\n",
      "epoch 199: loss=2.942730188369751\n",
      "training patch with 1460 edges\n",
      "epoch 0: loss=19.299943923950195\n",
      "epoch 1: loss=18.305753707885742\n",
      "epoch 2: loss=17.092451095581055\n",
      "epoch 3: loss=18.225317001342773\n",
      "epoch 4: loss=18.077102661132812\n",
      "epoch 5: loss=17.176952362060547\n",
      "epoch 6: loss=16.072139739990234\n",
      "epoch 7: loss=16.5020751953125\n",
      "epoch 8: loss=16.666873931884766\n",
      "epoch 9: loss=18.886695861816406\n",
      "epoch 10: loss=18.764394760131836\n",
      "epoch 11: loss=19.001855850219727\n",
      "epoch 12: loss=17.376073837280273\n",
      "epoch 13: loss=16.0880184173584\n",
      "epoch 14: loss=14.415694236755371\n",
      "epoch 15: loss=14.719939231872559\n",
      "epoch 16: loss=12.820496559143066\n",
      "epoch 17: loss=12.927217483520508\n",
      "epoch 18: loss=12.777544021606445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: loss=12.270415306091309\n",
      "epoch 20: loss=12.474955558776855\n",
      "epoch 21: loss=10.468403816223145\n",
      "epoch 22: loss=10.651004791259766\n",
      "epoch 23: loss=10.289745330810547\n",
      "epoch 24: loss=10.101717948913574\n",
      "epoch 25: loss=9.671427726745605\n",
      "epoch 26: loss=8.413477897644043\n",
      "epoch 27: loss=7.4837965965271\n",
      "epoch 28: loss=6.3076581954956055\n",
      "epoch 29: loss=6.275375843048096\n",
      "epoch 30: loss=5.56739616394043\n",
      "epoch 31: loss=5.180123329162598\n",
      "epoch 32: loss=4.651453495025635\n",
      "epoch 33: loss=4.23728084564209\n",
      "epoch 34: loss=4.307375907897949\n",
      "epoch 35: loss=4.00064754486084\n",
      "epoch 36: loss=3.6601366996765137\n",
      "epoch 37: loss=3.3243489265441895\n",
      "epoch 38: loss=3.2822744846343994\n",
      "epoch 39: loss=3.215501070022583\n",
      "epoch 40: loss=3.237004280090332\n",
      "epoch 41: loss=3.1957387924194336\n",
      "epoch 42: loss=3.1504247188568115\n",
      "epoch 43: loss=3.038942813873291\n",
      "epoch 44: loss=3.000347852706909\n",
      "epoch 45: loss=3.031769275665283\n",
      "epoch 46: loss=3.0614013671875\n",
      "epoch 47: loss=2.9605588912963867\n",
      "epoch 48: loss=3.049252510070801\n",
      "epoch 49: loss=2.9567208290100098\n",
      "epoch 50: loss=2.976914882659912\n",
      "epoch 51: loss=2.9631335735321045\n",
      "epoch 52: loss=2.9448914527893066\n",
      "epoch 53: loss=2.8961637020111084\n",
      "epoch 54: loss=2.8241376876831055\n",
      "epoch 55: loss=2.8750360012054443\n",
      "epoch 56: loss=2.867831230163574\n",
      "epoch 57: loss=2.834890842437744\n",
      "epoch 58: loss=2.767359733581543\n",
      "epoch 59: loss=2.7980382442474365\n",
      "epoch 60: loss=2.7529377937316895\n",
      "epoch 61: loss=2.734801769256592\n",
      "epoch 62: loss=2.7270445823669434\n",
      "epoch 63: loss=2.782806873321533\n",
      "epoch 64: loss=2.718522548675537\n",
      "epoch 65: loss=2.697862148284912\n",
      "epoch 66: loss=2.7345404624938965\n",
      "epoch 67: loss=2.665531873703003\n",
      "epoch 68: loss=2.680009365081787\n",
      "epoch 69: loss=2.7111072540283203\n",
      "epoch 70: loss=2.7263879776000977\n",
      "epoch 71: loss=2.719748020172119\n",
      "epoch 72: loss=2.6763510704040527\n",
      "epoch 73: loss=2.675095319747925\n",
      "epoch 74: loss=2.7129123210906982\n",
      "epoch 75: loss=2.633268356323242\n",
      "epoch 76: loss=2.6400933265686035\n",
      "epoch 77: loss=2.694526195526123\n",
      "epoch 78: loss=2.545276641845703\n",
      "epoch 79: loss=2.6729202270507812\n",
      "epoch 80: loss=2.6466445922851562\n",
      "epoch 81: loss=2.6750712394714355\n",
      "epoch 82: loss=2.595073699951172\n",
      "epoch 83: loss=2.6255218982696533\n",
      "epoch 84: loss=2.569103717803955\n",
      "epoch 85: loss=2.619828701019287\n",
      "epoch 86: loss=2.547969341278076\n",
      "epoch 87: loss=2.6209235191345215\n",
      "epoch 88: loss=2.5652551651000977\n",
      "epoch 89: loss=2.6081881523132324\n",
      "epoch 90: loss=2.524960994720459\n",
      "epoch 91: loss=2.5361733436584473\n",
      "epoch 92: loss=2.5665555000305176\n",
      "epoch 93: loss=2.549947500228882\n",
      "epoch 94: loss=2.5619921684265137\n",
      "epoch 95: loss=2.627807140350342\n",
      "epoch 96: loss=2.5696377754211426\n",
      "epoch 97: loss=2.4824230670928955\n",
      "epoch 98: loss=2.547813892364502\n",
      "epoch 99: loss=2.5393881797790527\n",
      "epoch 100: loss=2.475114107131958\n",
      "epoch 101: loss=2.485644817352295\n",
      "epoch 102: loss=2.5577216148376465\n",
      "epoch 103: loss=2.5306577682495117\n",
      "epoch 104: loss=2.5020461082458496\n",
      "epoch 105: loss=2.4925003051757812\n",
      "epoch 106: loss=2.5583226680755615\n",
      "epoch 107: loss=2.4980387687683105\n",
      "epoch 108: loss=2.5546908378601074\n",
      "epoch 109: loss=2.5127649307250977\n",
      "epoch 110: loss=2.5638723373413086\n",
      "epoch 111: loss=2.4673023223876953\n",
      "epoch 112: loss=2.504011392593384\n",
      "epoch 113: loss=2.4671199321746826\n",
      "epoch 114: loss=2.5432164669036865\n",
      "epoch 115: loss=2.534940719604492\n",
      "epoch 116: loss=2.5665054321289062\n",
      "epoch 117: loss=2.51710844039917\n",
      "epoch 118: loss=2.508795738220215\n",
      "epoch 119: loss=2.5478010177612305\n",
      "epoch 120: loss=2.484973907470703\n",
      "epoch 121: loss=2.4984209537506104\n",
      "epoch 122: loss=2.468996524810791\n",
      "epoch 123: loss=2.5073089599609375\n",
      "epoch 124: loss=2.487612247467041\n",
      "epoch 125: loss=2.464292049407959\n",
      "epoch 126: loss=2.4939260482788086\n",
      "epoch 127: loss=2.502218246459961\n",
      "epoch 128: loss=2.469771385192871\n",
      "epoch 129: loss=2.525275707244873\n",
      "epoch 130: loss=2.560492515563965\n",
      "epoch 131: loss=2.46901535987854\n",
      "epoch 132: loss=2.564535140991211\n",
      "epoch 133: loss=2.603621006011963\n",
      "epoch 134: loss=2.4984750747680664\n",
      "epoch 135: loss=2.493709087371826\n",
      "epoch 136: loss=2.447810411453247\n",
      "epoch 137: loss=2.460536003112793\n",
      "epoch 138: loss=2.5420875549316406\n",
      "epoch 139: loss=2.454298734664917\n",
      "epoch 140: loss=2.4176228046417236\n",
      "epoch 141: loss=2.5267348289489746\n",
      "epoch 142: loss=2.4810423851013184\n",
      "epoch 143: loss=2.462705135345459\n",
      "epoch 144: loss=2.453902244567871\n",
      "epoch 145: loss=2.4738802909851074\n",
      "epoch 146: loss=2.4842326641082764\n",
      "epoch 147: loss=2.5835018157958984\n",
      "epoch 148: loss=2.436851978302002\n",
      "epoch 149: loss=2.4449751377105713\n",
      "epoch 150: loss=2.498891592025757\n",
      "epoch 151: loss=2.486900806427002\n",
      "epoch 152: loss=2.45378041267395\n",
      "epoch 153: loss=2.468852996826172\n",
      "epoch 154: loss=2.4988625049591064\n",
      "epoch 155: loss=2.4469399452209473\n",
      "epoch 156: loss=2.407395839691162\n",
      "epoch 157: loss=2.4189679622650146\n",
      "epoch 158: loss=2.4716243743896484\n",
      "epoch 159: loss=2.441019058227539\n",
      "epoch 160: loss=2.4505271911621094\n",
      "epoch 161: loss=2.4833006858825684\n",
      "epoch 162: loss=2.4779624938964844\n",
      "epoch 163: loss=2.455655574798584\n",
      "epoch 164: loss=2.448580741882324\n",
      "epoch 165: loss=2.430084228515625\n",
      "epoch 166: loss=2.4938621520996094\n",
      "epoch 167: loss=2.5483226776123047\n",
      "epoch 168: loss=2.4418463706970215\n",
      "epoch 169: loss=2.445020914077759\n",
      "epoch 170: loss=2.442361831665039\n",
      "epoch 171: loss=2.4667787551879883\n",
      "epoch 172: loss=2.489638090133667\n",
      "epoch 173: loss=2.4851279258728027\n",
      "epoch 174: loss=2.437554359436035\n",
      "epoch 175: loss=2.4826502799987793\n",
      "epoch 176: loss=2.462775707244873\n",
      "epoch 177: loss=2.4724388122558594\n",
      "epoch 178: loss=2.433832883834839\n",
      "epoch 179: loss=2.4705638885498047\n",
      "epoch 180: loss=2.5077433586120605\n",
      "epoch 181: loss=2.4455676078796387\n",
      "epoch 182: loss=2.5296833515167236\n",
      "epoch 183: loss=2.357358932495117\n",
      "epoch 184: loss=2.5458319187164307\n",
      "epoch 185: loss=2.4781365394592285\n",
      "epoch 186: loss=2.497422695159912\n",
      "epoch 187: loss=2.4349427223205566\n",
      "epoch 188: loss=2.4475765228271484\n",
      "epoch 189: loss=2.478214740753174\n",
      "epoch 190: loss=2.468169689178467\n",
      "epoch 191: loss=2.418264389038086\n",
      "epoch 192: loss=2.4128711223602295\n",
      "epoch 193: loss=2.5166189670562744\n",
      "epoch 194: loss=2.3946950435638428\n",
      "epoch 195: loss=2.4073429107666016\n",
      "epoch 196: loss=2.442117691040039\n",
      "epoch 197: loss=2.397230386734009\n",
      "epoch 198: loss=2.4192657470703125\n",
      "epoch 199: loss=2.4412081241607666\n",
      "training patch with 764 edges\n",
      "epoch 0: loss=17.250402450561523\n",
      "epoch 1: loss=18.795547485351562\n",
      "epoch 2: loss=18.192373275756836\n",
      "epoch 3: loss=17.52690887451172\n",
      "epoch 4: loss=18.5930118560791\n",
      "epoch 5: loss=18.72960662841797\n",
      "epoch 6: loss=17.839431762695312\n",
      "epoch 7: loss=18.098522186279297\n",
      "epoch 8: loss=18.767581939697266\n",
      "epoch 9: loss=18.614315032958984\n",
      "epoch 10: loss=19.18438720703125\n",
      "epoch 11: loss=20.44923210144043\n",
      "epoch 12: loss=21.09842300415039\n",
      "epoch 13: loss=20.395986557006836\n",
      "epoch 14: loss=18.795913696289062\n",
      "epoch 15: loss=18.26711082458496\n",
      "epoch 16: loss=16.61815643310547\n",
      "epoch 17: loss=15.429913520812988\n",
      "epoch 18: loss=14.727202415466309\n",
      "epoch 19: loss=14.532858848571777\n",
      "epoch 20: loss=15.095449447631836\n",
      "epoch 21: loss=14.879424095153809\n",
      "epoch 22: loss=13.700850486755371\n",
      "epoch 23: loss=13.243237495422363\n",
      "epoch 24: loss=13.124752044677734\n",
      "epoch 25: loss=12.796957969665527\n",
      "epoch 26: loss=13.098410606384277\n",
      "epoch 27: loss=12.07833480834961\n",
      "epoch 28: loss=11.767149925231934\n",
      "epoch 29: loss=10.37646770477295\n",
      "epoch 30: loss=10.960577011108398\n",
      "epoch 31: loss=9.393559455871582\n",
      "epoch 32: loss=8.449719429016113\n",
      "epoch 33: loss=7.72707462310791\n",
      "epoch 34: loss=7.139955520629883\n",
      "epoch 35: loss=6.665534496307373\n",
      "epoch 36: loss=6.076080322265625\n",
      "epoch 37: loss=5.991241455078125\n",
      "epoch 38: loss=5.318692684173584\n",
      "epoch 39: loss=4.88795280456543\n",
      "epoch 40: loss=4.61646842956543\n",
      "epoch 41: loss=4.125466346740723\n",
      "epoch 42: loss=4.194107532501221\n",
      "epoch 43: loss=4.044844150543213\n",
      "epoch 44: loss=3.9974236488342285\n",
      "epoch 45: loss=3.991034507751465\n",
      "epoch 46: loss=3.9470937252044678\n",
      "epoch 47: loss=3.852449417114258\n",
      "epoch 48: loss=3.893990993499756\n",
      "epoch 49: loss=3.7390084266662598\n",
      "epoch 50: loss=3.7993602752685547\n",
      "epoch 51: loss=3.777421474456787\n",
      "epoch 52: loss=3.7420003414154053\n",
      "epoch 53: loss=3.785372257232666\n",
      "epoch 54: loss=3.6709346771240234\n",
      "epoch 55: loss=3.5665199756622314\n",
      "epoch 56: loss=3.6205694675445557\n",
      "epoch 57: loss=3.5002005100250244\n",
      "epoch 58: loss=3.613901138305664\n",
      "epoch 59: loss=3.6049041748046875\n",
      "epoch 60: loss=3.5954525470733643\n",
      "epoch 61: loss=3.4318556785583496\n",
      "epoch 62: loss=3.4892783164978027\n",
      "epoch 63: loss=3.4419288635253906\n",
      "epoch 64: loss=3.4513046741485596\n",
      "epoch 65: loss=3.457613468170166\n",
      "epoch 66: loss=3.496807098388672\n",
      "epoch 67: loss=3.6049013137817383\n",
      "epoch 68: loss=3.479434013366699\n",
      "epoch 69: loss=3.398426055908203\n",
      "epoch 70: loss=3.342334747314453\n",
      "epoch 71: loss=3.490269899368286\n",
      "epoch 72: loss=3.4514269828796387\n",
      "epoch 73: loss=3.3354926109313965\n",
      "epoch 74: loss=3.4526591300964355\n",
      "epoch 75: loss=3.5441765785217285\n",
      "epoch 76: loss=3.336294174194336\n",
      "epoch 77: loss=3.4574995040893555\n",
      "epoch 78: loss=3.4920620918273926\n",
      "epoch 79: loss=3.403684616088867\n",
      "epoch 80: loss=3.452342987060547\n",
      "epoch 81: loss=3.4244260787963867\n",
      "epoch 82: loss=3.3487744331359863\n",
      "epoch 83: loss=3.4042739868164062\n",
      "epoch 84: loss=3.41615891456604\n",
      "epoch 85: loss=3.4094018936157227\n",
      "epoch 86: loss=3.443143606185913\n",
      "epoch 87: loss=3.3907227516174316\n",
      "epoch 88: loss=3.349393844604492\n",
      "epoch 89: loss=3.4066104888916016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90: loss=3.423001289367676\n",
      "epoch 91: loss=3.370722770690918\n",
      "epoch 92: loss=3.4289259910583496\n",
      "epoch 93: loss=3.224684000015259\n",
      "epoch 94: loss=3.2749674320220947\n",
      "epoch 95: loss=3.303929090499878\n",
      "epoch 96: loss=3.3459537029266357\n",
      "epoch 97: loss=3.3599295616149902\n",
      "epoch 98: loss=3.243295431137085\n",
      "epoch 99: loss=3.3305792808532715\n",
      "epoch 100: loss=3.282684087753296\n",
      "epoch 101: loss=3.1804914474487305\n",
      "epoch 102: loss=3.2772762775421143\n",
      "epoch 103: loss=3.3129563331604004\n",
      "epoch 104: loss=3.206510543823242\n",
      "epoch 105: loss=3.226616621017456\n",
      "epoch 106: loss=3.1883251667022705\n",
      "epoch 107: loss=3.3388671875\n",
      "epoch 108: loss=3.1482558250427246\n",
      "epoch 109: loss=3.4101359844207764\n",
      "epoch 110: loss=3.4404802322387695\n",
      "epoch 111: loss=3.197388172149658\n",
      "epoch 112: loss=3.3203039169311523\n",
      "epoch 113: loss=3.310802936553955\n",
      "epoch 114: loss=3.07881498336792\n",
      "epoch 115: loss=3.2975611686706543\n",
      "epoch 116: loss=3.2920236587524414\n",
      "epoch 117: loss=3.2091259956359863\n",
      "epoch 118: loss=3.3094229698181152\n",
      "epoch 119: loss=3.358302593231201\n",
      "epoch 120: loss=3.294100761413574\n",
      "epoch 121: loss=3.3051586151123047\n",
      "epoch 122: loss=3.2029685974121094\n",
      "epoch 123: loss=3.2668561935424805\n",
      "epoch 124: loss=3.3216285705566406\n",
      "epoch 125: loss=3.329169273376465\n",
      "epoch 126: loss=3.4211649894714355\n",
      "epoch 127: loss=3.2111310958862305\n",
      "epoch 128: loss=3.160586357116699\n",
      "epoch 129: loss=3.1992318630218506\n",
      "epoch 130: loss=3.282569169998169\n",
      "epoch 131: loss=3.358245372772217\n",
      "epoch 132: loss=3.170727252960205\n",
      "epoch 133: loss=3.303781509399414\n",
      "epoch 134: loss=3.3053925037384033\n",
      "epoch 135: loss=3.217790126800537\n",
      "epoch 136: loss=3.2101263999938965\n",
      "epoch 137: loss=3.3074631690979004\n",
      "epoch 138: loss=3.234316349029541\n",
      "epoch 139: loss=3.102717876434326\n",
      "epoch 140: loss=3.190321445465088\n",
      "epoch 141: loss=3.1655378341674805\n",
      "epoch 142: loss=3.319021224975586\n",
      "epoch 143: loss=3.123021125793457\n",
      "epoch 144: loss=3.2781264781951904\n",
      "epoch 145: loss=3.291675090789795\n",
      "epoch 146: loss=3.225480556488037\n",
      "epoch 147: loss=3.23307204246521\n",
      "epoch 148: loss=3.17716121673584\n",
      "epoch 149: loss=3.3638927936553955\n",
      "epoch 150: loss=3.2215073108673096\n",
      "epoch 151: loss=3.2164950370788574\n",
      "epoch 152: loss=3.1750903129577637\n",
      "epoch 153: loss=3.239436626434326\n",
      "epoch 154: loss=3.2078537940979004\n",
      "epoch 155: loss=3.2461204528808594\n",
      "epoch 156: loss=3.196723461151123\n",
      "epoch 157: loss=3.3128883838653564\n",
      "epoch 158: loss=3.185643196105957\n",
      "epoch 159: loss=3.238990545272827\n",
      "epoch 160: loss=3.28444242477417\n",
      "epoch 161: loss=3.2485408782958984\n",
      "epoch 162: loss=3.288137435913086\n",
      "epoch 163: loss=3.217952251434326\n",
      "epoch 164: loss=3.192922353744507\n",
      "epoch 165: loss=3.21781063079834\n",
      "epoch 166: loss=3.1808130741119385\n",
      "epoch 167: loss=3.276533603668213\n",
      "epoch 168: loss=3.2571756839752197\n",
      "epoch 169: loss=3.242180109024048\n",
      "epoch 170: loss=3.1746654510498047\n",
      "epoch 171: loss=3.3584344387054443\n",
      "epoch 172: loss=3.2449631690979004\n",
      "epoch 173: loss=3.210461378097534\n",
      "epoch 174: loss=3.362154006958008\n",
      "epoch 175: loss=3.2067155838012695\n",
      "epoch 176: loss=3.1881442070007324\n",
      "epoch 177: loss=3.1855673789978027\n",
      "epoch 178: loss=3.2080612182617188\n",
      "epoch 179: loss=3.2662839889526367\n",
      "epoch 180: loss=3.262662887573242\n",
      "epoch 181: loss=3.3014941215515137\n",
      "epoch 182: loss=3.3968818187713623\n",
      "epoch 183: loss=3.166667938232422\n",
      "epoch 184: loss=3.109238624572754\n",
      "epoch 185: loss=3.3209187984466553\n",
      "epoch 186: loss=3.2498509883880615\n",
      "epoch 187: loss=3.1336803436279297\n",
      "epoch 188: loss=3.1102261543273926\n",
      "epoch 189: loss=3.2946090698242188\n",
      "epoch 190: loss=3.308858871459961\n",
      "epoch 191: loss=3.114504337310791\n",
      "epoch 192: loss=3.210585594177246\n",
      "epoch 193: loss=3.246170997619629\n",
      "epoch 194: loss=3.341860294342041\n",
      "epoch 195: loss=3.275346279144287\n",
      "epoch 196: loss=3.244450092315674\n",
      "epoch 197: loss=3.157008171081543\n",
      "epoch 198: loss=3.2217016220092773\n",
      "epoch 199: loss=3.223447799682617\n",
      "training patch with 950 edges\n",
      "epoch 0: loss=17.79456329345703\n",
      "epoch 1: loss=18.2714786529541\n",
      "epoch 2: loss=18.663707733154297\n",
      "epoch 3: loss=18.46405029296875\n",
      "epoch 4: loss=17.363037109375\n",
      "epoch 5: loss=17.512025833129883\n",
      "epoch 6: loss=17.34475326538086\n",
      "epoch 7: loss=18.284442901611328\n",
      "epoch 8: loss=18.021263122558594\n",
      "epoch 9: loss=19.368892669677734\n",
      "epoch 10: loss=19.732540130615234\n",
      "epoch 11: loss=19.438175201416016\n",
      "epoch 12: loss=18.768848419189453\n",
      "epoch 13: loss=17.519670486450195\n",
      "epoch 14: loss=15.918492317199707\n",
      "epoch 15: loss=14.296258926391602\n",
      "epoch 16: loss=14.79024887084961\n",
      "epoch 17: loss=13.667552947998047\n",
      "epoch 18: loss=13.700958251953125\n",
      "epoch 19: loss=13.173272132873535\n",
      "epoch 20: loss=12.796015739440918\n",
      "epoch 21: loss=13.214827537536621\n",
      "epoch 22: loss=11.900065422058105\n",
      "epoch 23: loss=12.391362190246582\n",
      "epoch 24: loss=12.102339744567871\n",
      "epoch 25: loss=11.452201843261719\n",
      "epoch 26: loss=11.71207046508789\n",
      "epoch 27: loss=11.281542778015137\n",
      "epoch 28: loss=9.92264175415039\n",
      "epoch 29: loss=9.54122543334961\n",
      "epoch 30: loss=8.614989280700684\n",
      "epoch 31: loss=7.388380527496338\n",
      "epoch 32: loss=7.238640308380127\n",
      "epoch 33: loss=6.698978900909424\n",
      "epoch 34: loss=5.887234210968018\n",
      "epoch 35: loss=5.439776420593262\n",
      "epoch 36: loss=5.378013610839844\n",
      "epoch 37: loss=5.418758392333984\n",
      "epoch 38: loss=4.807956695556641\n",
      "epoch 39: loss=4.494303226470947\n",
      "epoch 40: loss=4.3193488121032715\n",
      "epoch 41: loss=3.863985538482666\n",
      "epoch 42: loss=3.891160011291504\n",
      "epoch 43: loss=3.827237129211426\n",
      "epoch 44: loss=3.8978381156921387\n",
      "epoch 45: loss=3.6640563011169434\n",
      "epoch 46: loss=3.552063465118408\n",
      "epoch 47: loss=3.395033359527588\n",
      "epoch 48: loss=3.4616265296936035\n",
      "epoch 49: loss=3.5209193229675293\n",
      "epoch 50: loss=3.480620861053467\n",
      "epoch 51: loss=3.511692762374878\n",
      "epoch 52: loss=3.423581600189209\n",
      "epoch 53: loss=3.2882869243621826\n",
      "epoch 54: loss=3.4253087043762207\n",
      "epoch 55: loss=3.383985757827759\n",
      "epoch 56: loss=3.3413009643554688\n",
      "epoch 57: loss=3.259251117706299\n",
      "epoch 58: loss=3.213439464569092\n",
      "epoch 59: loss=3.116147518157959\n",
      "epoch 60: loss=3.3182382583618164\n",
      "epoch 61: loss=3.2338027954101562\n",
      "epoch 62: loss=3.253431558609009\n",
      "epoch 63: loss=3.2393691539764404\n",
      "epoch 64: loss=3.2098395824432373\n",
      "epoch 65: loss=3.1577186584472656\n",
      "epoch 66: loss=3.2587273120880127\n",
      "epoch 67: loss=3.158144474029541\n",
      "epoch 68: loss=3.0936176776885986\n",
      "epoch 69: loss=3.205481767654419\n",
      "epoch 70: loss=3.2028613090515137\n",
      "epoch 71: loss=3.108851432800293\n",
      "epoch 72: loss=3.1885762214660645\n",
      "epoch 73: loss=3.133481502532959\n",
      "epoch 74: loss=3.1759371757507324\n",
      "epoch 75: loss=3.143904685974121\n",
      "epoch 76: loss=3.061957836151123\n",
      "epoch 77: loss=3.1018154621124268\n",
      "epoch 78: loss=3.195591926574707\n",
      "epoch 79: loss=3.0238585472106934\n",
      "epoch 80: loss=3.0491724014282227\n",
      "epoch 81: loss=2.9800076484680176\n",
      "epoch 82: loss=3.0979819297790527\n",
      "epoch 83: loss=3.0768682956695557\n",
      "epoch 84: loss=3.129974365234375\n",
      "epoch 85: loss=3.0541818141937256\n",
      "epoch 86: loss=2.998208522796631\n",
      "epoch 87: loss=3.08444881439209\n",
      "epoch 88: loss=3.133474826812744\n",
      "epoch 89: loss=3.0368919372558594\n",
      "epoch 90: loss=2.9980268478393555\n",
      "epoch 91: loss=3.0263209342956543\n",
      "epoch 92: loss=3.0009310245513916\n",
      "epoch 93: loss=2.970154285430908\n",
      "epoch 94: loss=3.0391454696655273\n",
      "epoch 95: loss=3.0003037452697754\n",
      "epoch 96: loss=2.9855422973632812\n",
      "epoch 97: loss=2.959163188934326\n",
      "epoch 98: loss=3.063877582550049\n",
      "epoch 99: loss=3.0718531608581543\n",
      "epoch 100: loss=2.947463035583496\n",
      "epoch 101: loss=3.0577163696289062\n",
      "epoch 102: loss=3.062652826309204\n",
      "epoch 103: loss=3.0130276679992676\n",
      "epoch 104: loss=2.9985339641571045\n",
      "epoch 105: loss=2.9691953659057617\n",
      "epoch 106: loss=2.9160385131835938\n",
      "epoch 107: loss=3.0190820693969727\n",
      "epoch 108: loss=2.961714267730713\n",
      "epoch 109: loss=2.9566545486450195\n",
      "epoch 110: loss=3.0308890342712402\n",
      "epoch 111: loss=2.8991005420684814\n",
      "epoch 112: loss=3.0743050575256348\n",
      "epoch 113: loss=2.9593825340270996\n",
      "epoch 114: loss=2.9273953437805176\n",
      "epoch 115: loss=3.025454044342041\n",
      "epoch 116: loss=2.9954497814178467\n",
      "epoch 117: loss=2.880777359008789\n",
      "epoch 118: loss=2.8573875427246094\n",
      "epoch 119: loss=3.0410385131835938\n",
      "epoch 120: loss=2.8859267234802246\n",
      "epoch 121: loss=2.9952008724212646\n",
      "epoch 122: loss=2.8953328132629395\n",
      "epoch 123: loss=3.023392915725708\n",
      "epoch 124: loss=3.0119662284851074\n",
      "epoch 125: loss=2.943794012069702\n",
      "epoch 126: loss=2.9271864891052246\n",
      "epoch 127: loss=2.987412452697754\n",
      "epoch 128: loss=2.9864344596862793\n",
      "epoch 129: loss=2.9300284385681152\n",
      "epoch 130: loss=3.029676914215088\n",
      "epoch 131: loss=2.943364143371582\n",
      "epoch 132: loss=2.9222817420959473\n",
      "epoch 133: loss=3.0006680488586426\n",
      "epoch 134: loss=3.004136562347412\n",
      "epoch 135: loss=2.9312782287597656\n",
      "epoch 136: loss=2.8748388290405273\n",
      "epoch 137: loss=2.8411078453063965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138: loss=2.853829860687256\n",
      "epoch 139: loss=2.9208173751831055\n",
      "epoch 140: loss=2.9282889366149902\n",
      "epoch 141: loss=2.9239096641540527\n",
      "epoch 142: loss=2.939840793609619\n",
      "epoch 143: loss=2.9251959323883057\n",
      "epoch 144: loss=2.8857922554016113\n",
      "epoch 145: loss=3.0222883224487305\n",
      "epoch 146: loss=2.8856377601623535\n",
      "epoch 147: loss=2.901432514190674\n",
      "epoch 148: loss=2.863945960998535\n",
      "epoch 149: loss=2.8367409706115723\n",
      "epoch 150: loss=2.906330108642578\n",
      "epoch 151: loss=2.9487242698669434\n",
      "epoch 152: loss=2.8820900917053223\n",
      "epoch 153: loss=2.9038562774658203\n",
      "epoch 154: loss=2.93750262260437\n",
      "epoch 155: loss=3.0790674686431885\n",
      "epoch 156: loss=2.9633736610412598\n",
      "epoch 157: loss=2.8371763229370117\n",
      "epoch 158: loss=2.9343528747558594\n",
      "epoch 159: loss=2.8596527576446533\n",
      "epoch 160: loss=2.9739255905151367\n",
      "epoch 161: loss=2.8778152465820312\n",
      "epoch 162: loss=2.95685076713562\n",
      "epoch 163: loss=2.9131574630737305\n",
      "epoch 164: loss=2.775961399078369\n",
      "epoch 165: loss=2.941378116607666\n",
      "epoch 166: loss=2.912567138671875\n",
      "epoch 167: loss=2.7260749340057373\n",
      "epoch 168: loss=2.8736114501953125\n",
      "epoch 169: loss=3.0108232498168945\n",
      "epoch 170: loss=2.957667827606201\n",
      "epoch 171: loss=2.825179100036621\n",
      "epoch 172: loss=2.8146684169769287\n",
      "epoch 173: loss=2.8981425762176514\n",
      "epoch 174: loss=2.8763771057128906\n",
      "epoch 175: loss=2.959585666656494\n",
      "epoch 176: loss=2.895045280456543\n",
      "epoch 177: loss=2.966071605682373\n",
      "epoch 178: loss=2.905229091644287\n",
      "epoch 179: loss=2.8650898933410645\n",
      "epoch 180: loss=2.9295730590820312\n",
      "epoch 181: loss=2.9112186431884766\n",
      "epoch 182: loss=2.9308836460113525\n",
      "epoch 183: loss=2.8705010414123535\n",
      "epoch 184: loss=2.7946524620056152\n",
      "epoch 185: loss=2.9333651065826416\n",
      "epoch 186: loss=2.8664631843566895\n",
      "epoch 187: loss=2.877232313156128\n",
      "epoch 188: loss=2.9377822875976562\n",
      "epoch 189: loss=2.8378725051879883\n",
      "epoch 190: loss=2.9264578819274902\n",
      "epoch 191: loss=2.8782870769500732\n",
      "epoch 192: loss=2.826939105987549\n",
      "epoch 193: loss=2.800642490386963\n",
      "epoch 194: loss=2.884605884552002\n",
      "epoch 195: loss=2.764592170715332\n",
      "epoch 196: loss=2.9121429920196533\n",
      "epoch 197: loss=2.982938051223755\n",
      "epoch 198: loss=2.8770580291748047\n",
      "epoch 199: loss=2.869027853012085\n",
      "training patch with 2922 edges\n",
      "epoch 0: loss=18.632347106933594\n",
      "epoch 1: loss=18.391571044921875\n",
      "epoch 2: loss=18.397418975830078\n",
      "epoch 3: loss=17.62397003173828\n",
      "epoch 4: loss=17.234708786010742\n",
      "epoch 5: loss=17.033145904541016\n",
      "epoch 6: loss=15.618619918823242\n",
      "epoch 7: loss=15.761210441589355\n",
      "epoch 8: loss=16.590152740478516\n",
      "epoch 9: loss=17.650550842285156\n",
      "epoch 10: loss=17.24168586730957\n",
      "epoch 11: loss=16.518856048583984\n",
      "epoch 12: loss=14.646517753601074\n",
      "epoch 13: loss=13.180275917053223\n",
      "epoch 14: loss=12.092116355895996\n",
      "epoch 15: loss=11.296510696411133\n",
      "epoch 16: loss=10.512187957763672\n",
      "epoch 17: loss=10.008113861083984\n",
      "epoch 18: loss=9.419886589050293\n",
      "epoch 19: loss=8.25493335723877\n",
      "epoch 20: loss=7.746951580047607\n",
      "epoch 21: loss=6.92963171005249\n",
      "epoch 22: loss=5.9696946144104\n",
      "epoch 23: loss=5.061351776123047\n",
      "epoch 24: loss=4.509833812713623\n",
      "epoch 25: loss=3.9140942096710205\n",
      "epoch 26: loss=3.443323850631714\n",
      "epoch 27: loss=3.2461371421813965\n",
      "epoch 28: loss=3.178507089614868\n",
      "epoch 29: loss=2.9668843746185303\n",
      "epoch 30: loss=2.7683162689208984\n",
      "epoch 31: loss=2.529332399368286\n",
      "epoch 32: loss=2.4341840744018555\n",
      "epoch 33: loss=2.434817314147949\n",
      "epoch 34: loss=2.441171884536743\n",
      "epoch 35: loss=2.4144980907440186\n",
      "epoch 36: loss=2.3282456398010254\n",
      "epoch 37: loss=2.3416647911071777\n",
      "epoch 38: loss=2.3502044677734375\n",
      "epoch 39: loss=2.351105213165283\n",
      "epoch 40: loss=2.3509416580200195\n",
      "epoch 41: loss=2.3493895530700684\n",
      "epoch 42: loss=2.327984094619751\n",
      "epoch 43: loss=2.3443820476531982\n",
      "epoch 44: loss=2.3272688388824463\n",
      "epoch 45: loss=2.328530788421631\n",
      "epoch 46: loss=2.297523260116577\n",
      "epoch 47: loss=2.2868452072143555\n",
      "epoch 48: loss=2.2732982635498047\n",
      "epoch 49: loss=2.266730308532715\n",
      "epoch 50: loss=2.243398666381836\n",
      "epoch 51: loss=2.222972869873047\n",
      "epoch 52: loss=2.205420970916748\n",
      "epoch 53: loss=2.198995590209961\n",
      "epoch 54: loss=2.165330410003662\n",
      "epoch 55: loss=2.124281883239746\n",
      "epoch 56: loss=2.117745876312256\n",
      "epoch 57: loss=2.0894124507904053\n",
      "epoch 58: loss=2.076594829559326\n",
      "epoch 59: loss=2.0759031772613525\n",
      "epoch 60: loss=2.0580220222473145\n",
      "epoch 61: loss=2.0391876697540283\n",
      "epoch 62: loss=2.023885726928711\n",
      "epoch 63: loss=1.9862401485443115\n",
      "epoch 64: loss=2.0158445835113525\n",
      "epoch 65: loss=2.000196933746338\n",
      "epoch 66: loss=1.9888100624084473\n",
      "epoch 67: loss=1.947364091873169\n",
      "epoch 68: loss=1.9494794607162476\n",
      "epoch 69: loss=1.9331915378570557\n",
      "epoch 70: loss=1.9402053356170654\n",
      "epoch 71: loss=1.9377557039260864\n",
      "epoch 72: loss=1.9029520750045776\n",
      "epoch 73: loss=1.9164583683013916\n",
      "epoch 74: loss=1.9230711460113525\n",
      "epoch 75: loss=1.889243721961975\n",
      "epoch 76: loss=1.916793704032898\n",
      "epoch 77: loss=1.887937068939209\n",
      "epoch 78: loss=1.8750807046890259\n",
      "epoch 79: loss=1.8839013576507568\n",
      "epoch 80: loss=1.8769603967666626\n",
      "epoch 81: loss=1.8771939277648926\n",
      "epoch 82: loss=1.8554205894470215\n",
      "epoch 83: loss=1.8738751411437988\n",
      "epoch 84: loss=1.8668346405029297\n",
      "epoch 85: loss=1.884002447128296\n",
      "epoch 86: loss=1.9114532470703125\n",
      "epoch 87: loss=1.8386090993881226\n",
      "epoch 88: loss=1.8860890865325928\n",
      "epoch 89: loss=1.8863930702209473\n",
      "epoch 90: loss=1.8694130182266235\n",
      "epoch 91: loss=1.8958971500396729\n",
      "epoch 92: loss=1.8856384754180908\n",
      "epoch 93: loss=1.8993494510650635\n",
      "epoch 94: loss=1.870097279548645\n",
      "epoch 95: loss=1.8487677574157715\n",
      "epoch 96: loss=1.8685762882232666\n",
      "epoch 97: loss=1.807185173034668\n",
      "epoch 98: loss=1.8112883567810059\n",
      "epoch 99: loss=1.8496679067611694\n",
      "epoch 100: loss=1.8440053462982178\n",
      "epoch 101: loss=1.855215311050415\n",
      "epoch 102: loss=1.8102434873580933\n",
      "epoch 103: loss=1.8228129148483276\n",
      "epoch 104: loss=1.839656114578247\n",
      "epoch 105: loss=1.839676022529602\n",
      "epoch 106: loss=1.8474960327148438\n",
      "epoch 107: loss=1.7870452404022217\n",
      "epoch 108: loss=1.8275177478790283\n",
      "epoch 109: loss=1.851643681526184\n",
      "epoch 110: loss=1.8097167015075684\n",
      "epoch 111: loss=1.8157627582550049\n",
      "epoch 112: loss=1.8278026580810547\n",
      "epoch 113: loss=1.8166110515594482\n",
      "epoch 114: loss=1.8127505779266357\n",
      "epoch 115: loss=1.823080062866211\n",
      "epoch 116: loss=1.8215316534042358\n",
      "epoch 117: loss=1.8251292705535889\n",
      "epoch 118: loss=1.813408613204956\n",
      "epoch 119: loss=1.8058860301971436\n",
      "epoch 120: loss=1.8323750495910645\n",
      "epoch 121: loss=1.8280583620071411\n",
      "epoch 122: loss=1.800229787826538\n",
      "epoch 123: loss=1.8135977983474731\n",
      "epoch 124: loss=1.7937049865722656\n",
      "epoch 125: loss=1.7942531108856201\n",
      "epoch 126: loss=1.8074994087219238\n",
      "epoch 127: loss=1.824711561203003\n",
      "epoch 128: loss=1.7935287952423096\n",
      "epoch 129: loss=1.7820184230804443\n",
      "epoch 130: loss=1.8152530193328857\n",
      "epoch 131: loss=1.81022310256958\n",
      "epoch 132: loss=1.8052337169647217\n",
      "epoch 133: loss=1.8274054527282715\n",
      "epoch 134: loss=1.7907629013061523\n",
      "epoch 135: loss=1.8278074264526367\n",
      "epoch 136: loss=1.7997924089431763\n",
      "epoch 137: loss=1.8070605993270874\n",
      "epoch 138: loss=1.7843316793441772\n",
      "epoch 139: loss=1.7966253757476807\n",
      "epoch 140: loss=1.7786164283752441\n",
      "epoch 141: loss=1.794344425201416\n",
      "epoch 142: loss=1.8049588203430176\n",
      "epoch 143: loss=1.7986067533493042\n",
      "epoch 144: loss=1.7654831409454346\n",
      "epoch 145: loss=1.7994847297668457\n",
      "epoch 146: loss=1.8141169548034668\n",
      "epoch 147: loss=1.8242874145507812\n",
      "epoch 148: loss=1.8025776147842407\n",
      "epoch 149: loss=1.8022346496582031\n",
      "epoch 150: loss=1.7996522188186646\n",
      "epoch 151: loss=1.7924878597259521\n",
      "epoch 152: loss=1.803254246711731\n",
      "epoch 153: loss=1.7844295501708984\n",
      "epoch 154: loss=1.7817652225494385\n",
      "epoch 155: loss=1.7947468757629395\n",
      "epoch 156: loss=1.788788080215454\n",
      "epoch 157: loss=1.7865581512451172\n",
      "epoch 158: loss=1.789048194885254\n",
      "epoch 159: loss=1.789940595626831\n",
      "epoch 160: loss=1.8025463819503784\n",
      "epoch 161: loss=1.7831919193267822\n",
      "epoch 162: loss=1.7810676097869873\n",
      "epoch 163: loss=1.8037186861038208\n",
      "epoch 164: loss=1.7732298374176025\n",
      "epoch 165: loss=1.79731285572052\n",
      "epoch 166: loss=1.7926578521728516\n",
      "epoch 167: loss=1.7683247327804565\n",
      "epoch 168: loss=1.748435139656067\n",
      "epoch 169: loss=1.7412657737731934\n",
      "epoch 170: loss=1.7606618404388428\n",
      "epoch 171: loss=1.7668259143829346\n",
      "epoch 172: loss=1.759735107421875\n",
      "epoch 173: loss=1.8084299564361572\n",
      "epoch 174: loss=1.7788784503936768\n",
      "epoch 175: loss=1.7621560096740723\n",
      "epoch 176: loss=1.774631142616272\n",
      "epoch 177: loss=1.7725657224655151\n",
      "epoch 178: loss=1.7623932361602783\n",
      "epoch 179: loss=1.8009090423583984\n",
      "epoch 180: loss=1.794402003288269\n",
      "epoch 181: loss=1.7610584497451782\n",
      "epoch 182: loss=1.7844403982162476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 183: loss=1.8082969188690186\n",
      "epoch 184: loss=1.7589693069458008\n",
      "epoch 185: loss=1.7961807250976562\n",
      "epoch 186: loss=1.7754108905792236\n",
      "epoch 187: loss=1.7830363512039185\n",
      "epoch 188: loss=1.7359517812728882\n",
      "epoch 189: loss=1.806868314743042\n",
      "epoch 190: loss=1.7627655267715454\n",
      "epoch 191: loss=1.7639129161834717\n",
      "epoch 192: loss=1.8230664730072021\n",
      "epoch 193: loss=1.753576397895813\n",
      "epoch 194: loss=1.7659260034561157\n",
      "epoch 195: loss=1.7320150136947632\n",
      "epoch 196: loss=1.7508299350738525\n",
      "epoch 197: loss=1.7753803730010986\n",
      "epoch 198: loss=1.7648860216140747\n",
      "epoch 199: loss=1.7900567054748535\n",
      "training patch with 1698 edges\n",
      "epoch 0: loss=19.381086349487305\n",
      "epoch 1: loss=18.79081916809082\n",
      "epoch 2: loss=19.23398780822754\n",
      "epoch 3: loss=17.77042579650879\n",
      "epoch 4: loss=17.373682022094727\n",
      "epoch 5: loss=17.809036254882812\n",
      "epoch 6: loss=16.738168716430664\n",
      "epoch 7: loss=17.18061637878418\n",
      "epoch 8: loss=16.703222274780273\n",
      "epoch 9: loss=17.226577758789062\n",
      "epoch 10: loss=18.39699935913086\n",
      "epoch 11: loss=19.197134017944336\n",
      "epoch 12: loss=17.62786865234375\n",
      "epoch 13: loss=17.070375442504883\n",
      "epoch 14: loss=15.012657165527344\n",
      "epoch 15: loss=14.226702690124512\n",
      "epoch 16: loss=13.302366256713867\n",
      "epoch 17: loss=11.34039306640625\n",
      "epoch 18: loss=11.605939865112305\n",
      "epoch 19: loss=10.281331062316895\n",
      "epoch 20: loss=9.888068199157715\n",
      "epoch 21: loss=8.968596458435059\n",
      "epoch 22: loss=8.57460880279541\n",
      "epoch 23: loss=7.890564918518066\n",
      "epoch 24: loss=6.99561882019043\n",
      "epoch 25: loss=6.278331756591797\n",
      "epoch 26: loss=4.98091459274292\n",
      "epoch 27: loss=4.475593090057373\n",
      "epoch 28: loss=4.186178207397461\n",
      "epoch 29: loss=3.8159611225128174\n",
      "epoch 30: loss=3.6077983379364014\n",
      "epoch 31: loss=3.462275743484497\n",
      "epoch 32: loss=3.232541084289551\n",
      "epoch 33: loss=2.976881504058838\n",
      "epoch 34: loss=2.876786947250366\n",
      "epoch 35: loss=2.9139842987060547\n",
      "epoch 36: loss=2.9420604705810547\n",
      "epoch 37: loss=2.841494083404541\n",
      "epoch 38: loss=2.836700439453125\n",
      "epoch 39: loss=2.794914722442627\n",
      "epoch 40: loss=2.8002166748046875\n",
      "epoch 41: loss=2.8037400245666504\n",
      "epoch 42: loss=2.785240650177002\n",
      "epoch 43: loss=2.7865047454833984\n",
      "epoch 44: loss=2.7403035163879395\n",
      "epoch 45: loss=2.762697219848633\n",
      "epoch 46: loss=2.737320899963379\n",
      "epoch 47: loss=2.7343451976776123\n",
      "epoch 48: loss=2.6850600242614746\n",
      "epoch 49: loss=2.642035722732544\n",
      "epoch 50: loss=2.6502649784088135\n",
      "epoch 51: loss=2.651588201522827\n",
      "epoch 52: loss=2.5798826217651367\n",
      "epoch 53: loss=2.5547842979431152\n",
      "epoch 54: loss=2.5655810832977295\n",
      "epoch 55: loss=2.5410923957824707\n",
      "epoch 56: loss=2.493586540222168\n",
      "epoch 57: loss=2.4753708839416504\n",
      "epoch 58: loss=2.46531081199646\n",
      "epoch 59: loss=2.4733662605285645\n",
      "epoch 60: loss=2.4513983726501465\n",
      "epoch 61: loss=2.433983087539673\n",
      "epoch 62: loss=2.384871244430542\n",
      "epoch 63: loss=2.3701117038726807\n",
      "epoch 64: loss=2.392514228820801\n",
      "epoch 65: loss=2.3978147506713867\n",
      "epoch 66: loss=2.4233627319335938\n",
      "epoch 67: loss=2.3989806175231934\n",
      "epoch 68: loss=2.3856000900268555\n",
      "epoch 69: loss=2.361173391342163\n",
      "epoch 70: loss=2.3928184509277344\n",
      "epoch 71: loss=2.3564047813415527\n",
      "epoch 72: loss=2.3641695976257324\n",
      "epoch 73: loss=2.367617607116699\n",
      "epoch 74: loss=2.379136323928833\n",
      "epoch 75: loss=2.348217248916626\n",
      "epoch 76: loss=2.380988359451294\n",
      "epoch 77: loss=2.330810070037842\n",
      "epoch 78: loss=2.3581767082214355\n",
      "epoch 79: loss=2.273383140563965\n",
      "epoch 80: loss=2.3322043418884277\n",
      "epoch 81: loss=2.3527963161468506\n",
      "epoch 82: loss=2.356502056121826\n",
      "epoch 83: loss=2.3108253479003906\n",
      "epoch 84: loss=2.370457172393799\n",
      "epoch 85: loss=2.3657913208007812\n",
      "epoch 86: loss=2.3716909885406494\n",
      "epoch 87: loss=2.293637752532959\n",
      "epoch 88: loss=2.33060884475708\n",
      "epoch 89: loss=2.306919813156128\n",
      "epoch 90: loss=2.2707724571228027\n",
      "epoch 91: loss=2.3091020584106445\n",
      "epoch 92: loss=2.311405897140503\n",
      "epoch 93: loss=2.3093154430389404\n",
      "epoch 94: loss=2.2694458961486816\n",
      "epoch 95: loss=2.274639368057251\n",
      "epoch 96: loss=2.273360252380371\n",
      "epoch 97: loss=2.366326332092285\n",
      "epoch 98: loss=2.3503544330596924\n",
      "epoch 99: loss=2.289487838745117\n",
      "epoch 100: loss=2.300266742706299\n",
      "epoch 101: loss=2.326934337615967\n",
      "epoch 102: loss=2.4016451835632324\n",
      "epoch 103: loss=2.33879017829895\n",
      "epoch 104: loss=2.3207693099975586\n",
      "epoch 105: loss=2.3450026512145996\n",
      "epoch 106: loss=2.327030897140503\n",
      "epoch 107: loss=2.3301868438720703\n",
      "epoch 108: loss=2.298957347869873\n",
      "epoch 109: loss=2.2508840560913086\n",
      "epoch 110: loss=2.2946181297302246\n",
      "epoch 111: loss=2.284411907196045\n",
      "epoch 112: loss=2.2472939491271973\n",
      "epoch 113: loss=2.2929611206054688\n",
      "epoch 114: loss=2.3151891231536865\n",
      "epoch 115: loss=2.274195671081543\n",
      "epoch 116: loss=2.3239331245422363\n",
      "epoch 117: loss=2.252209424972534\n",
      "epoch 118: loss=2.298255443572998\n",
      "epoch 119: loss=2.2810771465301514\n",
      "epoch 120: loss=2.2249560356140137\n",
      "epoch 121: loss=2.314340114593506\n",
      "epoch 122: loss=2.2482926845550537\n",
      "epoch 123: loss=2.2627811431884766\n",
      "epoch 124: loss=2.2334113121032715\n",
      "epoch 125: loss=2.3407833576202393\n",
      "epoch 126: loss=2.235436201095581\n",
      "epoch 127: loss=2.2343287467956543\n",
      "epoch 128: loss=2.262878179550171\n",
      "epoch 129: loss=2.2836122512817383\n",
      "epoch 130: loss=2.285928249359131\n",
      "epoch 131: loss=2.26304292678833\n",
      "epoch 132: loss=2.2446508407592773\n",
      "epoch 133: loss=2.344886302947998\n",
      "epoch 134: loss=2.262223720550537\n",
      "epoch 135: loss=2.2922110557556152\n",
      "epoch 136: loss=2.209589719772339\n",
      "epoch 137: loss=2.245008707046509\n",
      "epoch 138: loss=2.290478229522705\n",
      "epoch 139: loss=2.1753909587860107\n",
      "epoch 140: loss=2.2649574279785156\n",
      "epoch 141: loss=2.306203603744507\n",
      "epoch 142: loss=2.2397825717926025\n",
      "epoch 143: loss=2.2624242305755615\n",
      "epoch 144: loss=2.2354846000671387\n",
      "epoch 145: loss=2.235654592514038\n",
      "epoch 146: loss=2.1647000312805176\n",
      "epoch 147: loss=2.260089159011841\n",
      "epoch 148: loss=2.179858684539795\n",
      "epoch 149: loss=2.2145891189575195\n",
      "epoch 150: loss=2.2783918380737305\n",
      "epoch 151: loss=2.286745309829712\n",
      "epoch 152: loss=2.2372469902038574\n",
      "epoch 153: loss=2.249005079269409\n",
      "epoch 154: loss=2.2926859855651855\n",
      "epoch 155: loss=2.219722270965576\n",
      "epoch 156: loss=2.249735116958618\n",
      "epoch 157: loss=2.229325294494629\n",
      "epoch 158: loss=2.2827305793762207\n",
      "epoch 159: loss=2.2775766849517822\n",
      "epoch 160: loss=2.241692543029785\n",
      "epoch 161: loss=2.275651216506958\n",
      "epoch 162: loss=2.2734227180480957\n",
      "epoch 163: loss=2.2370386123657227\n",
      "epoch 164: loss=2.240435838699341\n",
      "epoch 165: loss=2.281479597091675\n",
      "epoch 166: loss=2.22615909576416\n",
      "epoch 167: loss=2.232891798019409\n",
      "epoch 168: loss=2.2474238872528076\n",
      "epoch 169: loss=2.2666690349578857\n",
      "epoch 170: loss=2.262180805206299\n",
      "epoch 171: loss=2.2604503631591797\n",
      "epoch 172: loss=2.2587130069732666\n",
      "epoch 173: loss=2.170814037322998\n",
      "epoch 174: loss=2.2473220825195312\n",
      "epoch 175: loss=2.247462272644043\n",
      "epoch 176: loss=2.2614541053771973\n",
      "epoch 177: loss=2.275635242462158\n",
      "epoch 178: loss=2.2577602863311768\n",
      "epoch 179: loss=2.197023391723633\n",
      "epoch 180: loss=2.2769556045532227\n",
      "epoch 181: loss=2.2580225467681885\n",
      "epoch 182: loss=2.2877602577209473\n",
      "epoch 183: loss=2.2507553100585938\n",
      "epoch 184: loss=2.1858503818511963\n",
      "epoch 185: loss=2.2663722038269043\n",
      "epoch 186: loss=2.240784168243408\n",
      "epoch 187: loss=2.1850881576538086\n",
      "epoch 188: loss=2.27567720413208\n",
      "epoch 189: loss=2.2429583072662354\n",
      "epoch 190: loss=2.1962826251983643\n",
      "epoch 191: loss=2.1760449409484863\n",
      "epoch 192: loss=2.2105116844177246\n",
      "epoch 193: loss=2.230769157409668\n",
      "epoch 194: loss=2.1914331912994385\n",
      "epoch 195: loss=2.242473602294922\n",
      "epoch 196: loss=2.2268319129943848\n",
      "epoch 197: loss=2.2272841930389404\n",
      "epoch 198: loss=2.2128632068634033\n",
      "epoch 199: loss=2.216179847717285\n",
      "training patch with 670 edges\n",
      "epoch 0: loss=18.204774856567383\n",
      "epoch 1: loss=17.81857681274414\n",
      "epoch 2: loss=19.646411895751953\n",
      "epoch 3: loss=18.567502975463867\n",
      "epoch 4: loss=18.399635314941406\n",
      "epoch 5: loss=16.69929313659668\n",
      "epoch 6: loss=16.418472290039062\n",
      "epoch 7: loss=17.79050636291504\n",
      "epoch 8: loss=17.90096092224121\n",
      "epoch 9: loss=18.276695251464844\n",
      "epoch 10: loss=17.48171615600586\n",
      "epoch 11: loss=19.834457397460938\n",
      "epoch 12: loss=20.997203826904297\n",
      "epoch 13: loss=20.483917236328125\n",
      "epoch 14: loss=18.86115264892578\n",
      "epoch 15: loss=20.363882064819336\n",
      "epoch 16: loss=16.265396118164062\n",
      "epoch 17: loss=16.45641326904297\n",
      "epoch 18: loss=16.219057083129883\n",
      "epoch 19: loss=14.405621528625488\n",
      "epoch 20: loss=15.237854957580566\n",
      "epoch 21: loss=13.686091423034668\n",
      "epoch 22: loss=13.385283470153809\n",
      "epoch 23: loss=13.534199714660645\n",
      "epoch 24: loss=12.726993560791016\n",
      "epoch 25: loss=13.122004508972168\n",
      "epoch 26: loss=12.571720123291016\n",
      "epoch 27: loss=12.195680618286133\n",
      "epoch 28: loss=11.877084732055664\n",
      "epoch 29: loss=11.193552017211914\n",
      "epoch 30: loss=11.390487670898438\n",
      "epoch 31: loss=10.653310775756836\n",
      "epoch 32: loss=10.220964431762695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33: loss=9.668612480163574\n",
      "epoch 34: loss=7.799648284912109\n",
      "epoch 35: loss=7.641808986663818\n",
      "epoch 36: loss=6.353418350219727\n",
      "epoch 37: loss=7.050119876861572\n",
      "epoch 38: loss=5.884376525878906\n",
      "epoch 39: loss=5.524484157562256\n",
      "epoch 40: loss=5.432044506072998\n",
      "epoch 41: loss=4.678998947143555\n",
      "epoch 42: loss=4.721468925476074\n",
      "epoch 43: loss=4.2538557052612305\n",
      "epoch 44: loss=4.163800239562988\n",
      "epoch 45: loss=4.472867012023926\n",
      "epoch 46: loss=4.40110445022583\n",
      "epoch 47: loss=4.277752876281738\n",
      "epoch 48: loss=4.180115699768066\n",
      "epoch 49: loss=3.7567386627197266\n",
      "epoch 50: loss=3.9480154514312744\n",
      "epoch 51: loss=3.9770615100860596\n",
      "epoch 52: loss=4.00105619430542\n",
      "epoch 53: loss=3.966123104095459\n",
      "epoch 54: loss=3.831634044647217\n",
      "epoch 55: loss=3.6717681884765625\n",
      "epoch 56: loss=3.8565640449523926\n",
      "epoch 57: loss=3.7806050777435303\n",
      "epoch 58: loss=3.7648026943206787\n",
      "epoch 59: loss=3.6997573375701904\n",
      "epoch 60: loss=3.678256034851074\n",
      "epoch 61: loss=3.604154586791992\n",
      "epoch 62: loss=3.8242573738098145\n",
      "epoch 63: loss=3.615201473236084\n",
      "epoch 64: loss=3.6657447814941406\n",
      "epoch 65: loss=3.7130303382873535\n",
      "epoch 66: loss=3.64036226272583\n",
      "epoch 67: loss=3.7211015224456787\n",
      "epoch 68: loss=3.668888568878174\n",
      "epoch 69: loss=3.6118693351745605\n",
      "epoch 70: loss=3.7254066467285156\n",
      "epoch 71: loss=3.6558728218078613\n",
      "epoch 72: loss=3.4609413146972656\n",
      "epoch 73: loss=3.8374483585357666\n",
      "epoch 74: loss=3.595383405685425\n",
      "epoch 75: loss=3.65195631980896\n",
      "epoch 76: loss=3.5670371055603027\n",
      "epoch 77: loss=3.550602912902832\n",
      "epoch 78: loss=3.4073233604431152\n",
      "epoch 79: loss=3.3259992599487305\n",
      "epoch 80: loss=3.563222885131836\n",
      "epoch 81: loss=3.5146594047546387\n",
      "epoch 82: loss=3.3868730068206787\n",
      "epoch 83: loss=3.410853624343872\n",
      "epoch 84: loss=3.349574565887451\n",
      "epoch 85: loss=3.3194096088409424\n",
      "epoch 86: loss=3.410618305206299\n",
      "epoch 87: loss=3.5279626846313477\n",
      "epoch 88: loss=3.5095102787017822\n",
      "epoch 89: loss=3.3923301696777344\n",
      "epoch 90: loss=3.2508890628814697\n",
      "epoch 91: loss=3.4011096954345703\n",
      "epoch 92: loss=3.3990321159362793\n",
      "epoch 93: loss=3.4913973808288574\n",
      "epoch 94: loss=3.33786940574646\n",
      "epoch 95: loss=3.3774969577789307\n",
      "epoch 96: loss=3.433452606201172\n",
      "epoch 97: loss=3.37432861328125\n",
      "epoch 98: loss=3.4310660362243652\n",
      "epoch 99: loss=3.392953872680664\n",
      "epoch 100: loss=3.458892583847046\n",
      "epoch 101: loss=3.5207579135894775\n",
      "epoch 102: loss=3.400705099105835\n",
      "epoch 103: loss=3.3994362354278564\n",
      "epoch 104: loss=3.426326274871826\n",
      "epoch 105: loss=3.474137306213379\n",
      "epoch 106: loss=3.4563727378845215\n",
      "epoch 107: loss=3.4066083431243896\n",
      "epoch 108: loss=3.3712520599365234\n",
      "epoch 109: loss=3.3591065406799316\n",
      "epoch 110: loss=3.419804573059082\n",
      "epoch 111: loss=3.4046006202697754\n",
      "epoch 112: loss=3.5123002529144287\n",
      "epoch 113: loss=3.3813459873199463\n",
      "epoch 114: loss=3.309486150741577\n",
      "epoch 115: loss=3.620098114013672\n",
      "epoch 116: loss=3.48396635055542\n",
      "epoch 117: loss=3.3852391242980957\n",
      "epoch 118: loss=3.526320457458496\n",
      "epoch 119: loss=3.3157966136932373\n",
      "epoch 120: loss=3.583498001098633\n",
      "epoch 121: loss=3.1588854789733887\n",
      "epoch 122: loss=3.3347864151000977\n",
      "epoch 123: loss=3.4432928562164307\n",
      "epoch 124: loss=3.395636796951294\n",
      "epoch 125: loss=3.54433536529541\n",
      "epoch 126: loss=3.3697028160095215\n",
      "epoch 127: loss=3.329313278198242\n",
      "epoch 128: loss=3.454397439956665\n",
      "epoch 129: loss=3.4159789085388184\n",
      "epoch 130: loss=3.2591500282287598\n",
      "epoch 131: loss=3.479325294494629\n",
      "epoch 132: loss=3.3325796127319336\n",
      "epoch 133: loss=3.4441628456115723\n",
      "epoch 134: loss=3.3659720420837402\n",
      "epoch 135: loss=3.3120322227478027\n",
      "epoch 136: loss=3.451521635055542\n",
      "epoch 137: loss=3.43379545211792\n",
      "epoch 138: loss=3.3318891525268555\n",
      "epoch 139: loss=3.3474655151367188\n",
      "epoch 140: loss=3.39662504196167\n",
      "epoch 141: loss=3.4736533164978027\n",
      "epoch 142: loss=3.455371856689453\n",
      "epoch 143: loss=3.249390125274658\n",
      "epoch 144: loss=3.408278465270996\n",
      "epoch 145: loss=3.392038345336914\n",
      "epoch 146: loss=3.2627382278442383\n",
      "epoch 147: loss=3.353855609893799\n",
      "epoch 148: loss=3.3911633491516113\n",
      "epoch 149: loss=3.3880786895751953\n",
      "epoch 150: loss=3.312105655670166\n",
      "epoch 151: loss=3.1166629791259766\n",
      "epoch 152: loss=3.4484448432922363\n",
      "epoch 153: loss=3.366891860961914\n",
      "epoch 154: loss=3.3994550704956055\n",
      "epoch 155: loss=3.2873754501342773\n",
      "epoch 156: loss=3.315398693084717\n",
      "epoch 157: loss=3.2773027420043945\n",
      "epoch 158: loss=3.3799569606781006\n",
      "epoch 159: loss=3.3648271560668945\n",
      "epoch 160: loss=3.3924713134765625\n",
      "epoch 161: loss=3.190506935119629\n",
      "epoch 162: loss=3.337124824523926\n",
      "epoch 163: loss=3.3466813564300537\n",
      "epoch 164: loss=3.2274436950683594\n",
      "epoch 165: loss=3.23179292678833\n",
      "epoch 166: loss=3.227926254272461\n",
      "epoch 167: loss=3.3831894397735596\n",
      "epoch 168: loss=3.148411512374878\n",
      "epoch 169: loss=3.25300931930542\n",
      "epoch 170: loss=3.2523627281188965\n",
      "epoch 171: loss=3.3471460342407227\n",
      "epoch 172: loss=3.255499839782715\n",
      "epoch 173: loss=3.5541350841522217\n",
      "epoch 174: loss=3.3843584060668945\n",
      "epoch 175: loss=3.4002420902252197\n",
      "epoch 176: loss=3.385354518890381\n",
      "epoch 177: loss=3.509011745452881\n",
      "epoch 178: loss=3.504807949066162\n",
      "epoch 179: loss=3.287665605545044\n",
      "epoch 180: loss=3.419302463531494\n",
      "epoch 181: loss=3.161594867706299\n",
      "epoch 182: loss=3.228362560272217\n",
      "epoch 183: loss=3.3317251205444336\n",
      "epoch 184: loss=3.3756542205810547\n",
      "epoch 185: loss=3.2725815773010254\n",
      "epoch 186: loss=3.4040234088897705\n",
      "epoch 187: loss=3.3720130920410156\n",
      "epoch 188: loss=3.2468161582946777\n",
      "epoch 189: loss=3.3530080318450928\n",
      "epoch 190: loss=3.168823719024658\n",
      "epoch 191: loss=3.32466459274292\n",
      "epoch 192: loss=3.303558826446533\n",
      "epoch 193: loss=3.29952335357666\n",
      "epoch 194: loss=3.328460693359375\n",
      "epoch 195: loss=3.2676501274108887\n",
      "epoch 196: loss=3.1667613983154297\n",
      "epoch 197: loss=3.249749183654785\n",
      "epoch 198: loss=3.2093582153320312\n",
      "epoch 199: loss=3.3944032192230225\n",
      "training patch with 1602 edges\n",
      "epoch 0: loss=18.056108474731445\n",
      "epoch 1: loss=18.33932876586914\n",
      "epoch 2: loss=18.041837692260742\n",
      "epoch 3: loss=16.877323150634766\n",
      "epoch 4: loss=17.171804428100586\n",
      "epoch 5: loss=16.739253997802734\n",
      "epoch 6: loss=16.725114822387695\n",
      "epoch 7: loss=17.29574203491211\n",
      "epoch 8: loss=17.110519409179688\n",
      "epoch 9: loss=17.08572769165039\n",
      "epoch 10: loss=18.496179580688477\n",
      "epoch 11: loss=18.99449348449707\n",
      "epoch 12: loss=18.945608139038086\n",
      "epoch 13: loss=17.430309295654297\n",
      "epoch 14: loss=14.962031364440918\n",
      "epoch 15: loss=14.128886222839355\n",
      "epoch 16: loss=14.220681190490723\n",
      "epoch 17: loss=12.41664981842041\n",
      "epoch 18: loss=12.854937553405762\n",
      "epoch 19: loss=11.805495262145996\n",
      "epoch 20: loss=11.082073211669922\n",
      "epoch 21: loss=10.703705787658691\n",
      "epoch 22: loss=10.24692440032959\n",
      "epoch 23: loss=9.603950500488281\n",
      "epoch 24: loss=8.496338844299316\n",
      "epoch 25: loss=7.833254337310791\n",
      "epoch 26: loss=6.556901454925537\n",
      "epoch 27: loss=5.858848571777344\n",
      "epoch 28: loss=5.287769317626953\n",
      "epoch 29: loss=4.700038909912109\n",
      "epoch 30: loss=4.3248291015625\n",
      "epoch 31: loss=4.161472797393799\n",
      "epoch 32: loss=3.892791748046875\n",
      "epoch 33: loss=3.715399980545044\n",
      "epoch 34: loss=3.233398199081421\n",
      "epoch 35: loss=3.190214157104492\n",
      "epoch 36: loss=2.959454298019409\n",
      "epoch 37: loss=3.055048942565918\n",
      "epoch 38: loss=3.0164573192596436\n",
      "epoch 39: loss=2.928650379180908\n",
      "epoch 40: loss=2.8598623275756836\n",
      "epoch 41: loss=2.8096110820770264\n",
      "epoch 42: loss=2.7995963096618652\n",
      "epoch 43: loss=2.8539865016937256\n",
      "epoch 44: loss=2.799020290374756\n",
      "epoch 45: loss=2.797069549560547\n",
      "epoch 46: loss=2.780494213104248\n",
      "epoch 47: loss=2.753430128097534\n",
      "epoch 48: loss=2.6959195137023926\n",
      "epoch 49: loss=2.716373920440674\n",
      "epoch 50: loss=2.726461410522461\n",
      "epoch 51: loss=2.7037949562072754\n",
      "epoch 52: loss=2.641859531402588\n",
      "epoch 53: loss=2.589081287384033\n",
      "epoch 54: loss=2.5862717628479004\n",
      "epoch 55: loss=2.612189292907715\n",
      "epoch 56: loss=2.4873452186584473\n",
      "epoch 57: loss=2.557756185531616\n",
      "epoch 58: loss=2.4944992065429688\n",
      "epoch 59: loss=2.473574161529541\n",
      "epoch 60: loss=2.4960663318634033\n",
      "epoch 61: loss=2.432727336883545\n",
      "epoch 62: loss=2.4401745796203613\n",
      "epoch 63: loss=2.4578609466552734\n",
      "epoch 64: loss=2.367692470550537\n",
      "epoch 65: loss=2.4198105335235596\n",
      "epoch 66: loss=2.3798561096191406\n",
      "epoch 67: loss=2.3756418228149414\n",
      "epoch 68: loss=2.3734524250030518\n",
      "epoch 69: loss=2.343780517578125\n",
      "epoch 70: loss=2.3200621604919434\n",
      "epoch 71: loss=2.4112844467163086\n",
      "epoch 72: loss=2.3447375297546387\n",
      "epoch 73: loss=2.3528995513916016\n",
      "epoch 74: loss=2.2877442836761475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75: loss=2.3331775665283203\n",
      "epoch 76: loss=2.3064658641815186\n",
      "epoch 77: loss=2.315095901489258\n",
      "epoch 78: loss=2.3769407272338867\n",
      "epoch 79: loss=2.3614306449890137\n",
      "epoch 80: loss=2.315345048904419\n",
      "epoch 81: loss=2.355485200881958\n",
      "epoch 82: loss=2.323739528656006\n",
      "epoch 83: loss=2.3036117553710938\n",
      "epoch 84: loss=2.283280849456787\n",
      "epoch 85: loss=2.3098888397216797\n",
      "epoch 86: loss=2.257136106491089\n",
      "epoch 87: loss=2.2783470153808594\n",
      "epoch 88: loss=2.2953922748565674\n",
      "epoch 89: loss=2.2157249450683594\n",
      "epoch 90: loss=2.261382818222046\n",
      "epoch 91: loss=2.3703763484954834\n",
      "epoch 92: loss=2.2423176765441895\n",
      "epoch 93: loss=2.336437940597534\n",
      "epoch 94: loss=2.2581021785736084\n",
      "epoch 95: loss=2.2550127506256104\n",
      "epoch 96: loss=2.3120832443237305\n",
      "epoch 97: loss=2.259571075439453\n",
      "epoch 98: loss=2.3182826042175293\n",
      "epoch 99: loss=2.3165526390075684\n",
      "epoch 100: loss=2.2974326610565186\n",
      "epoch 101: loss=2.298227310180664\n",
      "epoch 102: loss=2.273319721221924\n",
      "epoch 103: loss=2.261138439178467\n",
      "epoch 104: loss=2.2913055419921875\n",
      "epoch 105: loss=2.252858877182007\n",
      "epoch 106: loss=2.262631416320801\n",
      "epoch 107: loss=2.251417636871338\n",
      "epoch 108: loss=2.256363868713379\n",
      "epoch 109: loss=2.3095645904541016\n",
      "epoch 110: loss=2.3724894523620605\n",
      "epoch 111: loss=2.225407123565674\n",
      "epoch 112: loss=2.2334301471710205\n",
      "epoch 113: loss=2.3028197288513184\n",
      "epoch 114: loss=2.2518672943115234\n",
      "epoch 115: loss=2.2545578479766846\n",
      "epoch 116: loss=2.293675422668457\n",
      "epoch 117: loss=2.254351854324341\n",
      "epoch 118: loss=2.238696813583374\n",
      "epoch 119: loss=2.258779525756836\n",
      "epoch 120: loss=2.261068344116211\n",
      "epoch 121: loss=2.264549493789673\n",
      "epoch 122: loss=2.2386863231658936\n",
      "epoch 123: loss=2.2829508781433105\n",
      "epoch 124: loss=2.2528016567230225\n",
      "epoch 125: loss=2.2448081970214844\n",
      "epoch 126: loss=2.2027018070220947\n",
      "epoch 127: loss=2.2905421257019043\n",
      "epoch 128: loss=2.2827844619750977\n",
      "epoch 129: loss=2.315796136856079\n",
      "epoch 130: loss=2.249814987182617\n",
      "epoch 131: loss=2.2170324325561523\n",
      "epoch 132: loss=2.301298141479492\n",
      "epoch 133: loss=2.285714626312256\n",
      "epoch 134: loss=2.271157741546631\n",
      "epoch 135: loss=2.1986236572265625\n",
      "epoch 136: loss=2.2291533946990967\n",
      "epoch 137: loss=2.2850518226623535\n",
      "epoch 138: loss=2.2392284870147705\n",
      "epoch 139: loss=2.2038660049438477\n",
      "epoch 140: loss=2.2540087699890137\n",
      "epoch 141: loss=2.2915942668914795\n",
      "epoch 142: loss=2.2541873455047607\n",
      "epoch 143: loss=2.2973875999450684\n",
      "epoch 144: loss=2.2386374473571777\n",
      "epoch 145: loss=2.2327117919921875\n",
      "epoch 146: loss=2.227797508239746\n",
      "epoch 147: loss=2.3371236324310303\n",
      "epoch 148: loss=2.2431812286376953\n",
      "epoch 149: loss=2.239086866378784\n",
      "epoch 150: loss=2.269080400466919\n",
      "epoch 151: loss=2.212719440460205\n",
      "epoch 152: loss=2.2482681274414062\n",
      "epoch 153: loss=2.2121124267578125\n",
      "epoch 154: loss=2.1932907104492188\n",
      "epoch 155: loss=2.2271623611450195\n",
      "epoch 156: loss=2.1953797340393066\n",
      "epoch 157: loss=2.235822916030884\n",
      "epoch 158: loss=2.18973708152771\n",
      "epoch 159: loss=2.280837297439575\n",
      "epoch 160: loss=2.269819736480713\n",
      "epoch 161: loss=2.2528815269470215\n",
      "epoch 162: loss=2.270319700241089\n",
      "epoch 163: loss=2.207803249359131\n",
      "epoch 164: loss=2.252023935317993\n",
      "epoch 165: loss=2.1944451332092285\n",
      "epoch 166: loss=2.2202844619750977\n",
      "epoch 167: loss=2.3002750873565674\n",
      "epoch 168: loss=2.3135147094726562\n",
      "epoch 169: loss=2.233807325363159\n",
      "epoch 170: loss=2.281026601791382\n",
      "epoch 171: loss=2.2306582927703857\n",
      "epoch 172: loss=2.2264418601989746\n",
      "epoch 173: loss=2.2539408206939697\n",
      "epoch 174: loss=2.265953779220581\n",
      "epoch 175: loss=2.2282395362854004\n",
      "epoch 176: loss=2.2209179401397705\n",
      "epoch 177: loss=2.272996187210083\n",
      "epoch 178: loss=2.2398149967193604\n",
      "epoch 179: loss=2.3045339584350586\n",
      "epoch 180: loss=2.2523488998413086\n",
      "epoch 181: loss=2.210078716278076\n",
      "epoch 182: loss=2.267268180847168\n",
      "epoch 183: loss=2.184401512145996\n",
      "epoch 184: loss=2.255901336669922\n",
      "epoch 185: loss=2.213395833969116\n",
      "epoch 186: loss=2.2413575649261475\n",
      "epoch 187: loss=2.2340962886810303\n",
      "epoch 188: loss=2.212648868560791\n",
      "epoch 189: loss=2.218992233276367\n",
      "epoch 190: loss=2.2108118534088135\n",
      "epoch 191: loss=2.2015926837921143\n",
      "epoch 192: loss=2.2342889308929443\n",
      "epoch 193: loss=2.2832694053649902\n",
      "epoch 194: loss=2.194723129272461\n",
      "epoch 195: loss=2.2122714519500732\n",
      "epoch 196: loss=2.235194683074951\n",
      "epoch 197: loss=2.225722551345825\n",
      "epoch 198: loss=2.2065229415893555\n",
      "epoch 199: loss=2.1351318359375\n",
      "training patch with 1800 edges\n",
      "epoch 0: loss=18.996074676513672\n",
      "epoch 1: loss=18.034475326538086\n",
      "epoch 2: loss=18.68099021911621\n",
      "epoch 3: loss=17.680816650390625\n",
      "epoch 4: loss=17.136579513549805\n",
      "epoch 5: loss=17.857847213745117\n",
      "epoch 6: loss=17.346097946166992\n",
      "epoch 7: loss=15.82830810546875\n",
      "epoch 8: loss=16.159635543823242\n",
      "epoch 9: loss=17.420164108276367\n",
      "epoch 10: loss=19.047807693481445\n",
      "epoch 11: loss=18.842212677001953\n",
      "epoch 12: loss=17.941041946411133\n",
      "epoch 13: loss=16.376068115234375\n",
      "epoch 14: loss=14.260316848754883\n",
      "epoch 15: loss=13.547220230102539\n",
      "epoch 16: loss=13.159473419189453\n",
      "epoch 17: loss=12.548101425170898\n",
      "epoch 18: loss=12.406498908996582\n",
      "epoch 19: loss=11.384774208068848\n",
      "epoch 20: loss=10.931264877319336\n",
      "epoch 21: loss=10.046625137329102\n",
      "epoch 22: loss=9.417135238647461\n",
      "epoch 23: loss=8.849132537841797\n",
      "epoch 24: loss=7.930145263671875\n",
      "epoch 25: loss=7.079408645629883\n",
      "epoch 26: loss=5.653736591339111\n",
      "epoch 27: loss=4.930980682373047\n",
      "epoch 28: loss=4.396563529968262\n",
      "epoch 29: loss=4.159877777099609\n",
      "epoch 30: loss=3.842716693878174\n",
      "epoch 31: loss=3.604861259460449\n",
      "epoch 32: loss=3.4069461822509766\n",
      "epoch 33: loss=3.2020368576049805\n",
      "epoch 34: loss=3.0171072483062744\n",
      "epoch 35: loss=2.9689853191375732\n",
      "epoch 36: loss=2.987602949142456\n",
      "epoch 37: loss=2.979966640472412\n",
      "epoch 38: loss=2.9200193881988525\n",
      "epoch 39: loss=2.8638365268707275\n",
      "epoch 40: loss=2.846902847290039\n",
      "epoch 41: loss=2.85329270362854\n",
      "epoch 42: loss=2.8448832035064697\n",
      "epoch 43: loss=2.8926761150360107\n",
      "epoch 44: loss=2.850355863571167\n",
      "epoch 45: loss=2.8281660079956055\n",
      "epoch 46: loss=2.7995495796203613\n",
      "epoch 47: loss=2.7754569053649902\n",
      "epoch 48: loss=2.78330659866333\n",
      "epoch 49: loss=2.713602066040039\n",
      "epoch 50: loss=2.729405164718628\n",
      "epoch 51: loss=2.6816914081573486\n",
      "epoch 52: loss=2.6738948822021484\n",
      "epoch 53: loss=2.664792537689209\n",
      "epoch 54: loss=2.659682273864746\n",
      "epoch 55: loss=2.604412078857422\n",
      "epoch 56: loss=2.595579147338867\n",
      "epoch 57: loss=2.579606294631958\n",
      "epoch 58: loss=2.5904269218444824\n",
      "epoch 59: loss=2.5470774173736572\n",
      "epoch 60: loss=2.530527114868164\n",
      "epoch 61: loss=2.4929118156433105\n",
      "epoch 62: loss=2.451592445373535\n",
      "epoch 63: loss=2.4468789100646973\n",
      "epoch 64: loss=2.544389009475708\n",
      "epoch 65: loss=2.5456249713897705\n",
      "epoch 66: loss=2.513091564178467\n",
      "epoch 67: loss=2.4863100051879883\n",
      "epoch 68: loss=2.4865341186523438\n",
      "epoch 69: loss=2.4980149269104004\n",
      "epoch 70: loss=2.4983184337615967\n",
      "epoch 71: loss=2.4979896545410156\n",
      "epoch 72: loss=2.448469638824463\n",
      "epoch 73: loss=2.4531168937683105\n",
      "epoch 74: loss=2.4046435356140137\n",
      "epoch 75: loss=2.401668071746826\n",
      "epoch 76: loss=2.4949889183044434\n",
      "epoch 77: loss=2.4293508529663086\n",
      "epoch 78: loss=2.449338912963867\n",
      "epoch 79: loss=2.422755718231201\n",
      "epoch 80: loss=2.3712611198425293\n",
      "epoch 81: loss=2.4715752601623535\n",
      "epoch 82: loss=2.3799757957458496\n",
      "epoch 83: loss=2.4542911052703857\n",
      "epoch 84: loss=2.4150471687316895\n",
      "epoch 85: loss=2.393869161605835\n",
      "epoch 86: loss=2.3933424949645996\n",
      "epoch 87: loss=2.3680856227874756\n",
      "epoch 88: loss=2.400745391845703\n",
      "epoch 89: loss=2.338024616241455\n",
      "epoch 90: loss=2.3227181434631348\n",
      "epoch 91: loss=2.3770461082458496\n",
      "epoch 92: loss=2.391615390777588\n",
      "epoch 93: loss=2.3767998218536377\n",
      "epoch 94: loss=2.361093044281006\n",
      "epoch 95: loss=2.327371120452881\n",
      "epoch 96: loss=2.3591761589050293\n",
      "epoch 97: loss=2.36305570602417\n",
      "epoch 98: loss=2.347815990447998\n",
      "epoch 99: loss=2.344398021697998\n",
      "epoch 100: loss=2.3219261169433594\n",
      "epoch 101: loss=2.3209352493286133\n",
      "epoch 102: loss=2.3323638439178467\n",
      "epoch 103: loss=2.3247833251953125\n",
      "epoch 104: loss=2.3794260025024414\n",
      "epoch 105: loss=2.324936866760254\n",
      "epoch 106: loss=2.384852409362793\n",
      "epoch 107: loss=2.2464470863342285\n",
      "epoch 108: loss=2.336883306503296\n",
      "epoch 109: loss=2.336383581161499\n",
      "epoch 110: loss=2.322577953338623\n",
      "epoch 111: loss=2.348418951034546\n",
      "epoch 112: loss=2.278416633605957\n",
      "epoch 113: loss=2.299030303955078\n",
      "epoch 114: loss=2.3436546325683594\n",
      "epoch 115: loss=2.302438259124756\n",
      "epoch 116: loss=2.337111234664917\n",
      "epoch 117: loss=2.3003299236297607\n",
      "epoch 118: loss=2.3171181678771973\n",
      "epoch 119: loss=2.3104088306427\n",
      "epoch 120: loss=2.390223503112793\n",
      "epoch 121: loss=2.295745849609375\n",
      "epoch 122: loss=2.315220594406128\n",
      "epoch 123: loss=2.3330397605895996\n",
      "epoch 124: loss=2.3231730461120605\n",
      "epoch 125: loss=2.3257877826690674\n",
      "epoch 126: loss=2.3170533180236816\n",
      "epoch 127: loss=2.347867012023926\n",
      "epoch 128: loss=2.2570924758911133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129: loss=2.250858783721924\n",
      "epoch 130: loss=2.3013367652893066\n",
      "epoch 131: loss=2.244950294494629\n",
      "epoch 132: loss=2.3126144409179688\n",
      "epoch 133: loss=2.2305476665496826\n",
      "epoch 134: loss=2.3142895698547363\n",
      "epoch 135: loss=2.2938597202301025\n",
      "epoch 136: loss=2.3043899536132812\n",
      "epoch 137: loss=2.310391426086426\n",
      "epoch 138: loss=2.3275303840637207\n",
      "epoch 139: loss=2.3022756576538086\n",
      "epoch 140: loss=2.3538548946380615\n",
      "epoch 141: loss=2.283268451690674\n",
      "epoch 142: loss=2.2812743186950684\n",
      "epoch 143: loss=2.2873263359069824\n",
      "epoch 144: loss=2.317641019821167\n",
      "epoch 145: loss=2.299297571182251\n",
      "epoch 146: loss=2.284019708633423\n",
      "epoch 147: loss=2.283968448638916\n",
      "epoch 148: loss=2.305886745452881\n",
      "epoch 149: loss=2.2952210903167725\n",
      "epoch 150: loss=2.2882022857666016\n",
      "epoch 151: loss=2.35299015045166\n",
      "epoch 152: loss=2.2905988693237305\n",
      "epoch 153: loss=2.2949702739715576\n",
      "epoch 154: loss=2.262838840484619\n",
      "epoch 155: loss=2.292938470840454\n",
      "epoch 156: loss=2.2767765522003174\n",
      "epoch 157: loss=2.2473738193511963\n",
      "epoch 158: loss=2.268099308013916\n",
      "epoch 159: loss=2.285705089569092\n",
      "epoch 160: loss=2.3053627014160156\n",
      "epoch 161: loss=2.308879852294922\n",
      "epoch 162: loss=2.3240373134613037\n",
      "epoch 163: loss=2.2529428005218506\n",
      "epoch 164: loss=2.251420021057129\n",
      "epoch 165: loss=2.340256690979004\n",
      "epoch 166: loss=2.220188617706299\n",
      "epoch 167: loss=2.307779550552368\n",
      "epoch 168: loss=2.2390999794006348\n",
      "epoch 169: loss=2.2771263122558594\n",
      "epoch 170: loss=2.2561821937561035\n",
      "epoch 171: loss=2.323439359664917\n",
      "epoch 172: loss=2.292853832244873\n",
      "epoch 173: loss=2.3026299476623535\n",
      "epoch 174: loss=2.3152823448181152\n",
      "epoch 175: loss=2.282510995864868\n",
      "epoch 176: loss=2.242434024810791\n",
      "epoch 177: loss=2.237701654434204\n",
      "epoch 178: loss=2.2508721351623535\n",
      "epoch 179: loss=2.2680578231811523\n",
      "epoch 180: loss=2.305581569671631\n",
      "epoch 181: loss=2.225032329559326\n",
      "epoch 182: loss=2.2328591346740723\n",
      "epoch 183: loss=2.287601947784424\n",
      "epoch 184: loss=2.267612934112549\n",
      "epoch 185: loss=2.2328381538391113\n",
      "epoch 186: loss=2.270442247390747\n",
      "epoch 187: loss=2.2394371032714844\n",
      "epoch 188: loss=2.294381618499756\n",
      "epoch 189: loss=2.2410049438476562\n",
      "epoch 190: loss=2.251347541809082\n",
      "epoch 191: loss=2.274583339691162\n",
      "epoch 192: loss=2.2181334495544434\n",
      "epoch 193: loss=2.253268003463745\n",
      "epoch 194: loss=2.268251419067383\n",
      "epoch 195: loss=2.238642692565918\n",
      "epoch 196: loss=2.3108153343200684\n",
      "epoch 197: loss=2.239485740661621\n",
      "epoch 198: loss=2.251721143722534\n",
      "epoch 199: loss=2.2447702884674072\n",
      "training patch with 1844 edges\n",
      "epoch 0: loss=18.4800968170166\n",
      "epoch 1: loss=18.233919143676758\n",
      "epoch 2: loss=18.38849449157715\n",
      "epoch 3: loss=17.480024337768555\n",
      "epoch 4: loss=17.116615295410156\n",
      "epoch 5: loss=17.286983489990234\n",
      "epoch 6: loss=16.966156005859375\n",
      "epoch 7: loss=16.70167350769043\n",
      "epoch 8: loss=16.2833251953125\n",
      "epoch 9: loss=18.111478805541992\n",
      "epoch 10: loss=19.056705474853516\n",
      "epoch 11: loss=17.98093605041504\n",
      "epoch 12: loss=16.422988891601562\n",
      "epoch 13: loss=14.83899211883545\n",
      "epoch 14: loss=13.62119197845459\n",
      "epoch 15: loss=12.579297065734863\n",
      "epoch 16: loss=12.288691520690918\n",
      "epoch 17: loss=12.209977149963379\n",
      "epoch 18: loss=11.355093002319336\n",
      "epoch 19: loss=10.976317405700684\n",
      "epoch 20: loss=10.351935386657715\n",
      "epoch 21: loss=9.833883285522461\n",
      "epoch 22: loss=9.255687713623047\n",
      "epoch 23: loss=8.769292831420898\n",
      "epoch 24: loss=8.114185333251953\n",
      "epoch 25: loss=6.790657997131348\n",
      "epoch 26: loss=6.348158359527588\n",
      "epoch 27: loss=5.313305377960205\n",
      "epoch 28: loss=4.589781761169434\n",
      "epoch 29: loss=4.391389846801758\n",
      "epoch 30: loss=3.93216872215271\n",
      "epoch 31: loss=3.7357921600341797\n",
      "epoch 32: loss=3.712754726409912\n",
      "epoch 33: loss=3.3921051025390625\n",
      "epoch 34: loss=3.1056830883026123\n",
      "epoch 35: loss=2.9821128845214844\n",
      "epoch 36: loss=2.9291439056396484\n",
      "epoch 37: loss=2.8760080337524414\n",
      "epoch 38: loss=2.8412904739379883\n",
      "epoch 39: loss=2.7850029468536377\n",
      "epoch 40: loss=2.7534730434417725\n",
      "epoch 41: loss=2.716215133666992\n",
      "epoch 42: loss=2.713160276412964\n",
      "epoch 43: loss=2.713906764984131\n",
      "epoch 44: loss=2.730397939682007\n",
      "epoch 45: loss=2.6699342727661133\n",
      "epoch 46: loss=2.658386707305908\n",
      "epoch 47: loss=2.7012696266174316\n",
      "epoch 48: loss=2.6967854499816895\n",
      "epoch 49: loss=2.6571245193481445\n",
      "epoch 50: loss=2.5986180305480957\n",
      "epoch 51: loss=2.5952019691467285\n",
      "epoch 52: loss=2.587071657180786\n",
      "epoch 53: loss=2.546048641204834\n",
      "epoch 54: loss=2.542665958404541\n",
      "epoch 55: loss=2.5733561515808105\n",
      "epoch 56: loss=2.5090603828430176\n",
      "epoch 57: loss=2.487269163131714\n",
      "epoch 58: loss=2.450810432434082\n",
      "epoch 59: loss=2.4370431900024414\n",
      "epoch 60: loss=2.40765380859375\n",
      "epoch 61: loss=2.4062023162841797\n",
      "epoch 62: loss=2.3863396644592285\n",
      "epoch 63: loss=2.3508262634277344\n",
      "epoch 64: loss=2.344902515411377\n",
      "epoch 65: loss=2.342827320098877\n",
      "epoch 66: loss=2.3272576332092285\n",
      "epoch 67: loss=2.363785743713379\n",
      "epoch 68: loss=2.2788190841674805\n",
      "epoch 69: loss=2.3796093463897705\n",
      "epoch 70: loss=2.272514820098877\n",
      "epoch 71: loss=2.279811382293701\n",
      "epoch 72: loss=2.303746223449707\n",
      "epoch 73: loss=2.260964870452881\n",
      "epoch 74: loss=2.2615554332733154\n",
      "epoch 75: loss=2.3224782943725586\n",
      "epoch 76: loss=2.2224113941192627\n",
      "epoch 77: loss=2.280914306640625\n",
      "epoch 78: loss=2.253084182739258\n",
      "epoch 79: loss=2.2822587490081787\n",
      "epoch 80: loss=2.20731782913208\n",
      "epoch 81: loss=2.2938060760498047\n",
      "epoch 82: loss=2.276909351348877\n",
      "epoch 83: loss=2.2728493213653564\n",
      "epoch 84: loss=2.2914116382598877\n",
      "epoch 85: loss=2.234093189239502\n",
      "epoch 86: loss=2.2404425144195557\n",
      "epoch 87: loss=2.1927719116210938\n",
      "epoch 88: loss=2.194169044494629\n",
      "epoch 89: loss=2.313070297241211\n",
      "epoch 90: loss=2.2165377140045166\n",
      "epoch 91: loss=2.2326104640960693\n",
      "epoch 92: loss=2.2181386947631836\n",
      "epoch 93: loss=2.2485170364379883\n",
      "epoch 94: loss=2.223510503768921\n",
      "epoch 95: loss=2.2635245323181152\n",
      "epoch 96: loss=2.207648754119873\n",
      "epoch 97: loss=2.188817262649536\n",
      "epoch 98: loss=2.231253147125244\n",
      "epoch 99: loss=2.22397518157959\n",
      "epoch 100: loss=2.1957783699035645\n",
      "epoch 101: loss=2.197326898574829\n",
      "epoch 102: loss=2.179786205291748\n",
      "epoch 103: loss=2.217395782470703\n",
      "epoch 104: loss=2.225020170211792\n",
      "epoch 105: loss=2.191744327545166\n",
      "epoch 106: loss=2.142430305480957\n",
      "epoch 107: loss=2.1979684829711914\n",
      "epoch 108: loss=2.228036642074585\n",
      "epoch 109: loss=2.192838191986084\n",
      "epoch 110: loss=2.1895532608032227\n",
      "epoch 111: loss=2.168640613555908\n",
      "epoch 112: loss=2.2049129009246826\n",
      "epoch 113: loss=2.199622869491577\n",
      "epoch 114: loss=2.229660987854004\n",
      "epoch 115: loss=2.187879800796509\n",
      "epoch 116: loss=2.1705846786499023\n",
      "epoch 117: loss=2.2016329765319824\n",
      "epoch 118: loss=2.170501232147217\n",
      "epoch 119: loss=2.1937193870544434\n",
      "epoch 120: loss=2.196091413497925\n",
      "epoch 121: loss=2.1589677333831787\n",
      "epoch 122: loss=2.1891303062438965\n",
      "epoch 123: loss=2.205374002456665\n",
      "epoch 124: loss=2.1684162616729736\n",
      "epoch 125: loss=2.195603847503662\n",
      "epoch 126: loss=2.1884331703186035\n",
      "epoch 127: loss=2.2142174243927\n",
      "epoch 128: loss=2.147026300430298\n",
      "epoch 129: loss=2.152268171310425\n",
      "epoch 130: loss=2.2083184719085693\n",
      "epoch 131: loss=2.2773361206054688\n",
      "epoch 132: loss=2.211240530014038\n",
      "epoch 133: loss=2.2348427772521973\n",
      "epoch 134: loss=2.1781022548675537\n",
      "epoch 135: loss=2.1665492057800293\n",
      "epoch 136: loss=2.1459457874298096\n",
      "epoch 137: loss=2.130842685699463\n",
      "epoch 138: loss=2.1768863201141357\n",
      "epoch 139: loss=2.2118024826049805\n",
      "epoch 140: loss=2.1879429817199707\n",
      "epoch 141: loss=2.1891977787017822\n",
      "epoch 142: loss=2.212907314300537\n",
      "epoch 143: loss=2.1714396476745605\n",
      "epoch 144: loss=2.192169189453125\n",
      "epoch 145: loss=2.178072929382324\n",
      "epoch 146: loss=2.1822152137756348\n",
      "epoch 147: loss=2.2185754776000977\n",
      "epoch 148: loss=2.1855194568634033\n",
      "epoch 149: loss=2.169602870941162\n",
      "epoch 150: loss=2.136479616165161\n",
      "epoch 151: loss=2.192124843597412\n",
      "epoch 152: loss=2.181973934173584\n",
      "epoch 153: loss=2.2153844833374023\n",
      "epoch 154: loss=2.187520742416382\n",
      "epoch 155: loss=2.1670289039611816\n",
      "epoch 156: loss=2.1800649166107178\n",
      "epoch 157: loss=2.185730457305908\n",
      "epoch 158: loss=2.2074215412139893\n",
      "epoch 159: loss=2.1431221961975098\n",
      "epoch 160: loss=2.1744544506073\n",
      "epoch 161: loss=2.181555986404419\n",
      "epoch 162: loss=2.1879868507385254\n",
      "epoch 163: loss=2.1424098014831543\n",
      "epoch 164: loss=2.179469347000122\n",
      "epoch 165: loss=2.141324281692505\n",
      "epoch 166: loss=2.158404588699341\n",
      "epoch 167: loss=2.1728334426879883\n",
      "epoch 168: loss=2.175816297531128\n",
      "epoch 169: loss=2.159208297729492\n",
      "epoch 170: loss=2.1513566970825195\n",
      "epoch 171: loss=2.11206316947937\n",
      "epoch 172: loss=2.196148157119751\n",
      "epoch 173: loss=2.1764864921569824\n",
      "epoch 174: loss=2.1845762729644775\n",
      "epoch 175: loss=2.1154470443725586\n",
      "epoch 176: loss=2.176072835922241\n",
      "epoch 177: loss=2.147081136703491\n",
      "epoch 178: loss=2.1535239219665527\n",
      "epoch 179: loss=2.178896188735962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180: loss=2.1791248321533203\n",
      "epoch 181: loss=2.1731646060943604\n",
      "epoch 182: loss=2.171376943588257\n",
      "epoch 183: loss=2.1546339988708496\n",
      "epoch 184: loss=2.1231040954589844\n",
      "epoch 185: loss=2.1482315063476562\n",
      "epoch 186: loss=2.126830577850342\n",
      "epoch 187: loss=2.1341495513916016\n",
      "epoch 188: loss=2.154006004333496\n",
      "epoch 189: loss=2.1414742469787598\n",
      "epoch 190: loss=2.2129225730895996\n",
      "epoch 191: loss=2.154148817062378\n",
      "epoch 192: loss=2.149198293685913\n",
      "epoch 193: loss=2.1688127517700195\n",
      "epoch 194: loss=2.1432526111602783\n",
      "epoch 195: loss=2.1438260078430176\n",
      "epoch 196: loss=2.1242499351501465\n",
      "epoch 197: loss=2.184424877166748\n",
      "epoch 198: loss=2.156926393508911\n",
      "epoch 199: loss=2.112828254699707\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b8378166e24542a2061e97e0a58183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 9078.76953125\n",
      "Epoch 10, Loss: 7022.91845703125\n",
      "Epoch 20, Loss: 3576.93798828125\n",
      "Epoch 30, Loss: 3134.7578125\n",
      "Epoch 40, Loss: 2276.9990234375\n",
      "Epoch 50, Loss: 2035.444580078125\n",
      "Epoch 60, Loss: 1961.49462890625\n",
      "Epoch 70, Loss: 1465.7142333984375\n",
      "Epoch 80, Loss: 1493.6478271484375\n",
      "Epoch 90, Loss: 1671.6614990234375\n",
      "Epoch 100, Loss: 1810.0211181640625\n",
      "Epoch 110, Loss: 1576.5264892578125\n",
      "Epoch 120, Loss: 1674.5074462890625\n",
      "Epoch 130, Loss: 1648.909912109375\n",
      "Epoch 140, Loss: 1696.9154052734375\n",
      "Epoch 150, Loss: 1865.468994140625\n",
      "Epoch 160, Loss: 1811.6505126953125\n",
      "Epoch 170, Loss: 1654.883056640625\n",
      "Epoch 180, Loss: 1635.91357421875\n",
      "Epoch 190, Loss: 1760.725830078125\n"
     ]
    }
   ],
   "source": [
    "dimensions=[16, 32, 64, 128, 256, 512]\n",
    "AUC=[]\n",
    "AP=[]\n",
    "Loss=[]\n",
    "PATCHES=[]\n",
    "new_emb=[]\n",
    "for dim in dimensions:\n",
    "    patches_ip, models_ip =VGAE_patch_embeddings(clustered_data, dim=dim, num_epochs=200, device=device)\n",
    "    PATCHES.append(patches_ip)\n",
    "    emb_patches = preprocess_graphs(patches_ip, nodes)\n",
    "    res, loss_hist= train_model(emb_patches, dim, n_patches , num_epochs=200, learning_rate=0.05)\n",
    "    emb=get_embedding(patches_ip, res)\n",
    "    new_emb.append(emb)\n",
    "    auc, ap = full_model_ip.test(torch.tensor(emb), test_data.edge_index, neg_edges)\n",
    "    AUC.append(auc)\n",
    "    AP.append(ap)\n",
    "    Loss.append(loss_hist)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-contemporary",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "described-powder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd556d57cd0>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(AUC)), AUC, linestyle='-', marker='o', color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "495e7cf6-b911-497d-983a-f317c3150c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd556c42560>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(AUC)), AP, linestyle='-', marker='o', color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0a5ede15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdjElEQVR4nO3dfZRcdZ3n8fenqjrdkHRIYpoYkmhAgxh3MWAL+IA6oOFBhjCzyuDxDNFhNs4Os6u7zpnFcc8y68M54+yOOqwrHhyYCQ6K+IBkHXYwouO6ozw0EB4jpkEgCSHp0HkghE764bt/3F91V3W6091Jd1Xn1ud1Tp269bu/e+t3b3d/7q9/99YtRQRmZtYYCvVugJmZ1Y5D38ysgTj0zcwaiEPfzKyBOPTNzBpIqd4NOJz58+fH0qVL690MM7NjygMPPLAzItpGmjetQ3/p0qV0dHTUuxlmZscUSc+ONs/DO2ZmDcShb2bWQBz6ZmYNxKFvZtZAHPpmZg3EoW9m1kAc+mZmDSSXob9tzyt88UdP8nTXvno3xcxsWhkz9CW9QdKGisdeSZ+QNE/Sekmb0vPcVF+SrpPUKekRSWdWrGt1qr9J0uqp2qiulw5w3U86+c3Ol6fqLczMjkljhn5EPBkRKyJiBfAWYD9wO3ANcHdELAPuTq8BLgKWpcca4HoASfOAa4GzgbOAa8sHislWLAiA3n5/QYyZWaWJDu+cDzwVEc8Cq4C1qXwtcFmaXgXcHJl7gDmSFgIXAOsjojsidgHrgQuPdgNG0lTMNqtvYGAqVm9mdsyaaOhfAXwrTS+IiG1p+gVgQZpeBGyuWGZLKhutvIqkNZI6JHV0dXVNsHmZUurp9w+4p29mVmncoS9pBnAp8J3h8yL7ot1JSdiIuCEi2iOiva1txJvEjalUyDbLwztmZtUm0tO/CHgwIran19vTsA3peUcq3wosqVhucSobrXzSlYpZT7+v38M7ZmaVJhL6H2JoaAdgHVC+Amc1cEdF+ZXpKp5zgD1pGOguYKWkuekE7spUNunKwzt9Ht4xM6syrvvpS5oJvA/4WEXxXwK3SboKeBa4PJXfCVwMdJJd6fNRgIjolvRZ4P5U7zMR0X3UWzCCUvlErnv6ZmZVxhX6EfEy8KphZS+SXc0zvG4AV4+ynpuAmybezIkZHN5xT9/MrEouP5Hr4R0zs5HlNPQ9vGNmNpKchr57+mZmI8ll6BcKoiDo83X6ZmZVchn6kF3B456+mVm1/IZ+QR7TNzMbJt+h756+mVmV/IZ+seC7bJqZDZPf0C/IJ3LNzIbJbeg3+USumdkhchv6RZ/INTM7RG5Dv1QUve7pm5lVyW/oF0S/x/TNzKrkOPR99Y6Z2XC5Df2moq/TNzMbLrehX/Qlm2Zmh8ht6JeKBXp99Y6ZWZXchn5TUfR7eMfMrEpuQ79YKPiSTTOzYXIb+k0F0e+rd8zMquQ29H0i18zsULkN/SafyDUzO0RuQ7/kE7lmZofIbegXC6LXwztmZlVyG/pNvg2DmdkhxhX6kuZI+q6kX0naKOltkuZJWi9pU3qem+pK0nWSOiU9IunMivWsTvU3SVo9VRsFUPTwjpnZIcbb0/8b4J8i4jTgzcBG4Brg7ohYBtydXgNcBCxLjzXA9QCS5gHXAmcDZwHXlg8UU6HJwztmZocYM/QlnQC8C7gRICIORsRuYBWwNlVbC1yWplcBN0fmHmCOpIXABcD6iOiOiF3AeuDCSdyWKqViwT19M7NhxtPTPxnoAv5O0kOS/lbSTGBBRGxLdV4AFqTpRcDmiuW3pLLRyqtIWiOpQ1JHV1fXxLamQqkgX7JpZjbMeEK/BJwJXB8RZwAvMzSUA0BEBDAp3eqIuCEi2iOiva2t7YjXU/Ktlc3MDjGe0N8CbImIe9Pr75IdBLanYRvS8440fyuwpGL5xalstPIpUSxkwzvZ8cjMzGAcoR8RLwCbJb0hFZ0PPAGsA8pX4KwG7kjT64Ar01U85wB70jDQXcBKSXPTCdyVqWxKNBUE4N6+mVmF0jjr/XvgFkkzgKeBj5IdMG6TdBXwLHB5qnsncDHQCexPdYmIbkmfBe5P9T4TEd2TshUjKBWz41n/QNBUnKp3MTM7towr9CNiA9A+wqzzR6gbwNWjrOcm4KYJtO+IlVJPv7d/gBanvpkZkONP5JaKaXjH1+qbmQ3Kb+h7TN/M7BD5Df00pu/775iZDclv6Bc8vGNmNlx+Q7/o4R0zs+HyG/qFNLzjWzGYmQ3Kcei7p29mNlx+Q798Itdj+mZmg3Ic+uWevod3zMzK8hv6Ht4xMztEjkM/2zTfU9/MbEh+Qz8N7/jbs8zMhuQ39P3hLDOzQ+Q29JsGb8Pg0DczK8tt6BcHe/oe0zczK8tt6DelMf1e9/TNzAblNvTLV+/0+zp9M7NBuQ394uA3Z7mnb2ZWltvQb/JtGMzMDpHb0C/39D28Y2Y2JLehP3gi1z19M7NBuQ398l02/YlcM7Mh+Q398olcD++YmQ3Kfej7RK6Z2ZBxhb6kZyQ9KmmDpI5UNk/Sekmb0vPcVC5J10nqlPSIpDMr1rM61d8kafXUbFKm6Fsrm5kdYiI9/d+KiBUR0Z5eXwPcHRHLgLvTa4CLgGXpsQa4HrKDBHAtcDZwFnBt+UAxFSRRKsi3YTAzq3A0wzurgLVpei1wWUX5zZG5B5gjaSFwAbA+IrojYhewHrjwKN5/TKWifCLXzKzCeEM/gB9JekDSmlS2ICK2pekXgAVpehGwuWLZLalstPIqktZI6pDU0dXVNc7mjaxUKPiSTTOzCqVx1ntnRGyVdCKwXtKvKmdGREialHSNiBuAGwDa29uPap2lovwduWZmFcbV04+Irel5B3A72Zj89jRsQ3rekapvBZZULL44lY1WPmVKBflErplZhTFDX9JMSa3laWAl8BiwDihfgbMauCNNrwOuTFfxnAPsScNAdwErJc1NJ3BXprIpUyoUfCLXzKzCeIZ3FgC3SyrX/2ZE/JOk+4HbJF0FPAtcnurfCVwMdAL7gY8CRES3pM8C96d6n4mI7knbkhFkwzvu6ZuZlY0Z+hHxNPDmEcpfBM4foTyAq0dZ103ATRNv5pHJLtl06JuZleX2E7mQ3X/HJ3LNzIbkO/Td0zczq5Lv0PeYvplZlXyHfqHg0Dczq5Dz0Pe9d8zMKuU79Ise0zczq5Tv0C/46h0zs0r5Dn2fyDUzq5Lv0C8UPLxjZlYh16HfVBQHfSLXzGxQrkO/panIwT6HvplZWa5Dv7lUoKe3v97NMDObNnIf+gfc0zczG5Tr0G9pKnKgzz19M7OyXId+NrwzQHa3ZzMzy3foNxUBfAWPmVmS79AvZZvX0+vQNzODvId+6ul7XN/MLJPr0G9JPf0D7umbmQE5D3339M3MquU79D2mb2ZWJdeh3+KevplZlVyHfrPH9M3MqjRG6PtWDGZmQM5Dvzy845uumZllxh36koqSHpL0w/T6ZEn3SuqU9G1JM1J5c3rdmeYvrVjHp1L5k5IumPStGcY9fTOzahPp6X8c2Fjx+gvAlyLi9cAu4KpUfhWwK5V/KdVD0nLgCuBNwIXAVyUVj675h+cTuWZm1cYV+pIWA+8H/ja9FnAe8N1UZS1wWZpelV6T5p+f6q8Cbo2IAxHxG6ATOGsStmFUvmTTzKzaeHv6Xwb+DCin56uA3RHRl15vARal6UXAZoA0f0+qP1g+wjKDJK2R1CGpo6ura/xbMgJ/OMvMrNqYoS/pEmBHRDxQg/YQETdERHtEtLe1tR3Vulrc0zczq1IaR513AJdKuhhoAWYDfwPMkVRKvfnFwNZUfyuwBNgiqQScALxYUV5WucyUKBULFAtyT9/MLBmzpx8Rn4qIxRGxlOxE7E8i4sPAT4EPpGqrgTvS9Lr0mjT/J5F9i8k64Ip0dc/JwDLgvknbklE0lwr+cJaZWTKenv5o/jNwq6TPAQ8BN6byG4FvSOoEuskOFETE45JuA54A+oCrI2LKu+AtTUV63NM3MwMmGPoR8c/AP6fppxnh6puI6AE+OMrynwc+P9FGHg339M3MhuT6E7mQQt8fzjIzAxog9Fuair4Ng5lZkvvQd0/fzGxI/kPfPX0zs0H5D3339M3MBjVA6Bcd+mZmSe5Dv6WpwAEP75iZAQ0Q+u7pm5kNyX/oNxV87x0zsyT3od9SKvoum2ZmSe5D3z19M7MhuQ/9llKR3v6gfyDq3RQzs7rLfeg3N5W/HN29fTOz/Id++vYs32nTzKwBQr8lfU+u76lvZtYAoe+evpnZkAYI/ayn7w9omZk1QOi3pBO5vtOmmVkDhL57+mZmQ/If+u7pm5kNyn3ot7inb2Y2KPeh756+mdmQ3If+Ccc1AbDnld46t8TMrP5yH/rzZs5Agh0vHah3U8zM6m7M0JfUIuk+SQ9LelzSf0vlJ0u6V1KnpG9LmpHKm9PrzjR/acW6PpXKn5R0wZRtVYWmYoF5x8+gy6FvZjaunv4B4LyIeDOwArhQ0jnAF4AvRcTrgV3AVan+VcCuVP6lVA9Jy4ErgDcBFwJflVScxG0ZVVtrs0PfzIxxhH5k9qWXTekRwHnAd1P5WuCyNL0qvSbNP1+SUvmtEXEgIn4DdAJnTcZGjKWttZmufQ59M7NxjelLKkraAOwA1gNPAbsjoi9V2QIsStOLgM0Aaf4e4FWV5SMsU/leayR1SOro6uqa8AaNpK21ma69PZOyLjOzY9m4Qj8i+iNiBbCYrHd+2lQ1KCJuiIj2iGhva2ublHWe2NpC174DRPiLVMyssU3o6p2I2A38FHgbMEdSKc1aDGxN01uBJQBp/gnAi5XlIywzpdpam+ntD1+2aWYNbzxX77RJmpOmjwPeB2wkC/8PpGqrgTvS9Lr0mjT/J5F1sdcBV6Sre04GlgH3TdJ2HFZbazOAT+aaWcMrjV2FhcDadKVNAbgtIn4o6QngVkmfAx4Cbkz1bwS+IakT6Ca7YoeIeFzSbcATQB9wdUTU5GOyJ1aE/rIFrbV4SzOzaWnM0I+IR4AzRih/mhGuvomIHuCDo6zr88DnJ97Mo1Pu6fsDWmbW6HL/iVzw8I6ZWVlDhH5rc4nmUsHX6ptZw2uI0JfEibP9qVwzs4YIfYC2Wc3seMkf0DKzxtY4od/azPa97umbWWNrmNB/85I5dO7YxwPP7qp3U8zM6qZhQv8jb1/Kia3NfO4fn/DtGMysYTVM6B8/o8QnV57KQ8/t5is/6XTwm1lDapjQB/jAW5bw/tMX8tfrf82ffueRejfHzKzmGir0iwXxlQ+dwcfefQrfe3ALv3hqZ72bZGZWUw0V+pBds/8f33sqC2Y38+X1mzzMY2YNpeFCH6Clqcgfv+f13PdMN7986sV6N8fMrGYaMvQBfu+tS5h7fBPfvO+5ejfFzKxmGjb0W5qKvP/0hfx443b2HegbewEzsxxo2NAHuGzFInp6B1j/xAv1boqZWU00dOif+Zq5LJpzHHdseL7eTTEzq4mGDv1CQVy64iR+vmknO33bZTNrAA0d+gCrVpxE/0Bw56Pb6t0UM7Mp1/Chf9qrZ3Paq1s9xGNmDaHhQx/g0hUn8cCzu9jcvb/eTTEzm1IOfeC3Tz8JgHUPu7dvZvnm0AeWzDue9tfO5QcPbfVtGcws1xz6yaozFrFpxz5+9cJL9W6KmdmUcegn7//XCykVxA82bK13U8zMpoxDP5k3cwbnLpvP/97wPAMDHuIxs3waM/QlLZH0U0lPSHpc0sdT+TxJ6yVtSs9zU7kkXSepU9Ijks6sWNfqVH+TpNVTt1lHZtWKRTy/p4cOf4+umeXUeHr6fcAnI2I5cA5wtaTlwDXA3RGxDLg7vQa4CFiWHmuA6yE7SADXAmcDZwHXlg8U08X7li/guKaih3jMLLfGDP2I2BYRD6bpl4CNwCJgFbA2VVsLXJamVwE3R+YeYI6khcAFwPqI6I6IXcB64MLJ3JijNbO5xPuWL+DOR7dxsG+g3s0xM5t0ExrTl7QUOAO4F1gQEeV7F7wALEjTi4DNFYttSWWjlQ9/jzWSOiR1dHV1TaR5k2LVipPYvb+Xn2+q/XubmU21cYe+pFnA94BPRMTeynmRXdw+KWc/I+KGiGiPiPa2trbJWOWEnLusjXkzZ3DzL5+t+XubmU21cYW+pCaywL8lIr6firenYRvS845UvhVYUrH44lQ2Wvm0MqNU4N+eewo/+3UXHc9017s5ZmaTajxX7wi4EdgYEV+smLUOKF+Bsxq4o6L8ynQVzznAnjQMdBewUtLcdAJ3ZSqbdla//bW0tTbzV3c96U/omlmujKen/w7g94HzJG1Ij4uBvwTeJ2kT8N70GuBO4GmgE/g68McAEdENfBa4Pz0+k8qmneNnlPgP572e+37TzXc6ttS7OWZmk0bTuSfb3t4eHR0ddXnv/oHgypvu5YFnd7HuT97JqQta69IOM7OJkvRARLSPNM+fyB1FsSC+9HsrmNVcYvVN9/FU1756N8nM7Kg59A/jxNYWvnHV2fT2D3D5137pE7tmdsxz6I/hjQtnc9vH3kZrS4kPff0evnnvc/VukpnZEXPoj8MpbbO44+p38vbXzefPb3+UT9/+KL39/sSumR17HPrjdMLxTdz0kbfyR+9+Hbfc+xz/7h8epKe3v97NMjObEIf+BBQL4pqLTuOzq97Ejzdu5w/XdrD/YF+9m2VmNm4O/SPw+29byv/44Jv5xVM7ufLG+9jb01vvJpmZjYtD/wh94C2L+Z8fOpMNm3fz4a/fS/fLB+vdJDOzMTn0j8L7T1/IDVe+hSe3v8TvfvVfePA5f/mKmU1vDv2jdN5pC7jlD8+mtz/4wPW/4JO3PcyT/nJ1M5umfBuGSbK3p5cvr9/EN+97lp7eAU57dSuXnL6QS04/iaXzZ9a7eWbWQA53GwaH/iTrfvkg6zZs5YePbBv8rt1/tWg2l5x+EpecvpDFc4+vcwvNLO8c+nXy/O5X+MdHtvHDR57n4S17kOAdr5vP5W9dwsrlC2hpKta7iWaWQw79aeC5F/dz+0Nbua1jM1t3v0JrS4l3ndrGeW84kXe/oY35s5rr3UQzywmH/jQyMBD8y1M7WbfheX76ZBc79x0A4OT5M1mxZA4rlszhjNfM4bRXz2ZGyefZzWziDhf6pVo3ptEVCuLcZW2cu6yNgYHgsef38PNNO9mweTf/r3Mntz+UfYNkU1G8rm0Wy0+azfKF2eONC2czd+aMOm+BmR3LHPp1VCiI0xfP4fTFcwCICLbufoUNm3fz2Na9bNy2l59v2sn3Hxz6KuGFJ7TwxnQQWLZgFgtPOI6T5rSwYHYLTUX/Z2Bmh+fQn0YksXju8SyeezyXnH7SYPnOfQfYuG0vTzyfHQie2LaXn/26i/6BqFgWTmxtZv6sZubNnMHc42cwb2b2mDtzBvOOn8HcmU3MmzmDE45rYlZziZkzShQKqsemmlmdOPSPAfNnNQ8OCZX19PazuXs/z+/pYdvuVwafu18+SPf+gzzXvZ/ulw/yUs/oN4STYNaMErNaSsxqLtHaUmJWSxOtzdnrWS0ljmsq0lwq0NJUpLmpQEspe24uVb8efK6o31QUTYWCDyxm04hD/xjV0lRk2YJWlo3x3b0H+wbYvT87EHS/nD32vtLHvgO97Ovp46UDfezr6WPfgeyx95Vent/9Sjavp5eevoGq/yiOREFQKhZoKih7LopSoUCpKJqKBUoFUSyk6XSgKBVVsUw2v6DsuShRqHwuUFVWLAybr6xO1fxh9YoFhsokJKqfyf4TK6jyOZsWWZ1yfQlEVqdQGFq2vK5Cml+uWxg2D6rfp6DsoFle12C9tB4ov2e2TLaGrCybTjPHUa88zQjlGixXxfTQuuzY4NDPuRmlAifObuHE2S1HvI6+/gF6+gY40NtPT98APb39HOgdoKev+vlAxeue3n56+4Pe/gH6+oPegey5r3+A3oHsOStPZf1B30B2gOntH+Bg3wAvH+wfrNcfwcBA9tw/UDkNA4eUxVDZ9L04LZcOe3AYPPKMfrAZfkBiWPlo9YaOO9UHKKrmVbThkPLK+iMfxEY6IE50nVVrHqPue05t479csnzEthwNh76NqVQsMKtYYFbzsffrEpEFf+WBYPAAMjhNVdlABFGxbER2YKl8DsrzygeW7HlgIFt2IKuUlcXwspGXjcF52ZFq6D2rly2va/CANtjeoW2umFUxHYNl2btGxfTI5YPrG6NeVLRj6H2jYnpYedX6DlNv2HaN1YaIwdZULXvI9Gh1GLv+KJNUXv4+0nrGU7fyxcI5xzEVjr2/YrMJkERR2RfgmJnvsmlm1lDGDH1JN0naIemxirJ5ktZL2pSe56ZySbpOUqekRySdWbHM6lR/k6TVU7M5ZmZ2OOPp6f89cOGwsmuAuyNiGXB3eg1wEbAsPdYA10N2kACuBc4GzgKuLR8ozMysdsYM/Yj4v0D3sOJVwNo0vRa4rKL85sjcA8yRtBC4AFgfEd0RsQtYz6EHEjMzm2JHOqa/ICK2pekXgAVpehGwuaLellQ2WvkhJK2R1CGpo6ur6wibZ2ZmIznqE7mRXXs0aVdDR8QNEdEeEe1tbW1jL2BmZuN2pKG/PQ3bkJ53pPKtwJKKeotT2WjlZmZWQ0ca+uuA8hU4q4E7KsqvTFfxnAPsScNAdwErJc1NJ3BXpjIzM6uhMb9ERdK3gPcA84HtZFfh/AC4DXgN8CxweUR0K/v88FfITtLuBz4aER1pPX8A/Hla7ecj4u/GbJzUldZ/pOYDO49i+anidk2M2zVx07VtbtfEHGm7XhsRI46PT+tvzjpakjpG+/aYenK7Jsbtmrjp2ja3a2Kmol3+RK6ZWQNx6JuZNZC8h/4N9W7AKNyuiXG7Jm66ts3tmphJb1eux/TNzKxa3nv6ZmZWwaFvZtZAchn6ki6U9GS6xfM1Yy8xZe1YIumnkp6Q9Likj6fyv5C0VdKG9Li4Tu17RtKjqQ3lz1OMeNvsGrbpDRX7ZYOkvZI+UY99Nlm3Fa9Ru/67pF+l975d0pxUvlTSKxX77WtT1a7DtG3Un52kT6V99qSkC2rcrm9XtOkZSRtSec322WEyYup+z7KvQsvPAygCTwGnADOAh4HldWrLQuDMNN0K/BpYDvwF8KfTYF89A8wfVvZXwDVp+hrgC3X+Wb4AvLYe+wx4F3Am8NhY+we4GPg/ZF93eg5wb43btRIopekvVLRraWW9Ou2zEX926W/hYaAZODn93RZr1a5h8/8a+K+13meHyYgp+z3LY0//LKAzIp6OiIPArWS3fK65iNgWEQ+m6ZeAjYxyd9FpZLTbZtfD+cBTEXE0n8o+YjE5txWvSbsi4kcR0Zde3kN2f6uaG2WfjWYVcGtEHIiI3wCdZH+/NW1XupPA5cC3puK9D+cwGTFlv2d5DP1x38a5liQtBc4A7k1Ff5L+Pbup1kMoFQL4kaQHJK1JZaPdNrserqD6D3E67LOJ3la8Hv6ArDdYdrKkhyT9TNK5dWrTSD+76bLPzgW2R8SmirKa77NhGTFlv2d5DP1pR9Is4HvAJyJiL9k3ir0OWAFsI/vXsh7eGRFnkn3j2dWS3lU5M7L/J+tyTa+kGcClwHdS0XTZZ4PquX9GI+nTQB9wSyraBrwmIs4A/hPwTUmza9ysafezG+ZDVHcuar7PRsiIQZP9e5bH0J9Wt3GW1ET2w7wlIr4PEBHbI6I/IgaArzNF/9KOJSK2pucdwO2pHaPdNrvWLgIejIjtqY3TYp8x8duK14ykjwCXAB9OQUEaOnkxTT9ANm5+ai3bdZif3XTYZyXgd4Fvl8tqvc9Gygim8Pcsj6F/P7BM0smpt3gF2S2fay6NFd4IbIyIL1aUV47B/Q7w2PBla9C2mZJay9NkJwIfY/TbZtdaVe9rOuyzZKK3Fa8JSRcCfwZcGhH7K8rbJBXT9Clk31/9dK3ald53tJ/dOuAKSc2STk5tu6+WbQPeC/wqIraUC2q5z0bLCKby96wWZ6hr/SA7w/1rsiP0p+vYjneS/Vv2CLAhPS4GvgE8msrXAQvr0LZTyK6ceBh4vLyfgFeRfdn9JuDHwLw6tG0m8CJwQkVZzfcZ2UFnG9BLNnZ61Wj7h+xqiv+VfuceBdpr3K5OsrHe8u/Z11Ldf5N+vhuAB4HfrsM+G/VnB3w67bMngYtq2a5U/vfAHw2rW7N9dpiMmLLfM9+GwcysgeRxeMfMzEbh0DczayAOfTOzBuLQNzNrIA59M7MG4tA3M2sgDn0zswby/wE6XVYwrFzUNQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for l in Loss:\n",
    "    plt.plot(l)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6048bc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d13f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19313697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ac0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2c607f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69239304ad974140bfb031094fbab8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute relative transformations:   0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c868bc02b64995a0fe2bc6cd8628a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute mean embedding:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df21e3c52554e78841d5a4cb48272e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute relative transformations:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adfbd0f5e2049288968e3ea6a04cc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute mean embedding:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7b28e6609c4b4095fcfdd7e8d407d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute relative transformations:   0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39c15bcc1e542969a87d2a44681634e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute mean embedding:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11bc8889e724770831d630b271afdaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute relative transformations:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab28d807426493e8f287b6878da635f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute mean embedding:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f4ff7ff5154075b7a4eb2dd7775f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute relative transformations:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1aa1facd534f91bf8b8769b7da4a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute mean embedding:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f28a064c4443f4a0558353ae3679d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute relative transformations: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5fbda62be4f4bada9de0d0c384c9f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute mean embedding:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OLD_AUC=[]\n",
    "OLD_AP=[]\n",
    "old_emb=[]\n",
    "for p in PATCHES:\n",
    "    prob=l2g.AlignmentProblem(p)\n",
    "    e=prob.get_aligned_embedding()\n",
    "    old_emb.append(e)\n",
    "    auc, ap= full_model_ip.test(torch.tensor(e), test_data.edge_index, neg_edges)\n",
    "    OLD_AUC.append(auc)\n",
    "    OLD_AP.append(ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2886eb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(AUC)), AUC, linestyle='-', marker='o', color='b', label='new')\n",
    "plt.plot(np.arange(len(AUC)), OLD_AUC, linestyle='-', marker='o', color='r', label='old')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ca4feac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(AUC)), AP, linestyle='-', marker='o', color='b', label='new')\n",
    "plt.plot(np.arange(len(AUC)), OLD_AP, linestyle='-', marker='o', color='r', label='old')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d39a466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import procrustes\n",
    "ERR=[]\n",
    "for i in range(len(dimensions)):\n",
    "    _, _, error = procrustes(new_emb[i], old_emb[i])\n",
    "    ERR.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a264b4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd556ac6770>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(AUC)), ERR, linestyle='-', marker='o', color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a4dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
